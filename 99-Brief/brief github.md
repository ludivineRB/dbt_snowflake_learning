# ğŸ™ Brief Pratique GitHub - Data Engineering

**DurÃ©e estimÃ©e :** 6 heures
**Niveau :** IntermÃ©diaire
**ModalitÃ© :** Pratique individuelle

---

## ğŸ¯ Objectifs du Brief

Ã€ l'issue de ce brief, vous serez capable de :
- MaÃ®triser les Pull Requests et le code review
- GÃ©rer les Issues et Projects pour organiser le travail
- Mettre en place des workflows CI/CD avec GitHub Actions
- Utiliser les fonctionnalitÃ©s de sÃ©curitÃ© de GitHub
- Collaborer efficacement sur des projets Data Engineering
- Automatiser les tests et dÃ©ploiements

---

## ğŸ“‹ Contexte

Vous Ãªtes Data Engineer chez **CloudData Analytics**. L'Ã©quipe a migrÃ© le code sur GitHub, mais utilise encore peu les fonctionnalitÃ©s avancÃ©es de la plateforme. Votre mission est de mettre en place un workflow professionnel utilisant l'Ã©cosystÃ¨me complet de GitHub.

---

## ğŸš€ Partie 1 : Configuration et premiers pas (1h)

### TÃ¢che 1.1 : Configurer votre profil GitHub

CrÃ©ez ou amÃ©liorez votre profil GitHub professionnel :

**Instructions :**
1. Allez sur [github.com](https://github.com)
2. AccÃ©dez Ã  votre profil (Settings)
3. Configurez :
   - Photo de profil professionnelle
   - Nom complet
   - Bio (ex: "Data Engineer | Python, SQL, Airflow | Data Pipelines")
   - Localisation
   - Site web ou LinkedIn

**CritÃ¨res de validation :**
- âœ… Profil complÃ©tÃ© avec toutes les informations
- âœ… Bio professionnelle

---

### TÃ¢che 1.2 : Configurer l'authentification SSH

**Instructions :**

1. **GÃ©nÃ©rer une clÃ© SSH :**
```bash
# GÃ©nÃ©rer une clÃ© SSH
ssh-keygen -t ed25519 -C "votre.email@example.com"

# DÃ©marrer l'agent SSH
eval "$(ssh-agent -s)"

# Ajouter la clÃ© Ã  l'agent
ssh-add ~/.ssh/id_ed25519

# Afficher la clÃ© publique
cat ~/.ssh/id_ed25519.pub
```

2. **Ajouter la clÃ© Ã  GitHub :**
- Allez dans **Settings** â†’ **SSH and GPG keys**
- Cliquez sur **New SSH key**
- Collez votre clÃ© publique
- Donnez un titre (ex: "MacBook Pro")

3. **Tester la connexion :**
```bash
ssh -T git@github.com
# RÃ©sultat attendu : "Hi username! You've successfully authenticated..."
```

**CritÃ¨res de validation :**
- âœ… ClÃ© SSH configurÃ©e
- âœ… Connexion SSH fonctionnelle

---

### TÃ¢che 1.3 : CrÃ©er votre repository de travail

CrÃ©ez un nouveau repository pour ce brief :

**Instructions :**
1. Cliquez sur le bouton **+** â†’ **New repository**
2. Nom : `github-data-pipeline-advanced`
3. Description : "Advanced GitHub features for Data Engineering"
4. Public
5. âœ… Cochez "Add a README file"
6. âœ… Ajoutez un .gitignore (Python)
7. âœ… Choisissez une License (MIT)
8. Cliquez sur **Create repository**

**CritÃ¨res de validation :**
- âœ… Repository crÃ©Ã© sur GitHub
- âœ… README, .gitignore et LICENSE prÃ©sents

---

### TÃ¢che 1.4 : Cloner et setup local

```bash
# Cloner avec SSH
git clone git@github.com:votre-username/github-data-pipeline-advanced.git

# Entrer dans le dossier
cd github-data-pipeline-advanced

# CrÃ©er la structure du projet
mkdir -p src tests data .github/workflows

# CrÃ©er des fichiers
touch src/__init__.py src/pipeline.py tests/test_pipeline.py
touch requirements.txt
```

**CrÃ©er le fichier requirements.txt :**
```
pandas==2.1.0
pytest==7.4.0
pytest-cov==4.1.0
sqlalchemy==2.0.20
psycopg2-binary==2.9.7
python-dotenv==1.0.0
```

**CrÃ©er src/pipeline.py :**
```python
"""
Data Pipeline for ETL operations
"""
import pandas as pd
from typing import Dict, List
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def extract_data(source_path: str) -> pd.DataFrame:
    """Extract data from CSV file"""
    logger.info(f"Extracting data from {source_path}")
    df = pd.read_csv(source_path)
    logger.info(f"Extracted {len(df)} rows")
    return df


def transform_data(df: pd.DataFrame) -> pd.DataFrame:
    """Transform data"""
    logger.info("Transforming data")
    # Remove duplicates
    df = df.drop_duplicates()
    # Remove null values
    df = df.dropna()
    logger.info(f"Transformed to {len(df)} rows")
    return df


def load_data(df: pd.DataFrame, destination: str) -> bool:
    """Load data to destination"""
    logger.info(f"Loading {len(df)} rows to {destination}")
    df.to_csv(destination, index=False)
    logger.info("Load completed")
    return True


def run_pipeline(source: str, destination: str) -> None:
    """Run the complete ETL pipeline"""
    logger.info("Starting pipeline")
    df = extract_data(source)
    df = transform_data(df)
    load_data(df, destination)
    logger.info("Pipeline completed successfully")


if __name__ == "__main__":
    # Test pipeline
    pass
```

**CrÃ©er tests/test_pipeline.py :**
```python
"""
Tests for pipeline module
"""
import pytest
import pandas as pd
from src.pipeline import extract_data, transform_data, load_data


def test_transform_data():
    """Test data transformation"""
    # Create test data with duplicates and nulls
    df = pd.DataFrame({
        'id': [1, 2, 2, 3, 4],
        'value': [10, 20, 20, None, 40]
    })

    result = transform_data(df)

    # Should remove duplicates and nulls
    assert len(result) == 3
    assert result['value'].isnull().sum() == 0


def test_extract_data_invalid_path():
    """Test extraction with invalid path"""
    with pytest.raises(FileNotFoundError):
        extract_data("nonexistent.csv")
```

**Committer et pousser :**
```bash
git add .
git commit -m "Initial setup: project structure and pipeline code"
git push origin main
```

**CritÃ¨res de validation :**
- âœ… Structure de projet crÃ©Ã©e
- âœ… Code et tests prÃ©sents
- âœ… PoussÃ© sur GitHub

---

## ğŸ« Partie 2 : Issues et gestion de projet (1h30)

### TÃ¢che 2.1 : CrÃ©er des Issues

**ScÃ©nario :** Vous devez planifier 5 amÃ©liorations pour votre pipeline.

**Instructions :**

CrÃ©ez 5 issues sur GitHub avec les titres et descriptions suivants :

**Issue 1 : Bug - Pipeline fails with empty CSV**
```markdown
## Description
Le pipeline crash lorsqu'un fichier CSV est vide.

## Steps to reproduce
1. CrÃ©er un fichier CSV vide
2. ExÃ©cuter `run_pipeline('empty.csv', 'output.csv')`
3. Observer l'erreur

## Expected behavior
Le pipeline devrait gÃ©rer les fichiers vides gracieusement.

## Environment
- Python 3.11
- pandas 2.1.0
```

**Labels :** `bug`, `priority: high`

---

**Issue 2 : Feature - Add data validation**
```markdown
## Description
Ajouter un module de validation des donnÃ©es avant la transformation.

## Requirements
- VÃ©rifier le schÃ©ma (colonnes attendues)
- VÃ©rifier les types de donnÃ©es
- DÃ©tecter les anomalies

## Acceptance criteria
- [ ] Module de validation crÃ©Ã©
- [ ] Tests unitaires ajoutÃ©s
- [ ] Documentation mise Ã  jour
```

**Labels :** `enhancement`, `good first issue`

---

**Issue 3 : Feature - Implement logging to file**
```markdown
## Description
Les logs doivent Ãªtre sauvegardÃ©s dans un fichier en plus de la console.

## Proposed solution
- Utiliser `logging.FileHandler`
- Format JSON pour faciliter l'analyse
- Rotation des logs par taille ou date
```

**Labels :** `enhancement`

---

**Issue 4 : Feature - Add CI/CD with GitHub Actions**
```markdown
## Description
Mettre en place CI/CD pour :
- ExÃ©cuter les tests automatiquement sur chaque PR
- VÃ©rifier le code style (black, flake8)
- GÃ©nÃ©rer un rapport de couverture

## Tasks
- [ ] CrÃ©er workflow de tests
- [ ] Configurer linting
- [ ] IntÃ©grer codecov
```

**Labels :** `enhancement`, `devops`

---

**Issue 5 : Documentation - Add usage examples**
```markdown
## Description
Le README manque d'exemples d'utilisation concrets.

## To add
- Quick start
- Usage examples
- API reference
- Contribution guide
```

**Labels :** `documentation`

**CritÃ¨res de validation :**
- âœ… 5 issues crÃ©Ã©es
- âœ… Descriptions complÃ¨tes
- âœ… Labels appropriÃ©s

---

### TÃ¢che 2.2 : CrÃ©er un GitHub Project

**Instructions :**
1. Allez dans l'onglet **Projects**
2. Cliquez sur **New project**
3. Choisissez le template **Board**
4. Nom : "Data Pipeline Development"
5. CrÃ©ez les colonnes :
   - ğŸ“‹ Backlog
   - ğŸ“ To Do
   - ğŸ”„ In Progress
   - ğŸ‘€ Review
   - âœ… Done

6. **Ajoutez vos 5 issues au projet :**
   - Issues #2, #3, #5 â†’ Backlog
   - Issue #1 â†’ To Do (prioritÃ© haute)
   - Issue #4 â†’ To Do

**CritÃ¨res de validation :**
- âœ… Project crÃ©Ã© avec colonnes Kanban
- âœ… Issues organisÃ©es dans les colonnes

---

### TÃ¢che 2.3 : CrÃ©er un Milestone

**Instructions :**
1. Allez dans **Issues** â†’ **Milestones**
2. Cliquez sur **New milestone**
3. Titre : `v1.0.0 - Production Ready`
4. Date : Dans 2 semaines
5. Description : "PremiÃ¨re version stable avec validation, logging et CI/CD"

6. **Associez les issues au milestone :**
   - Issues #1, #2, #3, #4 â†’ Milestone v1.0.0

**CritÃ¨res de validation :**
- âœ… Milestone crÃ©Ã© avec date cible
- âœ… Issues liÃ©es au milestone

---

## ğŸ”€ Partie 3 : Pull Requests et Code Review (2h)

### TÃ¢che 3.1 : RÃ©soudre l'Issue #1 (Bug)

**Instructions :**

1. **CrÃ©er une branche :**
```bash
git checkout main
git pull origin main
git checkout -b fix/empty-csv-handling
```

2. **Modifier src/pipeline.py :**

Ajoutez au dÃ©but de la fonction `extract_data` :
```python
def extract_data(source_path: str) -> pd.DataFrame:
    """Extract data from CSV file"""
    logger.info(f"Extracting data from {source_path}")
    df = pd.read_csv(source_path)

    # Handle empty CSV
    if df.empty:
        logger.warning("Empty CSV file detected")
        raise ValueError("CSV file is empty")

    logger.info(f"Extracted {len(df)} rows")
    return df
```

3. **Ajouter un test dans tests/test_pipeline.py :**
```python
def test_extract_empty_csv(tmp_path):
    """Test extraction with empty CSV"""
    # Create empty CSV
    empty_csv = tmp_path / "empty.csv"
    empty_csv.write_text("col1,col2\n")

    with pytest.raises(ValueError, match="CSV file is empty"):
        extract_data(str(empty_csv))
```

4. **Committer et pousser :**
```bash
git add .
git commit -m "fix: handle empty CSV files gracefully

- Add validation for empty DataFrames
- Raise ValueError with clear message
- Add test for empty CSV handling

Closes #1"

git push -u origin fix/empty-csv-handling
```

5. **CrÃ©er une Pull Request :**
   - Allez sur GitHub
   - Cliquez sur "Compare & pull request"
   - Titre : `Fix: Handle empty CSV files`
   - Description :

```markdown
## ğŸ› Bug Fix

RÃ©sout le problÃ¨me du pipeline qui crashait avec des fichiers CSV vides.

## ğŸ“ Changements
- Ajout d'une validation dans `extract_data()`
- Le pipeline raise maintenant une `ValueError` explicite
- Test unitaire ajoutÃ© pour vÃ©rifier le comportement

## âœ… Tests
- [x] Tests unitaires passent
- [x] TestÃ© avec un CSV vide
- [x] Pas de rÃ©gression

## ğŸ”— Liens
Closes #1

## ğŸ“¸ Screenshot des tests
```
# (Ajoutez un screenshot de pytest passant)
```

---

**NE MERGEZ PAS ENCORE !**

**CritÃ¨res de validation :**
- âœ… Branche crÃ©Ã©e et poussÃ©e
- âœ… PR crÃ©Ã©e avec description complÃ¨te
- âœ… Issue #1 liÃ©e avec "Closes #1"

---

### TÃ¢che 3.2 : Faire un Code Review

**Instructions :**

Maintenant, jouez le rÃ´le du reviewer sur votre propre PR :

1. **Allez dans l'onglet "Files changed"**
2. **Ajoutez des commentaires :**
   - Cliquez sur une ligne de code
   - Ajoutez un commentaire constructif

**Exemples de commentaires Ã  ajouter :**

Sur la ligne `raise ValueError("CSV file is empty")` :
```
ğŸ’¡ Suggestion : Peut-Ãªtre ajouter le nom du fichier dans le message d'erreur pour faciliter le debug ?

Exemple :
`raise ValueError(f"CSV file is empty: {source_path}")`
```

Sur le test :
```
âœ… Bon test ! Couvre bien le cas limite.

Question : Devrait-on aussi tester le cas oÃ¹ le CSV a seulement des headers mais aucune ligne de donnÃ©es ?
```

3. **Ajoutez un commentaire gÃ©nÃ©ral :**
   - Allez en haut de "Files changed"
   - Cliquez sur "Review changes"
   - Choisissez "Comment"
   - Ã‰crivez :
```markdown
Bonne correction ! Le code est clair et bien testÃ©.

Points positifs :
- âœ… Message d'erreur explicite
- âœ… Test unitaire complet
- âœ… Logging appropriÃ©

Suggestions :
- Inclure le nom du fichier dans le message d'erreur
- ConsidÃ©rer le cas CSV avec headers seulement
```

**CritÃ¨res de validation :**
- âœ… Au moins 2 commentaires inline ajoutÃ©s
- âœ… Review gÃ©nÃ©rale soumise

---

### TÃ¢che 3.3 : IntÃ©grer les feedbacks et merger

**Instructions :**

1. **IntÃ©grer les suggestions :**
```bash
# Modifier src/pipeline.py
# Changer le message d'erreur :
raise ValueError(f"CSV file is empty: {source_path}")

# Ajouter un nouveau test
def test_extract_csv_with_only_headers(tmp_path):
    """Test CSV with only headers"""
    csv_file = tmp_path / "headers_only.csv"
    csv_file.write_text("col1,col2\n")

    with pytest.raises(ValueError):
        extract_data(str(csv_file))

# Committer
git add .
git commit -m "fix: improve error message and add test for headers-only CSV"
git push
```

2. **Approuver et merger la PR :**
   - Retournez sur la PR
   - Cliquez sur "Merge pull request"
   - Choisissez "Squash and merge"
   - Confirmez le merge

3. **Nettoyer localement :**
```bash
git checkout main
git pull origin main
git branch -d fix/empty-csv-handling
```

4. **VÃ©rifier que l'issue #1 est fermÃ©e automatiquement**

**CritÃ¨res de validation :**
- âœ… Feedbacks intÃ©grÃ©s
- âœ… PR mergÃ©e
- âœ… Issue #1 automatiquement fermÃ©e
- âœ… Branche locale supprimÃ©e

---

### TÃ¢che 3.4 : CrÃ©er une PR pour l'Issue #2 (Data Validation)

**Instructions :**

1. **CrÃ©er une branche :**
```bash
git checkout -b feature/data-validation
```

2. **CrÃ©er src/validation.py :**
```python
"""
Data validation module
"""
import pandas as pd
from typing import List, Dict, Any
import logging

logger = logging.getLogger(__name__)


def validate_schema(df: pd.DataFrame, expected_columns: List[str]) -> bool:
    """
    Validate that DataFrame has expected columns

    Args:
        df: DataFrame to validate
        expected_columns: List of expected column names

    Returns:
        True if schema is valid

    Raises:
        ValueError: If required columns are missing
    """
    missing_cols = set(expected_columns) - set(df.columns)
    if missing_cols:
        raise ValueError(f"Missing required columns: {missing_cols}")

    logger.info(f"âœ… Schema validation passed: {len(expected_columns)} columns")
    return True


def validate_data_types(df: pd.DataFrame, type_mapping: Dict[str, str]) -> bool:
    """
    Validate data types of columns

    Args:
        df: DataFrame to validate
        type_mapping: Dict mapping column names to expected types

    Returns:
        True if types are valid

    Raises:
        TypeError: If column types don't match
    """
    for col, expected_type in type_mapping.items():
        if col not in df.columns:
            continue

        actual_type = str(df[col].dtype)
        if not actual_type.startswith(expected_type):
            raise TypeError(
                f"Column '{col}' has type '{actual_type}', expected '{expected_type}'"
            )

    logger.info(f"âœ… Type validation passed: {len(type_mapping)} columns")
    return True


def detect_anomalies(df: pd.DataFrame) -> Dict[str, Any]:
    """
    Detect data quality issues

    Returns:
        Dict with anomaly information
    """
    anomalies = {}

    # Check for null values
    null_counts = df.isnull().sum()
    if null_counts.any():
        anomalies['null_values'] = null_counts[null_counts > 0].to_dict()

    # Check for duplicates
    dup_count = df.duplicated().sum()
    if dup_count > 0:
        anomalies['duplicate_rows'] = int(dup_count)

    # Check for empty strings in object columns
    for col in df.select_dtypes(include=['object']).columns:
        empty_count = (df[col] == '').sum()
        if empty_count > 0:
            if 'empty_strings' not in anomalies:
                anomalies['empty_strings'] = {}
            anomalies['empty_strings'][col] = int(empty_count)

    if anomalies:
        logger.warning(f"âš ï¸ Anomalies detected: {anomalies}")
    else:
        logger.info("âœ… No anomalies detected")

    return anomalies


if __name__ == "__main__":
    # Example usage
    df = pd.DataFrame({
        'id': [1, 2, 3],
        'name': ['Alice', 'Bob', 'Charlie'],
        'age': [25, 30, 35]
    })

    validate_schema(df, ['id', 'name', 'age'])
    validate_data_types(df, {'id': 'int', 'name': 'object', 'age': 'int'})
    anomalies = detect_anomalies(df)
    print(f"Anomalies: {anomalies}")
```

3. **CrÃ©er tests/test_validation.py :**
```python
"""
Tests for validation module
"""
import pytest
import pandas as pd
from src.validation import validate_schema, validate_data_types, detect_anomalies


def test_validate_schema_success():
    """Test successful schema validation"""
    df = pd.DataFrame({'a': [1, 2], 'b': [3, 4]})
    assert validate_schema(df, ['a', 'b']) == True


def test_validate_schema_missing_columns():
    """Test schema validation with missing columns"""
    df = pd.DataFrame({'a': [1, 2]})

    with pytest.raises(ValueError, match="Missing required columns"):
        validate_schema(df, ['a', 'b', 'c'])


def test_validate_data_types_success():
    """Test successful type validation"""
    df = pd.DataFrame({'id': [1, 2], 'name': ['Alice', 'Bob']})

    assert validate_data_types(df, {'id': 'int', 'name': 'object'}) == True


def test_validate_data_types_mismatch():
    """Test type validation with mismatch"""
    df = pd.DataFrame({'id': ['a', 'b']})

    with pytest.raises(TypeError, match="has type"):
        validate_data_types(df, {'id': 'int'})


def test_detect_anomalies_nulls():
    """Test anomaly detection with null values"""
    df = pd.DataFrame({'a': [1, None, 3], 'b': [4, 5, None]})

    anomalies = detect_anomalies(df)

    assert 'null_values' in anomalies
    assert anomalies['null_values']['a'] == 1
    assert anomalies['null_values']['b'] == 1


def test_detect_anomalies_duplicates():
    """Test anomaly detection with duplicates"""
    df = pd.DataFrame({'a': [1, 2, 1], 'b': [3, 4, 3]})

    anomalies = detect_anomalies(df)

    assert 'duplicate_rows' in anomalies
    assert anomalies['duplicate_rows'] == 1


def test_detect_anomalies_empty_strings():
    """Test anomaly detection with empty strings"""
    df = pd.DataFrame({'name': ['Alice', '', 'Bob']})

    anomalies = detect_anomalies(df)

    assert 'empty_strings' in anomalies
    assert anomalies['empty_strings']['name'] == 1
```

4. **Mettre Ã  jour README.md :**

Ajoutez une section :
```markdown
## Features

### Data Validation

Le module de validation permet de vÃ©rifier la qualitÃ© des donnÃ©es :

```python
from src.validation import validate_schema, validate_data_types, detect_anomalies

# Valider le schÃ©ma
validate_schema(df, ['id', 'name', 'age'])

# Valider les types
validate_data_types(df, {'id': 'int', 'name': 'object'})

# DÃ©tecter les anomalies
anomalies = detect_anomalies(df)
\```
```

5. **Committer et pousser :**
```bash
git add .
git commit -m "feat: add comprehensive data validation module

- Schema validation with clear error messages
- Data type validation
- Anomaly detection (nulls, duplicates, empty strings)
- Full test coverage
- Documentation updated

Closes #2"

git push -u origin feature/data-validation
```

6. **CrÃ©er la Pull Request avec un template complet :**
```markdown
## ğŸ¯ Feature: Data Validation Module

ImplÃ©mentation d'un module de validation complet pour assurer la qualitÃ© des donnÃ©es.

## ğŸ“ Changements

### Nouveau fichier : `src/validation.py`
- `validate_schema()` : VÃ©rifie que les colonnes attendues sont prÃ©sentes
- `validate_data_types()` : Valide les types de donnÃ©es
- `detect_anomalies()` : DÃ©tecte les problÃ¨mes de qualitÃ© (nulls, duplicates, empty strings)

### Tests : `tests/test_validation.py`
- 7 tests unitaires couvrant tous les cas
- Couverture Ã  100% du module

### Documentation
- README mis Ã  jour avec exemples d'utilisation

## âœ… Checklist

- [x] Code implÃ©mentÃ©
- [x] Tests unitaires ajoutÃ©s (7 tests)
- [x] Tests passent localement
- [x] Documentation mise Ã  jour
- [x] Pas de rÃ©gression

## ğŸ”— Liens

Closes #2

## âš ï¸ Points d'attention pour reviewers

- VÃ©rifier que les messages d'erreur sont clairs
- SuggÃ©rer d'autres types d'anomalies Ã  dÃ©tecter
- VÃ©rifier la gestion des edge cases

## ğŸ“Š Coverage

Tests coverage: 100% du module validation
```

**NE MERGEZ PAS ENCORE - Passez Ã  la tÃ¢che suivante**

**CritÃ¨res de validation :**
- âœ… Module de validation complet crÃ©Ã©
- âœ… Tests unitaires complets
- âœ… PR crÃ©Ã©e avec description dÃ©taillÃ©e
- âœ… Issue #2 liÃ©e

---

## âš™ï¸ Partie 4 : GitHub Actions - CI/CD (1h30)

### TÃ¢che 4.1 : CrÃ©er un workflow de tests

**Instructions :**

1. **CrÃ©er le fichier `.github/workflows/tests.yml` :**
```yaml
name: Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov
        pip install -r requirements.txt

    - name: Run tests with coverage
      run: |
        pytest tests/ --cov=src --cov-report=xml --cov-report=term

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage.xml
        fail_ci_if_error: false
```

2. **CrÃ©er le fichier `.github/workflows/lint.yml` :**
```yaml
name: Code Quality

on:
  pull_request:
    branches: [ main ]

jobs:
  lint:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install linters
      run: |
        pip install black flake8 mypy

    - name: Check code formatting with Black
      run: |
        black --check src/ tests/ || echo "âš ï¸ Code needs formatting"

    - name: Lint with Flake8
      run: |
        flake8 src/ tests/ --max-line-length=100 --extend-ignore=E203,W503

    - name: Type check with MyPy
      run: |
        mypy src/ --ignore-missing-imports || echo "âš ï¸ Type hints need improvement"
```

3. **Ajouter Ã  votre branche actuelle (feature/data-validation) :**
```bash
git add .github/
git commit -m "ci: add GitHub Actions workflows for tests and linting"
git push
```

4. **VÃ©rifier que les workflows s'exÃ©cutent :**
   - Allez sur votre PR
   - VÃ©rifiez l'onglet "Checks"
   - Les workflows devraient s'exÃ©cuter automatiquement

**CritÃ¨res de validation :**
- âœ… Fichiers workflows crÃ©Ã©s
- âœ… Workflows s'exÃ©cutent sur la PR
- âœ… Tests passent

---

### TÃ¢che 4.2 : ProtÃ©ger la branche main

**Instructions :**

1. Allez dans **Settings** â†’ **Branches**
2. Cliquez sur **Add branch protection rule**
3. Branch name pattern : `main`
4. Configurez :
   - âœ… **Require a pull request before merging**
     - Require approvals : 1
     - âœ… Dismiss stale reviews
   - âœ… **Require status checks to pass before merging**
     - Ajoutez les checks : "test", "lint"
     - âœ… Require branches to be up to date
   - âœ… **Require conversation resolution before merging**
5. Cliquez sur **Create**

**CritÃ¨res de validation :**
- âœ… Branch protection activÃ©e
- âœ… Impossible de push directement sur main

---

### TÃ¢che 4.3 : Merger la PR avec les CI checks

**Instructions :**

1. Retournez sur votre PR `feature/data-validation`
2. VÃ©rifiez que tous les checks sont verts âœ…
3. Si des checks Ã©chouent, corrigez :
```bash
# Formater le code
black src/ tests/

# Commit et push
git add .
git commit -m "style: format code with black"
git push
```

4. Une fois tous les checks verts :
   - Cliquez sur "Merge pull request"
   - Choisissez "Squash and merge"
   - Confirmez

5. **Nettoyage :**
```bash
git checkout main
git pull origin main
git branch -d feature/data-validation
```

6. **DÃ©placer les issues dans GitHub Project :**
   - Issue #1 â†’ Done
   - Issue #2 â†’ Done

**CritÃ¨res de validation :**
- âœ… Tous les CI checks passent
- âœ… PR mergÃ©e avec succÃ¨s
- âœ… Issues fermÃ©es automatiquement
- âœ… Project mis Ã  jour

---

## ğŸ”’ Partie 5 : SÃ©curitÃ© et bonnes pratiques (1h)

### TÃ¢che 5.1 : Activer Dependabot

**Instructions :**

1. **Allez dans Settings â†’ Code security and analysis**
2. **Activez :**
   - âœ… Dependabot alerts
   - âœ… Dependabot security updates

3. **CrÃ©er `.github/dependabot.yml` :**
```yaml
version: 2
updates:
  # Python dependencies
  - package-ecosystem: "pip"
    directory: "/"
    schedule:
      interval: "weekly"
    open-pull-requests-limit: 5
    reviewers:
      - "votre-username"
    labels:
      - "dependencies"
      - "python"

  # GitHub Actions
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"
    labels:
      - "dependencies"
      - "github-actions"
```

4. **Committer :**
```bash
git checkout -b config/dependabot
git add .github/dependabot.yml
git commit -m "chore: configure Dependabot for automated dependency updates"
git push -u origin config/dependabot
```

5. **CrÃ©er une PR et merger rapidement**

**CritÃ¨res de validation :**
- âœ… Dependabot activÃ©
- âœ… Configuration commitÃ©e

---

### TÃ¢che 5.2 : Ajouter des secrets

**Instructions :**

1. **Allez dans Settings â†’ Secrets and variables â†’ Actions**
2. **Cliquez sur New repository secret**
3. **CrÃ©ez les secrets suivants :**
   - Nom : `DATABASE_URL`
   - Value : `postgresql://user:password@localhost:5432/mydb`

   - Nom : `API_KEY`
   - Value : `test-api-key-12345`

4. **CrÃ©er un workflow de dÃ©ploiement `.github/workflows/deploy.yml` :**
```yaml
name: Deploy to Production

on:
  push:
    tags:
      - 'v*'

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        pip install -r requirements.txt

    - name: Run deployment tests
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}
        API_KEY: ${{ secrets.API_KEY }}
      run: |
        echo "Running deployment tests..."
        pytest tests/ -v

    - name: Deploy notification
      run: |
        echo "âœ… Deployment successful for ${{ github.ref_name }}"
```

5. **Committer :**
```bash
git checkout main
git pull
git checkout -b feat/deployment-workflow
git add .github/workflows/deploy.yml
git commit -m "feat: add deployment workflow with secrets"
git push -u origin feat/deployment-workflow
```

6. **CrÃ©er une PR et merger**

**CritÃ¨res de validation :**
- âœ… Secrets configurÃ©s
- âœ… Workflow de dÃ©ploiement crÃ©Ã©

---

### TÃ¢che 5.3 : CrÃ©er une release avec tag

**Instructions :**

1. **CrÃ©er un tag :**
```bash
git checkout main
git pull origin main

# CrÃ©er un tag annotÃ©
git tag -a v1.0.0 -m "Release v1.0.0 - Production Ready

Features:
- Complete ETL pipeline
- Data validation module
- CI/CD with GitHub Actions
- Comprehensive test suite"

# Pousser le tag
git push origin v1.0.0
```

2. **CrÃ©er une Release sur GitHub :**
   - Allez dans l'onglet **Releases**
   - Cliquez sur **Draft a new release**
   - Choisissez le tag `v1.0.0`
   - Titre : `v1.0.0 - Production Ready`
   - Description :

```markdown
## ğŸ‰ First Production Release

Cette version marque la premiÃ¨re release stable du pipeline de donnÃ©es.

## âœ¨ Features

- âœ… ETL Pipeline complet (extract, transform, load)
- âœ… Module de validation des donnÃ©es
- âœ… Gestion des erreurs robuste
- âœ… CI/CD automatisÃ© avec GitHub Actions
- âœ… Tests unitaires avec 90%+ coverage
- âœ… Linting et formatage automatique

## ğŸ“¦ Installation

\```bash
pip install -r requirements.txt
\```

## ğŸš€ Usage

\```python
from src.pipeline import run_pipeline

run_pipeline('input.csv', 'output.csv')
\```

## ğŸ› Bug Fixes

- Fixed: Pipeline now handles empty CSV files (#1)

## ğŸ™ Contributors

- @votre-username

## ğŸ“Š Stats

- 5 Issues closed
- 4 Pull Requests merged
- 15 commits
- 200+ lines of code
```

3. **Cliquez sur "Publish release"**

4. **VÃ©rifier que le workflow deploy.yml s'exÃ©cute**

**CritÃ¨res de validation :**
- âœ… Tag crÃ©Ã© et poussÃ©
- âœ… Release publiÃ©e sur GitHub
- âœ… Workflow de dÃ©ploiement dÃ©clenchÃ©

---

## ğŸ“š Partie 6 : Documentation et finitions (30 min)

### TÃ¢che 6.1 : AmÃ©liorer le README

**Instructions :**

Mettez Ã  jour votre README.md avec un template complet :

```markdown
# ğŸ“Š GitHub Data Pipeline Advanced

![Tests](https://github.com/votre-username/github-data-pipeline-advanced/workflows/Tests/badge.svg)
![Code Quality](https://github.com/votre-username/github-data-pipeline-advanced/workflows/Code%20Quality/badge.svg)
![Python Version](https://img.shields.io/badge/python-3.9%2B-blue)
![License](https://img.shields.io/badge/license-MIT-green)

Pipeline ETL avancÃ© pour Data Engineering avec fonctionnalitÃ©s GitHub complÃ¨tes.

## ğŸ¯ Features

- âœ… Pipeline ETL complet (Extract, Transform, Load)
- âœ… Module de validation des donnÃ©es
- âœ… Gestion robuste des erreurs
- âœ… CI/CD avec GitHub Actions
- âœ… Tests automatisÃ©s avec 90%+ coverage
- âœ… Code quality checks (Black, Flake8, MyPy)

## ğŸš€ Quick Start

\```bash
# Cloner le projet
git clone git@github.com:votre-username/github-data-pipeline-advanced.git
cd github-data-pipeline-advanced

# Installer les dÃ©pendances
pip install -r requirements.txt

# Lancer le pipeline
python -m src.pipeline
\```

## ğŸ“¦ Installation

\```bash
pip install -r requirements.txt
\```

## ğŸ”§ Usage

### Pipeline de base

\```python
from src.pipeline import run_pipeline

# ExÃ©cuter le pipeline complet
run_pipeline('input.csv', 'output.csv')
\```

### Validation des donnÃ©es

\```python
from src.validation import validate_schema, detect_anomalies
import pandas as pd

df = pd.read_csv('data.csv')

# Valider le schÃ©ma
validate_schema(df, ['id', 'name', 'value'])

# DÃ©tecter les anomalies
anomalies = detect_anomalies(df)
print(f"Anomalies trouvÃ©es: {anomalies}")
\```

## ğŸ—ï¸ Architecture

\```
github-data-pipeline-advanced/
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ workflows/
â”‚   â”‚   â”œâ”€â”€ tests.yml          # Tests automatisÃ©s
â”‚   â”‚   â”œâ”€â”€ lint.yml           # Code quality
â”‚   â”‚   â””â”€â”€ deploy.yml         # DÃ©ploiement
â”‚   â””â”€â”€ dependabot.yml         # Mises Ã  jour auto
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pipeline.py            # Pipeline ETL principal
â”‚   â””â”€â”€ validation.py          # Validation des donnÃ©es
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_pipeline.py
â”‚   â””â”€â”€ test_validation.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
\```

## ğŸ§ª Tests

\```bash
# Lancer tous les tests
pytest tests/

# Avec coverage
pytest tests/ --cov=src --cov-report=html

# Ouvrir le rapport
open htmlcov/index.html
\```

## ğŸ¨ Code Quality

\```bash
# Formater le code
black src/ tests/

# Linting
flake8 src/ tests/ --max-line-length=100

# Type checking
mypy src/
\```

## ğŸš€ CI/CD

Le projet utilise GitHub Actions pour :
- âœ… Tests automatiques sur Python 3.9, 3.10, 3.11
- âœ… VÃ©rification du code style
- âœ… Type checking
- âœ… DÃ©ploiement sur tag

## ğŸ¤ Contributing

Les contributions sont les bienvenues !

1. Fork le projet
2. CrÃ©ez une branche feature (`git checkout -b feature/amazing-feature`)
3. Commit vos changements (`git commit -m 'feat: add amazing feature'`)
4. Push vers la branche (`git push origin feature/amazing-feature`)
5. Ouvrez une Pull Request

Voir [CONTRIBUTING.md](CONTRIBUTING.md) pour plus de dÃ©tails.

## ğŸ“„ License

Ce projet est sous license MIT - voir [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ‘¥ Authors

- [@votre-username](https://github.com/votre-username) - Initial work

## ğŸ™ Acknowledgments

- InspirÃ© par les best practices Data Engineering
- GitHub Actions documentation
- Python testing best practices

## ğŸ“ Contact

Pour toute question : votre.email@example.com

---

â­ Si ce projet vous a Ã©tÃ© utile, n'hÃ©sitez pas Ã  lui donner une Ã©toile !
```

**Committer :**
```bash
git checkout main
git pull
git checkout -b docs/improve-readme
git add README.md
git commit -m "docs: comprehensive README with badges and examples"
git push -u origin docs/improve-readme
```

**CrÃ©er une PR et merger**

**CritÃ¨res de validation :**
- âœ… README complet avec badges
- âœ… Documentation claire
- âœ… Exemples d'utilisation

---

### TÃ¢che 6.2 : CrÃ©er un CONTRIBUTING.md

CrÃ©ez un fichier `CONTRIBUTING.md` :

```markdown
# Contributing to GitHub Data Pipeline Advanced

Merci de votre intÃ©rÃªt pour contribuer Ã  ce projet ! ğŸ‰

## ğŸš€ Comment contribuer

### Signaler un bug

1. VÃ©rifiez que le bug n'a pas dÃ©jÃ  Ã©tÃ© signalÃ© dans les [Issues](../../issues)
2. CrÃ©ez une nouvelle issue avec le template "Bug Report"
3. DÃ©crivez le bug de maniÃ¨re dÃ©taillÃ©e
4. Incluez les steps to reproduce
5. Mentionnez votre environnement (OS, Python version, etc.)

### Proposer une feature

1. CrÃ©ez une issue avec le template "Feature Request"
2. DÃ©crivez la fonctionnalitÃ© en dÃ©tail
3. Expliquez pourquoi elle serait utile
4. Proposez une implÃ©mentation si possible

### Soumettre une Pull Request

1. **Fork le projet**
2. **CrÃ©ez une branche feature :**
   \```bash
   git checkout -b feature/ma-nouvelle-feature
   \```

3. **Faites vos modifications**
4. **Ajoutez des tests**
5. **VÃ©rifiez que tout passe :**
   \```bash
   pytest tests/
   black src/ tests/
   flake8 src/ tests/
   \```

6. **Commit avec un message clair :**
   \```bash
   git commit -m "feat: add amazing feature"
   \```

   Suivez le format Conventional Commits :
   - `feat:` nouvelle fonctionnalitÃ©
   - `fix:` correction de bug
   - `docs:` documentation
   - `test:` ajout de tests
   - `refactor:` refactoring
   - `chore:` maintenance

7. **Push et crÃ©ez une PR**

## ğŸ“‹ Checklist avant de soumettre

- [ ] Tests ajoutÃ©s et qui passent
- [ ] Code formatÃ© avec Black
- [ ] Pas de warnings Flake8
- [ ] Documentation mise Ã  jour
- [ ] CHANGELOG mis Ã  jour (si applicable)

## ğŸ¨ Style Guide

- Suivre PEP 8
- Utiliser Black pour le formatage
- Max line length: 100
- Docstrings pour toutes les fonctions publiques
- Type hints encouragÃ©s

## ğŸ§ª Tests

- Couverture minimum : 80%
- Tests unitaires obligatoires pour nouvelles features
- Tests d'intÃ©gration pour les workflows

## ğŸ“ Commit Messages

Format : `type(scope): description`

Exemples :
- `feat(validation): add email validation`
- `fix(pipeline): handle None values in transform`
- `docs(readme): update installation instructions`

## ğŸ¤ Code Review

- Soyez respectueux et constructif
- Proposez des solutions, pas seulement des critiques
- Acceptez les feedbacks avec ouverture
- Les reviews sont lÃ  pour amÃ©liorer le code

## â“ Questions

Si vous avez des questions, n'hÃ©sitez pas Ã  :
- Ouvrir une issue
- Me contacter : votre.email@example.com

Merci de contribuer ! ğŸ™
```

**Committer :**
```bash
git add CONTRIBUTING.md
git commit -m "docs: add contributing guidelines"
git push
```

**CritÃ¨res de validation :**
- âœ… CONTRIBUTING.md crÃ©Ã©
- âœ… Guidelines claires

---

## ğŸ“¤ Livrables

Ã€ la fin du brief, vous devez avoir :

### 1. Repository GitHub complet avec :
- âœ… Code source du pipeline
- âœ… Module de validation
- âœ… Tests unitaires (couverture > 80%)
- âœ… 3+ workflows GitHub Actions fonctionnels
- âœ… Branch protection sur main
- âœ… README complet avec badges
- âœ… CONTRIBUTING.md

### 2. Issues et Project management :
- âœ… 5+ issues crÃ©Ã©es et fermÃ©es
- âœ… GitHub Project avec colonnes Kanban
- âœ… Milestone v1.0.0 complÃ©tÃ©

### 3. Pull Requests :
- âœ… Minimum 4 PR crÃ©Ã©es et mergÃ©es
- âœ… Code reviews effectuÃ©s
- âœ… Tous les CI checks passent

### 4. Release :
- âœ… Tag v1.0.0 crÃ©Ã©
- âœ… Release publiÃ©e sur GitHub
- âœ… Notes de release complÃ¨tes

### 5. SÃ©curitÃ© :
- âœ… Dependabot activÃ©
- âœ… Secrets configurÃ©s
- âœ… Branch protection activÃ©e

### 6. Documentation :
- âœ… README professionnel
- âœ… Guide de contribution
- âœ… Exemples d'utilisation

---

## âœ… CritÃ¨res d'Ã‰valuation

| CritÃ¨re | Points |
|---------|--------|
| Configuration du repository (SSH, README, structure) | 10 |
| Issues et gestion de projet (Project, Milestone) | 15 |
| Pull Requests et Code Review | 20 |
| GitHub Actions (Tests, Lint, Deploy) | 20 |
| SÃ©curitÃ© (Dependabot, Secrets, Branch protection) | 15 |
| Documentation (README, CONTRIBUTING) | 10 |
| Release et Tags | 10 |

**Total : 100 points**

**Bonus (+10 points) :**
- Couverture de tests > 90%
- Workflow supplÃ©mentaire crÃ©atif
- Documentation exceptionnelle

---

## ğŸ’¡ Conseils

### Workflow quotidien
- ğŸ”„ **Sync souvent** : `git pull origin main` avant de crÃ©er une branche
- ğŸŒ¿ **Branches descriptives** : `feature/add-validation`, `fix/csv-bug`
- ğŸ“ **PR descriptions complÃ¨tes** : Aidez les reviewers Ã  comprendre
- âœ… **CI Green** : Ne mergez jamais avec des checks qui Ã©chouent
- ğŸ·ï¸ **Labels pertinents** : Facilitent l'organisation

### Code Review
- ğŸ‘€ **Lisez tout** avant de commenter
- ğŸ’¬ **Soyez constructif** : Proposez des solutions
- â±ï¸ **RÃ©pondez rapidement** : Ne bloquez pas vos collÃ¨gues
- ğŸ¤ **Acceptez les feedbacks** : C'est pour amÃ©liorer le code

### GitHub Actions
- ğŸ“¦ **Cache les dÃ©pendances** : Gagnez du temps
- ğŸ¯ **Tests ciblÃ©s** : Ne testez que ce qui a changÃ©
- ğŸš€ **ParallÃ©lisez** : Matrix builds pour tester plusieurs versions
- ğŸ”’ **Secrets sÃ©curisÃ©s** : Ne jamais les hardcoder

---

## ğŸ†˜ Troubleshooting

### CI checks Ã©chouent
```bash
# Lancer les tests localement
pytest tests/

# Formater le code
black src/ tests/

# VÃ©rifier le linting
flake8 src/ tests/ --max-line-length=100
```

### Conflit de merge
```bash
# Mettre Ã  jour main
git checkout main
git pull origin main

# Rebase votre branche
git checkout feature/ma-branche
git rebase main

# RÃ©soudre les conflits
# Ã‰diter les fichiers marquÃ©s
git add .
git rebase --continue
```

### Branch protection bloque le merge
- VÃ©rifiez que tous les CI checks sont verts
- Assurez-vous d'avoir au moins une approbation
- RÃ©solvez toutes les conversations

---

## ğŸ“š Ressources

### Documentation officielle
- [GitHub Docs](https://docs.github.com)
- [GitHub Actions](https://docs.github.com/en/actions)
- [GitHub CLI](https://cli.github.com)

### Tutorials
- [GitHub Skills](https://skills.github.com)
- [GitHub Learning Lab](https://lab.github.com)

### Tools
- [GitHub Desktop](https://desktop.github.com)
- [VS Code GitHub Integration](https://code.visualstudio.com/docs/editor/github)

### Best Practices
- [Conventional Commits](https://www.conventionalcommits.org)
- [Semantic Versioning](https://semver.org)
- [Keep a Changelog](https://keepachangelog.com)

---

## ğŸ“ Pour aller plus loin

### AprÃ¨s ce brief, explorez :
- **GitHub Advanced Security** : Code scanning, Secret scanning
- **GitHub Packages** : HÃ©berger vos packages Python
- **GitHub Codespaces** : Dev environment dans le cloud
- **GitHub Projects (Beta)** : Nouvelle version avec tables et roadmaps
- **GitHub API** : Automatiser avec l'API REST ou GraphQL
- **GitHub Apps** : CrÃ©er des intÃ©grations personnalisÃ©es

---

**Bon courage ! ğŸš€**

*N'oubliez pas : GitHub n'est pas juste un hÃ©bergeur de code, c'est une plateforme complÃ¨te pour la collaboration et le DevOps !*
