# 06 - ETL Pipelines

[â† 05 - Spark SQL](05-spark-sql.md) | [ğŸ  Accueil](README.md) | [07 - Optimisation â†’](07-performance-optimization.md)

---

## 1. Extract (Lecture)

```python
df = spark.read.parquet("s3://bucket/data.parquet")
```

## 2. Transform (Nettoyage et Enrichissement)

- `dropna()`, `fillna()`
- `dropDuplicates()`
- Joins pour enrichissement.

## 3. Load (Ã‰criture)

```python
# Parquet partitionnÃ©
df.write 
    .mode("overwrite") 
    .partitionBy("year", "month") 
    .parquet("output/data")
```

## 4. Formats recommandÃ©s
- **Parquet** : Analytics, Data Lake (columnar).
- **Avro** : Streaming, Ã©volution de schÃ©ma.

---

[â† 05 - Spark SQL](05-spark-sql.md) | [ğŸ  Accueil](README.md) | [07 - Optimisation â†’](07-performance-optimization.md)
