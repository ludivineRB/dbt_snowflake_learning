# 01 - Introduction √† Apache Spark

[üè† Accueil](README.md) | [02 - Installation et Setup ‚Üí](02-installation-setup.md)

---

## 1. Qu'est-ce qu'Apache Spark ?

**Apache Spark** est un moteur d'analyse unifi√© pour le traitement de donn√©es √† grande √©chelle, avec des modules int√©gr√©s pour le streaming, SQL, le machine learning et le traitement de graphes.

### Caract√©ristiques principales

**Vitesse**
- Traitement en m√©moire (RAM) plut√¥t que disque
- Jusqu'√† 100x plus rapide que Hadoop MapReduce

**Facilit√© d'utilisation**
- APIs dans plusieurs langages : Python, Scala, Java, R, SQL
- API haut niveau (DataFrame) similaire √† Pandas/SQL

**√âvolutivit√©**
- Du laptop (mode local) aux clusters de milliers de machines
- Support de multiples gestionnaires de cluster (YARN, Kubernetes, Mesos)

## 2. Architecture de Spark

### Composants principaux

**Driver Program**
- Point d'entr√©e de l'application Spark
- Cr√©e le SparkContext/SparkSession
- Distribue les t√¢ches aux executors

**Cluster Manager**
- Alloue les ressources (CPU, m√©moire)
- Types : Standalone, YARN, Kubernetes

**Executors**
- Processus qui ex√©cutent les t√¢ches
- Stockent les donn√©es en cache
- Retournent les r√©sultats au driver

## 3. Concepts cl√©s

### RDD (Resilient Distributed Dataset)
API de bas niveau, collection distribu√©e immuable.

### DataFrame
API haut niveau, optimis√©e, similaire √† Pandas ou table SQL.

### Lazy Evaluation
Les transformations ne sont pas ex√©cut√©es imm√©diatement. Spark ne calcule que quand une action est appel√©e.

---

[üè† Accueil](README.md) | [02 - Installation et Setup ‚Üí](02-installation-setup.md)
