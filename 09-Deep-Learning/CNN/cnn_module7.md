---
title: 'Module 7: MÃ©triques et Optimisation des CNN'
description: 'Formation CNN - Module 7: MÃ©triques et Optimisation des CNN'
tags:
  - CNN
  - 09-Deep-Learning
category: 09-Deep-Learning
---

# ğŸ“Š Module 7: MÃ©triques et Optimisation des CNN

ğŸ“š Niveau: AvancÃ© | â±ï¸ DurÃ©e: 2h | ğŸ¯ Objectif: MaÃ®triser l'Ã©valuation et l'amÃ©lioration

## ğŸ“ˆ DÃ©crypter les MÃ©triques d'EntraÃ®nement

#### ğŸ¯ Exemple Concret d'EntraÃ®nement

Analysons ligne par ligne ce que nous disent les mÃ©triques d'un entraÃ®nement CNN rÃ©el :

Epoch 1/50  
1563/1563 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 220s 137ms/step - accuracy: 0.3300 - loss: 2.1425 - val\_accuracy: 0.5032 - val\_loss: 1.4824

Epoch 2/50  
1563/1563 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 260s 136ms/step - accuracy: 0.5592 - loss: 1.2421 - val\_accuracy: 0.5507 - val\_loss: 1.3214

Epoch 20/50  
1563/1563 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 265s 139ms/step - accuracy: 0.8310 - loss: 0.4850 - val\_accuracy: 0.8025 - val\_loss: 0.5852

Epoch 21/50  
1563/1563 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 216s 138ms/step - accuracy: 0.8465 - loss: 0.4378 - val\_accuracy: 0.8304 - val\_loss: 0.5089

### ğŸ” Anatomie d'une Ligne de MÃ©trique

Epoch 21/50

1563/1563 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

216s 138ms/step

accuracy: 0.8465

loss: 0.4378

val\_accuracy: 0.8304

val\_loss: 0.5089

ğŸ“… Epoch 21/50

**Ã‰poque actuelle :** 21e itÃ©ration sur 50 prÃ©vues

**Signification :** Le modÃ¨le a vu 21 fois l'ensemble des donnÃ©es d'entraÃ®nement

ğŸ”„ 1563/1563 Batches

**Progression :** 1563 mini-batches traitÃ©s sur 1563 total

**Calcul :** Si dataset = 50000 images et batch\_size = 32, alors 50000/32 â‰ˆ 1563 batches

â±ï¸ 216s 138ms/step

**Temps total :** 216 secondes pour cette Ã©poque

**Temps par batch :** 138ms par mini-batch (216s / 1563 batches)

âœ… Accuracy: 0.8465

**PrÃ©cision d'entraÃ®nement :** 84.65% des prÃ©dictions correctes

**Tendance :** Le modÃ¨le apprend bien sur les donnÃ©es d'entraÃ®nement

ğŸ“‰ Loss: 0.4378

**Perte d'entraÃ®nement :** Mesure de l'erreur du modÃ¨le

**Objectif :** Plus cette valeur est basse, mieux c'est

ğŸ” Val\_accuracy: 0.8304

**PrÃ©cision de validation :** 83.04% sur donnÃ©es non vues

**Comparaison :** Proche du training accuracy = bon signe

## ğŸ“Š MÃ©triques Principales ExpliquÃ©es

ğŸ¯

### Accuracy (PrÃ©cision)

Pourcentage de prÃ©dictions correctes

Accuracy = (PrÃ©dictions Correctes) / (Total PrÃ©dictions) Accuracy = (TP + TN) / (TP + TN + FP + FN)

**ğŸ’¡ Utilisation :** MÃ©trique principale pour les problÃ¨mes Ã©quilibrÃ©s

**âš ï¸ Attention :** Peut Ãªtre trompeuse avec des classes dÃ©sÃ©quilibrÃ©es

ğŸ“‰

### Loss (Perte)

Mesure de l'erreur du modÃ¨le

Categorical Crossentropy = -Î£ y\_true \* log(y\_pred) Plus la perte est faible, mieux c'est !

**ğŸ’¡ RÃ´le :** Guide l'optimisation, ce que le modÃ¨le cherche Ã  minimiser

**ğŸ¯ Objectif :** Perte dÃ©croissante et stable

ğŸ”

### Precision (PrÃ©cision)

Proportion de vrais positifs parmi les positifs prÃ©dits

Precision = TP / (TP + FP) "De tous ceux que j'ai dit positifs, combien le sont vraiment ?"

**ğŸ’¡ Important quand :** Les faux positifs coÃ»tent cher

**ğŸ“§ Exemple :** DÃ©tection de spam (Ã©viter de classer un email important comme spam)

ğŸ£

### Recall (Rappel)

Proportion de vrais positifs dÃ©tectÃ©s

Recall = TP / (TP + FN) "De tous les vrais positifs, combien ai-je dÃ©tectÃ©s ?"

**ğŸ’¡ Important quand :** Les faux nÃ©gatifs coÃ»tent cher

**ğŸ¥ Exemple :** DÃ©tection de cancer (ne pas rater un vrai cas)

âš–ï¸

### F1-Score

Moyenne harmonique de Precision et Recall

F1 = 2 \* (Precision \* Recall) / (Precision + Recall) Ã‰quilibre entre Precision et Recall

**ğŸ’¡ Avantage :** SynthÃ¨se en une mÃ©trique unique

**ğŸ¯ Usage :** Quand Precision et Recall sont Ã©galement importants

### ğŸ§® Matrice de Confusion - Comprendre les MÃ©triques

PrÃ©dit Positif

PrÃ©dit NÃ©gatif

Vrai Positif

TP  
âœ… Correct

FN  
âŒ ManquÃ©

Vrai NÃ©gatif

FP  
âŒ Fausse alerte

TN  
âœ… Correct

## ğŸ” Diagnostic des ProblÃ¨mes d'EntraÃ®nement

SymptÃ´mes ObservÃ©s

Diagnostic

ProblÃ¨me

Solutions

â€¢ Train accuracy â†—ï¸ 95%  
â€¢ Val accuracy ğŸ“‰ 65%  
â€¢ Gap croissant

Overfitting

Le modÃ¨le mÃ©morise au lieu d'apprendre

Dropout, regularization, plus de donnÃ©es

â€¢ Train accuracy ğŸ“‰ 55%  
â€¢ Val accuracy ğŸ“‰ 53%  
â€¢ Les deux stagnent

Underfitting

Le modÃ¨le est trop simple

ModÃ¨le plus complexe, plus d'Ã©poques

â€¢ Train accuracy â†—ï¸ 85%  
â€¢ Val accuracy â†—ï¸ 83%  
â€¢ Gap stable ~2%

Normal

Apprentissage sain

Continuer l'entraÃ®nement

â€¢ Loss oscille beaucoup  
â€¢ Accuracy monte/descend  
â€¢ Pas de tendance claire

Instable

Learning rate trop Ã©levÃ©

RÃ©duire learning rate, scheduler

#### ğŸ“Š Simulateur de Courbes d'EntraÃ®nement

Cliquez pour voir diffÃ©rents scÃ©narios d'entraÃ®nement :

ğŸ“ˆ EntraÃ®nement Normal ğŸ“Š Overfitting ğŸ“‰ Underfitting ğŸ“Š InstabilitÃ©

## ğŸš€ StratÃ©gies d'AmÃ©lioration du ModÃ¨le

ğŸ“Š Augmentation des DonnÃ©es

**Quand :** Overfitting, dataset petit

**Techniques :**

*   Rotation, flip, zoom
*   Ajustement luminositÃ©/contraste
*   Bruit alÃ©atoire
*   Mixup, CutMix

ğŸ›¡ï¸ RÃ©gularisation

**Quand :** Overfitting

**Techniques :**

*   Dropout (0.2 - 0.5)
*   L1/L2 regularization
*   Batch Normalization
*   Early Stopping

âš™ï¸ Ajustement Architecture

**Underfitting :** Plus de couches/neurones

**Overfitting :** Architecture plus simple

**Options :**

*   Nombre de filtres
*   Profondeur du rÃ©seau
*   Skip connections

ğŸ“ˆ Optimisation Learning Rate

**Trop Ã©levÃ© :** InstabilitÃ©, divergence

**Trop bas :** Convergence lente

**Solutions :**

*   Learning rate scheduler
*   Adaptive optimizers (Adam)
*   Learning rate finder
*   Cosine annealing

ğŸ”„ Transfer Learning

**Quand :** Dataset petit, domaine similaire

**Approches :**

*   Feature extraction
*   Fine-tuning
*   ModÃ¨les prÃ©-entraÃ®nÃ©s
*   Progressive unfreezing

âš¡ Optimisation Performance

**Objectif :** AccÃ©lÃ©rer l'entraÃ®nement

**Techniques :**

*   Mixed precision training
*   Batch size optimal
*   Multi-GPU training
*   Gradient accumulation

### ğŸ¯ Guide de DÃ©cision Rapide

#### ğŸ¤” "Mon modÃ¨le ne marche pas bien, que faire ?"

##### âŒ Si Accuracy < 60% :

1.  VÃ©rifier les donnÃ©es (labels corrects ?)
2.  Augmenter la complexitÃ© du modÃ¨le
3.  RÃ©duire le learning rate
4.  Plus d'Ã©poques d'entraÃ®nement
5.  PrÃ©processing des donnÃ©es

##### âš ï¸ Si Gap Train/Val > 10% :

1.  Ajouter du Dropout
2.  Data augmentation
3.  RÃ©duire la complexitÃ©
4.  Plus de donnÃ©es
5.  Early stopping

## ğŸ”¬ MÃ©triques AvancÃ©es pour l'Ã‰valuation

ğŸ“

### AUC-ROC

Area Under the Receiver Operating Characteristic Curve

AUC = âˆ« TPR d(FPR) de 0 Ã  1 TPR = Recall = TP/(TP+FN) FPR = FP/(FP+TN)

**ğŸ’¡ Usage :** Classification binaire, Ã©value tous les seuils

**ğŸ¯ InterprÃ©tation :** 0.5 = alÃ©atoire, 1.0 = parfait

ğŸ“Š

### Top-K Accuracy

PrÃ©cision dans les K meilleures prÃ©dictions

Top-5 Accuracy = (Vraie classe dans les 5 premiÃ¨res) / Total Utile pour classification avec nombreuses classes

**ğŸ’¡ Exemple :** ImageNet utilise Top-1 et Top-5 accuracy

**ğŸ¯ Avantage :** Plus indulgent que l'accuracy stricte

âš–ï¸

### Weighted F1-Score

F1-Score pondÃ©rÃ© par la frÃ©quence des classes

Weighted F1 = Î£ (nombre\_Ã©chantillons\_classe\_i / total) Ã— F1\_classe\_i Compense les dÃ©sÃ©quilibres de classes

**ğŸ’¡ Usage :** Datasets dÃ©sÃ©quilibrÃ©s

**ğŸ¯ Avantage :** Ã‰vite que les classes majoritaires dominent

### ğŸ“± MÃ©triques de Production

âš¡ Latence (ms)

**Mesure :** Temps de prÃ©diction par image

**Objectifs typiques :**

*   Temps rÃ©el : < 33ms (30 FPS)
*   Interactive : < 100ms
*   Batch : < 1s

ğŸ“¦ Taille ModÃ¨le (MB)

**Importance :** DÃ©ploiement mobile/edge

**Objectifs :**

*   Mobile : < 50MB
*   Edge : < 10MB
*   IoT : < 1MB

ğŸ”‹ Consommation (Watts)

**Mesure :** Ã‰nergie par infÃ©rence

**Solutions :**

*   Quantization
*   Pruning
*   Knowledge distillation

## ğŸ¬ Cas Pratiques d'Optimisation

#### ğŸ“‹ Ã‰tude de Cas : Optimisation CIFAR-10

Suivez l'Ã©volution d'un modÃ¨le CNN sur CIFAR-10 :

ğŸš€ ModÃ¨le Baseline ğŸ“Š + Data Augmentation ğŸ›¡ï¸ + RÃ©gularisation ğŸ—ï¸ + Architecture AvancÃ©e âœ¨ RÃ©sultat Final

### ğŸ”„ Processus d'AmÃ©lioration ItÃ©ratif

#### ğŸ“ˆ MÃ©thodologie RecommandÃ©e

1.  **Baseline :** ModÃ¨le simple qui fonctionne
2.  **Analyse :** Identifier le problÃ¨me principal
3.  **HypothÃ¨se :** Choisir UNE amÃ©lioration
4.  **Test :** ImplÃ©menter et mesurer
5.  **Validation :** Confirmer l'amÃ©lioration
6.  **ItÃ©ration :** RÃ©pÃ©ter le processus

**âš ï¸ Erreur Commune :** Changer plusieurs choses Ã  la fois. Il devient impossible de savoir ce qui amÃ©liore vraiment le modÃ¨le !

## ğŸ“‹ RÃ©sumÃ© du Module 7

### ğŸ¯ Ce que vous avez appris :

*   âœ… **Lecture des mÃ©triques :** InterprÃ©ter accuracy, loss, val\_accuracy, val\_loss
*   âœ… **Diagnostic :** Identifier overfitting, underfitting, instabilitÃ©
*   âœ… **MÃ©triques avancÃ©es :** Precision, Recall, F1-Score, AUC-ROC
*   âœ… **StratÃ©gies d'amÃ©lioration :** Data augmentation, rÃ©gularisation, architecture
*   âœ… **Optimisation :** Learning rate, transfer learning, mÃ©triques de production
*   âœ… **MÃ©thodologie :** Processus itÃ©ratif d'amÃ©lioration

### ğŸš€ Prochaines Ã©tapes :

Vous maÃ®trisez maintenant l'Ã©valuation et l'optimisation des CNN ! Utilisez ces connaissances pour :

*   Diagnostiquer rapidement les problÃ¨mes d'entraÃ®nement
*   Choisir les bonnes mÃ©triques selon votre problÃ¨me
*   Optimiser mÃ©thodiquement vos modÃ¨les
*   DÃ©ployer en production avec confiance

[â† Module 6: Projets & Exercices](cnn_module6.html)

**Module 7 (Bonus)**  
MÃ©triques & Optimisation

[ğŸ  Retour Ã  l'Index](index.html)

// DonnÃ©es pour les cas d'Ã©tude const caseStudies = { baseline: { title: "ğŸš€ ModÃ¨le Baseline", description: "CNN simple : Conv2D â†’ MaxPool â†’ Conv2D â†’ MaxPool â†’ Dense", metrics: { accuracy: "65%", val\_accuracy: "62%", loss: "1.2", parameters: "50K", training\_time: "5 min" }, problems: \["Underfitting lÃ©ger", "Performance limitÃ©e"\], next: "Ajouter de la complexitÃ© et des donnÃ©es" }, augmentation: { title: "ğŸ“Š + Data Augmentation", description: "Ajout de rotation, flip, zoom, ajustement de luminositÃ©", metrics: { accuracy: "72%", val\_accuracy: "70%", loss: "0.9", parameters: "50K", training\_time: "8 min" }, problems: \["Gap train/val rÃ©duit", "AmÃ©lioration significative"\], next: "PrÃ©venir l'overfitting potentiel" }, regularization: { title: "ğŸ›¡ï¸ + RÃ©gularisation", description: "Dropout (0.3), Batch Normalization, L2 regularization", metrics: { accuracy: "78%", val\_accuracy: "76%", loss: "0.7", parameters: "52K", training\_time: "10 min" }, problems: \["ModÃ¨le stable", "Bon Ã©quilibre"\], next: "AmÃ©liorer l'architecture" }, architecture: { title: "ğŸ—ï¸ + Architecture AvancÃ©e", description: "ResNet blocks, Skip connections, Plus de filtres", metrics: { accuracy: "85%", val\_accuracy: "83%", loss: "0.5", parameters: "180K", training\_time: "15 min" }, problems: \["Excellent Ã©quilibre", "Performance compÃ©titive"\], next: "Fine-tuning final" }, final: { title: "âœ¨ RÃ©sultat Final", description: "Optimisation learning rate, Early stopping, Ensemble", metrics: { accuracy: "88%", val\_accuracy: "86%", loss: "0.4", parameters: "180K", training\_time: "20 min" }, problems: \["Objectif atteint !", "PrÃªt pour production"\], next: "DÃ©ploiement et monitoring" } }; // DonnÃ©es pour les courbes d'entraÃ®nement const trainingCurves = { normal: { title: "ğŸ“ˆ EntraÃ®nement Normal", description: "Convergence saine avec gap stable entre train et validation", train\_acc: \[0.3, 0.5, 0.65, 0.75, 0.82, 0.86, 0.88, 0.89, 0.90, 0.91\], val\_acc: \[0.35, 0.48, 0.62, 0.72, 0.79, 0.83, 0.85, 0.86, 0.87, 0.88\], characteristics: \[ "Gap train/val stable (~3%)", "Progression continue", "Convergence douce", "Pas de sur-apprentissage" \] }, overfitting: { title: "ğŸ“Š Overfitting", description: "Le modÃ¨le mÃ©morise les donnÃ©es d'entraÃ®nement", train\_acc: \[0.3, 0.6, 0.75, 0.85, 0.92, 0.96, 0.98, 0.99, 0.995, 0.999\], val\_acc: \[0.35, 0.55, 0.68, 0.72, 0.70, 0.68, 0.65, 0.63, 0.61, 0.58\], characteristics: \[ "Gap train/val croissant (>40%)", "Train accuracy trÃ¨s Ã©levÃ©e", "Val accuracy plafonne puis baisse", "MÃ©morisation vs apprentissage" \] }, underfitting: { title: "ğŸ“‰ Underfitting", description: "Le modÃ¨le est trop simple pour apprendre", train\_acc: \[0.25, 0.28, 0.32, 0.35, 0.38, 0.40, 0.41, 0.42, 0.43, 0.43\], val\_acc: \[0.24, 0.27, 0.31, 0.34, 0.37, 0.39, 0.40, 0.41, 0.42, 0.42\], characteristics: \[ "Performance faible sur les deux", "Progression trÃ¨s lente", "Plateau prÃ©coce", "CapacitÃ© insuffisante" \] }, unstable: { title: "ğŸ“Š InstabilitÃ©", description: "Learning rate trop Ã©levÃ©, gradients explosent", train\_acc: \[0.1, 0.6, 0.3, 0.8, 0.2, 0.7, 0.4, 0.75, 0.35, 0.65\], val\_acc: \[0.12, 0.55, 0.35, 0.72, 0.25, 0.68, 0.42, 0.70, 0.38, 0.62\], characteristics: \[ "Oscillations importantes", "Pas de convergence claire", "Learning rate trop Ã©levÃ©", "Gradients instables" \] } }; // Explication des Ã©lÃ©ments de confusion matrix const confusionElements = { tp: { title: "True Positive (TP) - Vrai Positif âœ…", description: "Le modÃ¨le prÃ©dit POSITIF et c'est CORRECT", example: "ğŸ“§ Email de spam dÃ©tectÃ© comme spam â†’ âœ… Correct !", impact: "Contribue positivement Ã  Precision et Recall" }, fp: { title: "False Positive (FP) - Faux Positif âŒ", description: "Le modÃ¨le prÃ©dit POSITIF mais c'est FAUX", example: "ğŸ“§ Email important classÃ© comme spam â†’ âŒ ProblÃ©matique !", impact: "Diminue la Precision (fausse alerte)" }, fn: { title: "False Negative (FN) - Faux NÃ©gatif âŒ", description: "Le modÃ¨le prÃ©dit NÃ‰GATIF mais c'est FAUX", example: "ğŸ¥ Cancer non dÃ©tectÃ© â†’ âŒ TrÃ¨s grave !", impact: "Diminue le Recall (cas manquÃ©)" }, tn: { title: "True Negative (TN) - Vrai NÃ©gatif âœ…", description: "Le modÃ¨le prÃ©dit NÃ‰GATIF et c'est CORRECT", example: "ğŸ“§ Email normal classÃ© comme normal â†’ âœ… Parfait !", impact: "Contribue Ã  la Specificity et Accuracy" } }; // Explication des Ã©poques function explainEpoch(epochNum) { // Reset previous selections document.querySelectorAll('.epoch-line').forEach(line => { line.classList.remove('selected'); }); // Select current line event.target.classList.add('selected'); const explanationDiv = document.getElementById('epochExplanation'); let content = ''; if (epochNum === 1) { content = \` <h4>ğŸš€ Analyse Ã‰poque 1/50</h4> <p><strong>Situation :</strong> DÃ©but d'entraÃ®nement, le modÃ¨le dÃ©couvre les donnÃ©es</p> <ul> <li><strong>Accuracy 33% :</strong> Performance alÃ©atoire (CIFAR-10 = 10 classes, hasard = 10%)</li> <li><strong>Val\_accuracy 50% :</strong> Validation meilleure que train (normal au dÃ©but)</li> <li><strong>Loss Ã©levÃ©e (2.14) :</strong> Le modÃ¨le fait encore beaucoup d'erreurs</li> <li><strong>220s :</strong> Premier passage, compilation et optimisations</li> </ul> <p><strong>ğŸ“Š Diagnostic :</strong> DÃ©marrage normal, le modÃ¨le apprend les bases</p> \`; } else if (epochNum === 2) { content = \` <h4>ğŸ“ˆ Analyse Ã‰poque 2/50</h4> <p><strong>Situation :</strong> PremiÃ¨re amÃ©lioration visible</p> <ul> <li><strong>Accuracy 56% :</strong> +23% d'amÃ©lioration, excellent signe</li> <li><strong>Val\_accuracy 55% :</strong> Ã‰quilibre train/val, pas d'overfitting</li> <li><strong>Loss 1.24 :</strong> RÃ©duction significative (-0.9)</li> <li><strong>260s :</strong> Temps stable</li> </ul> <p><strong>ğŸ“Š Diagnostic :</strong> Apprentissage sain, continuer l'entraÃ®nement</p> \`; } else if (epochNum === 20) { content = \` <h4>ğŸ¯ Analyse Ã‰poque 20/50</h4> <p><strong>Situation :</strong> Milieu d'entraÃ®nement, performance mature</p> <ul> <li><strong>Accuracy 83% :</strong> Performance Ã©levÃ©e, modÃ¨le bien entraÃ®nÃ©</li> <li><strong>Val\_accuracy 80% :</strong> Gap de 3%, Ã©quilibre excellent</li> <li><strong>Loss 0.48 :</strong> Faible, modÃ¨le confiant</li> <li><strong>265s :</strong> Temps constant</li> </ul> <p><strong>ğŸ“Š Diagnostic :</strong> EntraÃ®nement optimal, proche de la convergence</p> \`; } else if (epochNum === 21) { content = \` <h4>âœ¨ Analyse Ã‰poque 21/50</h4> <p><strong>Situation :</strong> AmÃ©lioration continue</p> <ul> <li><strong>Accuracy 84.6% :</strong> +1.6% d'amÃ©lioration</li> <li><strong>Val\_accuracy 83% :</strong> +3% d'amÃ©lioration, rattrape le train</li> <li><strong>Gap rÃ©duit :</strong> 1.6% seulement, excellent Ã©quilibre</li> <li><strong>Learning rate :</strong> Probablement rÃ©duit automatiquement</li> </ul> <p><strong>ğŸ“Š Diagnostic :</strong> EntraÃ®nement parfait, peut continuer ou s'arrÃªter</p> \`; } explanationDiv.innerHTML = content; explanationDiv.style.display = 'block'; } // Explication des Ã©lÃ©ments de la matrice de confusion function explainConfusion(element) { const data = confusionElements\[element\]; const explanationDiv = document.getElementById('confusionExplanation'); explanationDiv.innerHTML = \` <h4>${data.title}</h4> <p><strong>DÃ©finition :</strong> ${data.description}</p> <p><strong>Exemple concret :</strong> ${data.example}</p> <p><strong>Impact sur mÃ©triques :</strong> ${data.impact}</p> \`; explanationDiv.style.display = 'block'; } // Affichage des courbes d'entraÃ®nement function showTrainingCurve(type) { const data = trainingCurves\[type\]; const canvas = document.getElementById('trainingChart'); const ctx = canvas.getContext('2d'); // Clear canvas ctx.clearRect(0, 0, canvas.width, canvas.height); // Set canvas size canvas.width = canvas.offsetWidth; canvas.height = canvas.offsetHeight; const width = canvas.width; const height = canvas.height; const padding = 50; // Draw axes ctx.strokeStyle = '#333'; ctx.lineWidth = 2; ctx.beginPath(); ctx.moveTo(padding, height - padding); ctx.lineTo(width - padding, height - padding); ctx.moveTo(padding, height - padding); ctx.lineTo(padding, padding); ctx.stroke(); // Draw labels ctx.fillStyle = '#333'; ctx.font = '12px Arial'; ctx.fillText('Accuracy', 10, height/2); ctx.fillText('Epochs', width/2, height - 10); // Draw training curve ctx.strokeStyle = '#e74c3c'; ctx.lineWidth = 3; ctx.beginPath(); for (let i = 0; i < data.train\_acc.length; i++) { const x = padding + (i \* (width - 2\*padding) / (data.train\_acc.length - 1)); const y = height - padding - (data.train\_acc\[i\] \* (height - 2\*padding)); if (i === 0) ctx.moveTo(x, y); else ctx.lineTo(x, y); } ctx.stroke(); // Draw validation curve ctx.strokeStyle = '#3498db'; ctx.lineWidth = 3; ctx.beginPath(); for (let i = 0; i < data.val\_acc.length; i++) { const x = padding + (i \* (width - 2\*padding) / (data.val\_acc.length - 1)); const y = height - padding - (data.val\_acc\[i\] \* (height - 2\*padding)); if (i === 0) ctx.moveTo(x, y); else ctx.lineTo(x, y); } ctx.stroke(); // Legend ctx.fillStyle = '#e74c3c'; ctx.fillText('Train Accuracy', width - 150, 30); ctx.fillStyle = '#3498db'; ctx.fillText('Val Accuracy', width - 150, 50); // Show explanation const explanationDiv = document.getElementById('curveExplanation'); explanationDiv.innerHTML = \` <h5 style="color: white;">${data.title}</h5> <p style="margin: 10px 0;">${data.description}</p> <ul style="margin: 10px 0; padding-left: 20px;"> ${data.characteristics.map(char => \`<li>${char}</li>\`).join('')} </ul> \`; explanationDiv.style.display = 'block'; } // Affichage des cas d'Ã©tude function showCase(caseType) { const data = caseStudies\[caseType\]; const display = document.getElementById('caseStudyDisplay'); display.innerHTML = \` <div style="color: white;"> <h5 style="color: white; margin-bottom: 15px;">${data.title}</h5> <p style="margin: 15px 0; font-style: italic;">${data.description}</p> <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(120px, 1fr)); gap: 15px; margin: 20px 0;"> <div style="background: rgba(255,255,255,0.1); padding: 10px; border-radius: 8px; text-align: center;"> <strong>Accuracy</strong><br> ${data.metrics.accuracy} </div> <div style="background: rgba(255,255,255,0.1); padding: 10px; border-radius: 8px; text-align: center;"> <strong>Val Accuracy</strong><br> ${data.metrics.val\_accuracy} </div> <div style="background: rgba(255,255,255,0.1); padding: 10px; border-radius: 8px; text-align: center;"> <strong>Loss</strong><br> ${data.metrics.loss} </div> <div style="background: rgba(255,255,255,0.1); padding: 10px; border-radius: 8px; text-align: center;"> <strong>ParamÃ¨tres</strong><br> ${data.metrics.parameters} </div> <div style="background: rgba(255,255,255,0.1); padding: 10px; border-radius: 8px; text-align: center;"> <strong>Temps</strong><br> ${data.metrics.training\_time} </div> </div> <div style="background: rgba(255,255,255,0.1); padding: 15px; border-radius: 8px; margin: 15px 0;"> <strong>ğŸ“Š Observations :</strong> <ul style="margin: 10px 0; padding-left: 20px;"> ${data.problems.map(problem => \`<li>${problem}</li>\`).join('')} </ul> </div> <div style="background: rgba(255,255,255,0.1); padding: 15px; border-radius: 8px;"> <strong>ğŸš€ Prochaine Ã©tape :</strong> ${data.next} </div> </div> \`; display.style.display = 'block'; } // Initialize canvas on load document.addEventListener('DOMContentLoaded', () => { // Show normal training curve by default setTimeout(() => showTrainingCurve('normal'), 1000); });
