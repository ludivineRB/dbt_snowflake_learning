# Chapitre 1 : Introduction au Deep Learning

## üéØ Objectifs

- Comprendre ce qu'est le Deep Learning et pourquoi il d√©passe le ML classique
- Conna√Ætre l'histoire et les perc√©es majeures du domaine
- Comprendre le neurone artificiel et le perceptron
- Identifier les architectures fondamentales (MLP, CNN, RNN, Transformers)
- Savoir quand utiliser le Deep Learning vs le Machine Learning classique
- Choisir le bon framework (PyTorch vs TensorFlow)

---

## 1. üß† Du Machine Learning au Deep Learning

### 1.1 Les limites du Machine Learning classique

Le Machine Learning classique (scikit-learn, XGBoost) fonctionne remarquablement bien sur les **donn√©es tabulaires structur√©es**. Mais il se heurte √† un mur d√®s que les donn√©es deviennent complexes :

**Le probl√®me du Feature Engineering manuel :**

```
Donn√©es brutes (image) ‚Üí Feature Engineering MANUEL ‚Üí Mod√®le ML ‚Üí Pr√©diction
                         ‚îú‚îÄ D√©tection de contours
                         ‚îú‚îÄ Histogrammes de couleurs
                         ‚îú‚îÄ HOG (Histogram of Oriented Gradients)
                         ‚îî‚îÄ SIFT descriptors
```

Un ing√©nieur ML devait **concevoir manuellement** les features pertinentes pour chaque probl√®me. Pour reconna√Ætre un chat dans une image, il fallait d√©cider quelles caract√©ristiques extraire : contours, textures, couleurs... Un processus long, co√ªteux, et sp√©cifique √† chaque domaine.

### 1.2 Le Deep Learning apprend ses propres features

Le Deep Learning √©limine cette √©tape manuelle :

```
Donn√©es brutes (image) ‚Üí R√©seau de neurones profond ‚Üí Pr√©diction
                         ‚îú‚îÄ Couche 1 : d√©tecte les bords
                         ‚îú‚îÄ Couche 2 : d√©tecte les textures
                         ‚îú‚îÄ Couche 3 : d√©tecte les formes
                         ‚îî‚îÄ Couche N : d√©tecte les objets
```

Le r√©seau apprend **automatiquement** la hi√©rarchie de features optimale pour la t√¢che. C'est la r√©volution fondamentale du Deep Learning.

### 1.3 Comparaison ML classique vs Deep Learning

| Crit√®re | ML classique (sklearn, XGBoost) | Deep Learning (PyTorch, TF) |
|---------|--------------------------------|----------------------------|
| **Feature Engineering** | Manuel, expert requis | Automatique |
| **Donn√©es n√©cessaires** | 100 - 10 000 samples | 10 000 - 10 000 000+ samples |
| **Interpr√©tabilit√©** | Bonne (feature importance) | Faible (bo√Æte noire) |
| **Donn√©es tabulaires** | Excellent | Correct |
| **Images, texte, audio** | Limit√© | Excellent |
| **Temps d'entra√Ænement** | Minutes | Heures √† jours |
| **GPU requis** | Non | Oui (fortement recommand√©) |
| **Complexit√© du code** | Faible | Moyenne √† √©lev√©e |
| **Performance sur peu de donn√©es** | Souvent meilleur | Risque d'overfitting |
| **Performance sur beaucoup de donn√©es** | Plafonne | Continue de progresser |

> üí° **Conseil** : Le Deep Learning n'est **PAS** toujours meilleur que le ML classique. Avec peu de donn√©es (<5 000 samples) et des features tabulaires, un Random Forest ou un XGBoost gagne souvent. Ne sortez pas PyTorch par r√©flexe !

---

## 2. üìú Histoire et perc√©es majeures

### 2.1 Timeline du Deep Learning

```
1958 ‚îÄ‚îÄ‚îÄ‚îÄ Perceptron (Frank Rosenblatt)
‚îÇ         Premier neurone artificiel. Enthousiasme √©norme.
‚îÇ
1969 ‚îÄ‚îÄ‚îÄ‚îÄ "Perceptrons" (Minsky & Papert)
‚îÇ         Montrent les limites du perceptron ‚Üí premier "hiver de l'IA"
‚îÇ
1986 ‚îÄ‚îÄ‚îÄ‚îÄ Backpropagation (Rumelhart, Hinton, Williams)
‚îÇ         Algorithme pour entra√Æner des r√©seaux multicouches
‚îÇ
1998 ‚îÄ‚îÄ‚îÄ‚îÄ LeNet-5 (Yann LeCun)
‚îÇ         Premier CNN pour reconnaissance de chiffres manuscrits
‚îÇ
2006 ‚îÄ‚îÄ‚îÄ‚îÄ Deep Belief Networks (Geoffrey Hinton)
‚îÇ         Renaissance du Deep Learning
‚îÇ
2012 ‚îÄ‚îÄ‚îÄ‚îÄ AlexNet ‚Üí Victoire ImageNet
‚îÇ         ‚ö° LE moment fondateur. Erreur r√©duite de 26% √† 16%
‚îÇ         Le monde d√©couvre la puissance des CNN + GPU
‚îÇ
2014 ‚îÄ‚îÄ‚îÄ‚îÄ GANs (Ian Goodfellow)
‚îÇ         G√©n√©ration d'images r√©alistes
‚îÇ
2015 ‚îÄ‚îÄ‚îÄ‚îÄ ResNet (152 couches !)
‚îÇ         Les r√©seaux tr√®s profonds deviennent possibles
‚îÇ
2017 ‚îÄ‚îÄ‚îÄ‚îÄ Transformers (Vaswani et al.)
‚îÇ         "Attention Is All You Need" ‚Üí r√©volution NLP
‚îÇ
2018 ‚îÄ‚îÄ‚îÄ‚îÄ BERT (Google)
‚îÇ         Transfer learning pour le NLP
‚îÇ
2020 ‚îÄ‚îÄ‚îÄ‚îÄ GPT-3 (OpenAI)
‚îÇ         175 milliards de param√®tres, few-shot learning
‚îÇ
2022 ‚îÄ‚îÄ‚îÄ‚îÄ ChatGPT (OpenAI)
‚îÇ         L'IA g√©n√©rative devient grand public
‚îÇ
2023 ‚îÄ‚îÄ‚îÄ‚îÄ GPT-4, LLaMA (Meta), Mistral
‚îÇ         Mod√®les multimodaux, open-source
‚îÇ
2024 ‚îÄ‚îÄ‚îÄ‚îÄ Claude 3, Gemini, LLaMA 3
‚îÇ         Course √† la performance et √† l'efficacit√©
```

### 2.2 Les trois p√®res fondateurs

| Chercheur | Contribution cl√© | Prix Turing 2018 |
|-----------|------------------|-------------------|
| **Geoffrey Hinton** | Backpropagation, Deep Belief Networks | Oui |
| **Yann LeCun** | CNN (LeNet), apprentissage auto-supervis√© | Oui |
| **Yoshua Bengio** | RNN, attention, repr√©sentations | Oui |

### 2.3 Pourquoi le DL a explos√© en 2012

Trois facteurs convergents :

1. **Donn√©es** : ImageNet (14M d'images labellis√©es), internet massif
2. **Calcul** : GPU NVIDIA (CUDA), parall√©lisme massif
3. **Algorithmes** : ReLU, Dropout, Batch Normalization

> üí° **Conseil** : Comprendre l'histoire aide √† comprendre pourquoi certaines architectures existent. Le Transformer n'a pas remplac√© les CNN par hasard : il r√©sout des limites fondamentales des RNN.

---

## 3. üî¨ Le neurone artificiel

### 3.1 Analogie biologique

Le neurone artificiel s'inspire (de mani√®re simplifi√©e) du neurone biologique :

```
Neurone biologique :
   Dendrites (entr√©es) ‚Üí Corps cellulaire (traitement) ‚Üí Axone (sortie)

Neurone artificiel :
   Inputs √ó Weights + Bias ‚Üí Fonction d'activation ‚Üí Output
```

### 3.2 Fonctionnement math√©matique

Un neurone artificiel effectue le calcul suivant :

```
         x1 ‚îÄ‚îÄw1‚îÄ‚îÄ‚îê
         x2 ‚îÄ‚îÄw2‚îÄ‚îÄ‚î§
         x3 ‚îÄ‚îÄw3‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚Üí Œ£ (somme pond√©r√©e) + b ‚îÄ‚îÄ‚Üí f(z) ‚îÄ‚îÄ‚Üí y
         ...      ‚îÇ
         xn ‚îÄ‚îÄwn‚îÄ‚îÄ‚îò

z = w1¬∑x1 + w2¬∑x2 + ... + wn¬∑xn + b
z = Œ£(wi¬∑xi) + b
y = f(z)  ‚Üê fonction d'activation
```

O√π :
- **x** = vecteur d'entr√©es (features)
- **w** = vecteur de poids (weights) ‚Äî ce que le r√©seau **apprend**
- **b** = biais (bias) ‚Äî un offset
- **f** = fonction d'activation (sigmoid, ReLU, etc.)
- **y** = sortie du neurone

### 3.3 Impl√©mentation Python from scratch

```python
import numpy as np

# Un neurone artificiel en 10 lignes
class Neurone:
    def __init__(self, n_entrees):
        # Initialisation al√©atoire des poids et du biais
        self.poids = np.random.randn(n_entrees)
        self.biais = np.random.randn()

    def sigmoid(self, z):
        """Fonction d'activation sigmoid"""
        return 1 / (1 + np.exp(-z))

    def forward(self, x):
        """Propagation avant : calcul de la sortie"""
        # Somme pond√©r√©e + biais
        z = np.dot(self.poids, x) + self.biais
        # Application de la fonction d'activation
        return self.sigmoid(z)

# Exemple d'utilisation
neurone = Neurone(n_entrees=3)
entree = np.array([0.5, 0.3, 0.8])
sortie = neurone.forward(entree)
print(f"Sortie du neurone : {sortie:.4f}")  # Valeur entre 0 et 1
```

> üí° **Conseil** : Ce code n'est PAS comment on fait du Deep Learning en pratique. C'est pour **comprendre** le m√©canisme. En vrai, PyTorch g√®re tout cela automatiquement.

---

## 4. üß© Le Perceptron et ses limites

### 4.1 Le Perceptron (1958)

Le perceptron est le plus simple des neurones artificiels : un **classifieur lin√©aire binaire**.

```python
import numpy as np

class Perceptron:
    def __init__(self, n_entrees, learning_rate=0.01):
        self.poids = np.zeros(n_entrees)
        self.biais = 0
        self.lr = learning_rate

    def predire(self, x):
        """Pr√©diction : 1 si somme pond√©r√©e > 0, sinon 0"""
        z = np.dot(self.poids, x) + self.biais
        return 1 if z > 0 else 0

    def entrainer(self, X, y, epochs=100):
        """Entra√Ænement par correction d'erreur"""
        for _ in range(epochs):
            for xi, yi in zip(X, y):
                prediction = self.predire(xi)
                erreur = yi - prediction
                # Mise √† jour des poids
                self.poids += self.lr * erreur * xi
                self.biais += self.lr * erreur

# Entra√Ænement sur AND logique
X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y_and = np.array([0, 0, 0, 1])

perceptron = Perceptron(n_entrees=2)
perceptron.entrainer(X, y_and)

# Test
for xi in X:
    print(f"{xi} ‚Üí {perceptron.predire(xi)}")
```

### 4.2 Le probl√®me XOR

Le perceptron ne peut r√©soudre que des probl√®mes **lin√©airement s√©parables**. Le XOR est le contre-exemple c√©l√®bre :

```
AND (s√©parable ‚úÖ)          XOR (NON s√©parable ‚ùå)

  1 ‚îÇ ‚óã   ‚óè                  1 ‚îÇ ‚óè   ‚óã
    ‚îÇ                           ‚îÇ
  0 ‚îÇ ‚óã   ‚óã                  0 ‚îÇ ‚óã   ‚óè
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      0   1                       0   1

On peut tracer une droite          Impossible de tracer UNE
s√©parant ‚óã et ‚óè                    droite s√©parant ‚óã et ‚óè
```

### 4.3 La solution : le Perceptron Multi-Couches (MLP)

En empilant plusieurs couches de neurones, on peut r√©soudre des probl√®mes non lin√©aires :

```
Entr√©e        Couche cach√©e       Sortie
  x1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí [n1] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚ï≤   ‚ï±              ‚îú‚îÄ‚îÄ‚Üí [n3] ‚îÄ‚îÄ‚Üí y
        ‚ï≤ ‚ï±               ‚îÇ
       ‚ï± ‚ï≤               ‚îú‚îÄ‚îÄ‚Üí
  x2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí [n2] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

C'est le **Multi-Layer Perceptron (MLP)**, aussi appel√© r√©seau **Fully Connected** ou **Dense**. C'est le fondement de tout le Deep Learning.

> ‚ö†Ô∏è **Attention** : Un r√©seau "profond" (deep) signifie qu'il a **plusieurs couches cach√©es**. C'est le "Deep" dans Deep Learning.

---

## 5. üèóÔ∏è Architectures fondamentales

### 5.1 Vue d'ensemble

```
                    Deep Learning
                         ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                ‚îÇ                ‚îÇ
       MLP              CNN              S√©quentiel
  (Fully Connected)  (Convolutions)       ‚îÇ
        ‚îÇ                ‚îÇ           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  Donn√©es tabulaires  Images        RNN/LSTM  Transformers
  Baseline simple     Vid√©o         (ancien)  (moderne)
                      M√©dical                  ‚îÇ
                                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                         NLP     Vision
                                         Audio   Multimodal
```

### 5.2 MLP (Multi-Layer Perceptron)

```
[x1] ‚îÄ‚îÄ‚Üí [h1] ‚îÄ‚îÄ‚Üí [h1'] ‚îÄ‚îÄ‚Üí [y1]
[x2] ‚îÄ‚îÄ‚Üí [h2] ‚îÄ‚îÄ‚Üí [h2'] ‚îÄ‚îÄ‚Üí [y2]
[x3] ‚îÄ‚îÄ‚Üí [h3] ‚îÄ‚îÄ‚Üí [h3']
[x4] ‚îÄ‚îÄ‚Üí [h4]

Entr√©e   Couche 1   Couche 2   Sortie
```

- **Architecture** : couches enti√®rement connect√©es (chaque neurone connect√© √† tous ceux de la couche suivante)
- **Usage** : donn√©es tabulaires, baseline, couches finales d'autres architectures
- **Limite** : pas de notion de structure spatiale ou temporelle

### 5.3 CNN (Convolutional Neural Networks)

```
Image ‚îÄ‚îÄ‚Üí [Conv] ‚îÄ‚îÄ‚Üí [Pool] ‚îÄ‚îÄ‚Üí [Conv] ‚îÄ‚îÄ‚Üí [Pool] ‚îÄ‚îÄ‚Üí [FC] ‚îÄ‚îÄ‚Üí Classe
          D√©tecte     R√©duit     D√©tecte     R√©duit    Classification
          les bords   la taille  les formes
```

- **Architecture** : filtres convolutifs qui glissent sur l'image
- **Usage** : images, vid√©o, imagerie m√©dicale
- **Avantage** : capture la structure spatiale (pixels voisins)
- **Mod√®les c√©l√®bres** : AlexNet, VGG, ResNet, EfficientNet

### 5.4 RNN / LSTM (Recurrent Neural Networks)

```
x1 ‚îÄ‚îÄ‚Üí [h] ‚îÄ‚îÄ‚Üí x2 ‚îÄ‚îÄ‚Üí [h] ‚îÄ‚îÄ‚Üí x3 ‚îÄ‚îÄ‚Üí [h] ‚îÄ‚îÄ‚Üí sortie
        ‚îÇ               ‚îÇ               ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ√©tat‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îî‚îÄ‚îÄ‚îÄ√©tat‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îî‚îÄ‚îÄ‚îÄ√©tat
```

- **Architecture** : boucle de r√©troaction (m√©moire des √©tapes pr√©c√©dentes)
- **Usage** : s√©ries temporelles, texte (historiquement)
- **Limite** : difficult√© avec les longues s√©quences (vanishing gradient)
- **LSTM** : version am√©lior√©e avec m√©canisme de portes (forget, input, output)

> ‚ö†Ô∏è **Attention** : Les RNN/LSTM sont aujourd'hui largement remplac√©s par les Transformers pour le NLP. Ils restent utiles pour certaines s√©ries temporelles.

### 5.5 Transformers

```
Entr√©e ‚îÄ‚îÄ‚Üí [Self-Attention] ‚îÄ‚îÄ‚Üí [Feed-Forward] ‚îÄ‚îÄ‚Üí Sortie
           "Quels mots sont      Transformation
            importants pour       non-lin√©aire
            comprendre ce mot ?"
```

- **Architecture** : m√©canisme d'attention (chaque √©l√©ment regarde tous les autres)
- **Usage** : NLP (BERT, GPT), vision (ViT), audio, multimodal
- **Avantage** : parall√©lisable (contrairement aux RNN), capture les d√©pendances longues
- **Mod√®les c√©l√®bres** : BERT, GPT-4, Claude, LLaMA, Mistral

### 5.6 Table comparative

| Architecture | Donn√©es typiques | Forces | Faiblesses | Exemple de mod√®le |
|-------------|------------------|--------|------------|-------------------|
| **MLP** | Tabulaires | Simple, baseline | Pas de structure | R√©seau dense |
| **CNN** | Images, vid√©o | Structure spatiale | Pas de s√©quences | ResNet, EfficientNet |
| **RNN/LSTM** | S√©quences | M√©moire temporelle | Lent, s√©q. longues | LSTM, GRU |
| **Transformer** | Tout (texte, image, audio) | Parall√®le, long-range | Co√ªteux en m√©moire | GPT, BERT, ViT |

---

## 6. ‚úÖ Quand utiliser le Deep Learning ?

### 6.1 Le DL est adapt√© quand...

- ‚úÖ **Images** : classification, d√©tection d'objets, segmentation
- ‚úÖ **Texte** : NLP, traduction, r√©sum√©, chatbots
- ‚úÖ **Audio** : reconnaissance vocale, musique, sons
- ‚úÖ **Vid√©o** : action recognition, tracking
- ‚úÖ **Donn√©es non structur√©es** en g√©n√©ral
- ‚úÖ **Grandes quantit√©s de donn√©es** (>10 000 samples)
- ‚úÖ **Features complexes** que l'humain ne sait pas concevoir

### 6.2 Le DL n'est PAS adapt√© quand...

- ‚ùå **Donn√©es tabulaires simples** ‚Üí scikit-learn ou XGBoost suffisent
- ‚ùå **Besoin d'interpr√©tabilit√© compl√®te** ‚Üí r√©gression logistique, arbre de d√©cision
- ‚ùå **Peu de donn√©es** (<1 000 samples) ‚Üí risque d'overfitting massif
- ‚ùå **Contraintes de latence extr√™mes** (mod√®le doit tourner en <1ms)
- ‚ùå **Pas de GPU disponible** ‚Üí l'entra√Ænement sera tr√®s lent
- ‚ùå **Budget limit√©** ‚Üí le co√ªt GPU peut √™tre significatif

### 6.3 Arbre de d√©cision : ML ou DL ?

```
Votre probl√®me
     ‚îÇ
     ‚îú‚îÄ‚îÄ Donn√©es tabulaires structur√©es ?
     ‚îÇ   ‚îú‚îÄ‚îÄ Oui ‚Üí XGBoost / Random Forest (ML classique)
     ‚îÇ   ‚îî‚îÄ‚îÄ Non ‚Üì
     ‚îÇ
     ‚îú‚îÄ‚îÄ Images, texte, audio, vid√©o ?
     ‚îÇ   ‚îú‚îÄ‚îÄ Oui ‚Üí Deep Learning ‚úÖ
     ‚îÇ   ‚îî‚îÄ‚îÄ Non ‚Üì
     ‚îÇ
     ‚îú‚îÄ‚îÄ Plus de 10 000 samples ?
     ‚îÇ   ‚îú‚îÄ‚îÄ Oui ‚Üí Deep Learning peut aider
     ‚îÇ   ‚îî‚îÄ‚îÄ Non ‚Üí ML classique probablement meilleur
     ‚îÇ
     ‚îî‚îÄ‚îÄ Besoin d'interpr√©tabilit√© ?
         ‚îú‚îÄ‚îÄ Oui ‚Üí ML classique (SHAP, LIME si DL n√©cessaire)
         ‚îî‚îÄ‚îÄ Non ‚Üí Deep Learning ‚úÖ
```

> üí° **Conseil de pro** : Avant de sortir PyTorch, demandez-vous toujours : "Est-ce qu'un XGBoost ne ferait pas le travail ?" Dans une comp√©tition Kaggle sur donn√©es tabulaires, XGBoost/LightGBM battent encore souvent le DL.

---

## 7. üõ†Ô∏è Les frameworks Deep Learning

### 7.1 PyTorch vs TensorFlow

| Crit√®re | PyTorch | TensorFlow |
|---------|---------|------------|
| **D√©veloppeur** | Meta (Facebook AI) | Google Brain |
| **Approche** | Define-by-run (dynamique) | Define-and-run ‚Üí Define-by-run (TF 2.x) |
| **Debugging** | Facile (Python natif) | Plus complexe |
| **Recherche** | Standard de facto (~80% des publications) | En d√©clin |
| **Production** | TorchServe, ONNX | TF Serving, TFLite (plus mature) |
| **Communaut√©** | En forte croissance | Grande mais stagnante |
| **Documentation** | Excellente | Bonne mais dispers√©e |
| **API haut niveau** | torch.nn | Keras (int√©gr√©) |
| **Mobile** | PyTorch Mobile | TFLite (plus mature) |
| **Courbe d'apprentissage** | Plus douce | Plus raide |

### 7.2 Pourquoi ce cours utilise PyTorch

1. **Standard en recherche** : 80%+ des publications NeurIPS/ICML utilisent PyTorch
2. **Pythonic** : le code PyTorch ressemble √† du Python standard
3. **Debug facile** : breakpoints, print() fonctionnent naturellement
4. **Communaut√© active** : plus de ressources, tutoriels, mod√®les pr√©-entra√Æn√©s
5. **Hugging Face** : l'√©cosyst√®me HF (Transformers, Datasets) est natif PyTorch

### 7.3 Autres frameworks

| Framework | Usage principal | Notes |
|-----------|----------------|-------|
| **Keras** | API haut niveau (int√©gr√© √† TF) | Excellent pour d√©buter, limit√© pour la recherche |
| **JAX** | Recherche avanc√©e (Google DeepMind) | Fonctionnel, JIT compilation, tr√®s performant |
| **ONNX** | Interop√©rabilit√© | Format d'√©change entre frameworks |
| **Hugging Face** | NLP, mod√®les pr√©-entra√Æn√©s | Bas√© sur PyTorch, incontournable |

> üí° **Conseil** : PyTorch est le standard en recherche et de plus en plus en production. TensorFlow reste fort en d√©ploiement mobile (TFLite). Apprenez PyTorch en premier, c'est le choix le plus polyvalent en 2024.

### 7.4 Installation rapide

```python
# Installation PyTorch (CPU)
# uv add torch torchvision torchaudio

# Installation PyTorch (GPU CUDA)
# uv add torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# V√©rification de l'installation
import torch

print(f"PyTorch version : {torch.__version__}")
print(f"CUDA disponible : {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU : {torch.cuda.get_device_name(0)}")
    print(f"M√©moire GPU : {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} Go")
else:
    print("Mode CPU uniquement (OK pour d√©buter)")
```

---

## 8. ‚ö° GPU et calcul

### 8.1 Pourquoi le GPU est essentiel

Le Deep Learning repose sur des **multiplications matricielles massives**. Le GPU excelle dans ce domaine gr√¢ce √† son **parall√©lisme massif** :

| Crit√®re | CPU | GPU |
|---------|-----|-----|
| **Coeurs** | 8-32 coeurs puissants | 1 000 - 16 000 coeurs simples |
| **Optimis√© pour** | T√¢ches s√©quentielles complexes | Calcul parall√®le massif |
| **Deep Learning** | Lent (heures ‚Üí jours) | Rapide (minutes ‚Üí heures) |
| **Multiplication matricielle** | S√©quentielle | Massivement parall√®le |

```
CPU (s√©quentiel) :          GPU (parall√®le) :
[A√óB] ‚Üí [C√óD] ‚Üí [E√óF]     [A√óB] [C√óD] [E√óF] ‚Üê tous en m√™me temps !
    Temps : 3 unit√©s             Temps : 1 unit√©
```

### 8.2 L'√©cosyst√®me GPU

- **NVIDIA CUDA** : plateforme de calcul GPU (standard de facto pour le DL)
- **cuDNN** : biblioth√®que optimis√©e pour les r√©seaux de neurones
- **NVIDIA A100, H100** : GPU de datacenter pour l'entra√Ænement
- **RTX 4090** : GPU grand public utilisable pour le DL
- **Apple Silicon (M1/M2/M3)** : Metal Performance Shaders (MPS) via PyTorch

### 8.3 Options pour d√©marrer sans investir

| Solution | GPU | Co√ªt | Dur√©e |
|----------|-----|------|-------|
| **Google Colab** | T4 (gratuit), A100 (payant) | Gratuit / 10‚Ç¨/mois | Sessions limit√©es |
| **Kaggle Notebooks** | T4 ou P100 | Gratuit | 30h GPU/semaine |
| **Lightning AI** | GPU vari√©s | Gratuit (limit√©) | Sessions |
| **AWS/GCP/Azure** | A100, H100 | ~2-10‚Ç¨/h | Illimit√© |
| **Lambda Labs** | A100, H100 | ~1-3‚Ç¨/h | Illimit√© |

> üí° **Conseil** : Pour d√©buter, Google Colab suffit largement. Pas besoin d'acheter un GPU ! Vous pouvez entra√Æner un CNN sur MNIST en quelques minutes avec un GPU gratuit.

### 8.4 V√©rifier et utiliser le GPU avec PyTorch

```python
import torch

# D√©tecter le device disponible
if torch.cuda.is_available():
    device = torch.device('cuda')
    print(f"Utilisation du GPU : {torch.cuda.get_device_name(0)}")
elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
    device = torch.device('mps')  # Apple Silicon
    print("Utilisation du GPU Apple Silicon (MPS)")
else:
    device = torch.device('cpu')
    print("Utilisation du CPU")

# Envoyer un tensor sur le GPU
x = torch.randn(1000, 1000).to(device)
y = torch.randn(1000, 1000).to(device)

# Le calcul s'effectue sur le GPU automatiquement
z = x @ y  # Multiplication matricielle sur GPU
print(f"R√©sultat sur : {z.device}")
```

> ‚ö†Ô∏è **Attention** : Tous les tensors d'un calcul doivent √™tre sur le **m√™me device**. Si le mod√®le est sur GPU mais les donn√©es sur CPU, vous aurez une erreur. Pensez toujours √† `.to(device)`.

---

## üìù Points cl√©s √† retenir

- Le Deep Learning **apprend automatiquement ses features**, contrairement au ML classique
- Un neurone artificiel calcule une **somme pond√©r√©e + activation**
- Le perceptron est limit√© aux probl√®mes lin√©aires ; le MLP r√©sout cette limitation
- **4 architectures fondamentales** : MLP, CNN, RNN/LSTM, Transformers
- Le DL excelle sur les donn√©es **non structur√©es** (images, texte, audio)
- Pour les donn√©es **tabulaires**, le ML classique (XGBoost) reste souvent meilleur
- **PyTorch** est le framework standard (recherche + production)
- Le **GPU** est essentiel pour l'entra√Ænement (Google Colab pour d√©buter)

## ‚úÖ Checklist de validation

- [ ] Je sais expliquer la diff√©rence entre ML classique et Deep Learning
- [ ] Je comprends le fonctionnement d'un neurone artificiel (weights, bias, activation)
- [ ] Je connais le probl√®me XOR et pourquoi il n√©cessite un MLP
- [ ] Je peux nommer les 4 architectures fondamentales et leurs cas d'usage
- [ ] Je sais quand utiliser le DL vs le ML classique
- [ ] J'ai install√© PyTorch et v√©rifi√© la disponibilit√© GPU
- [ ] Je comprends pourquoi le GPU est important pour le Deep Learning

---

**Prochain chapitre :** [02 - R√©seaux de neurones](./02-reseaux-neurones.md)

[Retour au sommaire](../README.md)
