# 03 - ReprÃ©sentations Textuelles

[â† 02 - Preprocessing](02-preprocessing-tokenisation.md) | [ğŸ  Accueil](README.md) | [04 - Embeddings â†’](04-word-embeddings.md)

---

## ğŸ”¢ Transformer le texte en nombres

Les algorithmes ne comprennent que les vecteurs numÃ©riques.

### ğŸ’ Bag of Words (BoW)
Compte simplement la frÃ©quence de chaque mot dans un document. Ne prend pas en compte l'ordre.

### âš–ï¸ TF-IDF
PondÃ¨re les mots pour donner plus d'importance aux mots rares et discriminants.
- **TF (Term Frequency)** : FrÃ©quence du mot dans le document.
- **IDF (Inverse Document Frequency)** : RaretÃ© du mot dans tout le corpus.

### ğŸ”— N-grams
Prend en compte des sÃ©quences de N mots consÃ©cutifs pour capturer un peu de contexte local (ex: Bigrams, Trigrams).

---

[â† 02 - Preprocessing](02-preprocessing-tokenisation.md) | [ğŸ  Accueil](README.md) | [04 - Embeddings â†’](04-word-embeddings.md)
