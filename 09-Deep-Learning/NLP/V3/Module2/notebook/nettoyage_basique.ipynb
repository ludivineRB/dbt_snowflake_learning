{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßπ Nettoyage Basique de Texte\n",
    "\n",
    "## Module 2 - Preprocessing et Tokenisation\n",
    "\n",
    "**Objectif :** Apprendre les techniques fondamentales de nettoyage de texte avec Python standard\n",
    "\n",
    "**Dur√©e estim√©e :** 45 minutes\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Ce que vous allez apprendre\n",
    "\n",
    "- ‚úÖ Normaliser la casse (majuscules/minuscules)\n",
    "- ‚úÖ Supprimer la ponctuation ind√©sirable  \n",
    "- ‚úÖ Nettoyer les URLs, emails et mentions\n",
    "- ‚úÖ G√©rer les espaces multiples\n",
    "- ‚úÖ Traiter les caract√®res sp√©ciaux\n",
    "- ‚úÖ Construire un pipeline de nettoyage simple\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Imports et Configuration\n",
    "\n",
    "Nous utilisons uniquement des modules Python standard :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modules import√©s avec succ√®s !\n"
     ]
    }
   ],
   "source": [
    "import re  # Pour les expressions r√©guli√®res\n",
    "import string  # Pour les caract√®res de ponctuation\n",
    "import unicodedata  # Pour la normalisation des caract√®res\n",
    "\n",
    "# Configuration pour un affichage plus joli\n",
    "def afficher_resultat(avant, apres, etape):\n",
    "    \"\"\"Fonction utilitaire pour afficher les transformations\"\"\"\n",
    "    print(f\"üîß {etape}\")\n",
    "    print(f\"   Avant : '{avant}'\")\n",
    "    print(f\"   Apr√®s : '{apres}'\")\n",
    "    print(f\"   Longueur : {len(avant)} ‚Üí {len(apres)} caract√®res\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"‚úÖ Modules import√©s avec succ√®s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Technique 1 : Normalisation de la Casse\n",
    "\n",
    "**Probl√®me :** \"SUPER\", \"Super\", \"super\" sont consid√©r√©s comme 3 mots diff√©rents\n",
    "\n",
    "**Solution :** Tout convertir en minuscules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî§ NORMALISATION DE LA CASSE\n",
      "\n",
      "Exemple 1:\n",
      "üîß Conversion en minuscules\n",
      "   Avant : 'BONJOUR COMMENT ALLEZ-VOUS ?'\n",
      "   Apr√®s : 'bonjour comment allez-vous ?'\n",
      "   Longueur : 28 ‚Üí 28 caract√®res\n",
      "--------------------------------------------------\n",
      "\n",
      "Exemple 2:\n",
      "üîß Conversion en minuscules\n",
      "   Avant : 'J'ADORE ce Produit G√âNIAL !!!'\n",
      "   Apr√®s : 'j'adore ce produit g√©nial !!!'\n",
      "   Longueur : 29 ‚Üí 29 caract√®res\n",
      "--------------------------------------------------\n",
      "\n",
      "Exemple 3:\n",
      "üîß Conversion en minuscules\n",
      "   Avant : 'Marie-Claire habite √Ä Paris'\n",
      "   Apr√®s : 'marie-claire habite √† paris'\n",
      "   Longueur : 27 ‚Üí 27 caract√®res\n",
      "--------------------------------------------------\n",
      "\n",
      "Exemple 4:\n",
      "üîß Conversion en minuscules\n",
      "   Avant : 'Le COVID-19 a chang√© nos HABITUDES'\n",
      "   Apr√®s : 'le covid-19 a chang√© nos habitudes'\n",
      "   Longueur : 34 ‚Üí 34 caract√®res\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exemples de textes avec diff√©rentes casses\n",
    "exemples_casse = [\n",
    "    \"BONJOUR COMMENT ALLEZ-VOUS ?\",\n",
    "    \"J'ADORE ce Produit G√âNIAL !!!\",\n",
    "    \"Marie-Claire habite √Ä Paris\",\n",
    "    \"Le COVID-19 a chang√© nos HABITUDES\"\n",
    "]\n",
    "\n",
    "print(\"üî§ NORMALISATION DE LA CASSE\\n\")\n",
    "\n",
    "for i, texte in enumerate(exemples_casse, 1):\n",
    "    texte_nettoye = texte.lower()\n",
    "    print(f\"Exemple {i}:\")\n",
    "    afficher_resultat(texte, texte_nettoye, \"Conversion en minuscules\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Attention aux Exceptions\n",
    "\n",
    "Parfois, la casse est importante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è CAS PROBL√âMATIQUES\n",
      "\n",
      "Original : US (√âtats-Unis) vs us (nous)\n",
      "Minuscules : us (√©tats-unis) vs us (nous)\n",
      "‚Üí Le sens peut changer !\n",
      "\n",
      "Original : WHO (OMS) vs who (qui)\n",
      "Minuscules : who (oms) vs who (qui)\n",
      "‚Üí Le sens peut changer !\n",
      "\n",
      "Original : Apple (entreprise) vs apple (pomme)\n",
      "Minuscules : apple (entreprise) vs apple (pomme)\n",
      "‚Üí Le sens peut changer !\n",
      "\n",
      "üí° Conseil : Pour la plupart des cas (sentiment, th√©matiques), les minuscules sont pr√©f√©rables\n"
     ]
    }
   ],
   "source": [
    "# Cas o√π la casse peut √™tre importante\n",
    "exemples_problematiques = [\n",
    "    \"US (√âtats-Unis) vs us (nous)\",\n",
    "    \"WHO (OMS) vs who (qui)\",\n",
    "    \"Apple (entreprise) vs apple (pomme)\"\n",
    "]\n",
    "\n",
    "print(\"‚ö†Ô∏è CAS PROBL√âMATIQUES\\n\")\n",
    "\n",
    "for exemple in exemples_problematiques:\n",
    "    print(f\"Original : {exemple}\")\n",
    "    print(f\"Minuscules : {exemple.lower()}\")\n",
    "    print(\"‚Üí Le sens peut changer !\\n\")\n",
    "\n",
    "print(\"üí° Conseil : Pour la plupart des cas (sentiment, th√©matiques), les minuscules sont pr√©f√©rables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Technique 2 : Suppression de la Ponctuation\n",
    "\n",
    "**Probl√®me :** \"super!\", \"super.\", \"super\" sont consid√©r√©s comme diff√©rents\n",
    "\n",
    "**Solutions :** Plusieurs approches possibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù SUPPRESSION DE LA PONCTUATION\n",
      "\n",
      "Texte original : 'Bonjour !!! Comment allez-vous ??? C'est g√©nial... N'est-ce pas ?'\n",
      "\n",
      "üîß M√©thode 1 : string.punctuation\n",
      "Caract√®res de ponctuation : !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "R√©sultat : 'Bonjour  Comment allezvous  Cest g√©nial Nestce pas '\n",
      "\n",
      "üîß M√©thode 2 : Regex simple\n",
      "R√©sultat : 'Bonjour  Comment allezvous  Cest g√©nial Nestce pas '\n",
      "\n",
      "üîß M√©thode 3 : Suppression s√©lective (garde les apostrophes)\n",
      "R√©sultat : 'Bonjour  Comment allezvous  C'est g√©nial N'estce pas '\n",
      "\n",
      "üí° Choisissez selon votre cas d'usage !\n"
     ]
    }
   ],
   "source": [
    "# Texte d'exemple avec beaucoup de ponctuation\n",
    "texte_ponctuation = \"Bonjour !!! Comment allez-vous ??? C'est g√©nial... N'est-ce pas ?\"\n",
    "\n",
    "print(\"üìù SUPPRESSION DE LA PONCTUATION\\n\")\n",
    "print(f\"Texte original : '{texte_ponctuation}'\\n\")\n",
    "\n",
    "# M√©thode 1 : Utiliser string.punctuation\n",
    "print(\"üîß M√©thode 1 : string.punctuation\")\n",
    "print(f\"Caract√®res de ponctuation : {string.punctuation}\")\n",
    "\n",
    "methode1 = texte_ponctuation.translate(str.maketrans('', '', string.punctuation))\n",
    "print(f\"R√©sultat : '{methode1}'\\n\")\n",
    "\n",
    "# M√©thode 2 : Expressions r√©guli√®res simples\n",
    "print(\"üîß M√©thode 2 : Regex simple\")\n",
    "methode2 = re.sub(r'[^\\w\\s]', '', texte_ponctuation)\n",
    "print(f\"R√©sultat : '{methode2}'\\n\")\n",
    "\n",
    "# M√©thode 3 : Suppression s√©lective\n",
    "print(\"üîß M√©thode 3 : Suppression s√©lective (garde les apostrophes)\")\n",
    "methode3 = re.sub(r\"[^\\w\\s']\", '', texte_ponctuation)\n",
    "print(f\"R√©sultat : '{methode3}'\\n\")\n",
    "\n",
    "print(\"üí° Choisissez selon votre cas d'usage !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Exercice Pratique : Testez vous-m√™me\n",
    "\n",
    "Modifiez le texte ci-dessous et testez les diff√©rentes m√©thodes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Votre texte : 'J'adore ce caf√© !!! Il co√ªte 3,50‚Ç¨... N'est-ce pas cher ???'\n",
      "\n",
      "üìä Comparaison des r√©sultats :\n",
      "M√©thode 1 : 'Jadore ce caf√©  Il co√ªte 350‚Ç¨ Nestce pas cher '\n",
      "M√©thode 2 : 'Jadore ce caf√©  Il co√ªte 350 Nestce pas cher '\n",
      "M√©thode 3 : 'J'adore ce caf√©  Il co√ªte 350 N'estce pas cher '\n",
      "\n",
      "ü§î R√©flexion : Quelle m√©thode pr√©servez-vous le mieux le sens ?\n"
     ]
    }
   ],
   "source": [
    "# üéØ EXERCICE : Modifiez ce texte pour tester\n",
    "votre_texte = \"J'adore ce caf√© !!! Il co√ªte 3,50‚Ç¨... N'est-ce pas cher ???\"\n",
    "\n",
    "print(f\"Votre texte : '{votre_texte}'\\n\")\n",
    "\n",
    "# Testez les 3 m√©thodes\n",
    "resultat1 = votre_texte.translate(str.maketrans('', '', string.punctuation))\n",
    "resultat2 = re.sub(r'[^\\w\\s]', '', votre_texte)\n",
    "resultat3 = re.sub(r\"[^\\w\\s']\", '', votre_texte)\n",
    "\n",
    "print(\"üìä Comparaison des r√©sultats :\")\n",
    "print(f\"M√©thode 1 : '{resultat1}'\")\n",
    "print(f\"M√©thode 2 : '{resultat2}'\")\n",
    "print(f\"M√©thode 3 : '{resultat3}'\")\n",
    "\n",
    "# Quelle m√©thode pr√©f√©rez-vous pour ce texte ?\n",
    "print(\"\\nü§î R√©flexion : Quelle m√©thode pr√©servez-vous le mieux le sens ?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Technique 3 : Nettoyage des URLs, Emails et Mentions\n",
    "\n",
    "**Probl√®me :** Les √©l√©ments web polluent l'analyse de sentiment\n",
    "\n",
    "**Solution :** Les supprimer ou les remplacer par des marqueurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê NETTOYAGE DES √âL√âMENTS WEB\n",
      "\n",
      "Texte original :\n",
      "'RT @marie_dupont: Super article sur https://example.com/article ! \n",
      "Contactez-moi sur marie@email.fr pour en discuter.\n",
      "Suivez @tech_news pour plus d'infos #NLP #IA'\n",
      "\n",
      "üîß √âtape 1 : Suppression des URLs\n",
      "üîß URLs supprim√©es\n",
      "   Avant : 'RT @marie_dupont: Super article sur https://example.com/article ! \n",
      "Contactez-moi sur marie@email.fr pour en discuter.\n",
      "Suivez @tech_news pour plus d'infos #NLP #IA'\n",
      "   Apr√®s : 'RT @marie_dupont: Super article sur  ! \n",
      "Contactez-moi sur marie@email.fr pour en discuter.\n",
      "Suivez @tech_news pour plus d'infos #NLP #IA'\n",
      "   Longueur : 162 ‚Üí 135 caract√®res\n",
      "--------------------------------------------------\n",
      "\n",
      "üîß √âtape 2 : Suppression des emails\n",
      "üîß Emails supprim√©s\n",
      "   Avant : 'RT @marie_dupont: Super article sur  ! \n",
      "Contactez-moi sur marie@email.fr pour en discuter.\n",
      "Suivez @tech_news pour plus d'infos #NLP #IA'\n",
      "   Apr√®s : 'RT @marie_dupont: Super article sur  ! \n",
      "Contactez-moi sur  pour en discuter.\n",
      "Suivez @tech_news pour plus d'infos #NLP #IA'\n",
      "   Longueur : 135 ‚Üí 121 caract√®res\n",
      "--------------------------------------------------\n",
      "\n",
      "üîß √âtape 3 : Suppression des mentions\n",
      "üîß Mentions supprim√©es\n",
      "   Avant : 'RT @marie_dupont: Super article sur  ! \n",
      "Contactez-moi sur  pour en discuter.\n",
      "Suivez @tech_news pour plus d'infos #NLP #IA'\n",
      "   Apr√®s : 'RT : Super article sur  ! \n",
      "Contactez-moi sur  pour en discuter.\n",
      "Suivez  pour plus d'infos #NLP #IA'\n",
      "   Longueur : 121 ‚Üí 98 caract√®res\n",
      "--------------------------------------------------\n",
      "\n",
      "üîß √âtape 4 : Suppression des hashtags\n",
      "üîß Hashtags supprim√©s\n",
      "   Avant : 'RT : Super article sur  ! \n",
      "Contactez-moi sur  pour en discuter.\n",
      "Suivez  pour plus d'infos #NLP #IA'\n",
      "   Apr√®s : 'RT : Super article sur  ! \n",
      "Contactez-moi sur  pour en discuter.\n",
      "Suivez  pour plus d'infos  '\n",
      "   Longueur : 98 ‚Üí 91 caract√®res\n",
      "--------------------------------------------------\n",
      "\n",
      "üîß √âtape 5 : Suppression des RT\n",
      "üîß RT supprim√©s\n",
      "   Avant : 'RT : Super article sur  ! \n",
      "Contactez-moi sur  pour en discuter.\n",
      "Suivez  pour plus d'infos  '\n",
      "   Apr√®s : ' : Super article sur  ! \n",
      "Contactez-moi sur  pour en discuter.\n",
      "Suivez  pour plus d'infos  '\n",
      "   Longueur : 91 ‚Üí 89 caract√®res\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Texte avec √©l√©ments web (simule un tweet ou post social)\n",
    "texte_web = \"\"\"\n",
    "RT @marie_dupont: Super article sur https://example.com/article ! \n",
    "Contactez-moi sur marie@email.fr pour en discuter.\n",
    "Suivez @tech_news pour plus d'infos #NLP #IA\n",
    "\"\"\".strip()\n",
    "\n",
    "print(\"üåê NETTOYAGE DES √âL√âMENTS WEB\\n\")\n",
    "print(f\"Texte original :\\n'{texte_web}'\\n\")\n",
    "\n",
    "# 1. Suppression des URLs\n",
    "print(\"üîß √âtape 1 : Suppression des URLs\")\n",
    "sans_urls = re.sub(r'https?://\\S+', '', texte_web)\n",
    "afficher_resultat(texte_web, sans_urls, \"URLs supprim√©es\")\n",
    "print()\n",
    "\n",
    "# 2. Suppression des emails\n",
    "print(\"üîß √âtape 2 : Suppression des emails\")\n",
    "sans_emails = re.sub(r'\\S+@\\S+', '', sans_urls)\n",
    "afficher_resultat(sans_urls, sans_emails, \"Emails supprim√©s\")\n",
    "print()\n",
    "\n",
    "# 3. Suppression des mentions (@)\n",
    "print(\"üîß √âtape 3 : Suppression des mentions\")\n",
    "sans_mentions = re.sub(r'@\\w+', '', sans_emails)\n",
    "afficher_resultat(sans_emails, sans_mentions, \"Mentions supprim√©es\")\n",
    "print()\n",
    "\n",
    "# 4. Suppression des hashtags\n",
    "print(\"üîß √âtape 4 : Suppression des hashtags\")\n",
    "sans_hashtags = re.sub(r'#\\w+', '', sans_mentions)\n",
    "afficher_resultat(sans_mentions, sans_hashtags, \"Hashtags supprim√©s\")\n",
    "print()\n",
    "\n",
    "# 5. Suppression des RT (retweets)\n",
    "print(\"üîß √âtape 5 : Suppression des RT\")\n",
    "texte_final = re.sub(r'\\bRT\\b', '', sans_hashtags)\n",
    "afficher_resultat(sans_hashtags, texte_final, \"RT supprim√©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîÑ Alternative : Remplacement par des Marqueurs\n",
    "\n",
    "Parfois, il est utile de garder l'information qu'un URL √©tait pr√©sent :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ REMPLACEMENT PAR DES MARQUEURS\n",
      "\n",
      "Texte original :\n",
      "'RT @marie_dupont: Super article sur https://example.com/article ! \n",
      "Contactez-moi sur marie@email.fr pour en discuter.\n",
      "Suivez @tech_news pour plus d'infos #NLP #IA'\n",
      "\n",
      "Avec marqueurs :\n",
      "'[RETWEET] [MENTION]: Super article sur [URL] ! \n",
      "Contactez-moi sur [EMAIL] pour en discuter.\n",
      "Suivez [MENTION] pour plus d'infos [HASHTAG] [HASHTAG]'\n",
      "\n",
      "üí° Avantage : On garde l'information qu'il y avait un URL, email, etc.\n"
     ]
    }
   ],
   "source": [
    "# Alternative : remplacer par des marqueurs\n",
    "print(\"üîÑ REMPLACEMENT PAR DES MARQUEURS\\n\")\n",
    "\n",
    "texte_avec_marqueurs = texte_web\n",
    "\n",
    "# Remplacements avec marqueurs\n",
    "texte_avec_marqueurs = re.sub(r'https?://\\S+', '[URL]', texte_avec_marqueurs)\n",
    "texte_avec_marqueurs = re.sub(r'\\S+@\\S+', '[EMAIL]', texte_avec_marqueurs)\n",
    "texte_avec_marqueurs = re.sub(r'@\\w+', '[MENTION]', texte_avec_marqueurs)\n",
    "texte_avec_marqueurs = re.sub(r'#\\w+', '[HASHTAG]', texte_avec_marqueurs)\n",
    "texte_avec_marqueurs = re.sub(r'\\bRT\\b', '[RETWEET]', texte_avec_marqueurs)\n",
    "\n",
    "print(f\"Texte original :\\n'{texte_web}'\\n\")\n",
    "print(f\"Avec marqueurs :\\n'{texte_avec_marqueurs}'\\n\")\n",
    "print(\"üí° Avantage : On garde l'information qu'il y avait un URL, email, etc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Technique 4 : Normalisation des Espaces\n",
    "\n",
    "**Probl√®me :** Espaces multiples, tabulations, retours √† la ligne parasites\n",
    "\n",
    "**Solution :** Normaliser tous les espaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìè NORMALISATION DES ESPACES\n",
      "\n",
      "Texte original (avec caract√®res visibles) :\n",
      "'Bonjour    comment\\tallez-vous ?\\n\\nTr√®s    bien   merci !'\n",
      "\n",
      "Texte affich√© normalement :\n",
      "'Bonjour    comment\tallez-vous ?\n",
      "\n",
      "Tr√®s    bien   merci !'\n",
      "\n",
      "üîß Normalisation en cours...\n",
      "üîß Espaces normalis√©s\n",
      "   Avant : 'Bonjour    comment\tallez-vous ?\n",
      "\n",
      "Tr√®s    bien   merci !'\n",
      "   Apr√®s : 'Bonjour comment allez-vous ? Tr√®s bien merci !'\n",
      "   Longueur : 55 ‚Üí 46 caract√®res\n",
      "--------------------------------------------------\n",
      "\n",
      "üìä Comparaison des longueurs :\n",
      "Avant : 55 caract√®res\n",
      "Apr√®s : 46 caract√®res\n",
      "√âconomie : 9 caract√®res\n"
     ]
    }
   ],
   "source": [
    "# Texte avec probl√®mes d'espaces\n",
    "texte_espaces = \"Bonjour    comment\\tallez-vous ?\\n\\nTr√®s    bien   merci !\"\n",
    "\n",
    "print(\"üìè NORMALISATION DES ESPACES\\n\")\n",
    "print(f\"Texte original (avec caract√®res visibles) :\")\n",
    "print(repr(texte_espaces))  # repr() montre les \\t et \\n\n",
    "print(f\"\\nTexte affich√© normalement :\")\n",
    "print(f\"'{texte_espaces}'\\n\")\n",
    "\n",
    "# Normalisation des espaces\n",
    "print(\"üîß Normalisation en cours...\")\n",
    "\n",
    "# √âtape 1 : Remplacer tous les types d'espaces par un espace simple\n",
    "espaces_normalises = re.sub(r'\\s+', ' ', texte_espaces)\n",
    "\n",
    "# √âtape 2 : Supprimer les espaces en d√©but et fin\n",
    "espaces_normalises = espaces_normalises.strip()\n",
    "\n",
    "afficher_resultat(texte_espaces, espaces_normalises, \"Espaces normalis√©s\")\n",
    "\n",
    "print(\"\\nüìä Comparaison des longueurs :\")\n",
    "print(f\"Avant : {len(texte_espaces)} caract√®res\")\n",
    "print(f\"Apr√®s : {len(espaces_normalises)} caract√®res\")\n",
    "print(f\"√âconomie : {len(texte_espaces) - len(espaces_normalises)} caract√®res\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Technique 5 : Gestion des Accents et Caract√®res Sp√©ciaux\n",
    "\n",
    "**Question :** Faut-il garder les accents fran√ßais ?\n",
    "\n",
    "**R√©ponse :** √áa d√©pend ! Voyons les options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî° GESTION DES ACCENTS\n",
      "\n",
      "Texte original : 'Caf√©, th√©√¢tre, h√¥tel, na√Øvet√©, No√´l, c≈ìur, ≈ìuf'\n",
      "\n",
      "‚úÖ Option 1 : Garder les accents\n",
      "R√©sultat : 'caf√©, th√©√¢tre, h√¥tel, na√Øvet√©, no√´l, c≈ìur, ≈ìuf'\n",
      "Avantage : Pr√©serve la richesse du fran√ßais\n",
      "\n",
      "üîÑ Option 2 : Supprimer les accents\n",
      "R√©sultat : 'cafe, theatre, hotel, naivete, noel, c≈ìur, ≈ìuf'\n",
      "Avantage : Plus simple pour certains algorithmes\n",
      "\n",
      "üîç Impact sur les mots :\n",
      "üìù caf√©, ‚Üí cafe,\n",
      "üìù th√©√¢tre, ‚Üí theatre,\n",
      "üìù h√¥tel, ‚Üí hotel,\n",
      "üìù na√Øvet√©, ‚Üí naivete,\n",
      "üìù no√´l, ‚Üí noel,\n",
      "‚ú® c≈ìur, ‚Üí c≈ìur,\n",
      "‚ú® ≈ìuf ‚Üí ≈ìuf\n",
      "\n",
      "üí° Recommandation : Gardez les accents pour le fran√ßais, sauf contrainte technique\n"
     ]
    }
   ],
   "source": [
    "# Texte avec accents fran√ßais\n",
    "texte_accents = \"Caf√©, th√©√¢tre, h√¥tel, na√Øvet√©, No√´l, c≈ìur, ≈ìuf\"\n",
    "\n",
    "print(\"üî° GESTION DES ACCENTS\\n\")\n",
    "print(f\"Texte original : '{texte_accents}'\\n\")\n",
    "\n",
    "# Option 1 : Garder les accents (recommand√© pour le fran√ßais)\n",
    "print(\"‚úÖ Option 1 : Garder les accents\")\n",
    "avec_accents = texte_accents.lower()\n",
    "print(f\"R√©sultat : '{avec_accents}'\")\n",
    "print(\"Avantage : Pr√©serve la richesse du fran√ßais\\n\")\n",
    "\n",
    "# Option 2 : Supprimer les accents\n",
    "print(\"üîÑ Option 2 : Supprimer les accents\")\n",
    "sans_accents = unicodedata.normalize('NFD', texte_accents.lower())\n",
    "sans_accents = ''.join(char for char in sans_accents if unicodedata.category(char) != 'Mn')\n",
    "print(f\"R√©sultat : '{sans_accents}'\")\n",
    "print(\"Avantage : Plus simple pour certains algorithmes\\n\")\n",
    "\n",
    "# Comparaison pratique\n",
    "print(\"üîç Impact sur les mots :\")\n",
    "mots_avec = avec_accents.split()\n",
    "mots_sans = sans_accents.split()\n",
    "\n",
    "for i, (avec, sans) in enumerate(zip(mots_avec, mots_sans)):\n",
    "    changement = \"üìù\" if avec != sans else \"‚ú®\"\n",
    "    print(f\"{changement} {avec} ‚Üí {sans}\")\n",
    "\n",
    "print(\"\\nüí° Recommandation : Gardez les accents pour le fran√ßais, sauf contrainte technique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Pipeline de Nettoyage Complet\n",
    "\n",
    "Combinons toutes les techniques dans une fonction r√©utilisable :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonction de nettoyage cr√©√©e !\n"
     ]
    }
   ],
   "source": [
    "def nettoyer_texte_basique(texte, \n",
    "                          minuscules=True,\n",
    "                          supprimer_ponctuation=True, \n",
    "                          supprimer_urls=True,\n",
    "                          supprimer_emails=True,\n",
    "                          supprimer_mentions=True,\n",
    "                          supprimer_hashtags=True,\n",
    "                          normaliser_espaces=True):\n",
    "    \"\"\"\n",
    "    Pipeline de nettoyage basique pour le texte fran√ßais.\n",
    "    \n",
    "    Args:\n",
    "        texte (str): Le texte √† nettoyer\n",
    "        minuscules (bool): Convertir en minuscules\n",
    "        supprimer_ponctuation (bool): Supprimer la ponctuation\n",
    "        supprimer_urls (bool): Supprimer les URLs\n",
    "        supprimer_emails (bool): Supprimer les emails\n",
    "        supprimer_mentions (bool): Supprimer les mentions (@)\n",
    "        supprimer_hashtags (bool): Supprimer les hashtags (#)\n",
    "        normaliser_espaces (bool): Normaliser les espaces\n",
    "    \n",
    "    Returns:\n",
    "        str: Texte nettoy√©\n",
    "    \"\"\"\n",
    "    resultat = texte\n",
    "    \n",
    "    # 1. Conversion en minuscules\n",
    "    if minuscules:\n",
    "        resultat = resultat.lower()\n",
    "    \n",
    "    # 2. Suppression des √©l√©ments web\n",
    "    if supprimer_urls:\n",
    "        resultat = re.sub(r'https?://\\S+', '', resultat)\n",
    "        resultat = re.sub(r'www\\.\\S+', '', resultat)\n",
    "    \n",
    "    if supprimer_emails:\n",
    "        resultat = re.sub(r'\\S+@\\S+', '', resultat)\n",
    "    \n",
    "    if supprimer_mentions:\n",
    "        resultat = re.sub(r'@\\w+', '', resultat)\n",
    "    \n",
    "    if supprimer_hashtags:\n",
    "        resultat = re.sub(r'#\\w+', '', resultat)\n",
    "    \n",
    "    # Suppression RT\n",
    "    resultat = re.sub(r'\\bRT\\b', '', resultat)\n",
    "    \n",
    "    # 3. Suppression de la ponctuation (garde les apostrophes pour le fran√ßais)\n",
    "    if supprimer_ponctuation:\n",
    "        resultat = re.sub(r\"[^\\w\\s']\", '', resultat)\n",
    "    \n",
    "    # 4. Normalisation des espaces\n",
    "    if normaliser_espaces:\n",
    "        resultat = re.sub(r'\\s+', ' ', resultat)\n",
    "        resultat = resultat.strip()\n",
    "    \n",
    "    return resultat\n",
    "\n",
    "print(\"‚úÖ Fonction de nettoyage cr√©√©e !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Test du Pipeline Complet\n",
    "\n",
    "Testons notre fonction sur diff√©rents types de textes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TEST DU PIPELINE COMPLET\n",
      "\n",
      "üìù Test 1:\n",
      "   Original : 'RT @user: SUPER article!!! https://bit.ly/xyz #amazing'\n",
      "   Nettoy√©  : 'rt super article'\n",
      "   R√©duction: 38 caract√®res (70.4%)\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Test 2:\n",
      "   Original : 'Bonjour !!! Comment allez-vous ??? C'est G√âNIAL...'\n",
      "   Nettoy√©  : 'bonjour comment allezvous c'est g√©nial'\n",
      "   R√©duction: 12 caract√®res (24.0%)\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Test 3:\n",
      "   Original : 'Contact: marie@email.fr ou    appelez le   01.23.45.67.89'\n",
      "   Nettoy√©  : 'contact ou appelez le 0123456789'\n",
      "   R√©duction: 25 caract√®res (43.9%)\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Test 4:\n",
      "   Original : 'J'adore ce caf√© ‚òï √† 3,50‚Ç¨ !!! N'est-ce pas cher ???'\n",
      "   Nettoy√©  : 'j'adore ce caf√© √† 350 n'estce pas cher'\n",
      "   R√©duction: 13 caract√®res (25.5%)\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Textes de test vari√©s\n",
    "textes_test = [\n",
    "    \"RT @user: SUPER article!!! https://bit.ly/xyz #amazing\",\n",
    "    \"Bonjour !!! Comment allez-vous ??? C'est G√âNIAL...\",\n",
    "    \"Contact: marie@email.fr ou    appelez le   01.23.45.67.89\",\n",
    "    \"J'adore ce caf√© ‚òï √† 3,50‚Ç¨ !!! N'est-ce pas cher ???\"\n",
    "]\n",
    "\n",
    "print(\"üß™ TEST DU PIPELINE COMPLET\\n\")\n",
    "\n",
    "for i, texte in enumerate(textes_test, 1):\n",
    "    print(f\"üìù Test {i}:\")\n",
    "    print(f\"   Original : '{texte}'\")\n",
    "    \n",
    "    # Nettoyage complet\n",
    "    nettoye = nettoyer_texte_basique(texte)\n",
    "    print(f\"   Nettoy√©  : '{nettoye}'\")\n",
    "    \n",
    "    # Statistiques\n",
    "    reduction = len(texte) - len(nettoye)\n",
    "    pourcentage = (reduction / len(texte)) * 100 if len(texte) > 0 else 0\n",
    "    print(f\"   R√©duction: {reduction} caract√®res ({pourcentage:.1f}%)\")\n",
    "    print(\"-\" * 60)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîß Test avec Options Personnalis√©es\n",
    "\n",
    "Voyons comment adapter le nettoyage selon le contexte :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß NETTOYAGE PERSONNALIS√â\n",
      "\n",
      "Texte : 'J'adore ce produit !!! Contact: info@boutique.fr #super'\n",
      "\n",
      "üé≠ Sc√©nario 1 : Analyse de sentiment\n",
      "R√©sultat : 'j'adore ce produit !!! contact:'\n",
      "üí° On garde les exclamations qui expriment l'√©motion\n",
      "\n",
      "üìä Sc√©nario 2 : Classification de texte\n",
      "R√©sultat : 'j'adore ce produit contact'\n",
      "üí° Focus sur les mots porteurs de sens\n",
      "\n",
      "üîç Sc√©nario 3 : Recherche\n",
      "R√©sultat : 'j'adore ce produit contact infofr super'\n",
      "üí° On garde les √©l√©ments qui peuvent √™tre recherch√©s\n"
     ]
    }
   ],
   "source": [
    "texte_exemple = \"J'adore ce produit !!! Contact: info@boutique.fr #super\"\n",
    "\n",
    "print(\"üîß NETTOYAGE PERSONNALIS√â\\n\")\n",
    "print(f\"Texte : '{texte_exemple}'\\n\")\n",
    "\n",
    "# Sc√©nario 1 : Analyse de sentiment (on garde plus d'infos)\n",
    "print(\"üé≠ Sc√©nario 1 : Analyse de sentiment\")\n",
    "sentiment = nettoyer_texte_basique(texte_exemple, \n",
    "                                  supprimer_emails=True,\n",
    "                                  supprimer_hashtags=True,\n",
    "                                  supprimer_ponctuation=False)  # On garde ! et ???\n",
    "print(f\"R√©sultat : '{sentiment}'\")\n",
    "print(\"üí° On garde les exclamations qui expriment l'√©motion\\n\")\n",
    "\n",
    "# Sc√©nario 2 : Classification de texte (nettoyage maximal)\n",
    "print(\"üìä Sc√©nario 2 : Classification de texte\")\n",
    "classification = nettoyer_texte_basique(texte_exemple)  # Tout nettoyer\n",
    "print(f\"R√©sultat : '{classification}'\")\n",
    "print(\"üí° Focus sur les mots porteurs de sens\\n\")\n",
    "\n",
    "# Sc√©nario 3 : Recherche (nettoyage mod√©r√©)\n",
    "print(\"üîç Sc√©nario 3 : Recherche\")\n",
    "recherche = nettoyer_texte_basique(texte_exemple,\n",
    "                                  supprimer_emails=False,  # Peut √™tre utile\n",
    "                                  supprimer_hashtags=False)  # Mots-cl√©s\n",
    "print(f\"R√©sultat : '{recherche}'\")\n",
    "print(\"üí° On garde les √©l√©ments qui peuvent √™tre recherch√©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Exercices Pratiques\n",
    "\n",
    "√Ä vous de jouer ! Testez vos comp√©tences :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1 : Nettoyage de Commentaires Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõí EXERCICE 1 : Nettoyage de commentaires clients\n",
      "\n",
      "üìù Votre mission : Nettoyer ces commentaires pour une analyse de sentiment\n",
      "\n",
      "Commentaire 1 :\n",
      "  Original : 'SUPER produit !!! Je le recommande √† 100% !!!'\n",
      "  Nettoy√©  : 'TODO: Votre nettoyage ici'\n",
      "\n",
      "Commentaire 2 :\n",
      "  Original : 'Bof... pas terrible üòï Service client = nul'\n",
      "  Nettoy√©  : 'TODO: Votre nettoyage ici'\n",
      "\n",
      "Commentaire 3 :\n",
      "  Original : 'Livraison rapide ! Contact: service@boutique.fr si probl√®me'\n",
      "  Nettoy√©  : 'TODO: Votre nettoyage ici'\n",
      "\n",
      "Commentaire 4 :\n",
      "  Original : 'Prix correct (29,99‚Ç¨) mais qualit√©    moyenne...'\n",
      "  Nettoy√©  : 'TODO: Votre nettoyage ici'\n",
      "\n",
      "Commentaire 5 :\n",
      "  Original : 'N'achetez PAS !!! ARNAQUE totale !!! #attention'\n",
      "  Nettoy√©  : 'TODO: Votre nettoyage ici'\n",
      "\n",
      "üí° Solution dans la cellule suivante !\n"
     ]
    }
   ],
   "source": [
    "# üéØ EXERCICE 1 : Commentaires clients e-commerce\n",
    "commentaires_clients = [\n",
    "    \"SUPER produit !!! Je le recommande √† 100% !!!\",\n",
    "    \"Bof... pas terrible üòï Service client = nul\",\n",
    "    \"Livraison rapide ! Contact: service@boutique.fr si probl√®me\",\n",
    "    \"Prix correct (29,99‚Ç¨) mais qualit√©    moyenne...\",\n",
    "    \"N'achetez PAS !!! ARNAQUE totale !!! #attention\"\n",
    "]\n",
    "\n",
    "print(\"üõí EXERCICE 1 : Nettoyage de commentaires clients\\n\")\n",
    "print(\"üìù Votre mission : Nettoyer ces commentaires pour une analyse de sentiment\\n\")\n",
    "\n",
    "# TODO: Nettoyez chaque commentaire\n",
    "# Conseil: Gardez les exclamations car elles expriment l'√©motion\n",
    "# Supprimez les emails et prix pour vous concentrer sur l'opinion\n",
    "\n",
    "for i, commentaire in enumerate(commentaires_clients, 1):\n",
    "    print(f\"Commentaire {i} :\")\n",
    "    print(f\"  Original : '{commentaire}'\")\n",
    "    \n",
    "    # üéØ VOTRE CODE ICI\n",
    "    # Utilisez la fonction nettoyer_texte_basique avec les bons param√®tres\n",
    "    commentaire_nettoye = \"TODO: Votre nettoyage ici\"\n",
    "    \n",
    "    print(f\"  Nettoy√©  : '{commentaire_nettoye}'\")\n",
    "    print()\n",
    "\n",
    "print(\"üí° Solution dans la cellule suivante !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SOLUTION EXERCICE 1\n",
      "\n",
      "Commentaire 1 :\n",
      "  Original : 'SUPER produit !!! Je le recommande √† 100% !!!'\n",
      "  Nettoy√©  : 'super produit !!! je le recommande √† 100% !!!'\n",
      "\n",
      "Commentaire 2 :\n",
      "  Original : 'Bof... pas terrible üòï Service client = nul'\n",
      "  Nettoy√©  : 'bof... pas terrible service client = nul'\n",
      "\n",
      "Commentaire 3 :\n",
      "  Original : 'Livraison rapide ! Contact: service@boutique.fr si probl√®me'\n",
      "  Nettoy√©  : 'livraison rapide ! contact: si probl√®me'\n",
      "\n",
      "Commentaire 4 :\n",
      "  Original : 'Prix correct (29,99‚Ç¨) mais qualit√©    moyenne...'\n",
      "  Nettoy√©  : 'prix correct () mais qualit√© moyenne...'\n",
      "\n",
      "Commentaire 5 :\n",
      "  Original : 'N'achetez PAS !!! ARNAQUE totale !!! #attention'\n",
      "  Nettoy√©  : 'n'achetez pas !!! arnaque totale !!!'\n",
      "\n",
      "üéØ Objectif atteint : Textes pr√™ts pour l'analyse de sentiment !\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ SOLUTION EXERCICE 1\n",
    "print(\"‚úÖ SOLUTION EXERCICE 1\\n\")\n",
    "\n",
    "for i, commentaire in enumerate(commentaires_clients, 1):\n",
    "    print(f\"Commentaire {i} :\")\n",
    "    print(f\"  Original : '{commentaire}'\")\n",
    "    \n",
    "    # Configuration optimale pour l'analyse de sentiment\n",
    "    commentaire_nettoye = nettoyer_texte_basique(\n",
    "        commentaire,\n",
    "        minuscules=True,\n",
    "        supprimer_ponctuation=False,  # Garder ! et ? pour l'√©motion\n",
    "        supprimer_emails=True,\n",
    "        supprimer_hashtags=True\n",
    "    )\n",
    "    \n",
    "    # Nettoyage suppl√©mentaire : supprimer prix et emojis\n",
    "    commentaire_nettoye = re.sub(r'\\d+[,.]\\d+‚Ç¨?', '', commentaire_nettoye)\n",
    "    commentaire_nettoye = re.sub(r'[üòïüòäüòçüò¢üò°]', '', commentaire_nettoye)\n",
    "    commentaire_nettoye = re.sub(r'\\s+', ' ', commentaire_nettoye).strip()\n",
    "    \n",
    "    print(f\"  Nettoy√©  : '{commentaire_nettoye}'\")\n",
    "    print()\n",
    "\n",
    "print(\"üéØ Objectif atteint : Textes pr√™ts pour l'analyse de sentiment !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2 : Analysez Vos Propres Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì± EXERCICE 2 : Analysez vos propres donn√©es\n",
      "\n",
      "Modifiez la liste ci-dessous avec vos propres textes :\n",
      "üìù Remplacez ce texte exemple par le v√¥tre : 'Ajoutez ici vos propres textes √† nettoyer'\n",
      "üìù Remplacez ce texte exemple par le v√¥tre : 'Par exemple des tweets, emails, ou commentaires'\n",
      "Texte 3 :\n",
      "  Original : 'Testez diff√©rents types de contenu !'\n",
      "  Nettoy√©  : 'testez diff√©rents types de contenu'\n",
      "  Mots     : 6 ‚Üí 5\n",
      "\n",
      "üí° Plus vous testez, mieux vous comprendrez les enjeux du nettoyage !\n"
     ]
    }
   ],
   "source": [
    "# üéØ EXERCICE 2 : Testez avec vos propres donn√©es\n",
    "print(\"üì± EXERCICE 2 : Analysez vos propres donn√©es\\n\")\n",
    "print(\"Modifiez la liste ci-dessous avec vos propres textes :\")\n",
    "\n",
    "# TODO: Remplacez par vos propres textes\n",
    "vos_textes = [\n",
    "    \"Ajoutez ici vos propres textes √† nettoyer\",\n",
    "    \"Par exemple des tweets, emails, ou commentaires\",\n",
    "    \"Testez diff√©rents types de contenu !\"\n",
    "]\n",
    "\n",
    "# Analysez vos textes\n",
    "for i, texte in enumerate(vos_textes, 1):\n",
    "    if texte.startswith(\"Ajoutez\") or texte.startswith(\"Par exemple\"):\n",
    "        print(f\"üìù Remplacez ce texte exemple par le v√¥tre : '{texte}'\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"Texte {i} :\")\n",
    "    print(f\"  Original : '{texte}'\")\n",
    "    \n",
    "    # Nettoyage standard\n",
    "    nettoye = nettoyer_texte_basique(texte)\n",
    "    print(f\"  Nettoy√©  : '{nettoye}'\")\n",
    "    \n",
    "    # Statistiques\n",
    "    mots_avant = len(texte.split())\n",
    "    mots_apres = len(nettoye.split())\n",
    "    print(f\"  Mots     : {mots_avant} ‚Üí {mots_apres}\")\n",
    "    print()\n",
    "\n",
    "print(\"üí° Plus vous testez, mieux vous comprendrez les enjeux du nettoyage !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä M√©triques et Validation\n",
    "\n",
    "Comment √©valuer la qualit√© de notre nettoyage ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ANALYSE DU NETTOYAGE\n",
      "\n",
      "Texte original : 'RT @user: SUPER article!!! https://bit.ly/xyz contact@email.fr #NLP #IA ??? üî•'\n",
      "Texte nettoy√©  : 'rt super article'\n",
      "\n",
      "üìà Statistiques :\n",
      "  Caract√®res : 77 ‚Üí 16 (-61)\n",
      "  Mots       : 10 ‚Üí 3 (-7)\n",
      "  R√©duction  : 79.2%\n",
      "\n",
      "üîç √âl√©ments d√©tect√©s dans l'original :\n",
      "  Urls : 1\n",
      "  Emails : 1\n",
      "  Mentions : 2\n",
      "  Hashtags : 2\n",
      "  Ponctuation : 17\n",
      "\n",
      "üí° Ces m√©triques vous aident √† valider votre nettoyage !\n"
     ]
    }
   ],
   "source": [
    "def analyser_nettoyage(texte_original, texte_nettoye):\n",
    "    \"\"\"\n",
    "    Analyse l'impact du nettoyage sur un texte.\n",
    "    \"\"\"\n",
    "    # Statistiques de base\n",
    "    stats = {\n",
    "        'caracteres_avant': len(texte_original),\n",
    "        'caracteres_apres': len(texte_nettoye),\n",
    "        'mots_avant': len(texte_original.split()),\n",
    "        'mots_apres': len(texte_nettoye.split()) if texte_nettoye.strip() else 0,\n",
    "    }\n",
    "    \n",
    "    # Calculs d√©riv√©s\n",
    "    stats['reduction_caracteres'] = stats['caracteres_avant'] - stats['caracteres_apres']\n",
    "    stats['reduction_mots'] = stats['mots_avant'] - stats['mots_apres']\n",
    "    stats['pourcentage_reduction'] = (stats['reduction_caracteres'] / stats['caracteres_avant']) * 100 if stats['caracteres_avant'] > 0 else 0\n",
    "    \n",
    "    # D√©tection d'√©l√©ments nettoy√©s\n",
    "    elements_detectes = {\n",
    "        'urls': len(re.findall(r'https?://\\S+', texte_original)),\n",
    "        'emails': len(re.findall(r'\\S+@\\S+', texte_original)),\n",
    "        'mentions': len(re.findall(r'@\\w+', texte_original)),\n",
    "        'hashtags': len(re.findall(r'#\\w+', texte_original)),\n",
    "        'ponctuation': len([c for c in texte_original if c in string.punctuation])\n",
    "    }\n",
    "    \n",
    "    return stats, elements_detectes\n",
    "\n",
    "# Test sur un √©chantillon\n",
    "texte_test = \"RT @user: SUPER article!!! https://bit.ly/xyz contact@email.fr #NLP #IA ??? üî•\"\n",
    "texte_test_nettoye = nettoyer_texte_basique(texte_test)\n",
    "\n",
    "stats, elements = analyser_nettoyage(texte_test, texte_test_nettoye)\n",
    "\n",
    "print(\"üìä ANALYSE DU NETTOYAGE\\n\")\n",
    "print(f\"Texte original : '{texte_test}'\")\n",
    "print(f\"Texte nettoy√©  : '{texte_test_nettoye}'\\n\")\n",
    "\n",
    "print(\"üìà Statistiques :\")\n",
    "print(f\"  Caract√®res : {stats['caracteres_avant']} ‚Üí {stats['caracteres_apres']} (-{stats['reduction_caracteres']})\")\n",
    "print(f\"  Mots       : {stats['mots_avant']} ‚Üí {stats['mots_apres']} (-{stats['reduction_mots']})\")\n",
    "print(f\"  R√©duction  : {stats['pourcentage_reduction']:.1f}%\\n\")\n",
    "\n",
    "print(\"üîç √âl√©ments d√©tect√©s dans l'original :\")\n",
    "for element, count in elements.items():\n",
    "    if count > 0:\n",
    "        print(f\"  {element.capitalize()} : {count}\")\n",
    "\n",
    "print(\"\\nüí° Ces m√©triques vous aident √† valider votre nettoyage !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì R√©sum√© et Bonnes Pratiques\n",
    "\n",
    "### ‚úÖ Ce que vous avez appris\n",
    "\n",
    "1. **Normalisation de la casse** : Unifier \"SUPER\" et \"super\"\n",
    "2. **Suppression de ponctuation** : Nettoyer tout en gardant le sens\n",
    "3. **Nettoyage web** : G√©rer URLs, emails, mentions, hashtags\n",
    "4. **Normalisation d'espaces** : √âliminer les espaces parasites\n",
    "5. **Gestion des accents** : Choisir selon le contexte\n",
    "6. **Pipeline modulaire** : Fonction r√©utilisable et configurable\n",
    "\n",
    "### üí° Bonnes Pratiques\n",
    "\n",
    "- **Adaptez au contexte** : Sentiment ‚â† Classification ‚â† Recherche\n",
    "- **Gardez l'original** : Toujours conserver une copie du texte brut\n",
    "- **Testez sur √©chantillons** : V√©rifiez manuellement quelques exemples\n",
    "- **Mesurez l'impact** : Utilisez des m√©triques pour valider\n",
    "- **Documentez vos choix** : Expliquez pourquoi vous gardez/supprimez\n",
    "\n",
    "### ‚ö†Ô∏è Pi√®ges √† √©viter\n",
    "\n",
    "- **Sur-nettoyage** : Ne pas supprimer trop d'informations utiles\n",
    "- **Sous-nettoyage** : Laisser du bruit qui nuit aux performances\n",
    "- **Ordre des op√©rations** : Nettoyer AVANT de tokeniser\n",
    "- **One-size-fits-all** : Adapter selon le type de texte\n",
    "\n",
    "### üöÄ Prochaines √©tapes\n",
    "\n",
    "Maintenant que vous ma√Ætrisez le nettoyage basique :\n",
    "\n",
    "1. **Tokenisation** : D√©couper le texte en mots intelligemment\n",
    "2. **Techniques avanc√©es** : Stopwords, lemmatisation, stemming\n",
    "3. **Pipeline complet** : Int√©grer toutes les √©tapes\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ F√©licitations !\n",
    "\n",
    "Vous ma√Ætrisez maintenant les fondamentaux du nettoyage de texte ! Ces comp√©tences sont essentielles pour tous vos projets NLP.\n",
    "\n",
    "**Pr√™t(e) pour la suite ?** Direction la tokenisation ! ‚úÇÔ∏è"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
