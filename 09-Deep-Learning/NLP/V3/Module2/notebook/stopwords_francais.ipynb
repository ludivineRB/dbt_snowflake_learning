{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üõë Gestion des Stopwords Fran√ßais\n",
        "\n",
        "**Module 2 - Preprocessing et Tokenisation**\n\n",
        "Dans ce notebook, nous allons explorer en d√©tail la gestion des stopwords (mots vides) en fran√ßais, comparer les approches NLTK et spaCy, et cr√©er nos propres listes personnalis√©es.\n",
        "\n",
        "## üìã Plan du Notebook\n",
        "\n",
        "1. **Introduction aux Stopwords**\n",
        "2. **Stopwords avec NLTK**\n",
        "3. **Stopwords avec spaCy**\n",
        "4. **Comparaison NLTK vs spaCy**\n",
        "5. **Stopwords Personnalis√©s**\n",
        "6. **Cas Pratiques**\n",
        "7. **Visualisations et Analyses**\n",
        "8. **Bonnes Pratiques**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Installation et Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Installation des packages n√©cessaires\n",
        "# !pip install nltk spacy matplotlib seaborn wordcloud\n",
        "# !python -m spacy download fr_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "import spacy\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "from typing import List, Set, Dict\n",
        "\n",
        "# Configuration pour les graphiques\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"‚úÖ Imports r√©alis√©s avec succ√®s !\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. üéØ Introduction aux Stopwords\n",
        "\n",
        "### Qu'est-ce qu'un stopword ?\n",
        "\n",
        "Un **stopword** (mot vide) est un mot tr√®s fr√©quent dans une langue mais qui apporte peu d'information s√©mantique pour l'analyse de texte.\n",
        "\n",
        "### Exemples en fran√ßais :\n",
        "- **Articles** : le, la, les, un, une, des\n",
        "- **Pr√©positions** : de, √†, dans, pour, avec, sur\n",
        "- **Pronoms** : je, tu, il, elle, nous, vous, ils, elles\n",
        "- **Conjonctions** : et, ou, mais, car, donc\n",
        "- **Auxiliaires** : √™tre, avoir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exemple d'impact des stopwords\n",
        "texte_exemple = \"\"\"\n",
        "Le chat noir mange des croquettes avec grand app√©tit dans le jardin ensoleill√©. \n",
        "Il est tr√®s content et ronronne de bonheur. Les oiseaux chantent dans les arbres \n",
        "pendant que le soleil brille de mille feux.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenisation simple\n",
        "mots = re.findall(r'\\w+', texte_exemple.lower())\n",
        "print(f\"üìù Texte original : {len(mots)} mots\")\n",
        "print(f\"Mots : {mots[:15]}...\\n\")\n",
        "\n",
        "# Comptage des fr√©quences\n",
        "frequences = Counter(mots)\n",
        "print(\"üîù Top 10 des mots les plus fr√©quents :\")\n",
        "for mot, freq in frequences.most_common(10):\n",
        "    print(f\"  '{mot}' : {freq} fois\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üí° Observation\n",
        "\n",
        "Comme vous pouvez le voir, les mots les plus fr√©quents sont souvent des mots grammaticaux peu informatifs. C'est exactement le probl√®me que les stopwords permettent de r√©soudre !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. üêç Stopwords avec NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# T√©l√©chargement des ressources NLTK\n",
        "nltk.download('stopwords', quiet=True)\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Obtenir les stopwords fran√ßais\n",
        "stopwords_nltk = set(stopwords.words('french'))\n",
        "\n",
        "print(f\"üìä NLTK fournit {len(stopwords_nltk)} stopwords fran√ßais\")\n",
        "print(f\"\\nüî§ √âchantillon de stopwords NLTK :\")\n",
        "print(sorted(list(stopwords_nltk))[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonction pour supprimer les stopwords avec NLTK\n",
        "def supprimer_stopwords_nltk(texte: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Supprime les stopwords d'un texte en utilisant NLTK.\n",
        "    \n",
        "    Args:\n",
        "        texte: Texte √† traiter\n",
        "    \n",
        "    Returns:\n",
        "        Liste des mots sans stopwords\n",
        "    \"\"\"\n",
        "    mots = re.findall(r'\\w+', texte.lower())\n",
        "    mots_filtres = [mot for mot in mots if mot not in stopwords_nltk]\n",
        "    return mots_filtres\n",
        "\n",
        "# Test sur notre exemple\n",
        "mots_sans_stopwords_nltk = supprimer_stopwords_nltk(texte_exemple)\n",
        "\n",
        "print(f\"üìä Statistiques avec NLTK :\")\n",
        "print(f\"  Mots originaux : {len(mots)}\")\n",
        "print(f\"  Mots apr√®s filtrage : {len(mots_sans_stopwords_nltk)}\")\n",
        "print(f\"  R√©duction : {(1 - len(mots_sans_stopwords_nltk)/len(mots))*100:.1f}%\")\n",
        "print(f\"\\nüéØ Mots conserv√©s : {mots_sans_stopwords_nltk[:15]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. ‚ö° Stopwords avec spaCy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chargement du mod√®le fran√ßais de spaCy\n",
        "try:\n",
        "    nlp = spacy.load(\"fr_core_news_sm\")\n",
        "    print(\"‚úÖ Mod√®le spaCy fran√ßais charg√© avec succ√®s\")\nexcept OSError:\n",
        "    print(\"‚ùå Mod√®le spaCy fran√ßais non trouv√©\")\n",
        "    print(\"   Ex√©cutez : python -m spacy download fr_core_news_sm\")\n",
        "    # Alternative : utiliser le mod√®le de base\n",
        "    nlp = spacy.load(\"fr_core_news_sm\")\n",
        "\n",
        "# Obtenir les stopwords de spaCy\n",
        "stopwords_spacy = nlp.Defaults.stop_words\n",
        "\n",
        "print(f\"\\nüìä spaCy fournit {len(stopwords_spacy)} stopwords fran√ßais\")\n",
        "print(f\"\\nüî§ √âchantillon de stopwords spaCy :\")\n",
        "print(sorted(list(stopwords_spacy))[:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonction pour supprimer les stopwords avec spaCy\n",
        "def supprimer_stopwords_spacy(texte: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Supprime les stopwords d'un texte en utilisant spaCy.\n",
        "    \n",
        "    Args:\n",
        "        texte: Texte √† traiter\n",
        "    \n",
        "    Returns:\n",
        "        Liste des mots sans stopwords\n",
        "    \"\"\"\n",
        "    doc = nlp(texte.lower())\n",
        "    mots_filtres = [token.text for token in doc \n",
        "                   if not token.is_stop and not token.is_punct and not token.is_space]\n",
        "    return mots_filtres\n",
        "\n",
        "# Test sur notre exemple\n",
        "mots_sans_stopwords_spacy = supprimer_stopwords_spacy(texte_exemple)\n",
        "\n",
        "print(f\"üìä Statistiques avec spaCy :\")\n",
        "print(f\"  Mots originaux : {len(mots)}\")\n",
        "print(f\"  Mots apr√®s filtrage : {len(mots_sans_stopwords_spacy)}\")\n",
        "print(f\"  R√©duction : {(1 - len(mots_sans_stopwords_spacy)/len(mots))*100:.1f}%\")\n",
        "print(f\"\\nüéØ Mots conserv√©s : {mots_sans_stopwords_spacy[:15]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. ‚öîÔ∏è Comparaison NLTK vs spaCy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyse comparative des listes de stopwords\n",
        "print(\"üîç ANALYSE COMPARATIVE DES STOPWORDS\\n\")\n",
        "\n",
        "# Statistiques de base\n",
        "print(f\"üìä Tailles des listes :\")\n",
        "print(f\"  NLTK : {len(stopwords_nltk)} mots\")\n",
        "print(f\"  spaCy : {len(stopwords_spacy)} mots\")\n",
        "\n",
        "# Intersections et diff√©rences\n",
        "communs = stopwords_nltk.intersection(stopwords_spacy)\n",
        "uniquement_nltk = stopwords_nltk - stopwords_spacy\n",
        "uniquement_spacy = stopwords_spacy - stopwords_nltk\n",
        "\n",
        "print(f\"\\nü§ù Mots communs : {len(communs)}\")\n",
        "print(f\"üêç Uniquement NLTK : {len(uniquement_nltk)}\")\n",
        "print(f\"‚ö° Uniquement spaCy : {len(uniquement_spacy)}\")\n",
        "\n",
        "print(f\"\\nüìù Exemples de diff√©rences :\")\n",
        "print(f\"  Uniquement NLTK : {sorted(list(uniquement_nltk))[:10]}\")\n",
        "print(f\"  Uniquement spaCy : {sorted(list(uniquement_spacy))[:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisation comparative\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Graphique en secteurs des intersections\n",
        "labels = ['Communs', 'NLTK seul', 'spaCy seul']\n",
        "sizes = [len(communs), len(uniquement_nltk), len(uniquement_spacy)]\n",
        "colors = ['#ff9999', '#66b3ff', '#99ff99']\n",
        "\n",
        "axes[0].pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
        "axes[0].set_title('ü•ß R√©partition des Stopwords', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Comparaison des longueurs de listes\n",
        "libraries = ['NLTK', 'spaCy', 'Communs']\n",
        "counts = [len(stopwords_nltk), len(stopwords_spacy), len(communs)]\n",
        "colors_bar = ['#ff7f0e', '#2ca02c', '#d62728']\n",
        "\n",
        "bars = axes[1].bar(libraries, counts, color=colors_bar, alpha=0.7)\n",
        "axes[1].set_title('üìä Nombre de Stopwords par Biblioth√®que', fontsize=14, fontweight='bold')\n",
        "axes[1].set_ylabel('Nombre de stopwords')\n",
        "\n",
        "# Ajout des valeurs sur les barres\n",
        "for bar, count in zip(bars, counts):\n",
        "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
        "                str(count), ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparaison sur plusieurs textes types\n",
        "textes_test = {\n",
        "    \"Article de presse\": \"\"\"\n",
        "    Le gouvernement fran√ßais a annonc√© hier de nouvelles mesures √©conomiques. \n",
        "    Ces d√©cisions, qui entreront en vigueur d√®s le mois prochain, visent √† \n",
        "    stimuler la croissance et √† r√©duire le ch√¥mage dans les r√©gions les plus touch√©es.\n",
        "    \"\"\",\n",
        "    \n",
        "    \"Avis client\": \"\"\"\n",
        "    Ce produit est vraiment g√©nial ! Je le recommande vivement √† tous ceux qui \n",
        "    cherchent quelque chose de fiable et d'efficace. Le service client est √©galement \n",
        "    tr√®s r√©actif et professionnel. Un excellent achat !\n",
        "    \"\"\",\n",
        "    \n",
        "    \"Tweet informel\": \"\"\"\n",
        "    Salut tout le monde ! Alors, qu'est-ce que vous pensez du nouveau film ? \n",
        "    Moi je l'ai trouv√© plut√¥t pas mal, mais bon, c'est pas non plus extraordinaire...\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "resultats_comparaison = []\n",
        "\n",
        "for titre, texte in textes_test.items():\n",
        "    mots_originaux = re.findall(r'\\w+', texte.lower())\n",
        "    mots_nltk = supprimer_stopwords_nltk(texte)\n",
        "    mots_spacy = supprimer_stopwords_spacy(texte)\n",
        "    \n",
        "    resultats_comparaison.append({\n",
        "        'Type': titre,\n",
        "        'Mots originaux': len(mots_originaux),\n",
        "        'Apr√®s NLTK': len(mots_nltk),\n",
        "        'Apr√®s spaCy': len(mots_spacy),\n",
        "        'R√©duction NLTK (%)': round((1 - len(mots_nltk)/len(mots_originaux))*100, 1),\n",
        "        'R√©duction spaCy (%)': round((1 - len(mots_spacy)/len(mots_originaux))*100, 1)\n",
        "    })\n",
        "\n",
        "df_comparaison = pd.DataFrame(resultats_comparaison)\n",
        "print(\"üìã COMPARAISON SUR DIFF√âRENTS TYPES DE TEXTES\\n\")\n",
        "print(df_comparaison.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. üéØ Stopwords Personnalis√©s\n",
        "\n",
        "Parfois, les listes pr√©d√©finies ne suffisent pas. Vous devez cr√©er vos propres listes selon :\n",
        "- **Le domaine** : m√©dical, juridique, technique...\n",
        "- **Le type de texte** : tweets, articles, emails...\n",
        "- **L'objectif** : sentiment, classification, extraction d'entit√©s..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cr√©ation de listes de stopwords personnalis√©es par domaine\n",
        "\n",
        "stopwords_domaines = {\n",
        "    'e-commerce': {\n",
        "        'produit', 'article', 'commande', 'livraison', 'client', 'service', \n",
        "        'achat', 'vente', 'prix', 'euros', 'boutique', 'magasin', 'site',\n",
        "        'avis', 'commentaire', 'note', '√©toiles'\n",
        "    },\n",
        "    \n",
        "    'm√©dical': {\n",
        "        'patient', 'm√©decin', 'docteur', 'traitement', 'maladie', 'sympt√¥me',\n",
        "        'diagnostic', 'h√¥pital', 'clinique', 'ordonnance', 'm√©dicament',\n",
        "        'consultation', 'examen', 'analyse'\n",
        "    },\n",
        "    \n",
        "    'r√©seaux_sociaux': {\n",
        "        'mdr', 'lol', 'ptdr', 'jsp', 'slt', 'bjr', 'bsr', 'cv', 'oui', 'non',\n",
        "        'ouais', 'genre', 'style', 'truc', 'machin', 'chose', '√ßa', 'ca'\n",
        "    },\n",
        "    \n",
        "    'actualit√©s': {\n",
        "        'selon', '√©galement', 'notamment', 'toutefois', 'cependant', 'n√©anmoins',\n",
        "        'par ailleurs', 'en effet', 'ainsi', 'donc', 'enfin', 'finalement'\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"üéØ STOPWORDS PERSONNALIS√âS PAR DOMAINE\\n\")\n",
        "for domaine, mots in stopwords_domaines.items():\n",
        "    print(f\"üìÇ {domaine.upper()} ({len(mots)} mots) :\")\n",
        "    print(f\"   {', '.join(sorted(list(mots))[:8])}...\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Classe pour g√©rer les stopwords personnalis√©s\n",
        "class StopwordsPersonnalises:\n",
        "    def __init__(self, base='nltk'):\n",
        "        \"\"\"\n",
        "        Initialise avec une base de stopwords (nltk ou spacy).\n",
        "        \"\"\"\n",
        "        if base == 'nltk':\n",
        "            self.stopwords = set(stopwords.words('french'))\n",
        "        elif base == 'spacy':\n",
        "            self.stopwords = nlp.Defaults.stop_words.copy()\n",
        "        else:\n",
        "            self.stopwords = set()\n",
        "    \n",
        "    def ajouter_domaine(self, domaine: str) -> None:\n",
        "        \"\"\"\n",
        "        Ajoute les stopwords d'un domaine sp√©cifique.\n",
        "        \"\"\"\n",
        "        if domaine in stopwords_domaines:\n",
        "            self.stopwords.update(stopwords_domaines[domaine])\n",
        "            print(f\"‚úÖ Stopwords du domaine '{domaine}' ajout√©s\")\n",
        "        else:\n",
        "            print(f\"‚ùå Domaine '{domaine}' non reconnu\")\n",
        "    \n",
        "    def ajouter_mots(self, mots: List[str]) -> None:\n",
        "        \"\"\"\n",
        "        Ajoute une liste de mots personnalis√©s.\n",
        "        \"\"\"\n",
        "        self.stopwords.update(mots)\n",
        "        print(f\"‚úÖ {len(mots)} mots ajout√©s aux stopwords\")\n",
        "    \n",
        "    def supprimer_mots(self, mots: List[str]) -> None:\n",
        "        \"\"\"\n",
        "        Supprime des mots de la liste des stopwords.\n",
        "        \"\"\"\n",
        "        self.stopwords -= set(mots)\n",
        "        print(f\"‚úÖ {len(mots)} mots supprim√©s des stopwords\")\n",
        "    \n",
        "    def filtrer_texte(self, texte: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Filtre un texte en supprimant les stopwords.\n",
        "        \"\"\"\n",
        "        mots = re.findall(r'\\w+', texte.lower())\n",
        "        return [mot for mot in mots if mot not in self.stopwords]\n",
        "    \n",
        "    def statistiques(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Retourne des statistiques sur les stopwords.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'total': len(self.stopwords),\n",
        "            'longueur_moyenne': sum(len(mot) for mot in self.stopwords) / len(self.stopwords),\n",
        "            'mot_plus_long': max(self.stopwords, key=len),\n",
        "            'mot_plus_court': min(self.stopwords, key=len)\n",
        "        }\n",
        "\n",
        "# Exemple d'utilisation\n",
        "print(\"üõ†Ô∏è CR√âATION D'UN GESTIONNAIRE PERSONNALIS√â\\n\")\n",
        "\n",
        "# Gestionnaire pour e-commerce\n",
        "stopwords_ecommerce = StopwordsPersonnalises(base='nltk')\n",
        "stopwords_ecommerce.ajouter_domaine('e-commerce')\n",
        "stopwords_ecommerce.ajouter_mots(['vraiment', 'super', 'tr√®s', 'assez', 'plut√¥t'])\n",
        "\n",
        "print(f\"\\nüìä Statistiques : {stopwords_ecommerce.statistiques()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. üß™ Cas Pratiques\n",
        "\n",
        "Testons nos diff√©rentes approches sur des textes r√©els de diff√©rents domaines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Textes d'exemple pour les cas pratiques\n",
        "cas_pratiques = {\n",
        "    \"Avis e-commerce\": \"\"\"\n",
        "    Ce produit est vraiment g√©nial ! La livraison a √©t√© super rapide et le service client \n",
        "    tr√®s r√©actif. Je recommande vivement cet article √† tous ceux qui cherchent de la qualit√©. \n",
        "    Excellent rapport qualit√© prix ! 5 √©toiles sans h√©siter.\n",
        "    \"\"\",\n",
        "    \n",
        "    \"Tweet informel\": \"\"\"\n",
        "    Salut les amis ! Alors, qu'est-ce que vous pensez du dernier √©pisode ? \n",
        "    Moi jsp, j'ai trouv√© √ßa plut√¥t bizarre... Genre, c'√©tait pas mal mais bon, \n",
        "    √ßa manquait un peu de rythme non ? Bref, dites-moi vos avis !\n",
        "    \"\"\",\n",
        "    \n",
        "    \"Article m√©dical\": \"\"\"\n",
        "    Le patient pr√©sente des sympt√¥mes caract√©ristiques de cette pathologie. \n",
        "    Le m√©decin recommande un traitement adapt√© avec surveillance r√©guli√®re. \n",
        "    L'examen clinique r√©v√®le des signes compatibles avec le diagnostic initial.\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "# Test avec diff√©rentes configurations\n",
        "configurations = {\n",
        "    'Standard NLTK': StopwordsPersonnalises(base='nltk'),\n",
        "    'Standard spaCy': StopwordsPersonnalises(base='spacy'),\n",
        "    'E-commerce': StopwordsPersonnalises(base='nltk'),\n",
        "    'R√©seaux sociaux': StopwordsPersonnalises(base='nltk'),\n",
        "    'M√©dical': StopwordsPersonnalises(base='nltk')\n",
        "}\n",
        "\n",
        "# Configuration des gestionnaires sp√©cialis√©s\n",
        "configurations['E-commerce'].ajouter_domaine('e-commerce')\n",
        "configurations['R√©seaux sociaux'].ajouter_domaine('r√©seaux_sociaux')\n",
        "configurations['M√©dical'].ajouter_domaine('m√©dical')\n",
        "\n",
        "print(\"üß™ CAS PRATIQUES - COMPARAISON DES APPROCHES\\n\")\n",
        "\n",
        "for titre_texte, texte in cas_pratiques.items():\n",
        "    print(f\"üìÑ {titre_texte.upper()}\")\n",
        "    print(f\"Texte : {texte.strip()[:100]}...\\n\")\n",
        "    \n",
        "    mots_originaux = re.findall(r'\\w+', texte.lower())\n",
        "    \n",
        "    for nom_config, gestionnaire in configurations.items():\n",
        "        mots_filtres = gestionnaire.filtrer_texte(texte)\n",
        "        reduction = (1 - len(mots_filtres)/len(mots_originaux)) * 100\n",
        "        \n",
        "        print(f\"  {nom_config:20s} : {len(mots_filtres):2d} mots ({reduction:5.1f}% r√©duction)\")\n",
        "        print(f\"  {'':22s} ‚Üí {mots_filtres[:8]}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. üìä Visualisations et Analyses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyse de l'impact des stopwords sur un corpus plus large\n",
        "corpus_exemple = [\n",
        "    \"Ce produit est vraiment excellent, je le recommande vivement √† tous mes amis.\",\n",
        "    \"Service client d√©cevant, j'ai attendu plus d'une heure au t√©l√©phone sans r√©ponse.\",\n",
        "    \"La livraison √©tait rapide mais l'emballage √©tait ab√Æm√© √† l'arriv√©e.\",\n",
        "    \"Tr√®s satisfait de mon achat, la qualit√© est au rendez-vous comme toujours.\",\n",
        "    \"Prix un peu √©lev√© mais la qualit√© justifie largement cet investissement.\",\n",
        "    \"Interface utilisateur intuitive et design moderne, parfait pour mon usage quotidien.\",\n",
        "    \"Probl√®me technique r√©current, le support n'arrive pas √† r√©soudre le dysfonctionnement.\",\n",
        "    \"Excellente alternative aux produits concurrents, rapport qualit√©-prix imbattable.\"\n",
        "]\n",
        "\n",
        "# Analyse avant/apr√®s pour chaque phrase\n",
        "resultats_analyse = []\n",
        "\n",
        "for i, phrase in enumerate(corpus_exemple):\n",
        "    mots_originaux = re.findall(r'\\w+', phrase.lower())\n",
        "    mots_sans_stopwords = supprimer_stopwords_nltk(phrase)\n",
        "    \n",
        "    resultats_analyse.append({\n",
        "        'Phrase': i + 1,\n",
        "        'Mots_originaux': len(mots_originaux),\n",
        "        'Mots_filtres': len(mots_sans_stopwords),\n",
        "        'Reduction_pct': (1 - len(mots_sans_stopwords)/len(mots_originaux)) * 100\n",
        "    })\n",
        "\n",
        "df_analyse = pd.DataFrame(resultats_analyse)\n",
        "\n",
        "# Visualisation\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Graphique 1: R√©duction par phrase\n",
        "axes[0,0].bar(df_analyse['Phrase'], df_analyse['Reduction_pct'], \n",
        "              color='skyblue', alpha=0.7, edgecolor='darkblue')\n",
        "axes[0,0].set_title('üìâ R√©duction du vocabulaire par phrase', fontweight='bold')\n",
        "axes[0,0].set_xlabel('Num√©ro de phrase')\n",
        "axes[0,0].set_ylabel('R√©duction (%)')\n",
        "axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "# Graphique 2: Comparaison avant/apr√®s\n",
        "x = df_analyse['Phrase']\n",
        "width = 0.35\n",
        "axes[0,1].bar(x - width/2, df_analyse['Mots_originaux'], width, \n",
        "              label='Avant', color='lightcoral', alpha=0.7)\n",
        "axes[0,1].bar(x + width/2, df_analyse['Mots_filtres'], width, \n",
        "              label='Apr√®s', color='lightgreen', alpha=0.7)\n",
        "axes[0,1].set_title('üìä Nombre de mots avant/apr√®s filtrage', fontweight='bold')\n",
        "axes[0,1].set_xlabel('Num√©ro de phrase')\n",
        "axes[0,1].set_ylabel('Nombre de mots')\n",
        "axes[0,1].legend()\n",
        "axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "# Graphique 3: Distribution des r√©ductions\n",
        "axes[1,0].hist(df_analyse['Reduction_pct'], bins=6, color='gold', alpha=0.7, \n",
        "               edgecolor='darkorange', rwidth=0.8)\n",
        "axes[1,0].set_title('üìà Distribution des taux de r√©duction', fontweight='bold')\n",
        "axes[1,0].set_xlabel('R√©duction (%)')\n",
        "axes[1,0].set_ylabel('Nombre de phrases')\n",
        "axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "# Graphique 4: Statistiques globales\n",
        "stats = ['Mots totaux\\navant', 'Mots totaux\\napr√®s', 'R√©duction\\nmoyenne (%)']\n",
        "values = [df_analyse['Mots_originaux'].sum(), \n",
        "          df_analyse['Mots_filtres'].sum(),\n",
        "          df_analyse['Reduction_pct'].mean()]\n",
        "colors = ['lightblue', 'lightgreen', 'lightyellow']\n",
        "\n",
        "bars = axes[1,1].bar(stats, values, color=colors, alpha=0.7, \n",
        "                     edgecolor=['darkblue', 'darkgreen', 'orange'])\n",
        "axes[1,1].set_title('üìã Statistiques globales', fontweight='bold')\n",
        "\n",
        "# Ajout des valeurs sur les barres\n",
        "for bar, value in zip(bars, values):\n",
        "    height = bar.get_height()\n",
        "    axes[1,1].text(bar.get_x() + bar.get_width()/2., height + max(values)*0.01,\n",
        "                   f'{value:.1f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä R√âSUM√â DE L'ANALYSE :\")\n",
        "print(f\"  üí° R√©duction moyenne : {df_analyse['Reduction_pct'].mean():.1f}%\")\n",
        "print(f\"  üìâ R√©duction minimale : {df_analyse['Reduction_pct'].min():.1f}%\")\n",
        "print(f\"  üìà R√©duction maximale : {df_analyse['Reduction_pct'].max():.1f}%\")\n",
        "print(f\"  üéØ Mots √©conomis√©s : {df_analyse['Mots_originaux'].sum() - df_analyse['Mots_filtres'].sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Nuage de mots des stopwords les plus courants\n",
        "try:\n",
        "    # Combinaison des stopwords NLTK et spaCy\n",
        "    tous_stopwords = stopwords_nltk.union(stopwords_spacy)\n",
        "    \n",
        "    # Cr√©ation du nuage de mots\n",
        "    texte_stopwords = ' '.join(tous_stopwords)\n",
        "    \n",
        "    wordcloud = WordCloud(\n",
        "        width=800, height=400, \n",
        "        background_color='white',\n",
        "        colormap='viridis',\n",
        "        max_words=100,\n",
        "        relative_scaling=0.5,\n",
        "        random_state=42\n",
        "    ).generate(texte_stopwords)\n",
        "    \n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.title('‚òÅÔ∏è Nuage de Mots des Stopwords Fran√ßais', \n",
        "              fontsize=16, fontweight='bold', pad=20)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \nexcept ImportError:\n",
        "    print(\"‚ùå WordCloud non disponible. Installez avec : pip install wordcloud\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. üí° Bonnes Pratiques\n",
        "\n",
        "### ‚úÖ √Ä FAIRE\n",
        "\n",
        "1. **Adapter au contexte** : Utiliser des stopwords sp√©cifiques au domaine\n",
        "2. **Tester l'impact** : Mesurer l'effet sur les performances finales\n",
        "3. **Documenter les choix** : Justifier pourquoi tel mot est consid√©r√© comme stopword\n",
        "4. **√ätre it√©ratif** : Ajuster la liste selon les r√©sultats obtenus\n",
        "5. **Conserver l'original** : Toujours garder une copie du texte non filtr√©\n",
        "\n",
        "### ‚ùå √Ä √âVITER\n",
        "\n",
        "1. **Sur-filtrage** : Supprimer trop de mots importants\n",
        "2. **One-size-fits-all** : Utiliser la m√™me liste pour tous les cas\n",
        "3. **Ignorer le contexte** : Un mot peut √™tre stopword dans un cas mais pas dans un autre\n",
        "4. **Oublier la casse** : G√©rer les majuscules/minuscules\n",
        "5. **Ne pas valider** : V√©rifier manuellement les r√©sultats sur un √©chantillon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fonction utilitaire finale pour l'analyse de stopwords\n",
        "def analyser_impact_stopwords(texte: str, stopwords_list: Set[str] = None) -> Dict:\n",
        "    \"\"\"\n",
        "    Analyse l'impact de la suppression des stopwords sur un texte.\n",
        "    \n",
        "    Args:\n",
        "        texte: Texte √† analyser\n",
        "        stopwords_list: Liste des stopwords (d√©faut: NLTK fran√ßais)\n",
        "    \n",
        "    Returns:\n",
        "        Dictionnaire avec les statistiques d'impact\n",
        "    \"\"\"\n",
        "    if stopwords_list is None:\n",
        "        stopwords_list = set(stopwords.words('french'))\n",
        "    \n",
        "    # Tokenisation\n",
        "    mots_originaux = re.findall(r'\\w+', texte.lower())\n",
        "    mots_filtres = [mot for mot in mots_originaux if mot not in stopwords_list]\n",
        "    \n",
        "    # Identification des stopwords supprim√©s\n",
        "    stopwords_trouves = [mot for mot in mots_originaux if mot in stopwords_list]\n",
        "    \n",
        "    # Calcul des statistiques\n",
        "    reduction_pct = (1 - len(mots_filtres)/len(mots_originaux)) * 100 if mots_originaux else 0\n",
        "    \n",
        "    return {\n",
        "        'mots_originaux': len(mots_originaux),\n",
        "        'mots_apres_filtrage': len(mots_filtres),\n",
        "        'stopwords_supprimes': len(stopwords_trouves),\n",
        "        'reduction_pourcentage': round(reduction_pct, 1),\n",
        "        'stopwords_uniques': len(set(stopwords_trouves)),\n",
        "        'mots_conserves': mots_filtres[:10],  # √âchantillon\n",
        "        'stopwords_liste': list(set(stopwords_trouves))[:10]  # √âchantillon\n",
        "    }\n",
        "\n",
        "# Test de la fonction\n",
        "texte_test = \"\"\"\n",
        "Le service client de cette entreprise est vraiment excellent. J'ai √©t√© tr√®s \n",
        "satisfait de ma commande et je recommande vivement ce produit √† tous ceux qui \n",
        "cherchent de la qualit√©. Le rapport qualit√©-prix est imbattable !\n",
        "\"\"\"\n",
        "\n",
        "analyse = analyser_impact_stopwords(texte_test)\n",
        "\n",
        "print(\"üîç ANALYSE D√âTAILL√âE D'IMPACT\\n\")\n",
        "print(f\"üìä Statistiques :\")\n",
        "print(f\"  ‚Ä¢ Mots originaux : {analyse['mots_originaux']}\")\n",
        "print(f\"  ‚Ä¢ Mots apr√®s filtrage : {analyse['mots_apres_filtrage']}\")\n",
        "print(f\"  ‚Ä¢ Stopwords supprim√©s : {analyse['stopwords_supprimes']}\")\n",
        "print(f\"  ‚Ä¢ R√©duction : {analyse['reduction_pourcentage']}%\")\n",
        "print(f\"  ‚Ä¢ Stopwords uniques trouv√©s : {analyse['stopwords_uniques']}\")\n",
        "\n",
        "print(f\"\\nüéØ √âchantillon de mots conserv√©s :\")\n",
        "print(f\"  {', '.join(analyse['mots_conserves'])}\")\n",
        "\n",
        "print(f\"\\nüõë Stopwords trouv√©s dans le texte :\")\n",
        "print(f\"  {', '.join(analyse['stopwords_liste'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Conclusion\n",
        "\n",
        "### Ce que vous avez appris :\n",
        "\n",
        "‚úÖ **Comprendre** le r√¥le des stopwords dans le preprocessing  \n",
        "‚úÖ **Utiliser** NLTK et spaCy pour la gestion des stopwords fran√ßais  \n",
        "‚úÖ **Comparer** les diff√©rentes approches et leurs avantages  \n",
        "‚úÖ **Cr√©er** des listes personnalis√©es selon le domaine  \n",
        "‚úÖ **Analyser** l'impact des stopwords sur vos donn√©es  \n",
        "‚úÖ **Visualiser** les r√©sultats et optimiser vos choix  \n",
        "\n",
        "### Prochaines √©tapes :\n",
        "\n",
        "üéØ **Lemmatisation et Stemming** : R√©duction des mots √† leur forme canonique  \n",
        "üéØ **Pipeline complet** : Int√©gration de toutes les techniques de preprocessing  \n",
        "üéØ **√âvaluation** : Mesurer l'impact sur les performances des mod√®les  \n",
        "\n",
        "---\n",
        "\n",
        "**üí° Conseil final :** Les stopwords ne sont pas universels ! Adaptez toujours votre approche selon votre contexte, votre domaine et vos objectifs."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}