---
title: Module 2 - Techniques Avanc√©es de Preprocessing
description: Formation NLP - Module 2 - Techniques Avanc√©es de Preprocessing
tags:
  - NLP
  - 09-Deep-Learning
category: 09-Deep-Learning
---

# ‚öôÔ∏èTechniques Avanc√©es de Preprocessing

Stopwords, Lemmatisation, Stemming et Normalisation Avanc√©e

## üéØTechniques Avanc√©es

Maintenant que vous ma√Ætrisez le nettoyage et la tokenisation, d√©couvrons les techniques avanc√©es pour optimiser vos donn√©es textuelles !

üõë Stopwords

Mots tr√®s fr√©quents mais peu informatifs ("le", "de", "et")

**Quand :** Classification, recherche

üå± Lemmatisation

R√©duction √† la forme canonique ("mangeaient" ‚Üí "manger")

**Quand :** Analyse s√©mantique pr√©cise

‚úÇÔ∏è Stemming

Suppression des suffixes ("mangeons" ‚Üí "mang")

**Quand :** Recherche rapide, peu pr√©cise

üè∑Ô∏è Entit√©s Nomm√©es

Pr√©servation des noms propres, dates, montants

**Quand :** Extraction d'informations

## üõëGestion des Stopwords

Concept Fran√ßais D√©mo Personnalis√©s

### Qu'est-ce que les Stopwords ?

**D√©finition :** Mots tr√®s fr√©quents dans une langue mais qui apportent peu d'information s√©mantique.

#### Exemples en fran√ßais :

**Articles :** le, la, les, un, une, des  
**Pr√©positions :** de, du, √†, avec, pour, dans  
**Pronoms :** je, tu, il, elle, nous, vous  
**Conjonctions :** et, ou, mais, donc, car  
**Auxiliaires :** √™tre, avoir, faire

#### Quand supprimer les stopwords ?

*   ‚úÖ **Classification de documents** (topic, sentiment)
*   ‚úÖ **Recherche d'information** (moteur de recherche)
*   ‚úÖ **Clustering de texte**
*   ‚ùå **Traduction automatique** (structure grammaticale importante)
*   ‚ùå **Analyse syntaxique** (relations grammaticales)
*   ‚ùå **G√©n√©ration de texte** (fluidit√© n√©cessaire)

### Sp√©cificit√©s du Fran√ßais

Le fran√ßais a des particularit√©s que n'ont pas l'anglais :

Caract√©ristique

Fran√ßais

Anglais

Impact

**Contractions**

du, des, au, aux

don't, won't, I'm

Plus de variations

**Genre/Nombre**

le/la/les, un/une/des

the, a/an

Liste plus longue

**Conjugaisons**

suis, es, est, sommes...

am, is, are

Variabilit√© √©lev√©e

**Accents**

√†, o√π, d√©j√†

Rares

Normalisation n√©cessaire

üìì stopwords\_francais.ipynb

Notebook pour g√©rer les stopwords fran√ßais avec NLTK et spaCy

[üìì Ouvrir le Notebook](notebook/stopwords_francais.ipynb)

### D√©mo Interactive : Impact des Stopwords

**Entrez un texte fran√ßais :** Le chat noir mange des croquettes avec grand app√©tit dans le jardin ensoleill√©. üßπ Analyser l'impact des stopwords

Cliquez sur "Analyser" pour voir l'impact de la suppression des stopwords...

### Stopwords Personnalis√©s

Selon votre domaine, vous pouvez avoir besoin de stopwords sp√©cifiques :

#### üè• M√©dical

**Ajouter :** patient, traitement, m√©decin, diagnostic

#### üíº Business

**Ajouter :** entreprise, soci√©t√©, business, client

#### üé• Cin√©ma

**Ajouter :** film, acteur, r√©alisateur, cin√©ma

#### üíª Tech

**Supprimer :** python, java, code (importants !)

üìì stopwords\_custom.ipynb

Notebook pour cr√©er et g√©rer des listes de stopwords personnalis√©es

[üìì Ouvrir le Notebook](notebook/stopwords_custom.ipynb)

## üå±Lemmatisation vs Stemming

Concepts Comparaison D√©mo Fran√ßais

### Stemming vs Lemmatisation

#### ‚úÇÔ∏è Stemming

**Principe :** Suppression m√©canique des suffixes

**Exemple :**

*   "mangent" ‚Üí "mang"
*   "mangeait" ‚Üí "mange"
*   "mangeur" ‚Üí "mang"

**Avantages :** Rapide, simple

**Inconv√©nients :** R√©sultats parfois incorrects

#### üå± Lemmatisation

**Principe :** R√©duction √† la forme canonique via dictionnaire

**Exemple :**

*   "mangent" ‚Üí "manger"
*   "mangeait" ‚Üí "manger"
*   "mangeur" ‚Üí "mangeur"

**Avantages :** Pr√©cis, mots valides

**Inconv√©nients :** Plus lent, complexe

### Tableau Comparatif D√©taill√©

Crit√®re

Stemming

Lemmatisation

Recommandation

**Vitesse**

‚ö° Tr√®s rapide

üêå Plus lent

Stemming si performance critique

**Pr√©cision**

‚ùå Approximative

‚úÖ √âlev√©e

Lemmatisation si qualit√© importante

**Lisibilit√©**

‚ùå Mots tronqu√©s

‚úÖ Mots valides

Lemmatisation pour interface utilisateur

**Taille vocabulaire**

üìâ R√©duit beaucoup

üìä R√©duit mod√©r√©ment

Stemming pour compression maximale

**Gestion erreurs**

‚ùå Propagation d'erreurs

‚úÖ Robuste

Lemmatisation pour donn√©es bruit√©es

**Domaine sp√©cialis√©**

‚ùå Difficile √† adapter

‚úÖ Dictionnaires sp√©cialis√©s

Lemmatisation pour m√©dical, juridique...

#### üí° Conseils de Choix

**Utilisez le Stemming quand :**

*   Vous traitez de gros volumes (millions de documents)
*   La pr√©cision n'est pas critique (recherche approximative)
*   Vous voulez maximiser la r√©duction du vocabulaire

**Utilisez la Lemmatisation quand :**

*   Vous analysez le sens (sentiment, th√©matiques)
*   Vous voulez des r√©sultats lisibles par l'utilisateur
*   Vous travaillez dans un domaine sp√©cialis√©

### Comparaison Interactive

**Entrez des mots fran√ßais conjugu√©s :** mangeons, mangeait, mangeur, courions, courait, coureur, finissons, finissait, finisseur ‚öîÔ∏è Comparer Stemming vs Lemmatisation

Entrez des mots et cliquez sur "Comparer" pour voir la diff√©rence...

### D√©fis du Fran√ßais

Le fran√ßais pr√©sente des d√©fis particuliers pour la lemmatisation :

#### üîÑ Verbes Irr√©guliers

**Exemple :** "vais", "va", "irai" ‚Üí "aller"

N√©cessite un dictionnaire complet

#### üë• Homonymie

**Exemple :** "fils" ‚Üí "fil" (objet) OU "fils" (enfant)

D√©pend du contexte

#### üìù Accord

**Exemple :** "mang√©es" ‚Üí "manger" (pas "mang√©e")

Analyser la nature grammaticale

üìì lemmatisation\_francais.ipynb

Notebook complet sur la lemmatisation fran√ßaise avec spaCy et comparaison avec stemming

[üìì Ouvrir le Notebook](notebook/lemmatisation_francais.ipynb)

## üîßNormalisation Avanc√©e

### Types de Normalisation

üìÖ Dates

"3 mars 2024", "03/03/2024" ‚Üí "2024-03-03"

üí∞ Montants

"1.500,50‚Ç¨", "1500.5 euros" ‚Üí "MONTANT"

üìß Emails

"contact@exemple.fr" ‚Üí "EMAIL"

üåê URLs

"https://www.exemple.com" ‚Üí "URL"

üì± T√©l√©phones

"01 23 45 67 89", "+33123456789" ‚Üí "TELEPHONE"

üî¢ Nombres

"mille", "1000", "1 000" ‚Üí "NOMBRE"

### D√©mo : Normalisation Compl√®te

**Entrez un texte avec des entit√©s √† normaliser :** Rendez-vous le 15 mars 2024 √† 14h30. Contactez-moi au 01.23.45.67.89 ou jean.dupont@email.fr. Le budget est de 1.500,50‚Ç¨. üîß Normaliser les entit√©s

Entrez du texte et cliquez sur "Normaliser" pour voir la transformation...

üìì normalisation\_avancee.ipynb

Notebook complet de normalisation des entit√©s en fran√ßais

[üìì Ouvrir le Notebook](notebook/normalisation_avancee.ipynb)

## üèóÔ∏èPipeline de Preprocessing Complet

### Architecture du Pipeline

**üìù Texte Brut**  
Donn√©es d'entr√©e

‚Üí

**üßπ Nettoyage**  
Casse, ponctuation

‚Üí

**‚úÇÔ∏è Tokenisation**  
Division en mots

‚Üí

**üõë Stopwords**  
Filtrage

‚Üí

**üå± Lemmatisation**  
Forme canonique

‚Üí

**‚úÖ Texte Pr√™t**  
Pour ML

### Configurateur de Pipeline

 üî§ Minuscules  üìù Supprimer ponctuation  üî¢ Supprimer nombres  üåê Nettoyer URLs  üõë Supprimer stopwords  üå± Lemmatiser  üìè Longueur min (3 char)  üè∑Ô∏è Normaliser entit√©s

**Testez votre pipeline personnalis√© :** Bonjour ! Je suis tr√®s CONTENT de ce COURS sur https://nlp-course.com. Rendez-vous le 15/03/2024 √† contact@exemple.fr ! üîß Ex√©cuter le pipeline

Configurez les options et testez votre pipeline...

üìì pipeline\_complet.ipynb

Notebook avec classe Pipeline configurable int√©grant toutes les techniques avanc√©es

[üìì Ouvrir le Notebook](notebook/pipeline_complet.ipynb)

## üí°Bonnes Pratiques et Pi√®ges √† √âviter

### ‚úÖ Bonnes Pratiques

*   üéØ **Adapter au domaine :** Stopwords sp√©cifiques au contexte
*   üìä **Mesurer l'impact :** Comparer avant/apr√®s preprocessing
*   üîÑ **Pipeline reproductible :** Sauvegarder la configuration
*   üß™ **Tester sur √©chantillon :** V√©rifier manuellement
*   ‚ö° **Optimiser progressivement :** Ajouter √©tapes une par une
*   üìù **Documenter les choix :** Justifier chaque √©tape

### ‚ùå Pi√®ges √† √âviter

*   üö´ **Trop nettoyer :** Perdre de l'information importante
*   ‚ö†Ô∏è **Ordre des √©tapes :** Lemmatiser avant de supprimer stopwords
*   üé≠ **Ignorer le contexte :** M√™me pipeline pour tous les cas
*   üêå **Pipeline trop lourd :** Impact sur les performances
*   üîç **Pas de validation :** Ne pas v√©rifier les r√©sultats
*   üß† **Oublier l'humain :** Preprocessing illisible

### Checklist de Validation

#### Avant de finaliser votre preprocessing :

 üìä J'ai mesur√© la taille du vocabulaire avant/apr√®s  üéØ J'ai test√© sur des exemples repr√©sentatifs  ‚ö° Le temps de traitement est acceptable  üëÄ Les r√©sultats restent lisibles  üîÑ Le pipeline est reproductible  üìù J'ai document√© mes choix  üß™ J'ai valid√© sur un √©chantillon test  üé≠ J'ai adapt√© au domaine d'application

[‚Üê Tokenisation](module2_tokenisation.html) [Mini-Projet ‚Üí](module2_projet.html)

// Gestion des onglets function showTab(tabId) { // Cacher tous les contenus const contents = document.querySelectorAll('.tab-content'); contents.forEach(content => content.classList.remove('active')); // D√©sactiver tous les onglets const tabs = document.querySelectorAll('.tab'); tabs.forEach(tab => tab.classList.remove('active')); // Activer l'onglet et contenu s√©lectionn√©s document.getElementById(tabId).classList.add('active'); event.target.classList.add('active'); } // D√©monstration des stopwords function demonstrateStopwords() { const input = document.getElementById('stopwords-input').value; const resultDiv = document.getElementById('stopwords-result'); // Simulation - remplacer par appel √† stopwords\_francais.py const stopwords = \['le', 'la', 'les', 'un', 'une', 'des', 'de', 'du', 'avec', 'dans', 'grand'\]; const words = input.toLowerCase().split(/\\s+/); const filtered = words.filter(word => !stopwords.includes(word)); const originalCount = words.length; const filteredCount = filtered.length; const reduction = ((originalCount - filteredCount) / originalCount \* 100).toFixed(1); resultDiv.innerHTML = \` <strong>üìä Analyse des stopwords :</strong> üî∏ Texte original (${originalCount} mots) : ${words.join(', ')} üî∏ Apr√®s suppression des stopwords (${filteredCount} mots) : ${filtered.join(', ')} üìâ R√©duction du vocabulaire : ${reduction}% üõë Stopwords supprim√©s : ${words.filter(word => stopwords.includes(word)).join(', ')} üí° ${reduction > 30 ? 'Forte r√©duction ! Bon pour la classification.' : 'R√©duction mod√©r√©e. Normal pour ce type de texte.'}\`; } // Comparaison Lemmatisation vs Stemming function compareLemmaVsStem() { const input = document.getElementById('lemma-input').value; const resultDiv = document.getElementById('lemma-result'); // Simulation - remplacer par appel √† lemmatisation\_francais.py const words = input.split(/\[,\\s\]+/).filter(w => w.trim()); const stemResults = words.map(word => { // Simulation de stemming simple return word.replace(/ons$|ait$|eur$|ons$|ez$|ent$/, ''); }); const lemmaResults = words.map(word => { // Simulation de lemmatisation const lemmaDict = { 'mangeons': 'manger', 'mangeait': 'manger', 'mangeur': 'mangeur', 'courions': 'courir', 'courait': 'courir', 'coureur': 'coureur', 'finissons': 'finir', 'finissait': 'finir', 'finisseur': 'finisseur' }; return lemmaDict\[word.toLowerCase()\] || word; }); resultDiv.innerHTML = \` <strong>‚öîÔ∏è Comparaison Stemming vs Lemmatisation :</strong> üìù Mots originaux : ${words.join(', ')} ‚úÇÔ∏è Stemming : ${stemResults.join(', ')} üå± Lemmatisation : ${lemmaResults.join(', ')} üéØ Observations : ‚Ä¢ Stemming : ${stemResults.some(w => w.length < 4) ? 'Certains mots sont trop courts' : 'Longueurs correctes'} ‚Ä¢ Lemmatisation : ${lemmaResults.every(w => w.endsWith('er') || w.endsWith('ir') || w.endsWith('eur')) ? 'Formes valides du fran√ßais' : 'R√©sultats mixtes'} üí° Pour ce cas : ${lemmaResults.join(' ').length > stemResults.join(' ').length ? 'La lemmatisation pr√©serve mieux le sens' : 'Le stemming est plus compact'}\`; } // Normalisation avanc√©e function normalizeAdvanced() { const input = document.getElementById('normalize-input').value; const resultDiv = document.getElementById('normalize-result'); // Simulation - remplacer par appel √† normalisation\_avancee.py let normalized = input; // Dates normalized = normalized.replace(/\\d{1,2}\\s+(janvier|f√©vrier|mars|avril|mai|juin|juillet|ao√ªt|septembre|octobre|novembre|d√©cembre)\\s+\\d{4}/gi, 'DATE'); normalized = normalized.replace(/\\d{1,2}\\/\\d{1,2}\\/\\d{4}/g, 'DATE'); // Heures normalized = normalized.replace(/\\d{1,2}h\\d{2}/g, 'HEURE'); // T√©l√©phones normalized = normalized.replace(/\\d{2}\[\\.\\s\]\\d{2}\[\\.\\s\]\\d{2}\[\\.\\s\]\\d{2}\[\\.\\s\]\\d{2}/g, 'TELEPHONE'); // Emails normalized = normalized.replace(/\[a-zA-Z0-9.\_%+-\]+@\[a-zA-Z0-9.-\]+\\.\[a-zA-Z\]{2,}/g, 'EMAIL'); // Montants normalized = normalized.replace(/\\d{1,3}(?:\[.\\s\]\\d{3})\*,\\d{2}‚Ç¨?/g, 'MONTANT'); resultDiv.innerHTML = \` <strong>üîß Normalisation des entit√©s :</strong> üî∏ Texte original : ${input} üî∏ Texte normalis√© : ${normalized} üè∑Ô∏è Entit√©s d√©tect√©es : ${input.match(/\\d{1,2}\\s+mars\\s+\\d{4}/) ? '‚Ä¢ DATE : "15 mars 2024"' : ''} ${input.match(/\\d{1,2}h\\d{2}/) ? '‚Ä¢ HEURE : "14h30"' : ''} ${input.match(/\\d{2}\[\\.\\s\]\\d{2}/) ? '‚Ä¢ TELEPHONE : "01.23.45.67.89"' : ''} ${input.match(/@/) ? '‚Ä¢ EMAIL : "jean.dupont@email.fr"' : ''} ${input.match(/\\d.\*‚Ç¨/) ? '‚Ä¢ MONTANT : "1.500,50‚Ç¨"' : ''} üí° Avantages : Vocabulaire r√©duit, focus sur le contenu textuel, anonymisation partielle\`; } // Pipeline personnalis√© function runCustomPipeline() { const input = document.getElementById('pipeline-input').value; const resultDiv = document.getElementById('pipeline-result'); let processed = input; const steps = \[\]; // Minuscules if (document.getElementById('clean-case').checked) { processed = processed.toLowerCase(); steps.push('üî§ Conversion en minuscules'); } // Ponctuation if (document.getElementById('clean-punct').checked) { processed = processed.replace(/\[^\\w\\s\]/g, ' '); steps.push('üìù Suppression de la ponctuation'); } // URLs if (document.getElementById('clean-urls').checked) { processed = processed.replace(/https?:\\/\\/\[^\\s\]+/g, ''); steps.push('üåê Suppression des URLs'); } // Nombres if (document.getElementById('clean-numbers').checked) { processed = processed.replace(/\\d+/g, ''); steps.push('üî¢ Suppression des nombres'); } // Normalisation des espaces processed = processed.replace(/\\s+/g, ' ').trim(); // Tokenisation let tokens = processed.split(' ').filter(t => t.length > 0); // Longueur minimale if (document.getElementById('min-length').checked) { tokens = tokens.filter(t => t.length >= 3); steps.push('üìè Filtrage longueur minimale (3 caract√®res)'); } // Stopwords if (document.getElementById('remove-stopwords').checked) { const stopwords = \['le', 'la', 'les', 'un', 'une', 'des', 'de', 'du', 'je', 'tu', 'il', 'elle', 'nous', 'vous', 'ils', 'elles', 'ce', 'cette', 'ces', 'et', 'ou', 'mais', 'donc', 'car', 'sur', 'avec', 'dans', 'pour', 'par', '√†', 'tr√®s'\]; tokens = tokens.filter(t => !stopwords.includes(t)); steps.push('üõë Suppression des stopwords'); } // Lemmatisation (simulation) if (document.getElementById('lemmatize').checked) { // Simulation simple tokens = tokens.map(token => { if (token.endsWith('ent')) return token.slice(0, -3) + 'er'; if (token.endsWith('ait')) return token.slice(0, -3) + 'er'; return token; }); steps.push('üå± Lemmatisation'); } // Entit√©s if (document.getElementById('normalize-entities').checked) { tokens = tokens.map(token => { if (token.includes('@')) return 'EMAIL'; if (/\\d{2}\\/\\d{2}\\/\\d{4}/.test(token)) return 'DATE'; return token; }); steps.push('üè∑Ô∏è Normalisation des entit√©s'); } resultDiv.innerHTML = \` <strong>üîß R√©sultats du pipeline personnalis√© :</strong> üìù Texte original (${input.split(' ').length} mots) : ${input} ‚úÖ Texte trait√© (${tokens.length} tokens) : ${tokens.join(', ')} üõ†Ô∏è √âtapes appliqu√©es : ${steps.map(step => \`‚Ä¢ ${step}\`).join('\\n')} üìä Statistiques : ‚Ä¢ R√©duction du vocabulaire : ${((input.split(' ').length - tokens.length) / input.split(' ').length \* 100).toFixed(1)}% ‚Ä¢ Tokens finaux : ${tokens.length} ‚Ä¢ Caract√®res √©conomis√©s : ${input.length - tokens.join(' ').length} üí° ${tokens.length < 5 ? 'Attention : vocabulaire tr√®s r√©duit, v√©rifiez les param√®tres' : 'Pipeline √©quilibr√© pour l\\'analyse'}\`; }
