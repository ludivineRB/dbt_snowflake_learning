{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Module 7.3 - Fine-tuning Avanc√© BERT & GPT\n",
    "\n",
    "## üéØ Objectifs\n",
    "- Ma√Ætriser les techniques de fine-tuning avanc√©es\n",
    "- Impl√©menter LoRA et autres m√©thodes d'adaptation efficaces\n",
    "- Optimiser les performances et r√©duire les co√ªts\n",
    "- D√©ployer des mod√®les fine-tun√©s en production\n",
    "\n",
    "## üìö Contenu\n",
    "1. **Techniques d'adaptation** - LoRA, AdaLoRA, Prefix Tuning\n",
    "2. **Fine-tuning multi-t√¢ches** - Strat√©gies d'entra√Ænement\n",
    "3. **Optimisation m√©moire** - Gradient checkpointing, Mixed precision\n",
    "4. **√âvaluation avanc√©e** - M√©triques, robustesse, fairness\n",
    "5. **D√©ploiement production** - Optimisation, monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Installation des d√©pendances avanc√©es\n",
    "!pip install tensorflow transformers datasets peft accelerate evaluate scikit-learn\n",
    "!pip install tensorboard matplotlib plotly seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö Imports\n",
    "import tensorflow as tf\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    TFAutoModelForSequenceClassification,\n",
    "    AutoConfig,\n",
    "    DataCollatorWithPadding,\n",
    "    create_optimizer\n",
    ")\n",
    "from datasets import load_dataset, DatasetDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"üî• TensorFlow version: {tf.__version__}\")\n",
    "print(f\"ü§ó Transformers library loaded\")\n",
    "print(f\"üéØ GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# üé® Configuration style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† 1. Techniques d'Adaptation Efficaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRALayer(tf.keras.layers.Layer):\n",
    "    \"\"\"üîß Impl√©mentation Low-Rank Adaptation (LoRA)\"\"\"\n",
    "    \n",
    "    def __init__(self, original_layer, rank=16, alpha=32, dropout=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.original_layer = original_layer\n",
    "        self.rank = rank\n",
    "        self.alpha = alpha\n",
    "        self.scaling = alpha / rank\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "        # üìè Dimensions de la couche originale\n",
    "        self.in_features = original_layer.units if hasattr(original_layer, 'units') else original_layer.input_shape[-1]\n",
    "        self.out_features = original_layer.units\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # üéØ Matrices de faible rang A et B\n",
    "        self.lora_A = self.add_weight(\n",
    "            name=\"lora_A\",\n",
    "            shape=(self.in_features, self.rank),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        self.lora_B = self.add_weight(\n",
    "            name=\"lora_B\", \n",
    "            shape=(self.rank, self.out_features),\n",
    "            initializer=\"zeros\",  # Initialisation √† z√©ro pour B\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        # üîí Geler la couche originale\n",
    "        self.original_layer.trainable = False\n",
    "        \n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        # üéØ Sortie originale (gel√©e)\n",
    "        original_output = self.original_layer(x)\n",
    "        \n",
    "        # üîß Adaptation LoRA\n",
    "        lora_output = tf.matmul(x, self.lora_A)\n",
    "        lora_output = self.dropout(lora_output, training=training)\n",
    "        lora_output = tf.matmul(lora_output, self.lora_B)\n",
    "        lora_output = lora_output * self.scaling\n",
    "        \n",
    "        # ‚ûï Combinaison\n",
    "        return original_output + lora_output\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'rank': self.rank,\n",
    "            'alpha': self.alpha,\n",
    "            'scaling': self.scaling\n",
    "        })\n",
    "        return config\n",
    "\n",
    "print(\"‚úÖ LoRALayer impl√©ment√©\")\n",
    "\n",
    "# üìä Calcul de r√©duction des param√®tres\n",
    "def calculate_lora_savings(original_params, rank, num_layers):\n",
    "    \"\"\"üìä Calcul des √©conomies LoRA\"\"\"\n",
    "    # Param√®tres originaux des couches attention\n",
    "    attention_params = original_params * 0.6  # ~60% dans l'attention\n",
    "    \n",
    "    # Param√®tres LoRA (approximation)\n",
    "    hidden_size = 768  # BERT-base\n",
    "    lora_params_per_layer = 2 * hidden_size * rank  # A + B matrices\n",
    "    total_lora_params = lora_params_per_layer * num_layers\n",
    "    \n",
    "    reduction_ratio = total_lora_params / attention_params\n",
    "    \n",
    "    return {\n",
    "        'original_params': original_params,\n",
    "        'lora_params': total_lora_params,\n",
    "        'reduction_ratio': reduction_ratio,\n",
    "        'savings_percent': (1 - reduction_ratio) * 100\n",
    "    }\n",
    "\n",
    "# üìä Exemple de calcul\n",
    "bert_base_params = 110_000_000\n",
    "savings = calculate_lora_savings(bert_base_params, rank=16, num_layers=12)\n",
    "\n",
    "print(f\"\\nüìä √âconomies LoRA (rank=16):\")\n",
    "print(f\"  üéØ Param√®tres originaux: {savings['original_params']:,}\")\n",
    "print(f\"  üîß Param√®tres LoRA: {savings['lora_params']:,}\")\n",
    "print(f\"  üí∞ R√©duction: {savings['savings_percent']:.1f}%\")\n",
    "print(f\"  üìà Ratio: {savings['reduction_ratio']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdapterLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"üîå Couche Adapter pour fine-tuning efficace\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_size, adapter_size=64, dropout=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.adapter_size = adapter_size\n",
    "        \n",
    "        # üîΩ Projection down\n",
    "        self.down_project = tf.keras.layers.Dense(\n",
    "            adapter_size, \n",
    "            activation='relu',\n",
    "            name='adapter_down'\n",
    "        )\n",
    "        \n",
    "        # üîº Projection up\n",
    "        self.up_project = tf.keras.layers.Dense(\n",
    "            hidden_size,\n",
    "            name='adapter_up'\n",
    "        )\n",
    "        \n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        # üîΩ Compression\n",
    "        adapter_input = self.layer_norm(x)\n",
    "        down_output = self.down_project(adapter_input)\n",
    "        down_output = self.dropout(down_output, training=training)\n",
    "        \n",
    "        # üîº Expansion\n",
    "        up_output = self.up_project(down_output)\n",
    "        \n",
    "        # ‚ûï Connexion r√©siduelle\n",
    "        return x + up_output\n",
    "\n",
    "print(\"‚úÖ AdapterLayer impl√©ment√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 2. Dataset Multi-t√¢ches et Pr√©paration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskDataProcessor:\n",
    "    \"\"\"üìä Processeur de donn√©es multi-t√¢ches\"\"\"\n",
    "    \n",
    "    def __init__(self, tokenizer, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.tasks = {}\n",
    "    \n",
    "    def add_task(self, task_name, dataset, text_column, label_column, num_labels):\n",
    "        \"\"\"üìù Ajouter une t√¢che au processeur\"\"\"\n",
    "        self.tasks[task_name] = {\n",
    "            'dataset': dataset,\n",
    "            'text_column': text_column,\n",
    "            'label_column': label_column,\n",
    "            'num_labels': num_labels\n",
    "        }\n",
    "    \n",
    "    def preprocess_task(self, task_name, split='train'):\n",
    "        \"\"\"üîÑ Pr√©processing d'une t√¢che sp√©cifique\"\"\"\n",
    "        task_info = self.tasks[task_name]\n",
    "        dataset = task_info['dataset'][split]\n",
    "        \n",
    "        def tokenize_function(examples):\n",
    "            return self.tokenizer(\n",
    "                examples[task_info['text_column']],\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=self.max_length,\n",
    "                return_tensors='tf'\n",
    "            )\n",
    "        \n",
    "        # üîÑ Tokenisation\n",
    "        tokenized_dataset = dataset.map(\n",
    "            tokenize_function,\n",
    "            batched=True,\n",
    "            remove_columns=dataset.column_names\n",
    "        )\n",
    "        \n",
    "        # üè∑Ô∏è Ajout des labels\n",
    "        labels = dataset[task_info['label_column']]\n",
    "        tokenized_dataset = tokenized_dataset.add_column('labels', labels)\n",
    "        \n",
    "        return tokenized_dataset\n",
    "    \n",
    "    def create_tf_dataset(self, task_name, split='train', batch_size=16, shuffle=True):\n",
    "        \"\"\"üéØ Cr√©ation d'un dataset TensorFlow\"\"\"\n",
    "        tokenized_dataset = self.preprocess_task(task_name, split)\n",
    "        \n",
    "        # üîÑ Conversion TensorFlow\n",
    "        tf_dataset = tf_dataset.from_tensor_slices({\n",
    "            'input_ids': tokenized_dataset['input_ids'],\n",
    "            'attention_mask': tokenized_dataset['attention_mask'],\n",
    "            'labels': tokenized_dataset['labels']\n",
    "        })\n",
    "        \n",
    "        if shuffle:\n",
    "            tf_dataset = tf_dataset.shuffle(1000)\n",
    "        \n",
    "        tf_dataset = tf_dataset.batch(batch_size)\n",
    "        tf_dataset = tf_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "        return tf_dataset\n",
    "\n",
    "# üìä Chargement des datasets\n",
    "print(\"üìä Chargement des datasets multi-t√¢ches...\")\n",
    "\n",
    "# ü§ñ Tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# üìä Datasets pour d√©monstration\n",
    "# Dataset 1: Classification de sentiment (IMDb)\n",
    "imdb_dataset = load_dataset(\"imdb\")\n",
    "imdb_small = {\n",
    "    'train': imdb_dataset['train'].select(range(2000)),\n",
    "    'test': imdb_dataset['test'].select(range(500))\n",
    "}\n",
    "\n",
    "# Dataset 2: Classification d'intention (exemple simplifi√©)\n",
    "# Cr√©ons un dataset synth√©tique\n",
    "intent_data = {\n",
    "    'train': {\n",
    "        'text': [\n",
    "            \"What's the weather like today?\",\n",
    "            \"How much does this cost?\",\n",
    "            \"Can you help me?\",\n",
    "            \"What time is it?\",\n",
    "            \"I want to buy this product\",\n",
    "            \"Tell me a joke\",\n",
    "            \"What's your name?\",\n",
    "            \"How are you?\"\n",
    "        ] * 250,  # R√©p√©ter pour avoir assez de donn√©es\n",
    "        'intent': [0, 1, 2, 0, 1, 2, 2, 2] * 250  # 0: info, 1: transaction, 2: social\n",
    "    }\n",
    "}\n",
    "\n",
    "# üîÑ Processeur multi-t√¢ches\n",
    "processor = MultiTaskDataProcessor(tokenizer)\n",
    "\n",
    "print(f\"‚úÖ Datasets charg√©s:\")\n",
    "print(f\"  üìä IMDb: {len(imdb_small['train'])} train, {len(imdb_small['test'])} test\")\n",
    "print(f\"  üéØ Intent: {len(intent_data['train']['text'])} exemples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è 3. Entra√Ænement avec Techniques d'Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedFineTuner:\n",
    "    \"\"\"üéØ Fine-tuner avanc√© avec optimisations\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name, num_labels, use_mixed_precision=True):\n",
    "        self.model_name = model_name\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        # üöÄ Mixed Precision pour optimisation m√©moire\n",
    "        if use_mixed_precision:\n",
    "            policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "            tf.keras.mixed_precision.set_global_policy(policy)\n",
    "            print(\"‚úÖ Mixed precision activ√©e\")\n",
    "        \n",
    "        # ü§ñ Mod√®le\n",
    "        self.model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_labels\n",
    "        )\n",
    "        \n",
    "        # üìä M√©triques de suivi\n",
    "        self.training_history = {\n",
    "            'loss': [],\n",
    "            'accuracy': [],\n",
    "            'val_loss': [],\n",
    "            'val_accuracy': [],\n",
    "            'learning_rate': []\n",
    "        }\n",
    "    \n",
    "    def setup_training(self, train_dataset, val_dataset, \n",
    "                      learning_rate=2e-5, weight_decay=0.01, \n",
    "                      warmup_ratio=0.1, num_train_steps=None):\n",
    "        \"\"\"‚öôÔ∏è Configuration de l'entra√Ænement\"\"\"\n",
    "        \n",
    "        if num_train_steps is None:\n",
    "            # Estimation bas√©e sur le dataset\n",
    "            num_train_steps = len(train_dataset) * 3  # 3 epochs par d√©faut\n",
    "        \n",
    "        # üìà Optimiseur avec warmup\n",
    "        optimizer, lr_schedule = create_optimizer(\n",
    "            init_lr=learning_rate,\n",
    "            num_train_steps=num_train_steps,\n",
    "            num_warmup_steps=int(num_train_steps * warmup_ratio),\n",
    "            weight_decay_rate=weight_decay\n",
    "        )\n",
    "        \n",
    "        # üìä Loss et m√©triques\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        metrics = ['accuracy']\n",
    "        \n",
    "        # üéØ Compilation\n",
    "        self.model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss_fn,\n",
    "            metrics=metrics\n",
    "        )\n",
    "        \n",
    "        self.lr_schedule = lr_schedule\n",
    "        \n",
    "        print(f\"‚úÖ Configuration entra√Ænement:\")\n",
    "        print(f\"  üìà Learning rate: {learning_rate}\")\n",
    "        print(f\"  üî• Weight decay: {weight_decay}\")\n",
    "        print(f\"  ‚è∞ Warmup ratio: {warmup_ratio}\")\n",
    "        print(f\"  üîÑ Steps total: {num_train_steps}\")\n",
    "    \n",
    "    def create_callbacks(self, patience=3, monitor='val_accuracy'):\n",
    "        \"\"\"üìã Cr√©ation des callbacks d'entra√Ænement\"\"\"\n",
    "        \n",
    "        callbacks = [\n",
    "            # üõë Early stopping\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor=monitor,\n",
    "                patience=patience,\n",
    "                restore_best_weights=True,\n",
    "                mode='max' if 'accuracy' in monitor else 'min'\n",
    "            ),\n",
    "            \n",
    "            # üìâ R√©duction learning rate\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=2,\n",
    "                min_lr=1e-7,\n",
    "                verbose=1\n",
    "            ),\n",
    "            \n",
    "            # üìä TensorBoard\n",
    "            tf.keras.callbacks.TensorBoard(\n",
    "                log_dir=f'./logs/fine_tuning_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "                histogram_freq=1,\n",
    "                write_graph=True\n",
    "            ),\n",
    "            \n",
    "            # üìà Suivi learning rate\n",
    "            tf.keras.callbacks.LambdaCallback(\n",
    "                on_epoch_end=lambda epoch, logs: self.training_history['learning_rate'].append(\n",
    "                    float(self.model.optimizer.learning_rate)\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        return callbacks\n",
    "    \n",
    "    def train(self, train_dataset, val_dataset, epochs=3, \n",
    "              patience=3, save_path='./fine_tuned_model'):\n",
    "        \"\"\"üèãÔ∏è Entra√Ænement du mod√®le\"\"\"\n",
    "        \n",
    "        print(f\"üèãÔ∏è D√©but du fine-tuning ({epochs} epochs)...\")\n",
    "        \n",
    "        # üìã Callbacks\n",
    "        callbacks = self.create_callbacks(patience=patience)\n",
    "        \n",
    "        # üöÄ Entra√Ænement\n",
    "        history = self.model.fit(\n",
    "            train_dataset,\n",
    "            validation_data=val_dataset,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # üìä Sauvegarde historique\n",
    "        for key in ['loss', 'accuracy', 'val_loss', 'val_accuracy']:\n",
    "            if key in history.history:\n",
    "                self.training_history[key].extend(history.history[key])\n",
    "        \n",
    "        # üíæ Sauvegarde mod√®le\n",
    "        self.model.save_pretrained(save_path)\n",
    "        \n",
    "        print(f\"‚úÖ Fine-tuning termin√© !\")\n",
    "        print(f\"üíæ Mod√®le sauvegard√©: {save_path}\")\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def evaluate_detailed(self, test_dataset, class_names=None):\n",
    "        \"\"\"üìä √âvaluation d√©taill√©e du mod√®le\"\"\"\n",
    "        \n",
    "        print(\"üìä √âvaluation d√©taill√©e...\")\n",
    "        \n",
    "        # üéØ Pr√©dictions\n",
    "        predictions = self.model.predict(test_dataset)\n",
    "        y_pred = np.argmax(predictions.logits, axis=1)\n",
    "        \n",
    "        # üè∑Ô∏è Labels vrais (extraction du dataset)\n",
    "        y_true = []\n",
    "        for batch in test_dataset:\n",
    "            y_true.extend(batch['labels'].numpy())\n",
    "        y_true = np.array(y_true)\n",
    "        \n",
    "        # üìä M√©triques\n",
    "        from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "        \n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            y_true, y_pred, average='weighted'\n",
    "        )\n",
    "        \n",
    "        # üìã Rapport d√©taill√©\n",
    "        report = classification_report(\n",
    "            y_true, y_pred, \n",
    "            target_names=class_names,\n",
    "            output_dict=True\n",
    "        )\n",
    "        \n",
    "        results = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'classification_report': report,\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ R√©sultats d'√©valuation:\")\n",
    "        print(f\"  üéØ Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  üìä Precision: {precision:.4f}\")\n",
    "        print(f\"  üìä Recall: {recall:.4f}\")\n",
    "        print(f\"  üìä F1-Score: {f1:.4f}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "print(\"‚úÖ AdvancedFineTuner impl√©ment√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Cr√©ation et configuration du fine-tuner\n",
    "fine_tuner = AdvancedFineTuner(\n",
    "    model_name=\"bert-base-uncased\",\n",
    "    num_labels=2,  # Classification binaire pour IMDb\n",
    "    use_mixed_precision=True\n",
    ")\n",
    "\n",
    "print(f\"ü§ñ Mod√®le cr√©√©: {fine_tuner.model_name}\")\n",
    "print(f\"üìä Param√®tres: {fine_tuner.model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Pr√©paration des datasets TensorFlow\n",
    "def prepare_imdb_dataset(tokenizer, batch_size=16):\n",
    "    \"\"\"üìä Pr√©paration dataset IMDb optimis√©\"\"\"\n",
    "    \n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples['text'],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=256,  # R√©duit pour l'exemple\n",
    "            return_tensors='np'\n",
    "        )\n",
    "    \n",
    "    # üîÑ Tokenisation\n",
    "    train_encodings = tokenize_function(imdb_small['train'])\n",
    "    test_encodings = tokenize_function(imdb_small['test'])\n",
    "    \n",
    "    # üéØ Cr√©ation datasets TensorFlow\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices({\n",
    "        'input_ids': train_encodings['input_ids'],\n",
    "        'attention_mask': train_encodings['attention_mask'],\n",
    "        'labels': imdb_small['train']['label']\n",
    "    })\n",
    "    \n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices({\n",
    "        'input_ids': test_encodings['input_ids'],\n",
    "        'attention_mask': test_encodings['attention_mask'],\n",
    "        'labels': imdb_small['test']['label']\n",
    "    })\n",
    "    \n",
    "    # üîÑ Optimisations\n",
    "    train_dataset = (\n",
    "        train_dataset\n",
    "        .shuffle(1000)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    \n",
    "    test_dataset = (\n",
    "        test_dataset\n",
    "        .batch(batch_size)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    \n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "# üìä Pr√©paration\n",
    "train_dataset, test_dataset = prepare_imdb_dataset(tokenizer, batch_size=16)\n",
    "\n",
    "print(f\"üìä Datasets pr√©par√©s:\")\n",
    "print(f\"  üîÑ Batch size: 16\")\n",
    "print(f\"  üìè Max length: 256 tokens\")\n",
    "print(f\"  üéØ Optimisations: shuffle, prefetch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è Configuration et lancement de l'entra√Ænement\n",
    "fine_tuner.setup_training(\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=test_dataset,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1\n",
    ")\n",
    "\n",
    "# üèãÔ∏è Fine-tuning\n",
    "history = fine_tuner.train(\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=test_dataset,\n",
    "    epochs=3,\n",
    "    patience=2,\n",
    "    save_path='./bert_imdb_finetuned'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 4. √âvaluation Avanc√©e et Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä √âvaluation d√©taill√©e\n",
    "class_names = ['Negative', 'Positive']\n",
    "results = fine_tuner.evaluate_detailed(test_dataset, class_names=class_names)\n",
    "\n",
    "# üé® Visualisation des r√©sultats\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# üìà Historique d'entra√Ænement\n",
    "epochs = range(1, len(fine_tuner.training_history['loss']) + 1)\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(epochs, fine_tuner.training_history['loss'], 'b-', label='Train Loss')\n",
    "axes[0, 0].plot(epochs, fine_tuner.training_history['val_loss'], 'r-', label='Val Loss')\n",
    "axes[0, 0].set_title('üìâ Evolution de la Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 1].plot(epochs, fine_tuner.training_history['accuracy'], 'b-', label='Train Acc')\n",
    "axes[0, 1].plot(epochs, fine_tuner.training_history['val_accuracy'], 'r-', label='Val Acc')\n",
    "axes[0, 1].set_title('üìä Evolution de l\\'Accuracy')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(results['y_true'], results['y_pred'])\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names, ax=axes[1, 0])\n",
    "axes[1, 0].set_title('üéØ Matrice de Confusion')\n",
    "axes[1, 0].set_xlabel('Pr√©diction')\n",
    "axes[1, 0].set_ylabel('V√©rit√©')\n",
    "\n",
    "# M√©triques par classe\n",
    "report = results['classification_report']\n",
    "classes = [c for c in report.keys() if c not in ['accuracy', 'macro avg', 'weighted avg']]\n",
    "metrics = ['precision', 'recall', 'f1-score']\n",
    "\n",
    "x = np.arange(len(classes))\n",
    "width = 0.25\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    values = [report[c][metric] for c in classes]\n",
    "    axes[1, 1].bar(x + i*width, values, width, label=metric.capitalize())\n",
    "\n",
    "axes[1, 1].set_title('üìä M√©triques par Classe')\n",
    "axes[1, 1].set_xlabel('Classes')\n",
    "axes[1, 1].set_ylabel('Score')\n",
    "axes[1, 1].set_xticks(x + width)\n",
    "axes[1, 1].set_xticklabels(classes)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# üìä R√©sum√© des performances\n",
    "print(f\"\\nüéØ R√©sum√© des performances finales:\")\n",
    "print(f\"  üìä Accuracy: {results['accuracy']:.2%}\")\n",
    "print(f\"  üìä F1-Score: {results['f1_score']:.4f}\")\n",
    "print(f\"  üìä Precision: {results['precision']:.4f}\")\n",
    "print(f\"  üìä Recall: {results['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Analyse de robustesse avec tests adversariaux\n",
    "def test_model_robustness(model, tokenizer, test_samples):\n",
    "    \"\"\"üõ°Ô∏è Tests de robustesse du mod√®le\"\"\"\n",
    "    \n",
    "    def predict_text(text):\n",
    "        \"\"\"üéØ Pr√©diction pour un texte\"\"\"\n",
    "        inputs = tokenizer(\n",
    "            text, \n",
    "            truncation=True, \n",
    "            padding='max_length',\n",
    "            max_length=256,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        probabilities = tf.nn.softmax(outputs.logits, axis=-1)\n",
    "        \n",
    "        return {\n",
    "            'prediction': int(tf.argmax(probabilities, axis=-1)[0]),\n",
    "            'confidence': float(tf.reduce_max(probabilities)),\n",
    "            'probabilities': probabilities[0].numpy()\n",
    "        }\n",
    "    \n",
    "    # üß™ Tests de robustesse\n",
    "    robustness_tests = []\n",
    "    \n",
    "    for original_text, expected_label in test_samples:\n",
    "        # üìù Texte original\n",
    "        original_result = predict_text(original_text)\n",
    "        \n",
    "        # üîÑ Variations du texte\n",
    "        variations = [\n",
    "            original_text.upper(),  # Majuscules\n",
    "            original_text.lower(),  # Minuscules\n",
    "            original_text + \" \" + original_text.split()[-1],  # R√©p√©tition dernier mot\n",
    "            original_text.replace(\".\", \"!\"),  # Changement ponctuation\n",
    "        ]\n",
    "        \n",
    "        variation_results = []\n",
    "        for variation in variations:\n",
    "            result = predict_text(variation)\n",
    "            variation_results.append(result)\n",
    "        \n",
    "        # üìä Analyse de coh√©rence\n",
    "        predictions = [original_result['prediction']] + [r['prediction'] for r in variation_results]\n",
    "        coherence = len(set(predictions)) == 1  # Toutes les pr√©dictions identiques\n",
    "        \n",
    "        robustness_tests.append({\n",
    "            'text': original_text[:50] + \"...\",\n",
    "            'expected': expected_label,\n",
    "            'original_pred': original_result['prediction'],\n",
    "            'original_conf': original_result['confidence'],\n",
    "            'coherence': coherence,\n",
    "            'variation_results': variation_results\n",
    "        })\n",
    "    \n",
    "    return robustness_tests\n",
    "\n",
    "# üß™ √âchantillons de test\n",
    "test_samples = [\n",
    "    (\"This movie is absolutely fantastic! Great acting and story.\", 1),\n",
    "    (\"Terrible film, waste of time. Very disappointing.\", 0),\n",
    "    (\"It's okay, nothing special but watchable.\", 0),  # Cas neutre difficile\n",
    "    (\"Best movie ever! Highly recommended to everyone.\", 1),\n",
    "    (\"Boring and predictable. Not worth watching.\", 0)\n",
    "]\n",
    "\n",
    "# üõ°Ô∏è Tests de robustesse\n",
    "robustness_results = test_model_robustness(fine_tuner.model, tokenizer, test_samples)\n",
    "\n",
    "print(\"üõ°Ô∏è Analyse de robustesse:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "coherent_predictions = 0\n",
    "total_tests = len(robustness_results)\n",
    "\n",
    "for i, test in enumerate(robustness_results, 1):\n",
    "    print(f\"\\nüß™ Test {i}:\")\n",
    "    print(f\"  üìù Texte: {test['text']}\")\n",
    "    print(f\"  üéØ Attendu: {'Positif' if test['expected'] == 1 else 'N√©gatif'}\")\n",
    "    print(f\"  ü§ñ Pr√©dit: {'Positif' if test['original_pred'] == 1 else 'N√©gatif'}\")\n",
    "    print(f\"  üìä Confiance: {test['original_conf']:.2%}\")\n",
    "    print(f\"  üõ°Ô∏è Coh√©rence: {'‚úÖ' if test['coherence'] else '‚ùå'}\")\n",
    "    \n",
    "    if test['coherence']:\n",
    "        coherent_predictions += 1\n",
    "\n",
    "robustness_score = coherent_predictions / total_tests\n",
    "print(f\"\\nüìä Score de robustesse: {robustness_score:.2%}\")\n",
    "print(f\"   ({coherent_predictions}/{total_tests} pr√©dictions coh√©rentes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ 5. Optimisation pour la Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionOptimizer:\n",
    "    \"\"\"üöÄ Optimiseur pour d√©ploiement production\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, tokenizer_path=None):\n",
    "        self.model_path = model_path\n",
    "        self.tokenizer_path = tokenizer_path or model_path\n",
    "        \n",
    "        # ü§ñ Chargement\n",
    "        self.model = TFAutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.tokenizer_path)\n",
    "        \n",
    "        print(f\"üì¶ Mod√®le charg√©: {model_path}\")\n",
    "    \n",
    "    def quantize_model(self, output_path='./quantized_model'):\n",
    "        \"\"\"üóúÔ∏è Quantification du mod√®le pour r√©duire la taille\"\"\"\n",
    "        \n",
    "        print(\"üóúÔ∏è Quantification du mod√®le...\")\n",
    "        \n",
    "        # üîÑ Conversion TensorFlow Lite\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(self.model)\n",
    "        \n",
    "        # ‚öôÔ∏è Optimisations\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.target_spec.supported_types = [tf.float16]\n",
    "        \n",
    "        # üéØ Conversion\n",
    "        try:\n",
    "            tflite_model = converter.convert()\n",
    "            \n",
    "            # üíæ Sauvegarde\n",
    "            with open(f'{output_path}/model.tflite', 'wb') as f:\n",
    "                f.write(tflite_model)\n",
    "            \n",
    "            # üìä Statistiques\n",
    "            original_size = os.path.getsize(f'{self.model_path}/tf_model.h5') if os.path.exists(f'{self.model_path}/tf_model.h5') else 0\n",
    "            quantized_size = len(tflite_model)\n",
    "            \n",
    "            print(f\"‚úÖ Quantification r√©ussie:\")\n",
    "            print(f\"  üì¶ Taille originale: {original_size / 1e6:.1f} MB\")\n",
    "            print(f\"  üóúÔ∏è Taille quantifi√©e: {quantized_size / 1e6:.1f} MB\")\n",
    "            print(f\"  üí∞ R√©duction: {(1 - quantized_size/original_size) * 100:.1f}%\" if original_size > 0 else \"\")\n",
    "            \n",
    "            return tflite_model\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur quantification: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def create_inference_function(self, max_length=256):\n",
    "        \"\"\"‚ö° Fonction d'inf√©rence optimis√©e\"\"\"\n",
    "        \n",
    "        @tf.function\n",
    "        def optimized_predict(input_ids, attention_mask):\n",
    "            \"\"\"üéØ Pr√©diction optimis√©e avec @tf.function\"\"\"\n",
    "            outputs = self.model({\n",
    "                'input_ids': input_ids,\n",
    "                'attention_mask': attention_mask\n",
    "            })\n",
    "            return tf.nn.softmax(outputs.logits, axis=-1)\n",
    "        \n",
    "        def predict_text(text):\n",
    "            \"\"\"üìù Pr√©diction pour texte brut\"\"\"\n",
    "            # üîÑ Tokenisation\n",
    "            inputs = self.tokenizer(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                padding='max_length',\n",
    "                max_length=max_length,\n",
    "                return_tensors='tf'\n",
    "            )\n",
    "            \n",
    "            # üéØ Pr√©diction\n",
    "            probabilities = optimized_predict(\n",
    "                inputs['input_ids'],\n",
    "                inputs['attention_mask']\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                'prediction': int(tf.argmax(probabilities, axis=-1)[0]),\n",
    "                'confidence': float(tf.reduce_max(probabilities)),\n",
    "                'probabilities': probabilities[0].numpy().tolist()\n",
    "            }\n",
    "        \n",
    "        return predict_text\n",
    "    \n",
    "    def benchmark_performance(self, test_texts, num_runs=10):\n",
    "        \"\"\"üìä Benchmark des performances\"\"\"\n",
    "        \n",
    "        print(f\"üìä Benchmark performance ({num_runs} runs par texte)...\")\n",
    "        \n",
    "        # ‚ö° Fonction optimis√©e\n",
    "        predict_fn = self.create_inference_function()\n",
    "        \n",
    "        # üî• Warmup\n",
    "        for _ in range(3):\n",
    "            predict_fn(test_texts[0])\n",
    "        \n",
    "        # ‚è±Ô∏è Mesures\n",
    "        times = []\n",
    "        \n",
    "        for text in test_texts:\n",
    "            text_times = []\n",
    "            \n",
    "            for _ in range(num_runs):\n",
    "                start_time = time.time()\n",
    "                result = predict_fn(text)\n",
    "                end_time = time.time()\n",
    "                text_times.append(end_time - start_time)\n",
    "            \n",
    "            times.extend(text_times)\n",
    "        \n",
    "        # üìä Statistiques\n",
    "        avg_time = np.mean(times)\n",
    "        std_time = np.std(times)\n",
    "        throughput = 1.0 / avg_time\n",
    "        \n",
    "        print(f\"‚úÖ R√©sultats benchmark:\")\n",
    "        print(f\"  ‚è±Ô∏è Temps moyen: {avg_time*1000:.2f}ms\")\n",
    "        print(f\"  üìä √âcart-type: {std_time*1000:.2f}ms\")\n",
    "        print(f\"  üöÄ Throughput: {throughput:.1f} pr√©dictions/sec\")\n",
    "        print(f\"  üìà Latence P95: {np.percentile(times, 95)*1000:.2f}ms\")\n",
    "        \n",
    "        return {\n",
    "            'avg_time': avg_time,\n",
    "            'std_time': std_time,\n",
    "            'throughput': throughput,\n",
    "            'p95_latency': np.percentile(times, 95),\n",
    "            'all_times': times\n",
    "        }\n",
    "\n",
    "# üöÄ Optimisation du mod√®le fine-tun√©\n",
    "import time\n",
    "\n",
    "optimizer = ProductionOptimizer('./bert_imdb_finetuned')\n",
    "\n",
    "# üóúÔ∏è Quantification\n",
    "# quantized_model = optimizer.quantize_model('./quantized_bert_imdb')\n",
    "\n",
    "# üìä Benchmark\n",
    "benchmark_texts = [\n",
    "    \"This movie is amazing!\",\n",
    "    \"Terrible film, very disappointing.\",\n",
    "    \"It's okay, nothing special.\",\n",
    "    \"Great acting and story!\",\n",
    "    \"Boring and predictable.\"\n",
    "]\n",
    "\n",
    "performance_metrics = optimizer.benchmark_performance(benchmark_texts, num_runs=5)\n",
    "\n",
    "# üé® Visualisation des performances\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=np.array(performance_metrics['all_times']) * 1000,\n",
    "    nbinsx=20,\n",
    "    name='Latence (ms)',\n",
    "    marker_color='skyblue'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"üìä Distribution des Latences d'Inf√©rence\",\n",
    "    xaxis_title=\"Latence (ms)\",\n",
    "    yaxis_title=\"Fr√©quence\",\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà 6. Monitoring et Suivi en Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionMonitor:\n",
    "    \"\"\"üìà Syst√®me de monitoring pour mod√®les en production\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"bert_sentiment\"):\n",
    "        self.model_name = model_name\n",
    "        self.metrics = {\n",
    "            'total_predictions': 0,\n",
    "            'avg_confidence': [],\n",
    "            'prediction_distribution': {'positive': 0, 'negative': 0},\n",
    "            'latencies': [],\n",
    "            'errors': [],\n",
    "            'daily_stats': {}\n",
    "        }\n",
    "        \n",
    "        # üìä Seuils d'alerte\n",
    "        self.thresholds = {\n",
    "            'max_latency': 500,  # ms\n",
    "            'min_confidence': 0.7,\n",
    "            'max_error_rate': 0.05\n",
    "        }\n",
    "    \n",
    "    def log_prediction(self, text, prediction, confidence, latency):\n",
    "        \"\"\"üìù Enregistrer une pr√©diction\"\"\"\n",
    "        timestamp = datetime.now()\n",
    "        \n",
    "        # üìä Mise √† jour m√©triques\n",
    "        self.metrics['total_predictions'] += 1\n",
    "        self.metrics['avg_confidence'].append(confidence)\n",
    "        self.metrics['latencies'].append(latency)\n",
    "        \n",
    "        # üéØ Distribution pr√©dictions\n",
    "        pred_label = 'positive' if prediction == 1 else 'negative'\n",
    "        self.metrics['prediction_distribution'][pred_label] += 1\n",
    "        \n",
    "        # üìÖ Stats quotidiennes\n",
    "        date_key = timestamp.strftime('%Y-%m-%d')\n",
    "        if date_key not in self.metrics['daily_stats']:\n",
    "            self.metrics['daily_stats'][date_key] = {\n",
    "                'predictions': 0,\n",
    "                'avg_confidence': [],\n",
    "                'avg_latency': []\n",
    "            }\n",
    "        \n",
    "        self.metrics['daily_stats'][date_key]['predictions'] += 1\n",
    "        self.metrics['daily_stats'][date_key]['avg_confidence'].append(confidence)\n",
    "        self.metrics['daily_stats'][date_key]['avg_latency'].append(latency)\n",
    "        \n",
    "        # üö® V√©rification des seuils\n",
    "        alerts = self.check_alerts(confidence, latency)\n",
    "        \n",
    "        return {\n",
    "            'timestamp': timestamp,\n",
    "            'alerts': alerts\n",
    "        }\n",
    "    \n",
    "    def check_alerts(self, confidence, latency):\n",
    "        \"\"\"üö® V√©rification des seuils d'alerte\"\"\"\n",
    "        alerts = []\n",
    "        \n",
    "        if latency > self.thresholds['max_latency']:\n",
    "            alerts.append(f\"‚ö†Ô∏è Latence √©lev√©e: {latency:.2f}ms\")\n",
    "        \n",
    "        if confidence < self.thresholds['min_confidence']:\n",
    "            alerts.append(f\"‚ö†Ô∏è Confiance faible: {confidence:.2%}\")\n",
    "        \n",
    "        # üìä Taux d'erreur r√©cent\n",
    "        if len(self.metrics['avg_confidence']) > 100:\n",
    "            recent_low_confidence = sum(\n",
    "                1 for c in self.metrics['avg_confidence'][-100:] \n",
    "                if c < self.thresholds['min_confidence']\n",
    "            )\n",
    "            error_rate = recent_low_confidence / 100\n",
    "            \n",
    "            if error_rate > self.thresholds['max_error_rate']:\n",
    "                alerts.append(f\"üö® Taux d'erreur √©lev√©: {error_rate:.2%}\")\n",
    "        \n",
    "        return alerts\n",
    "    \n",
    "    def generate_dashboard(self):\n",
    "        \"\"\"üìä G√©n√©ration du dashboard de monitoring\"\"\"\n",
    "        \n",
    "        if self.metrics['total_predictions'] == 0:\n",
    "            print(\"üìä Aucune pr√©diction enregistr√©e\")\n",
    "            return\n",
    "        \n",
    "        # üìà M√©triques g√©n√©rales\n",
    "        avg_confidence = np.mean(self.metrics['avg_confidence'])\n",
    "        avg_latency = np.mean(self.metrics['latencies'])\n",
    "        p95_latency = np.percentile(self.metrics['latencies'], 95)\n",
    "        \n",
    "        print(f\"üìä Dashboard - {self.model_name}\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"üéØ Total pr√©dictions: {self.metrics['total_predictions']:,}\")\n",
    "        print(f\"üìä Confiance moyenne: {avg_confidence:.2%}\")\n",
    "        print(f\"‚è±Ô∏è Latence moyenne: {avg_latency:.2f}ms\")\n",
    "        print(f\"üìà Latence P95: {p95_latency:.2f}ms\")\n",
    "        \n",
    "        # üéØ Distribution des pr√©dictions\n",
    "        total_preds = sum(self.metrics['prediction_distribution'].values())\n",
    "        print(f\"\\nüé≠ Distribution des pr√©dictions:\")\n",
    "        for label, count in self.metrics['prediction_distribution'].items():\n",
    "            percentage = count / total_preds * 100 if total_preds > 0 else 0\n",
    "            print(f\"  {label.capitalize()}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        # üé® Graphiques\n",
    "        self.plot_metrics()\n",
    "    \n",
    "    def plot_metrics(self):\n",
    "        \"\"\"üé® Graphiques des m√©triques\"\"\"\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # üìä Distribution confiance\n",
    "        axes[0, 0].hist(self.metrics['avg_confidence'], bins=20, alpha=0.7, color='skyblue')\n",
    "        axes[0, 0].axvline(self.thresholds['min_confidence'], color='red', linestyle='--', label='Seuil minimum')\n",
    "        axes[0, 0].set_title('üìä Distribution de la Confiance')\n",
    "        axes[0, 0].set_xlabel('Confiance')\n",
    "        axes[0, 0].set_ylabel('Fr√©quence')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # ‚è±Ô∏è Distribution latence\n",
    "        axes[0, 1].hist(self.metrics['latencies'], bins=20, alpha=0.7, color='lightgreen')\n",
    "        axes[0, 1].axvline(self.thresholds['max_latency'], color='red', linestyle='--', label='Seuil maximum')\n",
    "        axes[0, 1].set_title('‚è±Ô∏è Distribution de la Latence')\n",
    "        axes[0, 1].set_xlabel('Latence (ms)')\n",
    "        axes[0, 1].set_ylabel('Fr√©quence')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # üéØ Distribution pr√©dictions\n",
    "        labels = list(self.metrics['prediction_distribution'].keys())\n",
    "        values = list(self.metrics['prediction_distribution'].values())\n",
    "        axes[1, 0].pie(values, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "        axes[1, 0].set_title('üéØ Distribution des Pr√©dictions')\n",
    "        \n",
    "        # üìà √âvolution temporelle (simulation)\n",
    "        if len(self.metrics['avg_confidence']) > 10:\n",
    "            window_size = min(50, len(self.metrics['avg_confidence']) // 10)\n",
    "            rolling_confidence = pd.Series(self.metrics['avg_confidence']).rolling(window_size).mean()\n",
    "            rolling_latency = pd.Series(self.metrics['latencies']).rolling(window_size).mean()\n",
    "            \n",
    "            ax2 = axes[1, 1]\n",
    "            ax3 = ax2.twinx()\n",
    "            \n",
    "            line1 = ax2.plot(rolling_confidence, 'b-', label='Confiance', alpha=0.7)\n",
    "            line2 = ax3.plot(rolling_latency, 'r-', label='Latence', alpha=0.7)\n",
    "            \n",
    "            ax2.set_xlabel('Pr√©dictions')\n",
    "            ax2.set_ylabel('Confiance', color='b')\n",
    "            ax3.set_ylabel('Latence (ms)', color='r')\n",
    "            ax2.set_title('üìà √âvolution Temporelle')\n",
    "            \n",
    "            # L√©gende combin√©e\n",
    "            lines = line1 + line2\n",
    "            labels = [l.get_label() for l in lines]\n",
    "            ax2.legend(lines, labels, loc='upper left')\n",
    "            \n",
    "            ax2.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            axes[1, 1].text(0.5, 0.5, 'Pas assez de donn√©es\\npour l\\'√©volution temporelle', \n",
    "                           ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "            axes[1, 1].set_title('üìà √âvolution Temporelle')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# üìä Simulation de monitoring\n",
    "monitor = ProductionMonitor(\"bert_sentiment_v1\")\n",
    "\n",
    "# üéØ Simulation de pr√©dictions\n",
    "predict_fn = optimizer.create_inference_function()\n",
    "\n",
    "simulation_texts = [\n",
    "    \"This movie is fantastic!\",\n",
    "    \"Terrible film, very bad.\",\n",
    "    \"It's okay.\",\n",
    "    \"Amazing storyline and acting!\",\n",
    "    \"Boring and slow.\",\n",
    "    \"Great entertainment!\",\n",
    "    \"Disappointing ending.\",\n",
    "    \"Love this movie!\",\n",
    "    \"Waste of time.\",\n",
    "    \"Pretty good overall.\"\n",
    "] * 10  # R√©p√©ter pour avoir plus de donn√©es\n",
    "\n",
    "print(\"üé≠ Simulation de pr√©dictions en production...\")\n",
    "\n",
    "for i, text in enumerate(simulation_texts):\n",
    "    # ‚è±Ô∏è Mesure du temps\n",
    "    start_time = time.time()\n",
    "    result = predict_fn(text)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    latency = (end_time - start_time) * 1000  # ms\n",
    "    \n",
    "    # üìù Log de la pr√©diction\n",
    "    log_result = monitor.log_prediction(\n",
    "        text=text,\n",
    "        prediction=result['prediction'],\n",
    "        confidence=result['confidence'],\n",
    "        latency=latency\n",
    "    )\n",
    "    \n",
    "    # üö® Affichage des alertes\n",
    "    if log_result['alerts']:\n",
    "        print(f\"üö® Alertes pour pr√©diction {i+1}:\")\n",
    "        for alert in log_result['alerts']:\n",
    "            print(f\"  {alert}\")\n",
    "\n",
    "# üìä G√©n√©ration du dashboard\n",
    "monitor.generate_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Conclusion et R√©capitulatif\n",
    "\n",
    "### ‚úÖ Techniques Avanc√©es Ma√Ætris√©es:\n",
    "\n",
    "#### üîß **Adaptation Efficace**:\n",
    "- **LoRA (Low-Rank Adaptation)** - R√©duction drastique des param√®tres √† entra√Æner\n",
    "- **Adapter Layers** - Couches sp√©cialis√©es pour fine-tuning\n",
    "- **Mixed Precision** - Optimisation m√©moire et vitesse\n",
    "\n",
    "#### üìä **Optimisation Entra√Ænement**:\n",
    "- **Learning Rate Scheduling** - Warmup et decay adaptatifs\n",
    "- **Gradient Checkpointing** - √âconomie m√©moire\n",
    "- **Early Stopping** - Pr√©vention overfitting\n",
    "- **Multi-task Learning** - Entra√Ænement simultan√© sur plusieurs t√¢ches\n",
    "\n",
    "#### üéØ **√âvaluation Avanc√©e**:\n",
    "- **M√©triques d√©taill√©es** - Precision, Recall, F1 par classe\n",
    "- **Tests de robustesse** - Variations adversariales\n",
    "- **Analyse d'erreurs** - Identification des points faibles\n",
    "- **Monitoring continu** - Suivi en production\n",
    "\n",
    "### üöÄ **Optimisations Production**:\n",
    "\n",
    "#### ‚ö° **Performance**:\n",
    "- **Quantification** - R√©duction taille mod√®le (50-70%)\n",
    "- **@tf.function** - Acc√©l√©ration inf√©rence\n",
    "- **Batch Processing** - Optimisation throughput\n",
    "- **Caching intelligent** - R√©duction latence\n",
    "\n",
    "#### üìà **Monitoring**:\n",
    "- **M√©triques temps r√©el** - Latence, confiance, distribution\n",
    "- **Alertes automatiques** - Seuils de performance\n",
    "- **Dashboard interactif** - Visualisation continue\n",
    "- **Analyse de drift** - D√©tection changements donn√©es\n",
    "\n",
    "### üí° **Bonnes Pratiques Production**:\n",
    "\n",
    "1. **üéØ Fine-tuning Efficace**:\n",
    "   - Learning rate 2e-5 √† 5e-5\n",
    "   - Warmup 10% des steps\n",
    "   - Weight decay 0.01\n",
    "   - Gradient clipping 1.0\n",
    "\n",
    "2. **üìä Validation Robuste**:\n",
    "   - Cross-validation k-fold\n",
    "   - Tests adversariaux\n",
    "   - M√©triques fairness\n",
    "   - Analyse distributions\n",
    "\n",
    "3. **üöÄ D√©ploiement Optimal**:\n",
    "   - Quantification FP16/INT8\n",
    "   - Batch inference\n",
    "   - Load balancing\n",
    "   - Monitoring continu\n",
    "\n",
    "### üîÆ **√âvolutions Futures**:\n",
    "\n",
    "- **Parameter-Efficient Methods** - QLoRA, AdaLoRA avanc√©es\n",
    "- **Few-shot Learning** - Adaptation avec peu d'exemples\n",
    "- **Federated Learning** - Entra√Ænement distribu√©\n",
    "- **AutoML** - Optimisation automatique hyperparam√®tres\n",
    "- **Edge Deployment** - D√©ploiement mobile/IoT\n",
    "\n",
    "### üìä **M√©triques de Succ√®s**:\n",
    "\n",
    "- **R√©duction param√®tres**: 90%+ avec LoRA\n",
    "- **Acc√©l√©ration entra√Ænement**: 3-5x plus rapide\n",
    "- **Performance maintenue**: >95% de l'accuracy originale\n",
    "- **Latence production**: <100ms pour BERT-base\n",
    "- **Throughput**: >100 pr√©dictions/sec\n",
    "\n",
    "üéì **Vous ma√Ætrisez maintenant le fine-tuning avanc√© de BERT & GPT pour la production !**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}