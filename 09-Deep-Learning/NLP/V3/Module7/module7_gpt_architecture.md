---
title: Module 7 - Architecture GPT
description: Formation NLP - Module 7 - Architecture GPT
tags:
  - NLP
  - 09-Deep-Learning
category: 09-Deep-Learning
---

# âœï¸ Architecture GPT

Generative Pre-trained Transformer

## ğŸ¯ Qu'est-ce que GPT ?

### ğŸ¨ La RÃ©volution GÃ©nÃ©rative

GPT (Generative Pre-trained Transformer) a rÃ©volutionnÃ© la **gÃ©nÃ©ration de texte** en utilisant l'architecture Transformer dans un mode autorÃ©gressif : chaque mot est prÃ©dit en fonction de tous les mots prÃ©cÃ©dents.

**ğŸ’¡ Innovation ClÃ© :**  
Contrairement Ã  BERT qui "voit" tout le contexte, GPT gÃ©nÃ¨re du texte **mot par mot** en ne regardant que le passÃ©, comme un humain qui Ã©crit une phrase sans connaÃ®tre la fin.

#### ğŸ—ï¸ Architecture GPT SimplifiÃ©e

**ğŸ“ GÃ©nÃ©ration du Token Suivant**  
PrÃ©diction probabiliste (softmax sur vocabulaire)

â¬‡ï¸

**ğŸ“Š Couche de Sortie (Linear + Softmax)**  
Projection vers la taille du vocabulaire

â¬‡ï¸

**ğŸ—ï¸ 12-96 Couches Transformer Decoder**  
Masked Self-Attention + Feed-Forward

â¬‡ï¸

**â• Embeddings = Token + Position**  
Pas de segment embeddings (sÃ©quence unique)

â¬‡ï¸

**ğŸ“ Input : SÃ©quence de Tokens**  
BPE/WordPiece tokenization

**ğŸ” DiffÃ©rence Fondamentale :**  
â€¢ BERT : "Le chat \[MASK\] des croquettes" â†’ devine "mange"  
â€¢ GPT : "Le chat mange des" â†’ gÃ©nÃ¨re "croquettes dans la cuisine"  
  
**ğŸ’¡ RÃ©sultat :** GPT crÃ©e du texte fluide et cohÃ©rent !

## ğŸš€ L'Ã‰volution de GPT

### ğŸ“ˆ De GPT-1 Ã  GPT-4

2018

ğŸŒ± GPT-1 : Les Fondations

117M paramÃ¨tres â€¢ Preuve de concept â€¢ GÃ©nÃ©ration cohÃ©rente sur petits textes

2019

ğŸŒ¿ GPT-2 : La PercÃ©e

1.5B paramÃ¨tres â€¢ "Trop dangereux pour Ãªtre relÃ¢chÃ©" â€¢ GÃ©nÃ©ration impressionnante

2020

ğŸŒ³ GPT-3 : Le GÃ©ant

175B paramÃ¨tres â€¢ Few-shot learning â€¢ RÃ©volution de l'IA gÃ©nÃ©rative

2022

ğŸ’¬ ChatGPT : L'Explosion

GPT-3.5 + RLHF â€¢ Interface conversationnelle â€¢ 100M utilisateurs en 2 mois

2023

ğŸ§  GPT-4 : L'Ã‰volution

Multimodal â€¢ Raisonnement amÃ©liorÃ© â€¢ Performance quasi-humaine

ModÃ¨le

ParamÃ¨tres

Contexte

Innovation

Impact

**GPT-1**

117M

512 tokens

Preuve de concept

GÃ©nÃ©ration basique

**GPT-2**

1.5B

1024 tokens

Scaling laws

GÃ©nÃ©ration cohÃ©rente

**GPT-3**

175B

2048 tokens

In-context learning

Few-shot performance

**GPT-4**

~1T

8192 tokens

Multimodal

Raisonnement avancÃ©

## ğŸ”„ GÃ©nÃ©ration Autoregressive

### ğŸ¯ Comment GPT GÃ©nÃ¨re du Texte

GPT utilise un processus **autorÃ©gressif** : il gÃ©nÃ¨re un token, l'ajoute au contexte, puis gÃ©nÃ¨re le suivant.

#### ğŸ­ DÃ©monstration de GÃ©nÃ©ration

**Prompt initial :** "L'intelligence artificielle va"

**Ã‰tape 1 :** "L'intelligence artificielle va rÃ©volutionner"

**Ã‰tape 2 :** "L'intelligence artificielle va rÃ©volutionner notre"

**Ã‰tape 3 :** "L'intelligence artificielle va rÃ©volutionner notre faÃ§on"

**Ã‰tape 4 :** "L'intelligence artificielle va rÃ©volutionner notre faÃ§on de"

**RÃ©sultat final :** "L'intelligence artificielle va rÃ©volutionner notre faÃ§on de travailler et de vivre."

**ğŸ›ï¸ Techniques de GÃ©nÃ©ration :**  
â€¢ Greedy decoding : Choisir le token le plus probable  
â€¢ Beam search : Explorer plusieurs hypothÃ¨ses simultanÃ©ment  
â€¢ Sampling : Ã‰chantillonner selon les probabilitÃ©s  
â€¢ Top-k/Top-p : Limiter les choix aux k meilleurs ou p% de probabilitÃ©

#### ğŸ§ª GÃ©nÃ©rateur GPT Interactif

GÃ©nÃ©ration GPT apparaÃ®tra ici...

## ğŸ§  Techniques AvancÃ©es

### ğŸ¯ In-Context Learning

GPT peut apprendre de nouvelles tÃ¢ches juste en voyant quelques exemples dans le prompt, sans modification des poids !

**ğŸ” Exemple de Few-Shot Learning :**  
  
**Prompt :**  
"Traduisez en anglais :  
FranÃ§ais: Bonjour â†’ Anglais: Hello  
FranÃ§ais: Au revoir â†’ Anglais: Goodbye  
FranÃ§ais: Merci â†’ Anglais:"  
  
**GPT gÃ©nÃ¨re :** "Thank you"

### âš¡ RLHF : Reinforcement Learning from Human Feedback

Technique rÃ©volutionnaire utilisÃ©e pour ChatGPT : entraÃ®ner GPT Ã  gÃ©nÃ©rer des rÃ©ponses que les humains prÃ©fÃ¨rent.

ğŸ‘¥

Ã‰tape 1: Collecte

Humains Ã©crivent des rÃ©ponses de haute qualitÃ© pour entraÃ®ner un modÃ¨le supervisÃ©.

âš–ï¸

Ã‰tape 2: Comparaison

Humains classent diffÃ©rentes rÃ©ponses pour entraÃ®ner un modÃ¨le de rÃ©compense.

ğŸ¯

Ã‰tape 3: Optimisation

Le modÃ¨le GPT est affinÃ© avec PPO pour maximiser les rÃ©compenses humaines.

## ğŸš€ Applications de GPT

### ğŸ’¼ Cas d'Usage RÃ©volutionnaires

âœï¸

GÃ©nÃ©ration de Contenu

Articles, blogs, scripts, poÃ©sie, code. CrÃ©ativitÃ© illimitÃ©e avec cohÃ©rence remarquable.

ğŸ’¬

Chatbots Conversationnels

Assistants virtuels capables de conversations naturelles et contextuelles.

ğŸ”„

ComplÃ©tion de Code

GitHub Copilot, assistance Ã  la programmation, gÃ©nÃ©ration automatique de code.

ğŸ“š

RÃ©sumÃ© Automatique

SynthÃ¨se de documents longs, extraction d'informations clÃ©s, vulgarisation.

ğŸŒ

Traduction Contextuelle

Traduction qui prÃ©serve le ton, le style et les nuances culturelles.

ğŸ“

Tuteur PersonnalisÃ©

Explications adaptÃ©es au niveau, exercices gÃ©nÃ©rÃ©s, feedback personnalisÃ©.

#### ğŸ§ª Simulateur d'Applications GPT

Application GPT apparaÃ®tra ici...

## âš ï¸ DÃ©fis et Limitations

### ğŸ¯ Challenges Actuels

**ğŸ” Principales Limitations :**  
â€¢ Hallucinations : GÃ©nÃ©ration d'informations fausses avec confiance  
â€¢ Contexte limitÃ© : FenÃªtre de tokens finie (mÃªme si elle grandit)  
â€¢ Pas de mise Ã  jour : Connaissances figÃ©es au moment de l'entraÃ®nement  
â€¢ Biais : Reproduction des biais prÃ©sents dans les donnÃ©es  
â€¢ CoÃ»t computationnel : InfÃ©rence coÃ»teuse pour les gros modÃ¨les

### ğŸ›¡ï¸ SÃ©curitÃ© et Ã‰thique

ğŸš«

Contenu InappropriÃ©

Filtrage et modÃ©ration pour Ã©viter la gÃ©nÃ©ration de contenu nuisible.

ğŸ­

Deepfakes Textuels

Risque de dÃ©sinformation et de manipulation par gÃ©nÃ©ration automatique.

âš–ï¸

PropriÃ©tÃ© Intellectuelle

Questions sur la propriÃ©tÃ© du contenu gÃ©nÃ©rÃ© et les droits d'auteur.

[â† Architecture BERT](module7_bert_architecture.html)

**Architecture GPT**  
GÃ©nÃ©ration autoregressive rÃ©volutionnaire

[Fine-tuning â†’](module7_fine_tuning.html)

// Animation de la barre de progression window.addEventListener('load', function() { setTimeout(() => { document.getElementById('progressBar').style.width = '100%'; }, 1000); }); // DÃ©monstration GPT function demonstrateGPT() { const input = document.getElementById('gptPrompt').value.trim(); if (!input) { document.getElementById('gptOutput').textContent = 'GÃ©nÃ©ration GPT apparaÃ®tra ici...'; return; } // Simulation de gÃ©nÃ©ration GPT const continuations = { "dans le futur": \["les robots aideront l'humanitÃ©", "la technologie sera omniprÃ©sente", "nous vivrons dans des villes intelligentes"\], "l'intelligence artificielle": \["transformera notre sociÃ©tÃ©", "rÃ©volutionnera la mÃ©decine", "crÃ©era de nouveaux emplois"\], "les robots": \["seront nos partenaires", "nous assisteront au quotidien", "auront des Ã©motions"\], "la technologie": \["connectera le monde entier", "rÃ©soudra les dÃ©fis climatiques", "dÃ©mocratisera l'Ã©ducation"\], "default": \["continuera Ã  Ã©voluer rapidement", "changera notre faÃ§on de vivre", "ouvrira de nouvelles possibilitÃ©s"\] }; let continuation = continuations.default\[Math.floor(Math.random() \* continuations.default.length)\]; // Recherche d'une continuation spÃ©cifique for (const \[key, values\] of Object.entries(continuations)) { if (input.toLowerCase().includes(key) && key !== 'default') { continuation = values\[Math.floor(Math.random() \* values.length)\]; break; } } const result = \` <strong>âœï¸ GÃ©nÃ©ration GPT Simulation</strong><br><br> <div style="background: #E8F5E8; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #4CAF50;"> <strong>ğŸ“ Prompt :</strong> "${input}"<br><br> <strong>ğŸ¤– GÃ©nÃ©ration :</strong> "${input} ${continuation}." </div> <div style="background: #F1F8E9; padding: 10px; border-radius: 5px; margin: 10px 0;"> <small> âš¡ <strong>MÃ©thode :</strong> Autoregressive generation<br> ğŸ¯ <strong>TempÃ©rature :</strong> 0.7<br> ğŸ“Š <strong>Top-p :</strong> 0.9<br> ğŸ”¢ <strong>Tokens gÃ©nÃ©rÃ©s :</strong> ${continuation.split(' ').length} </small> </div> \`; document.getElementById('gptOutput').innerHTML = result; } // DÃ©monstration Applications GPT function demonstrateGPTApp() { const input = document.getElementById('gptApp').value.trim(); if (!input) { document.getElementById('gptAppOutput').textContent = 'Application GPT apparaÃ®tra ici...'; return; } let appType = 'GÃ©nÃ©ration gÃ©nÃ©rale'; let output = ''; if (input.toLowerCase().includes('email')) { appType = 'ğŸ“§ RÃ©daction d\\'Email'; output = \`Objet: \[Sujet automatiquement gÃ©nÃ©rÃ©\] Bonjour \[Destinataire\], J'espÃ¨re que ce message vous trouve en bonne santÃ©. Je vous Ã©cris concernant \[contexte basÃ© sur votre demande\]. \[Corps du message adaptÃ© Ã  votre demande avec ton professionnel\] Cordialement, \[Votre nom\]\`; } else if (input.toLowerCase().includes('code') || input.toLowerCase().includes('program')) { appType = 'ğŸ’» GÃ©nÃ©ration de Code'; output = \`// Code gÃ©nÃ©rÃ© automatiquement function solution() { /\* \* Fonction gÃ©nÃ©rÃ©e selon vos spÃ©cifications \* Utilise les meilleures pratiques de dÃ©veloppement \*/ // ImplÃ©mentation basÃ©e sur votre demande return result; } // Tests automatiques console.log(solution());\`; } else if (input.toLowerCase().includes('rÃ©sumÃ©') || input.toLowerCase().includes('summary')) { appType = 'ğŸ“š RÃ©sumÃ© Automatique'; output = \`## RÃ©sumÃ© ExÃ©cutif \*\*Points clÃ©s :\*\* â€¢ Point principal 1 extrait du contexte â€¢ Insight important identifiÃ© â€¢ Conclusion et recommandations \*\*Longueur :\*\* AdaptÃ© automatiquement selon le besoin\`; } else { appType = 'âœï¸ GÃ©nÃ©ration CrÃ©ative'; output = \`Contenu gÃ©nÃ©rÃ© crÃ©ativement basÃ© sur votre demande : \[Texte fluide et cohÃ©rent qui rÃ©pond Ã  votre besoin spÃ©cifique, avec style et ton appropriÃ©s\] Adaptation automatique du registre de langue et du format selon le contexte.\`; } const result = \` <strong>ğŸš€ ${appType}</strong><br><br> <div style="background: #E8F5E8; padding: 15px; border-radius: 8px; margin: 10px 0;"> <strong>ğŸ“ Votre demande :</strong> "${input}"<br><br> <strong>ğŸ¯ RÃ©sultat GPT :</strong><br> <div style="background: white; padding: 10px; border-radius: 5px; margin: 10px 0; font-family: monospace; white-space: pre-line;">${output}</div> </div> <div style="background: #F1F8E9; padding: 10px; border-radius: 5px; margin: 10px 0;"> <small> ğŸ¤– <strong>ModÃ¨le :</strong> GPT-3.5/4<br> ğŸšï¸ <strong>Adaptation :</strong> Contexte dÃ©tectÃ© automatiquement<br> ğŸ“Š <strong>QualitÃ© :</strong> OptimisÃ©e pour l'usage professionnel </small> </div> \`; document.getElementById('gptAppOutput').innerHTML = result; } // Animation des couches GPT document.querySelectorAll('.gpt-layer').forEach((layer, index) => { layer.addEventListener('click', function() { this.style.animation = 'none'; setTimeout(() => { this.style.animation = 'pulse 0.8s ease-in-out'; this.style.background = 'linear-gradient(135deg, #81C784, #66BB6A)'; setTimeout(() => { this.style.background = 'linear-gradient(135deg, #E8F5E8, #C8E6C9)'; }, 800); }, 10); }); });
