---
title: Module 8 - Monitoring & ObservabilitÃ©
description: Formation NLP - Module 8 - Monitoring & ObservabilitÃ©
tags:
  - NLP
  - 09-Deep-Learning
category: 09-Deep-Learning
---

# ğŸ“Š Monitoring & ObservabilitÃ©

Surveillance et diagnostic des systÃ¨mes NLP en production

## ğŸ“ˆ Dashboard de Production

### ğŸ¯ MÃ©triques Temps RÃ©el

Un systÃ¨me de monitoring efficace fournit une visibilitÃ© complÃ¨te sur la santÃ© et les performances de vos services NLP.

âš¡ Performance SystÃ¨me

Latence P95 47ms

Throughput 2,847 req/sec

Taux d'erreur 0.12%

DisponibilitÃ© 99.97%

ğŸ§  MÃ©triques ML

Confiance moyenne 0.847

PrÃ©dictions/jour 245K

Cache hit rate 78%

Model drift Stable

ğŸ’» Infrastructure

CPU Usage 67%

Memory Usage 4.2GB / 8GB

GPU Utilization 85%

Instances actives 6 / 8

ğŸš¦ Ã‰tat des Services

API Gateway Healthy

Sentiment Service Healthy

NER Service Warning

Database Healthy

âš ï¸

Alerte : Latence Ã‰levÃ©e

Service NER dÃ©passe 120ms P95 depuis 5 minutes. Auto-scaling dÃ©clenchÃ©.

#### ğŸ“Š Ã‰volution Latence (24h)

00h

35ms

04h

45ms

08h

67ms

12h

84ms

16h

56ms

20h

42ms

24h

47ms

## ğŸ” DÃ©tection de Data Drift

### ğŸ“Š Surveillance des Distributions

La dÃ©rive des donnÃ©es est un phÃ©nomÃ¨ne critique oÃ¹ les donnÃ©es de production diffÃ¨rent des donnÃ©es d'entraÃ®nement, dÃ©gradant les performances du modÃ¨le.

ğŸ“ˆ

Statistical Drift Detection

DÃ©tection basÃ©e sur des tests statistiques (KS-test, chi-square) pour identifier les changements de distribution.

*   Tests Kolmogorov-Smirnov
*   Population Stability Index
*   Jensen-Shannon Divergence
*   Alertes automatiques

ğŸ¯

Performance Monitoring

Surveillance continue des mÃ©triques de performance pour dÃ©tecter une dÃ©gradation.

*   Accuracy tracking
*   Confidence distribution
*   Prediction drift
*   A/B testing continu

ğŸŒŠ

Feature Drift Analysis

Analyse fine des changements dans les features d'entrÃ©e du modÃ¨le.

*   Distribution embedding
*   Feature importance shift
*   Covariate shift detection
*   Concept drift identification

\# DÃ©tection de data drift pour modÃ¨les NLP import numpy as np from scipy import stats from sklearn.feature\_extraction.text import TfidfVectorizer import logging class NLPDriftDetector: def \_\_init\_\_(self, reference\_data, alert\_threshold=0.05): self.reference\_data = reference\_data self.alert\_threshold = alert\_threshold self.vectorizer = TfidfVectorizer(max\_features=1000, stop\_words='english') # Calcul des features de rÃ©fÃ©rence self.reference\_features = self.\_extract\_features(reference\_data) self.reference\_stats = self.\_compute\_baseline\_stats() def \_extract\_features(self, texts): """Extraction de features pour analyse de drift""" # Features statistiques lengths = \[len(text.split()) for text in texts\] char\_counts = \[len(text) for text in texts\] # Features TF-IDF if hasattr(self.vectorizer, 'vocabulary\_'): tfidf\_features = self.vectorizer.transform(texts) else: tfidf\_features = self.vectorizer.fit\_transform(texts) return { 'lengths': lengths, 'char\_counts': char\_counts, 'tfidf\_mean': np.mean(tfidf\_features.toarray(), axis=1), 'texts': texts } def \_compute\_baseline\_stats(self): """Calcul des statistiques de rÃ©fÃ©rence""" return { 'length\_mean': np.mean(self.reference\_features\['lengths'\]), 'length\_std': np.std(self.reference\_features\['lengths'\]), 'char\_mean': np.mean(self.reference\_features\['char\_counts'\]), 'char\_std': np.std(self.reference\_features\['char\_counts'\]), 'tfidf\_distribution': self.reference\_features\['tfidf\_mean'\] } def detect\_drift(self, new\_data, drift\_types=\['statistical', 'semantic'\]): """ DÃ©tection de drift sur nouvelles donnÃ©es """ results = {} new\_features = self.\_extract\_features(new\_data) if 'statistical' in drift\_types: results\['statistical\_drift'\] = self.\_statistical\_drift\_test(new\_features) if 'semantic' in drift\_types: results\['semantic\_drift'\] = self.\_semantic\_drift\_test(new\_data) # Drift global results\['overall\_drift'\] = any( result\['p\_value'\] < self.alert\_threshold for result in results.values() if 'p\_value' in result ) return results def \_statistical\_drift\_test(self, new\_features): """Test statistique de drift (Kolmogorov-Smirnov)""" # Test sur longueurs de texte ks\_stat, p\_value = stats.ks\_2samp( self.reference\_features\['lengths'\], new\_features\['lengths'\] ) # Population Stability Index psi = self.\_calculate\_psi( self.reference\_features\['tfidf\_mean'\], new\_features\['tfidf\_mean'\] ) return { 'test\_type': 'kolmogorov\_smirnov', 'ks\_statistic': ks\_stat, 'p\_value': p\_value, 'psi\_score': psi, 'drift\_detected': p\_value < self.alert\_threshold or psi > 0.2 } def \_semantic\_drift\_test(self, new\_texts): """Test de drift sÃ©mantique via embeddings""" # Utilisation de la similaritÃ© cosinus moyenne from sklearn.metrics.pairwise import cosine\_similarity ref\_tfidf = self.vectorizer.transform(self.reference\_data\[:100\]) new\_tfidf = self.vectorizer.transform(new\_texts\[:100\]) # SimilaritÃ© intra-rÃ©fÃ©rence vs inter-rÃ©fÃ©rence-nouveau ref\_similarity = np.mean(cosine\_similarity(ref\_tfidf)) cross\_similarity = np.mean(cosine\_similarity(ref\_tfidf, new\_tfidf)) semantic\_shift = abs(ref\_similarity - cross\_similarity) return { 'test\_type': 'semantic\_similarity', 'reference\_similarity': ref\_similarity, 'cross\_similarity': cross\_similarity, 'semantic\_shift': semantic\_shift, 'drift\_detected': semantic\_shift > 0.1 } def \_calculate\_psi(self, reference, current, buckets=10): """Calcul du Population Stability Index""" def scale\_range(input\_data, min\_val, max\_val): return (input\_data - min\_val) / (max\_val - min\_val) min\_val = min(min(reference), min(current)) max\_val = max(max(reference), max(current)) ref\_scaled = scale\_range(reference, min\_val, max\_val) cur\_scaled = scale\_range(current, min\_val, max\_val) breakpoints = np.arange(0, buckets + 1) / buckets ref\_counts, \_ = np.histogram(ref\_scaled, breakpoints) cur\_counts, \_ = np.histogram(cur\_scaled, breakpoints) # Ã‰viter division par zÃ©ro ref\_counts = np.where(ref\_counts == 0, 1, ref\_counts) cur\_counts = np.where(cur\_counts == 0, 1, cur\_counts) ref\_percents = ref\_counts / len(reference) cur\_percents = cur\_counts / len(current) psi = np.sum((cur\_percents - ref\_percents) \* np.log(cur\_percents / ref\_percents)) return psi

#### ğŸ” Simulateur de Drift Detection

Pas de Drift Drift LÃ©ger Drift SÃ©vÃ¨re Concept Drift

SÃ©lectionnez un scÃ©nario pour analyser le drift...

## ğŸ› ï¸ Stack Technique de Monitoring

### âš™ï¸ Outils et Technologies

ğŸ“Š

Prometheus + Grafana

Stack de rÃ©fÃ©rence pour mÃ©triques et dashboards temps rÃ©el avec alerting avancÃ©.

*   MÃ©triques custom ML
*   Dashboards interactifs
*   Alerting multicanal
*   RÃ©tention long terme

ğŸ“

ELK Stack

Elasticsearch, Logstash, Kibana pour logging centralisÃ© et analyse de logs structurÃ©s.

*   Logs centralisÃ©s
*   Recherche full-text
*   AgrÃ©gations complexes
*   Visualisations avancÃ©es

ğŸ”

Jaeger Tracing

Tracing distribuÃ© pour suivre les requÃªtes Ã  travers les microservices NLP.

*   Distributed tracing
*   Performance profiling
*   Bottleneck identification
*   Dependency mapping

ğŸš¨

MLflow + Weights & Biases

Tracking d'expÃ©riences ML et monitoring de modÃ¨les avec versioning.

*   Model versioning
*   Experiment tracking
*   Performance comparison
*   Artifact management

\# Configuration Prometheus pour mÃ©triques NLP personnalisÃ©es from prometheus\_client import Counter, Histogram, Gauge, start\_http\_server import time import functools # MÃ©triques custom pour NLP PREDICTION\_COUNTER = Counter( 'nlp\_predictions\_total', 'Total predictions made', \['model\_name', 'task\_type', 'status'\] ) PREDICTION\_LATENCY = Histogram( 'nlp\_prediction\_duration\_seconds', 'Time spent on predictions', \['model\_name', 'task\_type'\], buckets=\[0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0\] ) MODEL\_CONFIDENCE = Histogram( 'nlp\_prediction\_confidence', 'Confidence scores distribution', \['model\_name', 'task\_type'\], buckets=\[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0\] ) GPU\_MEMORY\_USAGE = Gauge( 'nlp\_gpu\_memory\_bytes', 'GPU memory usage in bytes', \['gpu\_id', 'model\_name'\] ) CACHE\_HIT\_RATE = Gauge( 'nlp\_cache\_hit\_rate', 'Cache hit rate percentage', \['cache\_type'\] ) class NLPMonitoringMiddleware: def \_\_init\_\_(self, model\_name, task\_type): self.model\_name = model\_name self.task\_type = task\_type def monitor\_prediction(self, func): """DÃ©corateur pour monitorer les prÃ©dictions""" @functools.wraps(func) def wrapper(\*args, \*\*kwargs): start\_time = time.time() status = 'success' try: result = func(\*args, \*\*kwargs) # Enregistrer la confiance si disponible if hasattr(result, 'confidence'): MODEL\_CONFIDENCE.labels( model\_name=self.model\_name, task\_type=self.task\_type ).observe(result.confidence) return result except Exception as e: status = 'error' raise finally: # Enregistrer latence et compteur duration = time.time() - start\_time PREDICTION\_LATENCY.labels( model\_name=self.model\_name, task\_type=self.task\_type ).observe(duration) PREDICTION\_COUNTER.labels( model\_name=self.model\_name, task\_type=self.task\_type, status=status ).inc() return wrapper # Exemple d'utilisation class SentimentAnalysisService: def \_\_init\_\_(self): self.monitor = NLPMonitoringMiddleware('bert-sentiment', 'classification') @monitor.monitor\_prediction def predict(self, text): # Simulation de prÃ©diction time.sleep(0.05) # Latence simulÃ©e return { 'sentiment': 'positive', 'confidence': 0.87, 'processing\_time': 0.05 } # DÃ©marrage du serveur de mÃ©triques if \_\_name\_\_ == "\_\_main\_\_": start\_http\_server(8000) service = SentimentAnalysisService()

**âš ï¸ Bonnes Pratiques Monitoring :**  
â€¢ MÃ©triques RED : Rate, Errors, Duration pour chaque service  
â€¢ Logging structurÃ© : JSON avec contexte complet  
â€¢ Correlation IDs : TraÃ§abilitÃ© cross-service  
â€¢ Alerting intelligent : Ã‰viter les false positives

## ğŸš¨ Alerting et Incident Response

### âš¡ StratÃ©gie d'Alerting

Un systÃ¨me d'alerting efficace dÃ©tecte les problÃ¨mes avant qu'ils impactent les utilisateurs et guide la rÃ©solution d'incidents.

**ğŸ¯ Niveaux d'Alerte NLP :**  
â€¢ INFO : DÃ©ploiement nouveau modÃ¨le, scaling automatique  
â€¢ WARNING : Latence Ã©levÃ©e, drift dÃ©tectÃ©, cache miss rate Ã©levÃ©  
â€¢ CRITICAL : Service down, accuracy chute >5%, erreurs >1%  
â€¢ EMERGENCY : Perte de donnÃ©es, security breach, corruption modÃ¨le

#### ğŸš¨ Simulateur d'Incident Response

Latence Ã‰levÃ©e Chute Accuracy Service Down Data Drift

SÃ©lectionnez un type d'incident pour voir la procÃ©dure...

[â† DÃ©ploiement](module8_deploiement_production.html)

**Monitoring & ObservabilitÃ©**  
Surveillance, Alerting, Incident Response

[Index Module 8 â†’](index.html)

// Animation de la barre de progression window.addEventListener('load', function() { setTimeout(() => { document.getElementById('progressBar').style.width = '100%'; }, 1000); }); // Simulateur de drift detection function simulateDrift(scenario) { let analysis = ''; switch(scenario) { case 'no\_drift': analysis = \`âœ… Pas de Drift DÃ©tectÃ© ğŸ“Š Analyse Statistique : â€¢ KS-test p-value: 0.45 (> 0.05) â€¢ Population Stability Index: 0.08 (< 0.2) â€¢ SimilaritÃ© sÃ©mantique: 0.91 (> 0.8) â€¢ Distribution longueur texte: Stable ğŸ¯ Recommandations : â€¢ Aucune action requise â€¢ Monitoring continu â€¢ Validation qualitÃ© mensuelle â€¢ Performance stable maintenue ğŸ“ˆ MÃ©triques ModÃ¨le : â€¢ Accuracy: 94.2% (stable) â€¢ Confiance moyenne: 0.87 â€¢ Latence P95: 47ms â€¢ Taux d'erreur: 0.12%\`; break; case 'slight\_drift': analysis = \`âš ï¸ Drift LÃ©ger DÃ©tectÃ© ğŸ“Š Analyse Statistique : â€¢ KS-test p-value: 0.03 (< 0.05) â€¢ Population Stability Index: 0.15 (limite) â€¢ SimilaritÃ© sÃ©mantique: 0.78 (lÃ©gÃ¨re baisse) â€¢ Distribution: Changement vocabulaire ğŸ¯ Recommandations : â€¢ Surveillance renforcÃ©e â€¢ Collecte donnÃ©es rÃ©centes â€¢ A/B test avec nouveau dataset â€¢ PrÃ©paration re-entraÃ®nement ğŸ“ˆ Impact ObservÃ© : â€¢ Accuracy: 92.8% (-1.4%) â€¢ Confiance: 0.83 (-0.04) â€¢ Certaines catÃ©gories affectÃ©es â€¢ TolÃ©rable Ã  court terme\`; break; case 'severe\_drift': analysis = \`ğŸš¨ Drift SÃ©vÃ¨re DÃ©tectÃ© ğŸ“Š Analyse Statistique : â€¢ KS-test p-value: 0.001 (<<< 0.05) â€¢ Population Stability Index: 0.35 (critique) â€¢ SimilaritÃ© sÃ©mantique: 0.62 (forte baisse) â€¢ Distribution: Changement majeur domaine ğŸ¯ Actions ImmÃ©diates : â€¢ ğŸš¨ Alerte Ã©quipe ML â€¢ Rollback vers modÃ¨le robuste â€¢ Investigation source du drift â€¢ Re-entraÃ®nement d'urgence ğŸ“ˆ Impact Critique : â€¢ Accuracy: 86.3% (-7.9%) â€¢ Confiance: 0.74 (-0.13) â€¢ Intervention humaine requise â€¢ Risque business Ã©levÃ©\`; break; case 'concept\_drift': analysis = \`ğŸ”„ Concept Drift DÃ©tectÃ© ğŸ“Š Analyse Complexe : â€¢ KS-test p-value: 0.15 (borderline) â€¢ Concept shift score: 0.8 (Ã©levÃ©) â€¢ Labels distribution: ChangÃ©e â€¢ SaisonnalitÃ© dÃ©tectÃ©e ğŸ¯ StratÃ©gie Adaptative : â€¢ Mise Ã  jour continue du modÃ¨le â€¢ Online learning activation â€¢ Rebalancing des classes â€¢ Adaptation aux nouveaux concepts ğŸ“ˆ Impact Ã‰volutif : â€¢ Accuracy globale: 91.5% â€¢ Performance par classe variable â€¢ Adaptation progressive nÃ©cessaire â€¢ Ã‰volution mÃ©tier dÃ©tectÃ©e\`; break; } document.getElementById('driftOutput').innerHTML = \`<div style="text-align: left; font-size: 0.9em; line-height: 1.4; white-space: pre-line;">${analysis}</div>\`; } // Simulateur d'incident response function simulateIncident(incidentType) { let response = ''; switch(incidentType) { case 'latency': response = \`âš¡ Incident: Latence Ã‰levÃ©e (P95 > 200ms) ğŸš¨ Alertes DÃ©clenchÃ©es : â€¢ 14:23 - WARNING: Latence P95 = 156ms â€¢ 14:25 - CRITICAL: Latence P95 = 210ms â€¢ 14:26 - Auto-scaling dÃ©clenchÃ© ğŸ” Investigation (SEV-2) : 1. VÃ©rification charge systÃ¨me âœ… 2. Analyse logs erreurs âœ… 3. Monitoring GPU utilization âš ï¸ 98% 4. VÃ©rification modÃ¨le drift âœ… ğŸ’¡ Cause IdentifiÃ©e : â€¢ Pic de trafic inattendu â€¢ GPU memory saturation â€¢ Garbage collection frÃ©quent âš¡ Actions Correctives : â€¢ 14:27 - Scale horizontal +2 instances â€¢ 14:29 - Activation circuit breaker â€¢ 14:30 - Latence revenue Ã  47ms â€¢ 14:35 - Incident rÃ©solu ğŸ“‹ Post-Incident : â€¢ Update alerting thresholds â€¢ AmÃ©lioration auto-scaling â€¢ Documentation playbook\`; break; case 'accuracy': response = \`ğŸ“‰ Incident: Chute d'Accuracy (-7%) ğŸš¨ Alertes Critiques : â€¢ 09:15 - Accuracy dropped to 87.2% â€¢ 09:16 - Data drift detected â€¢ 09:17 - Confidence scores declining ğŸ” Investigation (SEV-1) : 1. Model version check âœ… v2.1.3 2. Input data validation âš ï¸ Anomalies 3. Feature distribution âŒ Shifted 4. External data source âŒ Changed ğŸ’¡ Root Cause : â€¢ Upstream data pipeline modified â€¢ Feature encoding changed â€¢ Training/serving skew introduced âš¡ Actions ImmÃ©diates : â€¢ 09:20 - Rollback to model v2.1.2 â€¢ 09:22 - Fix data pipeline â€¢ 09:25 - Accuracy restored to 94.1% â€¢ 09:30 - Validation complete ğŸ“‹ Prevention : â€¢ Schema validation enforcement â€¢ Canary deployments â€¢ Data quality monitoring â€¢ Cross-validation automation\`; break; case 'service\_down': response = \`ğŸ’¥ Incident: Service Sentiment Down ğŸš¨ Alertes SystÃ¨me : â€¢ 16:42 - Service health check failed â€¢ 16:42 - 100% error rate â€¢ 16:43 - Failover to backup instances â€¢ 16:43 - User impact: 30% requests ğŸ” Investigation (SEV-0) : 1. Container status âŒ CrashLoopBackOff 2. Memory usage âŒ OOM Kill 3. Model loading âŒ Corrupted weights â€¢ Model file corruption dÃ©tectÃ©e ğŸ’¡ Cause Racine : â€¢ DÃ©ploiement interrompu â€¢ Fichier modÃ¨le partiellement Ã©crit â€¢ Health check insuffisant âš¡ Actions d'Urgence : â€¢ 16:44 - Stop deployment pipeline â€¢ 16:45 - Restore from backup â€¢ 16:47 - Service operational â€¢ 16:50 - Traffic fully restored ğŸ“‹ AmÃ©liorations : â€¢ Atomic deployments â€¢ Model integrity checks â€¢ Improved health probes â€¢ Faster rollback procedure\`; break; case 'data\_drift': response = \`ğŸŒŠ Incident: Data Drift Majeur ğŸš¨ ML Alerts : â€¢ 11:30 - PSI score: 0.42 (critical) â€¢ 11:31 - Feature importance shifted â€¢ 11:32 - Prediction distribution changed â€¢ 11:35 - Business metrics impacted ğŸ” Investigation ML (SEV-1) : 1. Data source analysis âœ… 2. Feature engineering âš ï¸ New features 3. User behavior âŒ Seasonal change 4. External factors âŒ Market shift ğŸ’¡ Drift Analysis : â€¢ Nouveau segment utilisateurs â€¢ Changement comportemental COVID â€¢ Vocabulaire Ã©volutif â€¢ SaisonnalitÃ© non modÃ©lisÃ©e âš¡ StratÃ©gie Adaptative : â€¢ 11:40 - Activate online learning â€¢ 11:45 - Collect recent labels â€¢ 12:00 - Retrain with new data â€¢ 12:30 - Deploy adapted model ğŸ“‹ Long Terme : â€¢ Continuous learning pipeline â€¢ Drift detection automation â€¢ Model versioning strategy â€¢ Business alignment meeting\`; break; } document.getElementById('incidentOutput').innerHTML = \`<div style="text-align: left; font-size: 0.9em; line-height: 1.4; white-space: pre-line;">${response}</div>\`; } // Animation des barres de chart document.querySelectorAll('.chart-bar').forEach((bar, index) => { bar.addEventListener('click', function() { this.style.animation = 'none'; setTimeout(() => { this.style.animation = 'pulse 0.8s ease-in-out'; this.style.background = 'linear-gradient(to top, #065F46, #10B981)'; setTimeout(() => { this.style.background = 'linear-gradient(to top, #10B981, #34D399)'; }, 800); }, 10); }); });
