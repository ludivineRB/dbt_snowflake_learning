---
title: 'Module 3 - TF-IDF : Concepts'
description: 'Formation NLP - Module 3 - TF-IDF : Concepts'
tags:
  - NLP
  - 09-Deep-Learning
category: 09-Deep-Learning
---

# âš–ï¸ TF-IDF : Concepts

PondÃ©ration Intelligente : Tous les mots ne se valent pas !

[ğŸ  Index Module 3](index.html) [â† BoW DÃ©mo](module3_bow_demo.html) [DÃ©monstrations â†’](module3_tfidf_demo.html)

## ğŸ¤” Le ProblÃ¨me du Bag of Words

### âš ï¸ Tous les Mots ont le MÃªme Poids !

**ğŸš¨ ProblÃ¨me central de BoW :**  
Dans BoW, "le" = "Python" = "blockchain" = "rÃ©volutionnaire"  
Tous comptent pareil ! Mais certains mots sont plus informatifs que d'autres...

#### ğŸ§ª DÃ©monstration du ProblÃ¨me

Analysons ces 3 articles de presse :

##### ğŸ“° Article 1 - Tech

"Le Python transforme le machine learning. Le langage Python rÃ©volutionne l'IA."

##### ğŸ“° Article 2 - Cuisine

"Le chef prÃ©pare le plat. Le restaurant sert le meilleur plat de la rÃ©gion."

##### ğŸ“° Article 3 - Sport

"Le joueur marque le but. Le stade acclame le joueur pour son but."

**ğŸ’¡ Observation :**  
Le mot "le" apparaÃ®t partout â†’ pas discriminant  
Les mots "Python", "chef", "joueur" sont spÃ©cifiques â†’ trÃ¨s informatifs  
**ğŸ¯ Solution : TF-IDF !**

## ğŸ§® Le Concept TF-IDF

### ğŸ“ L'IdÃ©e GÃ©niale

**TF-IDF** = **T**erm **F**requency Ã— **I**nverse **D**ocument **F**requency

#### ğŸ¯ Principe Central

Un mot est important s'il est :  
**FRÃ‰QUENT** dans le document ET **RARE** dans la collection

#### ğŸ“ˆ Term Frequency (TF)

**Question :** Ã€ quel point ce mot est-il important dans CE document ?

TF(t,d) = count(t in d) / |d|

FrÃ©quence du terme t dans le document d

#### ğŸ“‰ Inverse Document Frequency (IDF)

**Question :** Ã€ quel point ce mot est-il rare dans TOUTE la collection ?

IDF(t) = log(N / df(t))

N = total docs, df(t) = docs contenant t

#### ğŸ† Formule Finale TF-IDF

**TF-IDF(t,d) = TF(t,d) Ã— IDF(t)**

*Score Ã©levÃ© = Mot frÃ©quent localement ET rare globalement*

## ğŸ”¢ Calculs DÃ©taillÃ©s

### âœï¸ Exemple Ã‰tape par Ã‰tape

#### ğŸ“š Corpus d'exemple :

*   Doc 1: "Python est un langage de programmation"
*   Doc 2: "Java est aussi un langage de programmation"
*   Doc 3: "Machine learning utilise Python"

1 **Calcul Term Frequency (TF)**

Pour chaque mot dans chaque document :

Doc 1: "Python"(1/6) = 0.167, "langage"(1/6) = 0.167  
Doc 2: "Java"(1/7) = 0.143, "langage"(1/7) = 0.143  
Doc 3: "Python"(1/3) = 0.333, "machine"(1/3) = 0.333

2 **Calcul Inverse Document Frequency (IDF)**

Pour chaque mot unique du vocabulaire :

"Python": log(3/2) = 0.176 (dans 2 docs sur 3)  
"Java": log(3/1) = 0.477 (dans 1 doc sur 3)  
"langage": log(3/2) = 0.176 (dans 2 docs sur 3)

3 **Calcul TF-IDF Final**

Multiplication TF Ã— IDF :

Doc 1 "Python": 0.167 Ã— 0.176 = 0.029  
Doc 2 "Java": 0.143 Ã— 0.477 = 0.068  
Doc 3 "Python": 0.333 Ã— 0.176 = 0.059

**ğŸ¯ InterprÃ©tation :**  
â€¢ "Java" a le score TF-IDF le plus Ã©levÃ© (0.068) car il est rare dans le corpus  
â€¢ "Python" a des scores diffÃ©rents selon le document (frÃ©quence locale)  
â€¢ Les mots communs comme "un", "de" auront des scores faibles

## ğŸ“ Variantes et Optimisations

### ğŸ”§ Variantes de TF

Variant TF

Formule

Avantage

Usage

**Raw Count**

count(t, d)

Simple, direct

Documents similaires

**Term Frequency**

count(t, d) / |d|

Normalise par longueur

Documents variables

**Log Normalization**

1 + log(count(t, d))

RÃ©duit l'impact extrÃªme

Corpus trÃ¨s variables

**Boolean**

1 si t âˆˆ d, 0 sinon

PrÃ©sence/absence

Classification binaire

### ğŸ”§ Variantes d'IDF

Variant IDF

Formule

Avantage

ProblÃ¨me rÃ©solu

**Standard**

log(N / df(t))

Simple, efficace

\-

**Smooth**

log(N / (1 + df(t)))

Ã‰vite division par 0

Mots trÃ¨s rares

**Max**

log(max(df) / df(t))

Normalisation relative

Corpus dÃ©sÃ©quilibrÃ©s

**Probabilistic**

log((N - df(t)) / df(t))

InterprÃ©tation probabiliste

ModÃ©lisation formelle

## âš”ï¸ BoW vs TF-IDF : Le Duel

#### ğŸ’ Bag of Words

*   âœ… **Simple** : Facile Ã  comprendre
*   âœ… **Rapide** : Calcul trÃ¨s efficace
*   âœ… **Baseline** : Bon point de dÃ©part
*   âŒ **NaÃ¯f** : Tous mots Ã©gaux
*   âŒ **Bruiteux** : Stopwords dominants
*   âŒ **Peu discriminant** : Mauvaise sÃ©lectivitÃ©

#### âš–ï¸ TF-IDF

*   âœ… **Intelligent** : PondÃ©ration adaptÃ©e
*   âœ… **Discriminant** : Mots rares valorisÃ©s
*   âœ… **Robuste** : Moins sensible au bruit
*   âŒ **Plus complexe** : Calculs supplÃ©mentaires
*   âŒ **DÃ©pendant corpus** : IDF varie
*   âŒ **MÃ©moire** : Stockage des statistiques

### ğŸ“Š Quand Utiliser Chaque MÃ©thode ?

Contexte

BoW

TF-IDF

Recommandation

**Corpus homogÃ¨ne**

ğŸŸ¢ Bon

ğŸŸ¡ Neutre

BoW suffisant

**Corpus hÃ©tÃ©rogÃ¨ne**

ğŸ”´ Faible

ğŸŸ¢ Excellent

TF-IDF obligatoire

**Classification**

ğŸŸ¡ Acceptable

ğŸŸ¢ Meilleur

TF-IDF recommandÃ©

**Recherche**

ğŸ”´ Mauvais

ğŸŸ¢ Excellent

TF-IDF essentiel

**Temps rÃ©el**

ğŸŸ¢ Rapide

ğŸŸ¡ Moyen

BoW si contraintes

**Petit corpus**

ğŸŸ¢ Stable

ğŸ”´ Instable

BoW plus sÃ»r

### Navigation

[ğŸ  Index Module 3](index.html) [â† BoW DÃ©mo](module3_bow_demo.html) [TF-IDF DÃ©mo â†’](module3_tfidf_demo.html) [ğŸ  Accueil Formation](../index.html)
