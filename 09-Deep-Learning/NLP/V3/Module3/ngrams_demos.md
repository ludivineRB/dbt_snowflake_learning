---
title: Module 3 - N-grams DÃ©monstrations
description: Formation NLP - Module 3 - N-grams DÃ©monstrations
tags:
  - NLP
  - 09-Deep-Learning
category: 09-Deep-Learning
---

# ğŸ”— N-grams - DÃ©monstrations Interactives

Explorez la gÃ©nÃ©ration et les applications des sÃ©quences de mots

[â† Concepts N-grams](module3_ngrams_concepts.html) [Classification â†’](classification_final.html) [ğŸ  Index Module 3](index.html)

## ğŸ§ª GÃ©nÃ©rateur de N-grams Interactif

ğŸ¯ GÃ©nÃ©ration Basique âš™ï¸ Options AvancÃ©es ğŸ“Š Comparaison Tailles

### âœï¸ Entrez votre texte :

New York est une ville fantastique avec beaucoup d'attractions touristiques intÃ©ressantes

Taille N-gram : Unigrammes (1) Bigrammes (2) Trigrammes (3) Quadrigrammes (4) 5-grammes

 Supprimer mots vides

ğŸ”— GÃ©nÃ©rer N-grams

N-grams apparaÃ®tront ici...

0

N-grams Totaux

0

N-grams Uniques

0%

Ratio Unique

0

Long. Moyenne

### âš™ï¸ Configuration AvancÃ©e :

Le machine learning et l'intelligence artificielle transforment notre sociÃ©tÃ© moderne. Ces technologies rÃ©volutionnaires permettent d'automatiser de nombreuses tÃ¢ches complexes. Les algorithmes d'apprentissage automatique analysent des quantitÃ©s massives de donnÃ©es pour extraire des insights prÃ©cieux.

Plage N-grams :

 Ã  

FrÃ©quence minimale : 

Max N-grams : 

SÃ©parateur : Underscore (\_) Espace ( ) Tiret (-) Pipe (|)

ğŸ”§ GÃ©nÃ©rer avec Options

N-grams avancÃ©s apparaÃ®tront ici...

### ğŸ“Š Comparaison des Tailles de N-grams

L'intelligence artificielle et le machine learning rÃ©volutionnent le traitement automatique du langage naturel. Ces technologies permettent de crÃ©er des systÃ¨mes intelligents capables de comprendre et gÃ©nÃ©rer du texte humain avec une prÃ©cision remarquable. ğŸ“ˆ Comparer les Tailles

Comparaison apparaÃ®tra ici...

#### ğŸ“Š Impact de la Taille N sur le Vocabulaire

0

N=1

0

N=2

0

N=3

0

N=4

## ğŸ” Extracteur d'Expressions

### ğŸ“„ Texte technique Ã  analyser :

L'intelligence artificielle et le machine learning transforment notre sociÃ©tÃ© moderne. Le deep learning, une branche du machine learning, rÃ©volutionne la computer vision et le natural language processing. Les rÃ©seaux de neurones artificiels imitent le fonctionnement du cerveau humain. La data science exploite les big data pour extraire des insights prÃ©cieux grÃ¢ce aux algorithmes de machine learning.

Seuil de frÃ©quence :  2

Types d'expressions : Toutes Tech seulement Business seulement

N-gram max : Bigrammes Trigrammes Quadrigrammes

ğŸ” Extraire Expressions

Expressions extraites apparaÃ®tront ici...

## ğŸŒ DÃ©tecteur de Langue avec N-grams

### ğŸ§ª Testez la DÃ©tection de Langue :

Hello, how are you today? I hope you're having a great day and everything is going well!

MÃ©thode : Trigrammes de caractÃ¨res Bigrammes de mots CombinÃ©e

 Afficher dÃ©tails

ğŸŒ DÃ©tecter la Langue

Langue dÃ©tectÃ©e apparaÃ®tra ici...

#### ğŸ§ª Exemples de Test :

ğŸ‡«ğŸ‡· FranÃ§ais ğŸ‡ºğŸ‡¸ Anglais ğŸ‡ªğŸ‡¸ Espagnol ğŸ‡®ğŸ‡¹ Italien ğŸ‡©ğŸ‡ª Allemand

## ğŸ¯ Classification avec N-grams

### ğŸ“Š Comparaison : Mots seuls vs N-grams

Testez l'amÃ©lioration apportÃ©e par les N-grams en classification :

#### ğŸ“š Documents d'entraÃ®nement :

TECH: machine learning intelligence artificielle algorithmes deep learning SPORT: football match Ã©quipe victoire championnat coupe monde CUISINE: restaurant chef plat recette cuisine gastronomie franÃ§aise TECH: dÃ©veloppement web application mobile programmation software SPORT: tennis tournoi joueur raquette court set match point CUISINE: pÃ¢tisserie dessert chocolat four cuisson tempÃ©rature

#### ğŸ§ª Document Ã  classer :

Le deep learning et le machine learning rÃ©volutionnent l'intelligence artificielle moderne

MÃ©thode : Unigrammes seulement Bigrammes seulement Uni + Bigrammes Jusqu'aux trigrammes

ğŸ¯ Classifier

RÃ©sultat de classification...

## ğŸ“Š Analyse de Performance

### âš–ï¸ Trade-offs des N-grams

**ğŸš¨ Attention Ã  l'explosion combinatoire !**  
â€¢ Vocabulaire qui augmente exponentiellement  
â€¢ Matrice de plus en plus sparse  
â€¢ Risque d'overfitting sur des sÃ©quences rares

#### ğŸ“ˆ Analyseur d'Impact Performance

Testez l'impact des N-grams sur la taille du vocabulaire :

L'intelligence artificielle et le machine learning transforment notre monde. Le deep learning permet des avancÃ©es rÃ©volutionnaires en computer vision. Les rÃ©seaux de neurones artificiels imitent le fonctionnement du cerveau. La data science exploite les big data pour extraire des insights. Les algorithmes d'apprentissage automatique s'amÃ©liorent constamment.

N maximum :  3

 Estimer mÃ©moire

ğŸ“Š Analyser Performance

Analyse de performance...

#### ğŸ“Š Croissance du Vocabulaire par N

0

N=1

0

N=2

0

N=3

0

N=4

0

N=5

### ğŸ’¡ Bonnes Pratiques

#### âœ… Recommandations

*   Commencer par uni+bigrammes
*   Filtrer par frÃ©quence minimale
*   Limiter le vocabulaire total
*   Tester sur donnÃ©es de validation
*   Surveiller l'overfitting

#### âŒ Ã€ Ã‰viter

*   N-grams > 4 sauf cas spÃ©ciaux
*   Garder tous les N-grams rares
*   Ignorer la sparsitÃ©
*   Ne pas valider l'amÃ©lioration
*   Vocabulaire sans limite

#### ğŸ¯ Cas d'Usage

*   Classification de texte
*   DÃ©tection de langue
*   Extraction d'entitÃ©s
*   Analyse de sentiment
*   DÃ©tection de plagiat

#### âš¡ Alternatives Modernes

*   Word embeddings
*   ModÃ¨les contextuels
*   Transformers
*   BERT, GPT, etc.
*   RÃ©seaux rÃ©currents

[â† Concepts N-grams](module3_ngrams_concepts.html) [Classification â†’](classification_final.html) [ğŸ  Index Module 3](index.html)

// Variables globales let currentNgrams = null; let currentStats = null; // Stopwords franÃ§ais const STOPWORDS\_FR = new Set(\[ 'le', 'de', 'et', 'Ã ', 'un', 'il', 'Ãªtre', 'en', 'avoir', 'que', 'pour', 'dans', 'ce', 'son', 'une', 'sur', 'avec', 'ne', 'se', 'pas', 'tout', 'plus', 'par', 'grand', 'son', 'que', 'ce', 'lui', 'au', 'du', 'des', 'la', 'les', 'est', 'cette', 'ces', 'mais', 'ou', 'si', 'nous', 'vous', 'ils', 'elles', 'aussi', 'trÃ¨s', 'bien', 'comme', 'donc', 'peut', 'fait', 'sans' \]); // Gestion des onglets function openTab(evt, tabName) { var i, tabcontent, tabs; tabcontent = document.getElementsByClassName("tab-content"); for (i = 0; i < tabcontent.length; i++) { tabcontent\[i\].classList.remove("active"); } tabs = document.getElementsByClassName("tab"); for (i = 0; i < tabs.length; i++) { tabs\[i\].classList.remove("active"); } document.getElementById(tabName).classList.add("active"); evt.currentTarget.classList.add("active"); } // Preprocessing du texte function preprocessText(text, removeStopwords = true) { let processed = text.toLowerCase(); processed = processed.replace(/\[^\\w\\s\]/g, ' '); let tokens = processed.split(/\\s+/).filter(token => token.length > 0); if (removeStopwords) { tokens = tokens.filter(token => !STOPWORDS\_FR.has(token)); } return tokens; } // GÃ©nÃ©ration de N-grams function generateNgrams(tokens, n, separator = '\_') { if (tokens.length < n) return \[\]; const ngrams = \[\]; for (let i = 0; i <= tokens.length - n; i++) { const ngram = tokens.slice(i, i + n).join(separator); ngrams.push(ngram); } return ngrams; } // GÃ©nÃ©ration basique de N-grams function generateBasicNgrams() { const text = document.getElementById('ngramInput').value.trim(); if (!text) { document.getElementById('ngramResult').textContent = 'Veuillez entrer du texte !'; return; } const n = parseInt(document.getElementById('ngramSize').value); const removeStopwords = document.getElementById('removeStopwords').checked; const tokens = preprocessText(text, removeStopwords); const ngrams = generateNgrams(tokens, n); const unique = \[...new Set(ngrams)\]; let html = \`<strong>ğŸ”— N-GRAMS GÃ‰NÃ‰RÃ‰S (N=${n})</strong>\\n\`; html += '=' \* 35 + '\\n\\n'; html += \`<strong>ğŸ“ Texte original :</strong>\\n"${text}"\\n\\n\`; html += \`<strong>ğŸ”¤ Tokens aprÃ¨s preprocessing :</strong>\\n\[${tokens.join(', ')}\]\\n\\n\`; html += \`<strong>ğŸ”— ${ngrams.length} ${n}-grammes gÃ©nÃ©rÃ©s :</strong>\\n\`; ngrams.forEach((ngram, i) => { html += \`${(i + 1).toString().padStart(2, ' ')}. ${ngram}\\n\`; }); html += \`\\n<strong>ğŸ“Š Statistiques :</strong>\\n\`; html += \` Total: ${ngrams.length}\\n\`; html += \` Uniques: ${unique.length}\\n\`; html += \` RÃ©pÃ©titions: ${ngrams.length - unique.length}\\n\`; html += \` Ratio unique: ${(unique.length / ngrams.length \* 100).toFixed(1)}%\\n\`; if (unique.length !== ngrams.length) { html += \`\\n<strong>ğŸ”„ N-grammes rÃ©pÃ©tÃ©s :</strong>\\n\`; const counts = {}; ngrams.forEach(ngram => { counts\[ngram\] = (counts\[ngram\] || 0) + 1; }); Object.entries(counts) .filter((\[ngram, count\]) => count > 1) .forEach((\[ngram, count\]) => { html += \` "${ngram}" Ã— ${count}\\n\`; }); } document.getElementById('ngramResult').textContent = html; updateNgramsStats(ngrams, unique); } // Mise Ã  jour des statistiques function updateNgramsStats(ngrams, unique) { const ratio = unique.length > 0 ? ((unique.length / ngrams.length) \* 100).toFixed(1) : 0; const avgLength = ngrams.length > 0 ? (ngrams.reduce((sum, ng) => sum + ng.length, 0) / ngrams.length).toFixed(1) : 0; document.getElementById('totalNgrams').textContent = ngrams.length; document.getElementById('uniqueNgrams').textContent = unique.length; document.getElementById('ngramRatio').textContent = ratio + '%'; document.getElementById('avgLength').textContent = avgLength; document.getElementById('ngramStats').style.display = 'grid'; } // N-grams avancÃ©s function generateAdvancedNgrams() { const text = document.getElementById('advancedInput').value.trim(); if (!text) { document.getElementById('advancedResult').textContent = 'Veuillez entrer du texte !'; return; } const minN = parseInt(document.getElementById('minN').value); const maxN = parseInt(document.getElementById('maxN').value); const minFreq = parseInt(document.getElementById('minFreq').value); const maxNgrams = parseInt(document.getElementById('maxNgrams').value); const separator = document.getElementById('separator').value; if (minN > maxN) { document.getElementById('advancedResult').textContent = 'Erreur : N min doit Ãªtre â‰¤ N max !'; return; } const tokens = preprocessText(text, true); // GÃ©nÃ©rer tous les N-grams de la plage let allNgrams = \[\]; for (let n = minN; n <= maxN; n++) { const ngrams = generateNgrams(tokens, n, separator); allNgrams.push(...ngrams); } // Compter les frÃ©quences const frequencies = {}; allNgrams.forEach(ngram => { frequencies\[ngram\] = (frequencies\[ngram\] || 0) + 1; }); // Filtrer par frÃ©quence const filtered = Object.entries(frequencies) .filter((\[ngram, freq\]) => freq >= minFreq) .sort((a, b) => b\[1\] - a\[1\]) .slice(0, maxNgrams); let html = \`<strong>ğŸ”§ N-GRAMS AVANCÃ‰S (${minN}-${maxN})</strong>\\n\`; html += '=' \* 40 + '\\n\\n'; html += \`<strong>âš™ï¸ Configuration :</strong>\\n\`; html += \` Plage N: ${minN} Ã  ${maxN}\\n\`; html += \` FrÃ©quence min: ${minFreq}\\n\`; html += \` Max N-grams: ${maxNgrams}\\n\`; html += \` SÃ©parateur: "${separator}"\\n\\n\`; html += \`<strong>ğŸ“Š RÃ©sultats (${filtered.length} N-grams) :</strong>\\n\`; filtered.forEach((\[ngram, freq\], i) => { const n = ngram.split(separator).length; const medal = i < 3 ? \['ğŸ¥‡', 'ğŸ¥ˆ', 'ğŸ¥‰'\]\[i\] : \`${(i + 1).toString().padStart(2, ' ')}.\`; html += \`${medal} ${ngram} (N=${n}, freq=${freq})\\n\`; }); if (filtered.length === 0) { html += 'âŒ Aucun N-gram ne respecte les critÃ¨res.\\n'; html += 'ğŸ’¡ Essayez de rÃ©duire la frÃ©quence minimale.'; } document.getElementById('advancedResult').textContent = html; } // Comparaison des tailles de N-grams function compareNgramSizes() { const text = document.getElementById('comparisonInput').value.trim(); if (!text) { document.getElementById('comparisonResult').textContent = 'Veuillez entrer du texte !'; return; } const tokens = preprocessText(text, true); const sizes = \[1, 2, 3, 4\]; const results = {}; let html = \`<strong>ğŸ“Š COMPARAISON TAILLES N-GRAMS</strong>\\n\`; html += '=' \* 45 + '\\n\\n'; html += \`<strong>ğŸ“ Texte analysÃ© :</strong> "${text.substring(0, 60)}..."\\n\`; html += \`<strong>ğŸ”¤ Tokens :</strong> ${tokens.length} mots aprÃ¨s preprocessing\\n\\n\`; sizes.forEach(n => { if (tokens.length >= n) { const ngrams = generateNgrams(tokens, n); const unique = \[...new Set(ngrams)\]; results\[n\] = { total: ngrams.length, unique: unique.length, ratio: unique.length / ngrams.length \* 100 }; html += \`<strong>${n}-grammes :</strong>\\n\`; html += \` Total: ${ngrams.length}\\n\`; html += \` Uniques: ${unique.length}\\n\`; html += \` Ratio unique: ${results\[n\].ratio.toFixed(1)}%\\n\`; html += \` Exemples: ${unique.slice(0, 3).join(', ')}\\n\\n\`; } else { html += \`<strong>${n}-grammes :</strong> Impossible (texte trop court)\\n\\n\`; } }); html += \`<strong>ğŸ’¡ OBSERVATIONS :</strong>\\n\`; html += \`â€¢ Plus N augmente, plus on a de variÃ©tÃ©\\n\`; html += \`â€¢ Mais aussi plus de sparsitÃ© (N-grams uniques)\\n\`; html += \`â€¢ Trade-off entre contexte et gÃ©nÃ©ralisation\\n\`; html += \`â€¢ Optimal souvent entre N=2 et N=3\`; document.getElementById('comparisonResult').textContent = html; updateComparisonChart(results); } // Mise Ã  jour du graphique de comparaison function updateComparisonChart(results) { const chart = document.getElementById('performanceChart'); if (!chart) return; const maxValue = Math.max(...Object.values(results).map(r => r.unique)); \[1, 2, 3, 4\].forEach(n => { const bar = document.getElementById(\`bar${n}\`); const value = document.getElementById(\`value${n}\`); if (bar && value && results\[n\]) { const height = (results\[n\].unique / maxValue) \* 100; bar.style.height = height + '%'; value.textContent = results\[n\].unique; } }); chart.style.display = 'block'; } // Extraction d'expressions function extractExpressions() { const text = document.getElementById('expressionInput').value.trim(); if (!text) { document.getElementById('expressionResult').textContent = 'Veuillez entrer du texte !'; return; } const threshold = parseInt(document.getElementById('freqThreshold').value); const type = document.getElementById('expressionType').value; const maxN = parseInt(document.getElementById('maxNExpression').value); // DÃ©couper le texte en phrases pour avoir plusieurs documents const sentences = text.split(/\[.!?\]+/).filter(s => s.trim()); if (sentences.length < 2) { document.getElementById('expressionResult').textContent = 'Le texte doit contenir plusieurs phrases !'; return; } // GÃ©nÃ©rer N-grams de 2 Ã  maxN let allNgrams = \[\]; sentences.forEach(sentence => { const tokens = preprocessText(sentence, true); for (let n = 2; n <= maxN; n++) { const ngrams = generateNgrams(tokens, n); allNgrams.push(...ngrams); } }); // Compter les frÃ©quences const frequencies = {}; allNgrams.forEach(ngram => { frequencies\[ngram\] = (frequencies\[ngram\] || 0) + 1; }); // Filtrer par frÃ©quence et type let expressions = Object.entries(frequencies) .filter((\[ngram, freq\]) => freq >= threshold) .sort((a, b) => b\[1\] - a\[1\]); // Filtrer par type si spÃ©cifiÃ© if (type === 'tech') { const techWords = \['intelligence', 'artificielle', 'machine', 'learning', 'deep', 'algorithm', 'data', 'science', 'neural', 'network'\]; expressions = expressions.filter((\[ngram\]) => techWords.some(word => ngram.toLowerCase().includes(word)) ); } else if (type === 'business') { const businessWords = \['startup', 'entrepreneur', 'business', 'marketing', 'finance', 'management', 'strategy'\]; expressions = expressions.filter((\[ngram\]) => businessWords.some(word => ngram.toLowerCase().includes(word)) ); } let html = \`<strong>ğŸ” EXPRESSIONS EXTRAITES</strong>\\n\`; html += '=' \* 35 + '\\n\\n'; html += \`<strong>âš™ï¸ ParamÃ¨tres :</strong>\\n\`; html += \` Seuil frÃ©quence: ${threshold}\\n\`; html += \` Type: ${type}\\n\`; html += \` N-gram max: ${maxN}\\n\`; html += \` Phrases analysÃ©es: ${sentences.length}\\n\\n\`; if (expressions.length > 0) { html += \`<strong>ğŸ”‘ ${expressions.length} expressions trouvÃ©es :</strong>\\n\`; expressions.slice(0, 15).forEach((\[expr, freq\], i) => { const rank = i + 1; const medal = rank <= 3 ? \['ğŸ¥‡', 'ğŸ¥ˆ', 'ğŸ¥‰'\]\[rank - 1\] : \`${rank.toString().padStart(2, ' ')}.\`; const n = expr.split('\_').length; // CatÃ©goriser l'expression let category = "ğŸ’¡ GÃ©nÃ©ral"; if (\['intelligence', 'artificielle', 'machine', 'learning'\].some(word => expr.toLowerCase().includes(word))) { category = "ğŸ¤– IA/ML"; } else if (\['data', 'big', 'science'\].some(word => expr.toLowerCase().includes(word))) { category = "ğŸ“Š Data"; } else if (\['deep', 'rÃ©seaux', 'neurones'\].some(word => expr.toLowerCase().includes(word))) { category = "ğŸ§  Deep Learning"; } html += \`${medal} ${expr.replace(/\_/g, ' ')} (Ã—${freq}, ${n}-gram) ${category}\\n\`; }); // Affichage visuel const displayDiv = document.getElementById('expressionDisplay'); displayDiv.innerHTML = expressions.slice(0, 10).map((\[expr, freq\]) => \`<span class="ngram-token">${expr.replace(/\_/g, ' ')} (${freq})</span>\` ).join(''); displayDiv.style.display = 'flex'; } else { html += \`âŒ Aucune expression trouvÃ©e.\\n\`; html += \`ğŸ’¡ Essayez de rÃ©duire le seuil de frÃ©quence.\`; } document.getElementById('expressionResult').textContent = html; } // DÃ©tection de langue function detectLanguage() { const text = document.getElementById('languageInput').value.trim(); if (!text) { document.getElementById('languageResult').textContent = 'Veuillez entrer du texte !'; return; } const method = document.getElementById('detectionMethod').value; const showDetails = document.getElementById('showDetails').checked; // Profils de langues const languageProfiles = { 'franÃ§ais': { char\_trigrams: \['les', 'des', 'une', 'que', 'est', 'ent', 'ion', 'tion', 'eur', 'eau', 'ant', 'ment'\], word\_bigrams: \['de\_la', 'de\_le', 'et\_de', 'dans\_le', 'pour\_le', 'avec\_le'\] }, 'anglais': { char\_trigrams: \['the', 'and', 'ing', 'ion', 'tion', 'ent', 'ers', 'all', 'you', 'ork', 'arn', 'ive'\], word\_bigrams: \['of\_the', 'in\_the', 'to\_the', 'and\_the', 'for\_the', 'with\_the'\] }, 'espagnol': { char\_trigrams: \['que', 'los', 'las', 'iÃ³n', 'ado', 'osa', 'nte', 'era', 'mos', 'dad', 'cia', 'sta'\], word\_bigrams: \['de\_la', 'de\_los', 'en\_el', 'para\_el', 'con\_el', 'por\_el'\] }, 'italien': { char\_trigrams: \['che', 'gli', 'lla', 'nte', 'ama', 'ono', 'ere', 'ato', 'ivo', 'sta', 'ria', 'ica'\], word\_bigrams: \['di\_la', 'in\_il', 'per\_il', 'con\_il', 'del\_la', 'nel\_la'\] }, 'allemand': { char\_trigrams: \['und', 'der', 'die', 'ich', 'ung', 'eit', 'ein', 'ern', 'sch', 'ver', 'end', 'nen'\], word\_bigrams: \['in\_der', 'auf\_der', 'mit\_der', 'von\_der', 'zu\_der', 'bei\_der'\] } }; let scores = {}; if (method === 'char\_trigrams' || method === 'combined') { // Trigrammes de caractÃ¨res const textClean = text.toLowerCase().replace(/\[^\\w\\s\]/g, ''); const charTrigrams = \[\]; for (let i = 0; i <= textClean.length - 3; i++) { charTrigrams.push(textClean.substring(i, i + 3)); } Object.entries(languageProfiles).forEach((\[lang, profile\]) => { if (!scores\[lang\]) scores\[lang\] = 0; const score = charTrigrams.filter(trigram => profile.char\_trigrams.includes(trigram)).length; scores\[lang\] += score / charTrigrams.length; }); } if (method === 'word\_bigrams' || method === 'combined') { // Bigrammes de mots const tokens = preprocessText(text, false); const wordBigrams = generateNgrams(tokens, 2); Object.entries(languageProfiles).forEach((\[lang, profile\]) => { if (!scores\[lang\]) scores\[lang\] = 0; const score = wordBigrams.filter(bigram => profile.word\_bigrams.includes(bigram)).length; scores\[lang\] += score / wordBigrams.length; }); } // Trier par score const results = Object.entries(scores).sort((a, b) => b\[1\] - a\[1\]); let html = \`<strong>ğŸŒ DÃ‰TECTION DE LANGUE</strong>\\n\`; html += '=' \* 35 + '\\n\\n'; html += \`<strong>ğŸ“ Texte analysÃ© :</strong>\\n"${text}"\\n\\n\`; html += \`<strong>ğŸ”§ MÃ©thode :</strong> ${method}\\n\`; html += \`<strong>ğŸ“Š CaractÃ¨res :</strong> ${text.length}\\n\\n\`; html += \`<strong>ğŸ¯ RÃ©sultats de dÃ©tection :</strong>\\n\`; results.forEach((\[lang, score\], index) => { const percentage = (score \* 100).toFixed(1); const confidence = score > 0.1 ? 'Ã‰LEVÃ‰E' : score > 0.05 ? 'MOYENNE' : 'FAIBLE'; const flags = { 'franÃ§ais': 'ğŸ‡«ğŸ‡·', 'anglais': 'ğŸ‡ºğŸ‡¸', 'espagnol': 'ğŸ‡ªğŸ‡¸', 'italien': 'ğŸ‡®ğŸ‡¹', 'allemand': 'ğŸ‡©ğŸ‡ª' }; const flag = flags\[lang\] || 'ğŸŒ'; const prediction = index === 0 ? ' â† DÃ‰TECTÃ‰E' : ''; html += \`${flag} ${lang.padEnd(10)} : ${percentage.padStart(5)}% (${confidence})${prediction}\\n\`; }); const bestMatch = results\[0\]; html += \`\\n<strong>ğŸ† Langue dÃ©tectÃ©e :</strong> ${bestMatch\[0\].toUpperCase()}\\n\`; html += \`<strong>ğŸ“ˆ Score de confiance :</strong> ${(bestMatch\[1\] \* 100).toFixed(1)}%\`; document.getElementById('languageResult').textContent = html; } // Charger des exemples de langues function loadLanguageExample(language) { const examples = { 'french': "L'intelligence artificielle transforme notre faÃ§on de travailler et d'apprendre. Les algorithmes de machine learning analysent des quantitÃ©s massives de donnÃ©es.", 'english': "Artificial intelligence is transforming the way we work and learn. Machine learning algorithms analyze massive amounts of data.", 'spanish': "La inteligencia artificial estÃ¡ transformando la forma en que trabajamos y aprendemos. Los algoritmos de aprendizaje automÃ¡tico analizan cantidades masivas de datos.", 'italian': "L'intelligenza artificiale sta trasformando il modo in cui lavoriamo e impariamo. Gli algoritmi di machine learning analizzano quantitÃ  massive di dati.", 'german': "KÃ¼nstliche Intelligenz verÃ¤ndert die Art, wie wir arbeiten und lernen. Machine-Learning-Algorithmen analysieren massive Datenmengen." }; document.getElementById('languageInput').value = examples\[language\]; } // Classification avec N-grams function classifyWithNgrams() { const trainText = document.getElementById('trainDocsNgrams').value.trim(); const testText = document.getElementById('testDocNgrams').value.trim(); const method = document.getElementById('classificationMethod').value; if (!testText) { document.getElementById('ngramClassificationResult').textContent = 'Veuillez entrer un document Ã  classifier !'; return; } // Parser les documents d'entraÃ®nement const trainDocs = trainText.split('\\n').map(line => { const colonIndex = line.indexOf(':'); return { label: line.substring(0, colonIndex).trim(), content: line.substring(colonIndex + 1).trim() }; }); // CrÃ©er les profils par catÃ©gorie avec N-grams const categoryProfiles = {}; trainDocs.forEach(doc => { if (!categoryProfiles\[doc.label\]) { categoryProfiles\[doc.label\] = {}; } const tokens = preprocessText(doc.content, true); let ngrams = \[\]; if (method === 'unigrams') { ngrams = generateNgrams(tokens, 1); } else if (method === 'bigrams') { ngrams = generateNgrams(tokens, 2); } else if (method === 'mixed') { ngrams = \[ ...generateNgrams(tokens, 1), ...generateNgrams(tokens, 2) \]; } else if (method === 'trigrams') { ngrams = \[ ...generateNgrams(tokens, 1), ...generateNgrams(tokens, 2), ...generateNgrams(tokens, 3) \]; } ngrams.forEach(ngram => { categoryProfiles\[doc.label\]\[ngram\] = (categoryProfiles\[doc.label\]\[ngram\] || 0) + 1; }); }); // Analyser le document test const testTokens = preprocessText(testText, true); let testNgrams = \[\]; if (method === 'unigrams') { testNgrams = generateNgrams(testTokens, 1); } else if (method === 'bigrams') { testNgrams = generateNgrams(testTokens, 2); } else if (method === 'mixed') { testNgrams = \[ ...generateNgrams(testTokens, 1), ...generateNgrams(testTokens, 2) \]; } else if (method === 'trigrams') { testNgrams = \[ ...generateNgrams(testTokens, 1), ...generateNgrams(testTokens, 2), ...generateNgrams(testTokens, 3) \]; } // Calculer les scores const scores = {}; Object.entries(categoryProfiles).forEach((\[label, profile\]) => { let score = 0; testNgrams.forEach(ngram => { if (profile\[ngram\]) { score += profile\[ngram\]; } }); scores\[label\] = score / testNgrams.length; // Normaliser }); // PrÃ©diction const predicted = Object.entries(scores).sort((a, b) => b\[1\] - a\[1\]); let html = \`<strong>ğŸ¯ CLASSIFICATION AVEC N-GRAMS</strong>\\n\`; html += '=' \* 45 + '\\n\\n'; html += \`<strong>ğŸ“„ Document test :</strong>\\n"${testText}"\\n\\n\`; html += \`<strong>ğŸ”§ MÃ©thode :</strong> ${method}\\n\`; html += \`<strong>ğŸ”— N-grams extraits :</strong> ${testNgrams.length}\\n\`; html += \`<strong>ğŸ“ Exemples :</strong> ${testNgrams.slice(0, 5).join(', ')}\\n\\n\`; html += \`<strong>ğŸ“Š Scores par catÃ©gorie :</strong>\\n\`; predicted.forEach((\[label, score\], index) => { const percentage = (score \* 100).toFixed(1); const bar = 'â–ˆ'.repeat(Math.round(score \* 20)); const prediction = index === 0 ? ' â† PRÃ‰DICTION' : ''; html += \`${label.padEnd(8)} : ${bar.padEnd(20)} ${percentage}%${prediction}\\n\`; }); html += \`\\n<strong>ğŸ¯ CatÃ©gorie prÃ©dite :</strong> ${predicted\[0\]\[0\].toUpperCase()}\\n\`; html += \`<strong>ğŸ“ˆ Confiance :</strong> ${(predicted\[0\]\[1\] \* 100).toFixed(1)}%\`; document.getElementById('ngramClassificationResult').textContent = html; } // Analyse de performance function analyzePerformance() { const text = document.getElementById('performanceInput').value.trim(); if (!text) { document.getElementById('performanceResult').textContent = 'Veuillez entrer du texte !'; return; } const maxN = parseInt(document.getElementById('maxNPerf').value); const showMemory = document.getElementById('showMemory').checked; const docs = text.split('\\n').filter(doc => doc.trim()); const tokens = docs.map(doc => preprocessText(doc, true)); let html = \`<strong>ğŸ“Š ANALYSE DE PERFORMANCE N-GRAMS</strong>\\n\`; html += '=' \* 50 + '\\n\\n'; html += \`<strong>ğŸ“„ Corpus analysÃ© :</strong>\\n\`; html += \` Documents : ${docs.length}\\n\`; html += \` Mots totaux : ${tokens.flat().length}\\n\`; html += \` Mots moyens/doc : ${Math.round(tokens.flat().length / docs.length)}\\n\\n\`; const performanceData = {}; for (let n = 1; n <= maxN; n++) { let allNgrams = \[\]; tokens.forEach(docTokens => { const ngrams = generateNgrams(docTokens, n); allNgrams.push(...ngrams); }); const unique = \[...new Set(allNgrams)\]; performanceData\[n\] = { total: allNgrams.length, unique: unique.length, sparsity: allNgrams.length > 0 ? (1 - unique.length / allNgrams.length) \* 100 : 0 }; html += \`<strong>ğŸ“Š ${n}-grammes :</strong>\\n\`; html += \` Total gÃ©nÃ©rÃ© : ${allNgrams.length}\\n\`; html += \` Vocabulaire unique : ${unique.length}\\n\`; html += \` Taux de rÃ©pÃ©tition : ${(100 - (unique.length / Math.max(allNgrams.length, 1) \* 100)).toFixed(1)}%\\n\`; if (showMemory) { // Estimation mÃ©moire (trÃ¨s approximative) const avgLength = unique.reduce((sum, ng) => sum + ng.length, 0) / unique.length; const memoryKB = (unique.length \* avgLength \* 2) / 1024; // 2 bytes par char html += \` MÃ©moire estimÃ©e : ${memoryKB.toFixed(1)} KB\\n\`; } html += '\\n'; } // Analyse de l'explosion combinatoire html += \`<strong>ğŸš¨ ANALYSE DE L'EXPLOSION COMBINATOIRE :</strong>\\n\`; for (let n = 1; n <= maxN; n++) { const ratio = n > 1 ? (performanceData\[n\].unique / performanceData\[n - 1\].unique).toFixed(2) : 'N/A'; html += \` N=${n} : ${performanceData\[n\].unique} mots (Ã—${ratio} vs N=${n - 1})\\n\`; } html += \`\\n<strong>ğŸ’¡ RECOMMANDATIONS :</strong>\\n\`; if (performanceData\[2\] && performanceData\[2\].unique > 1000) { html += \`âš ï¸ Vocabulaire dÃ©jÃ  important avec bigrammes\\n\`; } if (performanceData\[3\] && performanceData\[3\].unique > 5000) { html += \`ğŸš¨ Explosion combinatoire avec trigrammes\\n\`; } html += \`âœ… Optimal probablement entre N=1 et N=${maxN <= 3 ? maxN : 3}\\n\`; html += \`ğŸ¯ ConsidÃ©rer filtrage par frÃ©quence minimale\`; document.getElementById('performanceResult').textContent = html; updatePerformanceChart(performanceData, maxN); } // Mise Ã  jour du graphique de performance function updatePerformanceChart(data, maxN) { const chart = document.getElementById('performanceVizChart'); if (!chart) return; const maxValue = Math.max(...Object.values(data).map(d => d.unique)); for (let n = 1; n <= 5; n++) { const bar = document.getElementById(\`perfBar${n}\`); const value = document.getElementById(\`perfValue${n}\`); if (bar && value) { if (n <= maxN && data\[n\]) { const height = (data\[n\].unique / maxValue) \* 100; bar.style.height = height + '%'; value.textContent = data\[n\].unique; bar.style.opacity = '1'; } else { bar.style.height = '0%'; value.textContent = '0'; bar.style.opacity = '0.3'; } } } chart.style.display = 'block'; } // Fonctions utilitaires function updateThresholdValue(value) { document.getElementById('thresholdValue').textContent = value; } function updateMaxNValue(value) { document.getElementById('maxNValue').textContent = value; } // Initialisation window.addEventListener('load', function () { // Animation des sections const sections = document.querySelectorAll('.section'); sections.forEach((section, index) => { setTimeout(() => { section.style.opacity = '1'; section.style.transform = 'translateY(0)'; }, index \* 200); }); });
