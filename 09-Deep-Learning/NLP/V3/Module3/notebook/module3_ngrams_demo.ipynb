{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìù Module 3 : N-grams en Python - D√©monstration Pratique\n",
    "\n",
    "Dans ce notebook, nous allons apprendre √† utiliser les **N-grams** en Python de mani√®re simple et pratique.\n",
    "\n",
    "## üéØ Objectifs\n",
    "- Comprendre ce que sont les N-grams\n",
    "- Cr√©er des N-grams manuellement\n",
    "- Utiliser scikit-learn pour les N-grams\n",
    "- Voir des applications concr√®tes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Qu'est-ce qu'un N-gram ?\n",
    "\n",
    "Un **N-gram** est une s√©quence de N mots cons√©cutifs dans un texte.\n",
    "\n",
    "**Exemples avec la phrase : \"Le chat mange des croquettes\"**\n",
    "- **1-gram (unigram)** : [\"Le\", \"chat\", \"mange\", \"des\", \"croquettes\"]\n",
    "- **2-gram (bigram)** : [\"Le chat\", \"chat mange\", \"mange des\", \"des croquettes\"]\n",
    "- **3-gram (trigram)** : [\"Le chat mange\", \"chat mange des\", \"mange des croquettes\"]\n",
    "\n",
    "üí° **Pourquoi c'est utile ?** Les N-grams capturent le **contexte** et l'**ordre des mots**, contrairement au simple Bag of Words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Installation et Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports r√©ussis !\n"
     ]
    }
   ],
   "source": [
    "# Imports n√©cessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "print(\"‚úÖ Imports r√©ussis !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî® M√©thode 1 : Cr√©er des N-grams Manuellement\n",
    "\n",
    "Commen√ßons par comprendre le principe en cr√©ant des N-grams \"√† la main\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Texte : Le chat mange des croquettes dans la cuisine\n",
      "\n",
      "üî∏ 1-grams : ['le', 'chat', 'mange', 'des', 'croquettes', 'dans', 'la', 'cuisine']\n",
      "   Nombre : 8\n",
      "\n",
      "üî∏ 2-grams : ['le chat', 'chat mange', 'mange des', 'des croquettes', 'croquettes dans', 'dans la', 'la cuisine']\n",
      "   Nombre : 7\n",
      "\n",
      "üî∏ 3-grams : ['le chat mange', 'chat mange des', 'mange des croquettes', 'des croquettes dans', 'croquettes dans la', 'dans la cuisine']\n",
      "   Nombre : 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_ngrams(text, n):\n",
    "    \"\"\"\n",
    "    Cr√©e des N-grams √† partir d'un texte\n",
    "    \n",
    "    Args:\n",
    "        text (str): Le texte d'entr√©e\n",
    "        n (int): La taille des N-grams (1, 2, 3, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        list: Liste des N-grams\n",
    "    \"\"\"\n",
    "    # Nettoyer et diviser en mots\n",
    "    words = text.lower().split()\n",
    "    \n",
    "    # Cr√©er les N-grams\n",
    "    ngrams = []\n",
    "    for i in range(len(words) - n + 1):\n",
    "        ngram = ' '.join(words[i:i+n])\n",
    "        ngrams.append(ngram)\n",
    "    \n",
    "    return ngrams\n",
    "\n",
    "# Test avec un exemple\n",
    "texte_exemple = \"Le chat mange des croquettes dans la cuisine\"\n",
    "print(f\"üìù Texte : {texte_exemple}\")\n",
    "print()\n",
    "\n",
    "# Cr√©er diff√©rents N-grams\n",
    "for n in [1, 2, 3]:\n",
    "    ngrams = create_ngrams(texte_exemple, n)\n",
    "    print(f\"üî∏ {n}-grams : {ngrams}\")\n",
    "    print(f\"   Nombre : {len(ngrams)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß M√©thode 2 : Utiliser scikit-learn (Recommand√©)\n",
    "\n",
    "scikit-learn offre une m√©thode plus simple et plus puissante pour cr√©er des N-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Documents d'exemple :\n",
      "   1. Le chat mange des croquettes\n",
      "   2. Le chien mange aussi des croquettes\n",
      "   3. Le chat boit de l'eau fra√Æche\n",
      "   4. Les animaux domestiques mangent bien\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Documents d'exemple\n",
    "documents = [\n",
    "    \"Le chat mange des croquettes\",\n",
    "    \"Le chien mange aussi des croquettes\", \n",
    "    \"Le chat boit de l'eau fra√Æche\",\n",
    "    \"Les animaux domestiques mangent bien\"\n",
    "]\n",
    "\n",
    "print(\"üìö Documents d'exemple :\")\n",
    "for i, doc in enumerate(documents, 1):\n",
    "    print(f\"   {i}. {doc}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Unigrammes (1-grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∏ Matrice Unigrammes (1-grams) :\n",
      "       animaux  aussi  bien  boit  chat  chien  croquettes  de  des  \\\n",
      "Doc 1        0      0     0     0     1      0           1   0    1   \n",
      "Doc 2        0      1     0     0     0      1           1   0    1   \n",
      "Doc 3        0      0     0     1     1      0           0   1    0   \n",
      "Doc 4        1      0     1     0     0      0           0   0    0   \n",
      "\n",
      "       domestiques  eau  fra√Æche  le  les  mange  mangent  \n",
      "Doc 1            0    0        0   1    0      1        0  \n",
      "Doc 2            0    0        0   1    0      1        0  \n",
      "Doc 3            0    1        1   1    0      0        0  \n",
      "Doc 4            1    0        0   0    1      0        1  \n",
      "\n",
      "üìè Taille du vocabulaire : 16 mots uniques\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er un vectoriseur pour les unigrammes\n",
    "vectorizer_1gram = CountVectorizer(\n",
    "    ngram_range=(1, 1),  # Seulement des 1-grams\n",
    "    lowercase=True,      # Convertir en minuscules\n",
    "    stop_words=None      # Pas de suppression de mots vides pour cet exemple\n",
    ")\n",
    "\n",
    "# Transformer les documents\n",
    "matrice_1gram = vectorizer_1gram.fit_transform(documents)\n",
    "\n",
    "# Obtenir les noms des features (mots)\n",
    "mots = vectorizer_1gram.get_feature_names_out()\n",
    "\n",
    "# Cr√©er un DataFrame pour la visualisation\n",
    "df_1gram = pd.DataFrame(\n",
    "    matrice_1gram.toarray(), \n",
    "    columns=mots,\n",
    "    index=[f\"Doc {i+1}\" for i in range(len(documents))]\n",
    ")\n",
    "\n",
    "print(\"üî∏ Matrice Unigrammes (1-grams) :\")\n",
    "print(df_1gram)\n",
    "print(f\"\\nüìè Taille du vocabulaire : {len(mots)} mots uniques\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Bigrammes (2-grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∏ Matrice Bigrammes (2-grams) :\n",
      "       animaux domestiques  aussi des  boit de  chat boit  chat mange  \\\n",
      "Doc 1                    0          0        0          0           1   \n",
      "Doc 2                    0          1        0          0           0   \n",
      "Doc 3                    0          0        1          1           0   \n",
      "Doc 4                    1          0        0          0           0   \n",
      "\n",
      "       chien mange  de eau  des croquettes  domestiques mangent  eau fra√Æche  \\\n",
      "Doc 1            0       0               1                    0            0   \n",
      "Doc 2            1       0               1                    0            0   \n",
      "Doc 3            0       1               0                    0            1   \n",
      "Doc 4            0       0               0                    1            0   \n",
      "\n",
      "       le chat  le chien  les animaux  mange aussi  mange des  mangent bien  \n",
      "Doc 1        1         0            0            0          1             0  \n",
      "Doc 2        0         1            0            1          0             0  \n",
      "Doc 3        1         0            0            0          0             0  \n",
      "Doc 4        0         0            1            0          0             1  \n",
      "\n",
      "üìè Nombre de bigrammes : 16\n",
      "\n",
      "üìù Quelques bigrammes trouv√©s : ['animaux domestiques', 'aussi des', 'boit de', 'chat boit', 'chat mange', 'chien mange', 'de eau', 'des croquettes']\n"
     ]
    }
   ],
   "source": [
    "# Cr√©er un vectoriseur pour les bigrammes\n",
    "vectorizer_2gram = CountVectorizer(\n",
    "    ngram_range=(2, 2),  # Seulement des 2-grams\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "# Transformer les documents\n",
    "matrice_2gram = vectorizer_2gram.fit_transform(documents)\n",
    "\n",
    "# Obtenir les bigrammes\n",
    "bigrammes = vectorizer_2gram.get_feature_names_out()\n",
    "\n",
    "# Cr√©er un DataFrame\n",
    "df_2gram = pd.DataFrame(\n",
    "    matrice_2gram.toarray(), \n",
    "    columns=bigrammes,\n",
    "    index=[f\"Doc {i+1}\" for i in range(len(documents))]\n",
    ")\n",
    "\n",
    "print(\"üî∏ Matrice Bigrammes (2-grams) :\")\n",
    "print(df_2gram)\n",
    "print(f\"\\nüìè Nombre de bigrammes : {len(bigrammes)}\")\n",
    "print(f\"\\nüìù Quelques bigrammes trouv√©s : {list(bigrammes[:8])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Combinaison : Unigrammes + Bigrammes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∏ Nombre total de features (1-grams + 2-grams) : 32\n",
      "\n",
      "üìù Exemples de features :\n",
      "   - Unigrammes : ['animaux', 'aussi', 'bien', 'boit', 'chat']\n",
      "   - Bigrammes : ['animaux domestiques', 'aussi des', 'boit de', 'chat boit', 'chat mange']\n",
      "\n",
      "üî∏ Aper√ßu de la matrice combin√©e (10 premi√®res colonnes) :\n",
      "       animaux  animaux domestiques  aussi  aussi des  bien  boit  boit de  \\\n",
      "Doc 1        0                    0      0          0     0     0        0   \n",
      "Doc 2        0                    0      1          1     0     0        0   \n",
      "Doc 3        0                    0      0          0     0     1        1   \n",
      "Doc 4        1                    1      0          0     1     0        0   \n",
      "\n",
      "       chat  chat boit  chat mange  \n",
      "Doc 1     1          0           1  \n",
      "Doc 2     0          0           0  \n",
      "Doc 3     1          1           0  \n",
      "Doc 4     0          0           0  \n"
     ]
    }
   ],
   "source": [
    "# Cr√©er un vectoriseur combin√© (1-grams + 2-grams)\n",
    "vectorizer_combo = CountVectorizer(\n",
    "    ngram_range=(1, 2),  # 1-grams ET 2-grams\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "# Transformer les documents\n",
    "matrice_combo = vectorizer_combo.fit_transform(documents)\n",
    "\n",
    "# Obtenir toutes les features\n",
    "features_combo = vectorizer_combo.get_feature_names_out()\n",
    "\n",
    "print(f\"üî∏ Nombre total de features (1-grams + 2-grams) : {len(features_combo)}\")\n",
    "print(f\"\\nüìù Exemples de features :\")\n",
    "print(f\"   - Unigrammes : {[f for f in features_combo if ' ' not in f][:5]}\")\n",
    "print(f\"   - Bigrammes : {[f for f in features_combo if ' ' in f][:5]}\")\n",
    "\n",
    "# Matrice dense (limit√©e aux 10 premi√®res colonnes pour la lisibilit√©)\n",
    "df_combo_sample = pd.DataFrame(\n",
    "    matrice_combo.toarray()[:, :10], \n",
    "    columns=features_combo[:10],\n",
    "    index=[f\"Doc {i+1}\" for i in range(len(documents))]\n",
    ")\n",
    "\n",
    "print(f\"\\nüî∏ Aper√ßu de la matrice combin√©e (10 premi√®res colonnes) :\")\n",
    "print(df_combo_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Application Pratique : Analyse de Sentiment avec N-grams\n",
    "\n",
    "Voyons comment les N-grams peuvent am√©liorer l'analyse de sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Avis clients d'exemple :\n",
      "   üòä Positif : 'Ce produit est vraiment tr√®s bon'\n",
      "   üòû N√©gatif : 'Je ne suis pas satisfait du service'\n",
      "   üòä Positif : 'Excellente qualit√©, je recommande fortement'\n",
      "   üòû N√©gatif : 'Pas terrible, √ßa pourrait √™tre mieux'\n",
      "   üòä Positif : 'Tr√®s bon rapport qualit√© prix'\n",
      "   üòû N√©gatif : 'Service client pas du tout professionnel'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Donn√©es d'exemple pour l'analyse de sentiment\n",
    "avis_clients = [\n",
    "    \"Ce produit est vraiment tr√®s bon\",\n",
    "    \"Je ne suis pas satisfait du service\", \n",
    "    \"Excellente qualit√©, je recommande fortement\",\n",
    "    \"Pas terrible, √ßa pourrait √™tre mieux\",\n",
    "    \"Tr√®s bon rapport qualit√© prix\",\n",
    "    \"Service client pas du tout professionnel\"\n",
    "]\n",
    "\n",
    "labels = [\"Positif\", \"N√©gatif\", \"Positif\", \"N√©gatif\", \"Positif\", \"N√©gatif\"]\n",
    "\n",
    "print(\"üí¨ Avis clients d'exemple :\")\n",
    "for avis, label in zip(avis_clients, labels):\n",
    "    emoji = \"üòä\" if label == \"Positif\" else \"üòû\"\n",
    "    print(f\"   {emoji} {label} : '{avis}'\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∏ Features importantes avec UNIGRAMMES seulement :\n",
      "['bon', 'du', 'je', 'mieux', 'ne', 'pas', 'pourrait', 'prix', 'produit', 'qualit√©', 'rapport', 'recommande', 'satisfait', 'service', 'suis', 'terrible', 'tout', 'tr√®s', 'vraiment', '√ßa']\n",
      "\n",
      "üî∏ Features importantes avec UNIGRAMMES + BIGRAMMES :\n",
      "   Unigrammes : ['bon', 'du', 'je', 'pas', 'qualit√©', 'rapport', 'recommande', 'satisfait', 'service', 'suis', 'terrible', 'tr√®s']\n",
      "   Bigrammes : ['qualit√© je', 'qualit√© prix', 'rapport qualit√©', 'recommande fortement', 'satisfait du', 'suis pas', 'terrible √ßa', 'tr√®s bon']\n"
     ]
    }
   ],
   "source": [
    "# Comparaison : Unigrammes vs Bigrammes\n",
    "\n",
    "# 1. Avec unigrammes seulement\n",
    "vectorizer_sentiment_1 = TfidfVectorizer(ngram_range=(1, 1), max_features=20)\n",
    "X_1gram = vectorizer_sentiment_1.fit_transform(avis_clients)\n",
    "\n",
    "print(\"üî∏ Features importantes avec UNIGRAMMES seulement :\")\n",
    "print(list(vectorizer_sentiment_1.get_feature_names_out()))\n",
    "print()\n",
    "\n",
    "# 2. Avec unigrammes + bigrammes\n",
    "vectorizer_sentiment_2 = TfidfVectorizer(ngram_range=(1, 2), max_features=20)\n",
    "X_2gram = vectorizer_sentiment_2.fit_transform(avis_clients)\n",
    "\n",
    "print(\"üî∏ Features importantes avec UNIGRAMMES + BIGRAMMES :\")\n",
    "features_sentiment = list(vectorizer_sentiment_2.get_feature_names_out())\n",
    "print(\"   Unigrammes :\", [f for f in features_sentiment if ' ' not in f])\n",
    "print(\"   Bigrammes :\", [f for f in features_sentiment if ' ' in f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Insights : Pourquoi les N-grams sont Utiles\n",
    "\n",
    "Regardons des exemples concrets o√π les N-grams capturent mieux le sens :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßê Analyse comparative : Unigrammes vs Bigrammes\n",
      "\n",
      "üìù Texte : 'Ce produit n'est pas bon'\n",
      "   üî∏ Unigrammes : ['ce', 'produit', \"n'est\", 'pas', 'bon']\n",
      "   üî∏ Bigrammes : ['ce produit', \"produit n'est\", \"n'est pas\", 'pas bon']\n",
      "   üí° Les bigrammes capturent mieux la n√©gation et les expressions !\n",
      "\n",
      "üìù Texte : 'Pas mal du tout'\n",
      "   üî∏ Unigrammes : ['pas', 'mal', 'du', 'tout']\n",
      "   üî∏ Bigrammes : ['pas mal', 'mal du', 'du tout']\n",
      "   üí° Les bigrammes capturent mieux la n√©gation et les expressions !\n",
      "\n",
      "üìù Texte : 'Service client tr√®s professionnel'\n",
      "   üî∏ Unigrammes : ['service', 'client', 'tr√®s', 'professionnel']\n",
      "   üî∏ Bigrammes : ['service client', 'client tr√®s', 'tr√®s professionnel']\n",
      "   üí° Les bigrammes capturent mieux la n√©gation et les expressions !\n",
      "\n",
      "üìù Texte : 'Pas du tout satisfait'\n",
      "   üî∏ Unigrammes : ['pas', 'du', 'tout', 'satisfait']\n",
      "   üî∏ Bigrammes : ['pas du', 'du tout', 'tout satisfait']\n",
      "   üí° Les bigrammes capturent mieux la n√©gation et les expressions !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exemples o√π les bigrammes sont plus informatifs\n",
    "exemples_problematiques = [\n",
    "    \"Ce produit n'est pas bon\",  # \"pas bon\" = n√©gatif\n",
    "    \"Pas mal du tout\",           # \"pas mal\" = positif\n",
    "    \"Service client tr√®s professionnel\",  # \"tr√®s professionnel\" = positif\n",
    "    \"Pas du tout satisfait\"      # \"pas du tout\" = tr√®s n√©gatif\n",
    "]\n",
    "\n",
    "print(\"üßê Analyse comparative : Unigrammes vs Bigrammes\\n\")\n",
    "\n",
    "for texte in exemples_problematiques:\n",
    "    print(f\"üìù Texte : '{texte}'\")\n",
    "    \n",
    "    # Unigrammes\n",
    "    unigrams = create_ngrams(texte, 1)\n",
    "    print(f\"   üî∏ Unigrammes : {unigrams}\")\n",
    "    \n",
    "    # Bigrammes\n",
    "    bigrams = create_ngrams(texte, 2)\n",
    "    print(f\"   üî∏ Bigrammes : {bigrams}\")\n",
    "    \n",
    "    print(f\"   üí° Les bigrammes capturent mieux la n√©gation et les expressions !\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Param√®tres Avanc√©s\n",
    "\n",
    "Explorons quelques param√®tres utiles pour affiner l'utilisation des N-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî∏ Nombre total de N-grams (1 √† 3) : 50\n",
      "\n",
      "üìä R√©partition par type :\n",
      "   - Unigrammes : 21\n",
      "   - Bigrammes : 15\n",
      "   - Trigrammes : 14\n",
      "\n",
      "üìù Quelques trigrammes int√©ressants :\n",
      "   - 'intelligence artificielle r√©volutionne'\n",
      "   - 'le deep learning'\n",
      "   - 'le machine learning'\n",
      "   - 'learning est un'\n",
      "   - 'learning est une'\n"
     ]
    }
   ],
   "source": [
    "# Param√®tres avanc√©s avec CountVectorizer\n",
    "vectorizer_avance = CountVectorizer(\n",
    "    ngram_range=(1, 3),      # 1-grams, 2-grams ET 3-grams\n",
    "    min_df=1,                # Minimum de documents contenant le N-gram\n",
    "    max_df=0.8,              # Maximum de documents (pour √©viter les mots trop fr√©quents)\n",
    "    max_features=50,         # Limite du nombre de features\n",
    "    lowercase=True,          # Minuscules\n",
    "    stop_words=None          # Pas de mots vides pour cet exemple\n",
    ")\n",
    "\n",
    "# Documents d'exemple plus riches\n",
    "documents_riches = [\n",
    "    \"Le machine learning est une branche de l'intelligence artificielle\",\n",
    "    \"L'intelligence artificielle r√©volutionne de nombreux secteurs\",\n",
    "    \"Le deep learning est un sous-domaine du machine learning\", \n",
    "    \"Les r√©seaux de neurones sont la base du deep learning\",\n",
    "    \"L'apprentissage automatique n√©cessite beaucoup de donn√©es\"\n",
    "]\n",
    "\n",
    "# Transformation\n",
    "X_avance = vectorizer_avance.fit_transform(documents_riches)\n",
    "features_avancees = vectorizer_avance.get_feature_names_out()\n",
    "\n",
    "print(f\"üî∏ Nombre total de N-grams (1 √† 3) : {len(features_avancees)}\")\n",
    "print(f\"\\nüìä R√©partition par type :\")\n",
    "unigrams_count = len([f for f in features_avancees if len(f.split()) == 1])\n",
    "bigrams_count = len([f for f in features_avancees if len(f.split()) == 2])\n",
    "trigrams_count = len([f for f in features_avancees if len(f.split()) == 3])\n",
    "\n",
    "print(f\"   - Unigrammes : {unigrams_count}\")\n",
    "print(f\"   - Bigrammes : {bigrams_count}\")\n",
    "print(f\"   - Trigrammes : {trigrams_count}\")\n",
    "\n",
    "print(f\"\\nüìù Quelques trigrammes int√©ressants :\")\n",
    "trigrams_examples = [f for f in features_avancees if len(f.split()) == 3][:5]\n",
    "for trigram in trigrams_examples:\n",
    "    print(f\"   - '{trigram}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã R√©sum√© et Bonnes Pratiques\n",
    "\n",
    "### ‚úÖ Ce qu'on a appris :\n",
    "1. **Les N-grams** capturent l'ordre et le contexte des mots\n",
    "2. **scikit-learn** rend leur utilisation tr√®s simple\n",
    "3. **Les bigrammes** sont particuli√®rement utiles pour les n√©gations\n",
    "4. **La combinaison** unigrammes + bigrammes est souvent optimale\n",
    "\n",
    "### üéØ Bonnes pratiques :\n",
    "- Commencez avec `ngram_range=(1, 2)` (unigrammes + bigrammes)\n",
    "- Utilisez `max_features` pour limiter la taille du vocabulaire\n",
    "- Les trigrammes sont rarement n√©cessaires (sauf cas sp√©ciaux)\n",
    "- Testez toujours avec et sans N-grams pour voir l'am√©lioration\n",
    "\n",
    "### ‚ö†Ô∏è Attention √† :\n",
    "- **Explosion du vocabulaire** : les N-grams augmentent rapidement le nombre de features\n",
    "- **Overfitting** : plus de features = risque de sur-apprentissage\n",
    "- **Temps de calcul** : plus de features = plus lent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Exercice Pratique\n",
    "\n",
    "√Ä vous de jouer ! Modifiez les param√®tres ci-dessous pour explorer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Vos r√©sultats :\n",
      "   Nombre de features : 20\n",
      "   Features trouv√©es : ['ajoutez', 'et', 'et voir', 'fonctionne', 'grams', 'ici', 'les', 'les grams', 'phrases ici', 'pour', 'pour tester', 'propres', 'propres phrases', 'tester', 'tester les', 'voir', 'voir comment', 'vos', 'vos propres', '√ßa']\n"
     ]
    }
   ],
   "source": [
    "# üéÆ Zone d'exp√©rimentation - Modifiez ces param√®tres !\n",
    "\n",
    "# Vos propres documents\n",
    "mes_documents = [\n",
    "    \"Ajoutez vos propres phrases ici\",\n",
    "    \"Pour tester les N-grams\",\n",
    "    \"Et voir comment √ßa fonctionne\"\n",
    "]\n",
    "\n",
    "# Param√®tres √† exp√©rimenter\n",
    "mon_vectorizer = CountVectorizer(\n",
    "    ngram_range=(1, 2),    # Changez √ßa ! Essayez (1,1), (2,2), (1,3)...\n",
    "    max_features=20,       # Changez √ßa ! Essayez 10, 50, 100...\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "# Transformation et affichage\n",
    "if len(mes_documents[0]) > 30:  # Si vous avez modifi√© les documents\n",
    "    X_perso = mon_vectorizer.fit_transform(mes_documents)\n",
    "    features_perso = mon_vectorizer.get_feature_names_out()\n",
    "    \n",
    "    print(\"üéØ Vos r√©sultats :\")\n",
    "    print(f\"   Nombre de features : {len(features_perso)}\")\n",
    "    print(f\"   Features trouv√©es : {list(features_perso)}\")\n",
    "else:\n",
    "    print(\"‚úèÔ∏è Modifiez les documents ci-dessus pour voir vos r√©sultats !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Conclusion\n",
    "\n",
    "**F√©licitations !** Vous ma√Ætrisez maintenant les N-grams en Python. \n",
    "\n",
    "üîó **Prochaine √©tape** : Dans le prochain module, nous verrons TF-IDF qui am√©liore encore la repr√©sentation textuelle !\n",
    "\n",
    "---\n",
    "*Module 3 - Formation NLP - N-grams avec Python*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
