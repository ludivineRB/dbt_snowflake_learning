---
title: Module 3 - D√©monstration TF-IDF
description: Formation NLP - Module 3 - D√©monstration TF-IDF
tags:
  - NLP
  - 09-Deep-Learning
category: 09-Deep-Learning
---

# üéØ D√©monstration Pratique : TF-IDF

Mise en ≈ìuvre et visualisation de la pond√©ration TF-IDF

## üìä Pr√©sentation de l'Exercice

Dans cette d√©monstration, nous allons :

1.  Charger un ensemble de documents texte
2.  Calculer les poids TF-IDF pour chaque terme
3.  Visualiser les r√©sultats
4.  Comparer avec l'approche Bag of Words simple

## üîß Pr√©paration des Donn√©es

Nous allons utiliser un petit corpus de documents pour illustrer le calcul TF-IDF :

üìù Documents d'exemple

```
documents = [
    "Le chat dort sur le tapis",
    "Le chien joue avec la balle",
    "Le chat attrape la souris",
    "Le chien et le chat jouent ensemble"
]
```

**Note :** Dans un cas r√©el, vous auriez un ensemble de documents beaucoup plus important et plus vari√©.

## üìù Impl√©mentation avec Scikit-learn

Voici comment impl√©menter TF-IDF en utilisant scikit-learn :

```
from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd

# Cr√©ation du vectoriseur TF-IDF
tfidf_vectorizer = TfidfVectorizer()

# Application aux documents
tfidf_matrix = tfidf_vectorizer.fit_transform(documents)

# Conversion en DataFrame pour une meilleure visualisation
df_tfidf = pd.DataFrame(
    tfidf_matrix.toarray(),
    columns=tfidf_vectorizer.get_feature_names_out()
)
```

### R√©sultats du TF-IDF :

üîç Matrice TF-IDF (simplifi√©e)

```
        attrape     balle     chat     chien     dans     dort     et     ...
0     0.000000  0.000000  0.523035  0.000000  0.000000  0.653270  0.000000  ...
1     0.000000  0.622766  0.000000  0.473629  0.000000  0.000000  0.000000  ...
2     0.622766  0.000000  0.473629  0.000000  0.000000  0.000000  0.000000  ...
3     0.000000  0.000000  0.366739  0.366739  0.622766  0.000000  0.622766  ...
```

**Interpr√©tation :** Les valeurs plus √©lev√©es indiquent des termes plus importants pour un document sp√©cifique par rapport √† l'ensemble du corpus.

## üîç Comparaison avec Bag of Words

Comparons avec une simple approche de comptage de mots :

```
from sklearn.feature_extraction.text import CountVectorizer

# Comptage simple des mots
count_vectorizer = CountVectorizer()
bow_matrix = count_vectorizer.fit_transform(documents)

# Conversion en DataFrame
df_bow = pd.DataFrame(
    bow_matrix.toarray(),
    columns=count_vectorizer.get_feature_names_out()
)
```

### R√©sultats du Bag of Words :

üîç Matrice de comptage (simplifi√©e)

```
   attrape  balle  chat  chien  dans  dort  et  ...
0        0      0     1      0     0     1   0  ...
1        0      1     0      1     0     0   0  ...
2        1      0     1      0     0     0   0  ...
3        0      0     1      1     1     0   1  ...
```

**Attention :** Contrairement √† TF-IDF, le simple comptage ne tient pas compte de l'importance relative des termes dans le corpus.

## üìà Analyse des R√©sultats

Observons les diff√©rences cl√©s :

1.  **Mots fr√©quents :** Les mots tr√®s courants comme "le" et "la" ont des poids TF-IDF faibles car ils apparaissent dans de nombreux documents.
2.  **Termes sp√©cifiques :** Les mots plus rares mais significatifs comme "attrape" ou "souris" re√ßoivent des poids plus √©lev√©s.
3.  **Normalisation :** Les vecteurs TF-IDF sont normalis√©s par d√©faut, ce qui permet des comparaisons plus justes entre documents de longueurs diff√©rentes.

**Astuce :** Vous pouvez ajuster les param√®tres du TfidfVectorizer comme `max_features`, `min_df`, et `max_df` pour affiner les r√©sultats selon vos besoins.

## üèÉ‚Äç‚ôÇÔ∏è Exercice Pratique

Essayez de modifier le code pour :

1.  Ajouter des documents suppl√©mentaires au corpus
2.  Changer les param√®tres du TfidfVectorizer
3.  Calculer la similarit√© cosinus entre les documents
4.  Visualiser les r√©sultats avec une heatmap

```
# Exemple de visualisation avec une heatmap
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 8))
sns.heatmap(df_tfidf, annot=True, cmap='YlGnBu', fmt='.2f')
plt.title('Matrice TF-IDF')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
```

[‚Üê Retour aux concepts TF-IDF](module3_tfidf_concepts.html) [Suivant : N-grammes ‚Üí](module3_ngrams_concepts.html)
