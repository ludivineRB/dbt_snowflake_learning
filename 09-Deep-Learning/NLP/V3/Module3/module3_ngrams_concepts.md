---
title: 'Module 3 - N-grammes : Concepts'
description: 'Formation NLP - Module 3 - N-grammes : Concepts'
tags:
  - NLP
  - 09-Deep-Learning
category: 09-Deep-Learning
---

# üìä N-grammes : Concepts

Comprendre et utiliser les s√©quences de mots en traitement du langage naturel

## üéØ Introduction aux N-grammes

Les n-grammes sont des s√©quences de n √©l√©ments (g√©n√©ralement des mots ou des caract√®res) extraites d'un texte. Ils sont largement utilis√©s en TAL pour capturer le contexte et les relations entre les mots.

üìù Exemple de phrase :

"Le chat noir dort sur le tapis"

#### 1-grammes (unigrammes)

"Le", "chat", "noir", "dort", "sur", "le", "tapis"

#### 2-grammes (bigrammes)

"Le chat", "chat noir", "noir dort", "dort sur", "sur le", "le tapis"

#### 3-grammes (trigrammes)

"Le chat noir", "chat noir dort", "noir dort sur", "dort sur le", "sur le tapis"

## üîç Pourquoi utiliser les N-grammes ?

Les n-grammes permettent de :

*   Capturer le contexte des mots (contrairement au sac de mots simple)
*   Am√©liorer les performances des mod√®les de classification de texte
*   D√©tecter des expressions et des motifs r√©currents
*   Am√©liorer les suggestions de texte et la correction orthographique

**Exemple d'application :** La fonction de saisie pr√©dictive sur votre t√©l√©phone utilise des n-grammes pour pr√©dire le mot suivant en fonction des mots pr√©c√©dents.

## ‚öôÔ∏è Impl√©mentation avec Scikit-learn

Voici comment g√©n√©rer des n-grammes en Python :

```
from sklearn.feature_extraction.text import CountVectorizer

# Exemple de documents
documents = [
    "Le chat noir dort sur le tapis",
    "Le chien joue avec la balle",
    "Le chat attrape la souris"
]

# Cr√©ation du vectoriseur avec des bigrammes
bigram_vectorizer = CountVectorizer(ngram_range=(2, 2))
X = bigram_vectorizer.fit_transform(documents)

# Affichage des caract√©ristiques (bigrammes)
print("Bigrammes trouv√©s:", bigram_vectorizer.get_feature_names_out())

# Cr√©ation d'un vectoriseur avec des unigrammes et des bigrammes
vectorizer = CountVectorizer(ngram_range=(1, 2))
X = vectorizer.fit_transform(documents)
print("\nUnigrammes et bigrammes:", vectorizer.get_feature_names_out())
```

## üìä Visualisation des N-grammes

Visualisons les n-grammes les plus fr√©quents :

```
import pandas as pd
import matplotlib.pyplot as plt

# Cr√©ation d'un DataFrame avec les fr√©quences
df_ngrams = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())

# Somme des fr√©quences par n-gramme
ngram_freq = df_ngrams.sum().sort_values(ascending=False)

# Visualisation des 10 n-grammes les plus fr√©quents
plt.figure(figsize=(10, 6))
ngram_freq.head(10).plot(kind='barh', color='skyblue')
plt.title('Top 10 des n-grammes les plus fr√©quents')
plt.xlabel('Fr√©quence')
plt.tight_layout()
plt.show()
```

## ‚öñÔ∏è Avantages et Inconv√©nients

#### ‚úÖ Avantages

*   Simple √† impl√©menter
*   Capture le contexte local
*   Am√©liore les performances des mod√®les
*   Utile pour la d√©tection d'expressions

#### ‚ùå Inconv√©nients

*   Explosion dimensionnelle
*   Ne capture pas les d√©pendances √† longue distance
*   Peut √™tre sensible au bruit
*   N√©cessite beaucoup de donn√©es pour les grands n

**Bon √† savoir :** En pratique, on utilise souvent des bigrammes ou des trigrammes, car au-del√†, la dimensionnalit√© devient trop importante sans apporter beaucoup plus d'information pertinente.

## üîç Cas d'Utilisation des N-grammes

#### üî§ Correction Orthographique

D√©tecter et corriger les fautes en utilisant la probabilit√© des s√©quences de mots.

#### üìù Saisie Pr√©dictive

Pr√©dire le mot suivant en fonction des mots pr√©c√©dents.

#### üß† Mod√®les de Langage

Cr√©er des mod√®les statistiques simples de la langue.

#### üè∑Ô∏è Classification de Texte

Am√©liorer les performances en capturant des expressions caract√©ristiques.

[‚Üê Retour √† TF-IDF](module3_tfidf_demo.html) [Voir les d√©monstrations pratiques ‚Üí](ngrams_demos.html)
