{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM et GRU - Les RNN AmÃ©liorÃ©s ğŸš€\n",
    "\n",
    "## ğŸ¯ Objectifs de ce notebook\n",
    "\n",
    "1. **Comprendre** pourquoi les RNN basiques ont des limites\n",
    "2. **DÃ©couvrir** comment LSTM et GRU rÃ©solvent ces problÃ¨mes\n",
    "3. **ImplÃ©menter** et comparer RNN, LSTM et GRU\n",
    "4. **Analyser** les performances sur des tÃ¢ches complexes\n",
    "5. **Choisir** le bon modÃ¨le selon le contexte\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¤” Rappel : Le problÃ¨me des RNN\n",
    "\n",
    "Dans le notebook prÃ©cÃ©dent, nous avons vu que les RNN basiques ont un gros problÃ¨me :\n",
    "\n",
    "**Ils oublient rapidement** ! ğŸ§ ğŸ’¨\n",
    "\n",
    "### Exemple concret :\n",
    "```\n",
    "Phrase : \"Ce film Ã©tait nul au dÃ©but mais finalement gÃ©nial\"\n",
    "         â†‘                                        â†‘\n",
    "      \"nul\"                                  \"gÃ©nial\"\n",
    "      \n",
    "RNN basique : Se souvient surtout de \"gÃ©nial\" â†’ PrÃ©diction correcte âœ…\n",
    "Mais si c'Ã©tait : \"Ce film Ã©tait gÃ©nial au dÃ©but mais finalement nul\"\n",
    "RNN basique : Se souvient surtout de \"nul\" â†’ PrÃ©diction correcte âœ…\n",
    "\n",
    "ProblÃ¨me : Et si l'information importante est au milieu d'une longue phrase ?\n",
    "RNN basique : Oublie le dÃ©but â†’ PrÃ©diction incorrecte âŒ\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Installation et imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des bibliothÃ¨ques\n",
    "!pip install tensorflow numpy matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports nÃ©cessaires\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "print(f\"âœ… TensorFlow version: {tf.__version__}\")\n",
    "print(f\"âœ… Imports terminÃ©s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  LSTM : La MÃ©moire SÃ©lective\n",
    "\n",
    "### L'idÃ©e gÃ©niale des LSTM :\n",
    "\n",
    "**\"Et si on donnait au rÃ©seau le pouvoir de choisir quoi retenir et quoi oublier ?\"**\n",
    "\n",
    "### Les 3 \"portes\" magiques des LSTM :\n",
    "\n",
    "1. **ğŸšª Porte d'oubli (Forget Gate)** : \"Est-ce que je garde cette info ?\"\n",
    "2. **ğŸšª Porte d'entrÃ©e (Input Gate)** : \"Est-ce que cette nouvelle info est importante ?\"\n",
    "3. **ğŸšª Porte de sortie (Output Gate)** : \"Qu'est-ce que je montre Ã  l'extÃ©rieur ?\"\n",
    "\n",
    "### Analogie simple :\n",
    "Imaginez votre cerveau en train de lire :\n",
    "- **Porte d'oubli** : \"Cette info n'est plus utile, je l'oublie\"\n",
    "- **Porte d'entrÃ©e** : \"Cette nouvelle info est importante, je la retiens\"\n",
    "- **Porte de sortie** : \"Voici ce que je pense maintenant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation simple du fonctionnement LSTM\n",
    "def visualiser_lstm():\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    \n",
    "    # Titre\n",
    "    ax.text(0.5, 0.95, 'ğŸ§  Comment fonctionne un LSTM', \n",
    "            ha='center', va='top', fontsize=16, fontweight='bold', transform=ax.transAxes)\n",
    "    \n",
    "    # Cellule LSTM centrale\n",
    "    lstm_rect = plt.Rectangle((0.4, 0.4), 0.2, 0.3, \n",
    "                             facecolor='lightblue', edgecolor='darkblue', linewidth=3)\n",
    "    ax.add_patch(lstm_rect)\n",
    "    ax.text(0.5, 0.55, 'LSTM\\nCell', ha='center', va='center', \n",
    "            fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Les 3 portes\n",
    "    gates = [\n",
    "        {'pos': (0.3, 0.6), 'name': 'ğŸšª Forget', 'color': 'red'},\n",
    "        {'pos': (0.5, 0.75), 'name': 'ğŸšª Input', 'color': 'green'},\n",
    "        {'pos': (0.7, 0.6), 'name': 'ğŸšª Output', 'color': 'orange'}\n",
    "    ]\n",
    "    \n",
    "    for gate in gates:\n",
    "        ax.text(gate['pos'][0], gate['pos'][1], gate['name'], \n",
    "                ha='center', va='center', fontsize=10, \n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=gate['color'], alpha=0.7))\n",
    "    \n",
    "    # Flux d'information\n",
    "    # EntrÃ©e\n",
    "    ax.arrow(0.1, 0.55, 0.25, 0, head_width=0.03, head_length=0.02, \n",
    "             fc='blue', ec='blue', linewidth=2)\n",
    "    ax.text(0.05, 0.55, 'ğŸ“ Nouveau\\nmot', ha='center', va='center', fontsize=10)\n",
    "    \n",
    "    # MÃ©moire prÃ©cÃ©dente\n",
    "    ax.arrow(0.5, 0.2, 0, 0.15, head_width=0.03, head_length=0.02, \n",
    "             fc='purple', ec='purple', linewidth=2)\n",
    "    ax.text(0.5, 0.15, 'ğŸ§  MÃ©moire\\nprÃ©cÃ©dente', ha='center', va='center', fontsize=10)\n",
    "    \n",
    "    # Sortie\n",
    "    ax.arrow(0.65, 0.55, 0.25, 0, head_width=0.03, head_length=0.02, \n",
    "             fc='red', ec='red', linewidth=2)\n",
    "    ax.text(0.95, 0.55, 'ğŸ¯ PrÃ©diction', ha='center', va='center', fontsize=10)\n",
    "    \n",
    "    # Nouvelle mÃ©moire\n",
    "    ax.arrow(0.5, 0.35, 0, -0.15, head_width=0.03, head_length=0.02, \n",
    "             fc='purple', ec='purple', linewidth=2)\n",
    "    ax.text(0.5, 0.05, 'ğŸ§  Nouvelle\\nmÃ©moire', ha='center', va='center', fontsize=10)\n",
    "    \n",
    "    # Explications\n",
    "    explanations = [\n",
    "        'ğŸšª Forget: \"Dois-je oublier l\\'ancienne information ?\"',\n",
    "        'ğŸšª Input: \"Cette nouvelle info est-elle importante ?\"',\n",
    "        'ğŸšª Output: \"Que dois-je rÃ©vÃ©ler maintenant ?\"'\n",
    "    ]\n",
    "    \n",
    "    for i, exp in enumerate(explanations):\n",
    "        ax.text(0.02, 0.35 - i*0.05, exp, fontsize=9, transform=ax.transAxes)\n",
    "    \n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualiser_lstm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ GRU : La Version SimplifiÃ©e\n",
    "\n",
    "### Le problÃ¨me des LSTM :\n",
    "\"3 portes, c'est peut-Ãªtre un peu compliquÃ©... ğŸ¤”\"\n",
    "\n",
    "### La solution GRU :\n",
    "**\"Faisons la mÃªme chose avec seulement 2 portes !\"**\n",
    "\n",
    "### Les 2 portes des GRU :\n",
    "1. **ğŸšª Porte de remise Ã  zÃ©ro (Reset Gate)** : \"Dois-je oublier le passÃ© ?\"\n",
    "2. **ğŸšª Porte de mise Ã  jour (Update Gate)** : \"Combien du passÃ© et du prÃ©sent je garde ?\"\n",
    "\n",
    "### Avantages des GRU :\n",
    "- âœ… **Plus simple** que LSTM (2 portes au lieu de 3)\n",
    "- âœ… **Plus rapide** Ã  entraÃ®ner\n",
    "- âœ… **Moins de paramÃ¨tres**\n",
    "- âœ… **Performances souvent similaires** aux LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison visuelle des architectures\n",
    "def comparer_architectures():\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # RNN Basique\n",
    "    ax1.set_title('ğŸ”´ RNN Basique', fontsize=14, fontweight='bold')\n",
    "    rnn_rect = plt.Rectangle((0.3, 0.4), 0.4, 0.2, \n",
    "                            facecolor='lightcoral', edgecolor='darkred', linewidth=2)\n",
    "    ax1.add_patch(rnn_rect)\n",
    "    ax1.text(0.5, 0.5, 'RNN', ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "    ax1.text(0.5, 0.2, 'â€¢ Pas de portes\\nâ€¢ Oublie rapidement\\nâ€¢ Simple mais limitÃ©', \n",
    "             ha='center', fontsize=9)\n",
    "    \n",
    "    # LSTM\n",
    "    ax2.set_title('ğŸ”µ LSTM', fontsize=14, fontweight='bold')\n",
    "    lstm_rect = plt.Rectangle((0.2, 0.4), 0.6, 0.2, \n",
    "                             facecolor='lightblue', edgecolor='darkblue', linewidth=2)\n",
    "    ax2.add_patch(lstm_rect)\n",
    "    ax2.text(0.5, 0.5, 'LSTM\\n3 portes', ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "    ax2.text(0.5, 0.2, 'â€¢ 3 portes\\nâ€¢ Excellente mÃ©moire\\nâ€¢ Plus complexe', \n",
    "             ha='center', fontsize=9)\n",
    "    \n",
    "    # GRU\n",
    "    ax3.set_title('ğŸŸ¢ GRU', fontsize=14, fontweight='bold')\n",
    "    gru_rect = plt.Rectangle((0.25, 0.4), 0.5, 0.2, \n",
    "                            facecolor='lightgreen', edgecolor='darkgreen', linewidth=2)\n",
    "    ax3.add_patch(gru_rect)\n",
    "    ax3.text(0.5, 0.5, 'GRU\\n2 portes', ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "    ax3.text(0.5, 0.2, 'â€¢ 2 portes\\nâ€¢ Bon compromis\\nâ€¢ Plus rapide', \n",
    "             ha='center', fontsize=9)\n",
    "    \n",
    "    for ax in [ax1, ax2, ax3]:\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle('Comparaison des Architectures RNN', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "comparer_architectures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ ImplÃ©mentation : RNN vs LSTM vs GRU\n",
    "\n",
    "CrÃ©ons les trois modÃ¨les et comparons-les !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions pour crÃ©er les diffÃ©rents modÃ¨les\n",
    "def creer_rnn_basique(vocab_size, embedding_dim, hidden_dim, max_length):\n",
    "    \"\"\"\n",
    "    RNN basique (notre rÃ©fÃ©rence)\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "        layers.SimpleRNN(hidden_dim, dropout=0.3),\n",
    "        layers.Dense(1, activation='sigmoid')  # Classification binaire\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def creer_lstm(vocab_size, embedding_dim, hidden_dim, max_length):\n",
    "    \"\"\"\n",
    "    LSTM avec ses 3 portes magiques\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "        layers.LSTM(hidden_dim, dropout=0.3),  # ğŸšªğŸšªğŸšª 3 portes\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def creer_gru(vocab_size, embedding_dim, hidden_dim, max_length):\n",
    "    \"\"\"\n",
    "    GRU avec ses 2 portes simplifiÃ©es\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "        layers.GRU(hidden_dim, dropout=0.3),    # ğŸšªğŸšª 2 portes\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# ParamÃ¨tres du modÃ¨le\n",
    "VOCAB_SIZE = 1000\n",
    "EMBEDDING_DIM = 50\n",
    "HIDDEN_DIM = 64\n",
    "MAX_LENGTH = 25  # Un peu plus long pour tester la mÃ©moire\n",
    "\n",
    "# CrÃ©er les trois modÃ¨les\n",
    "modeles = {\n",
    "    'ğŸ”´ RNN': creer_rnn_basique(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, MAX_LENGTH),\n",
    "    'ğŸ”µ LSTM': creer_lstm(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, MAX_LENGTH),\n",
    "    'ğŸŸ¢ GRU': creer_gru(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, MAX_LENGTH)\n",
    "}\n",
    "\n",
    "# Comparer le nombre de paramÃ¨tres\n",
    "print(\"ğŸ“Š Comparaison du nombre de paramÃ¨tres:\")\n",
    "print(\"=\" * 45)\n",
    "for nom, modele in modeles.items():\n",
    "    nb_params = modele.count_params()\n",
    "    print(f\"{nom:8s}: {nb_params:,} paramÃ¨tres\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Observation:\")\n",
    "print(\"   LSTM > GRU > RNN en nombre de paramÃ¨tres\")\n",
    "print(\"   Plus de paramÃ¨tres = plus de complexitÃ© = plus de mÃ©moire\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š CrÃ©ons un Dataset Difficile\n",
    "\n",
    "Pour vraiment tester les capacitÃ©s de mÃ©moire, crÃ©ons des phrases oÃ¹ l'information importante est **au dÃ©but** et le sentiment peut changer **Ã  la fin** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset spÃ©cialement conÃ§u pour tester la mÃ©moire Ã  long terme\n",
    "def creer_dataset_difficile():\n",
    "    \"\"\"\n",
    "    CrÃ©e des phrases oÃ¹ l'info importante est dispersÃ©e dans la phrase\n",
    "    \"\"\"\n",
    "    \n",
    "    # POSITIFS : Information importante Ã  diffÃ©rents endroits\n",
    "    positifs_complexes = [\n",
    "        # Info importante au dÃ©but, puis beaucoup de texte\n",
    "        \"Excellent ce produit mÃªme si le packaging pourrait Ãªtre amÃ©liorÃ© et la livraison a pris du temps mais au final je suis satisfait\",\n",
    "        \"Fantastique cette expÃ©rience malgrÃ© quelques petits dÃ©tails qui pourraient Ãªtre perfectionnÃ©s selon moi mais c'est vraiment bien\",\n",
    "        \"Parfait ce service bien que l'attente ait Ã©tÃ© longue et que le personnel semblait dÃ©bordÃ© mais le rÃ©sultat est lÃ \",\n",
    "        \"GÃ©nial ce film mÃªme si certaines scÃ¨nes sont un peu longues et l'histoire parfois prÃ©visible mais j'ai adorÃ©\",\n",
    "        \"Superbe cette formation bien que certains concepts soient complexes et que le rythme soit parfois soutenu mais trÃ¨s enrichissant\",\n",
    "        \n",
    "        # Info importante au milieu\n",
    "        \"Ce produit au dÃ©but me semblait moyen mais finalement il est vraiment excellent et je le recommande vivement Ã  tous\",\n",
    "        \"L'expÃ©rience a commencÃ© difficilement puis s'est rÃ©vÃ©lÃ©e absolument fantastique et dÃ©passÃ© toutes mes attentes\",\n",
    "        \"Le service paraissait dÃ©cevant au premier contact mais s'est avÃ©rÃ© parfait et trÃ¨s professionnel au final\",\n",
    "        \n",
    "        # Info importante Ã  la fin\n",
    "        \"Ce produit a un packaging ordinaire une prÃ©sentation basique un prix Ã©levÃ© mais une qualitÃ© absolument exceptionnelle\",\n",
    "        \"Cette formation a un contenu dense des exercices difficiles un rythme soutenu mais des rÃ©sultats vraiment fantastiques\"\n",
    "    ]\n",
    "    \n",
    "    # NÃ‰GATIFS : Information importante Ã  diffÃ©rents endroits  \n",
    "    negatifs_complexes = [\n",
    "        # Info importante au dÃ©but\n",
    "        \"DÃ©cevant ce produit mÃªme si l'emballage est joli et la prÃ©sentation soignÃ©e et la livraison rapide mais la qualitÃ© n'y est pas\",\n",
    "        \"Catastrophique cette expÃ©rience malgrÃ© un accueil chaleureux et un cadre agrÃ©able et des promesses allÃ©chantes mais rien ne va\",\n",
    "        \"Horrible ce service bien que le personnel soit souriant et les locaux propres et l'ambiance correcte mais le rÃ©sultat est nul\",\n",
    "        \"Nul ce film mÃªme si les acteurs sont connus et les dÃ©cors beaux et la musique agrÃ©able mais l'histoire est ratÃ©e\",\n",
    "        \"Mauvais cette formation bien que les supports soient beaux et la salle confortable et le formateur sympa mais inutile\",\n",
    "        \n",
    "        # Info importante au milieu\n",
    "        \"Ce produit commenÃ§ait bien avec de bonnes promesses mais s'est rÃ©vÃ©lÃ© vraiment dÃ©cevant et ne vaut pas son prix du tout\",\n",
    "        \"L'expÃ©rience a bien dÃ©marrÃ© avec un bon accueil puis s'est dÃ©gradÃ©e et est devenue catastrophique et frustrante\",\n",
    "        \"Le service semblait professionnel au dÃ©but mais s'est rÃ©vÃ©lÃ© horrible et dÃ©cevant et vraiment pas Ã  la hauteur\",\n",
    "        \n",
    "        # Info importante Ã  la fin  \n",
    "        \"Ce produit a un bel emballage une prÃ©sentation soignÃ©e un marketing rÃ©ussi mais une qualitÃ© vraiment dÃ©cevante\",\n",
    "        \"Cette formation a un programme allÃ©chant des supports modernes un formateur expÃ©rimentÃ© mais un contenu vraiment nul\"\n",
    "    ]\n",
    "    \n",
    "    # Phrases simples pour contrÃ´le\n",
    "    positifs_simples = [\n",
    "        \"Excellent produit parfait\",\n",
    "        \"TrÃ¨s bon je recommande\",\n",
    "        \"Fantastique vraiment bien\",\n",
    "        \"Super expÃ©rience gÃ©niale\",\n",
    "        \"Parfait trÃ¨s satisfait\"\n",
    "    ]\n",
    "    \n",
    "    negatifs_simples = [\n",
    "        \"Mauvais produit dÃ©cevant\",\n",
    "        \"TrÃ¨s nul je dÃ©conseille\",\n",
    "        \"Horrible vraiment mal\",\n",
    "        \"Catastrophique expÃ©rience nulle\",\n",
    "        \"DÃ©cevant pas satisfait\"\n",
    "    ]\n",
    "    \n",
    "    # Combiner toutes les donnÃ©es (plus de phrases complexes)\n",
    "    tous_textes = (\n",
    "        positifs_complexes * 4 +  # Plus de phrases complexes\n",
    "        negatifs_complexes * 4 +\n",
    "        positifs_simples * 2 +     # Moins de phrases simples\n",
    "        negatifs_simples * 2\n",
    "    )\n",
    "    \n",
    "    # Labels correspondants\n",
    "    labels = (\n",
    "        [1] * len(positifs_complexes) * 4 +\n",
    "        [0] * len(negatifs_complexes) * 4 +\n",
    "        [1] * len(positifs_simples) * 2 +\n",
    "        [0] * len(negatifs_simples) * 2\n",
    "    )\n",
    "    \n",
    "    return tous_textes, np.array(labels)\n",
    "\n",
    "# CrÃ©er le dataset\n",
    "textes, labels = creer_dataset_difficile()\n",
    "\n",
    "# MÃ©langer les donnÃ©es\n",
    "indices = np.random.permutation(len(textes))\n",
    "textes = [textes[i] for i in indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "print(f\"ğŸ“Š Dataset crÃ©Ã©: {len(textes)} exemples\")\n",
    "print(f\"ğŸ“Š Distribution: {np.sum(labels)} positifs, {len(labels) - np.sum(labels)} nÃ©gatifs\")\n",
    "\n",
    "print(\"\\nğŸ“ Exemples de phrases complexes:\")\n",
    "print(\"=\" * 60)\n",
    "for i in range(3):\n",
    "    sentiment = \"ğŸ˜Š POSITIF\" if labels[i] == 1 else \"ğŸ˜ NÃ‰GATIF\"\n",
    "    print(f\"{sentiment}:\")\n",
    "    print(f\"  '{textes[i][:80]}...'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrÃ©paration des donnÃ©es\n",
    "print(\"ğŸ”§ PrÃ©paration des donnÃ©es...\")\n",
    "\n",
    "# Tokenisation\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(textes)\n",
    "\n",
    "# Conversion en sÃ©quences\n",
    "sequences = tokenizer.texts_to_sequences(textes)\n",
    "\n",
    "# Statistiques sur les longueurs\n",
    "longueurs = [len(seq) for seq in sequences]\n",
    "print(f\"ğŸ“ Longueur moyenne: {np.mean(longueurs):.1f} mots\")\n",
    "print(f\"ğŸ“ Longueur max: {np.max(longueurs)} mots\")\n",
    "print(f\"ğŸ“ 90% des phrases ont moins de {np.percentile(longueurs, 90):.0f} mots\")\n",
    "\n",
    "# Padding\n",
    "X = pad_sequences(sequences, maxlen=MAX_LENGTH)\n",
    "y = labels\n",
    "\n",
    "# Division train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… DonnÃ©es prÃªtes !\")\n",
    "print(f\"   Train: {X_train.shape[0]} exemples\")\n",
    "print(f\"   Test: {X_test.shape[0]} exemples\")\n",
    "print(f\"   Longueur des sÃ©quences: {X_train.shape[1]} mots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ Le Grand Test : RNN vs LSTM vs GRU\n",
    "\n",
    "Maintenant, entraÃ®nons les trois modÃ¨les et voyons qui se dÃ©brouille le mieux avec nos phrases complexes !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour entraÃ®ner et Ã©valuer un modÃ¨le\n",
    "def entrainer_et_evaluer(modele, nom, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    EntraÃ®ne un modÃ¨le et retourne ses performances\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸš€ EntraÃ®nement du modÃ¨le {nom}...\")\n",
    "    \n",
    "    # Compilation\n",
    "    modele.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Mesurer le temps d'entraÃ®nement\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # EntraÃ®nement\n",
    "    historique = modele.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=32,\n",
    "        epochs=8,  # Moins d'epochs pour la dÃ©mo\n",
    "        validation_split=0.2,\n",
    "        verbose=0  # Pas d'affichage dÃ©taillÃ©\n",
    "    )\n",
    "    \n",
    "    temps_entrainement = time.time() - start_time\n",
    "    \n",
    "    # Ã‰valuation\n",
    "    test_loss, test_accuracy = modele.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    print(f\"   âœ… TerminÃ© en {temps_entrainement:.1f}s\")\n",
    "    print(f\"   ğŸ“Š PrÃ©cision: {test_accuracy:.1%}\")\n",
    "    \n",
    "    return {\n",
    "        'modele': modele,\n",
    "        'historique': historique,\n",
    "        'precision': test_accuracy,\n",
    "        'temps': temps_entrainement,\n",
    "        'nom': nom\n",
    "    }\n",
    "\n",
    "# EntraÃ®ner tous les modÃ¨les\n",
    "resultats = {}\n",
    "\n",
    "for nom, modele in modeles.items():\n",
    "    resultat = entrainer_et_evaluer(modele, nom, X_train, y_train, X_test, y_test)\n",
    "    resultats[nom] = resultat\n",
    "\n",
    "print(\"\\nğŸ† RÃ‰SULTATS FINAUX\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Trier par prÃ©cision\n",
    "resultats_tries = sorted(resultats.items(), key=lambda x: x[1]['precision'], reverse=True)\n",
    "\n",
    "for i, (nom, resultat) in enumerate(resultats_tries):\n",
    "    medaille = [\"ğŸ¥‡\", \"ğŸ¥ˆ\", \"ğŸ¥‰\"][i]\n",
    "    print(f\"{medaille} {nom}: {resultat['precision']:.1%} (en {resultat['temps']:.1f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des rÃ©sultats\n",
    "def visualiser_resultats(resultats):\n",
    "    noms = list(resultats.keys())\n",
    "    precisions = [resultats[nom]['precision'] for nom in noms]\n",
    "    temps = [resultats[nom]['temps'] for nom in noms]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Graphique des prÃ©cisions\n",
    "    couleurs = ['red', 'blue', 'green']\n",
    "    barres1 = ax1.bar(noms, precisions, color=couleurs, alpha=0.7)\n",
    "    ax1.set_ylabel('PrÃ©cision')\n",
    "    ax1.set_title('ğŸ¯ PrÃ©cision sur phrases complexes', fontweight='bold')\n",
    "    ax1.set_ylim(0, 1)\n",
    "    \n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for barre, precision in zip(barres1, precisions):\n",
    "        ax1.text(barre.get_x() + barre.get_width()/2, barre.get_height() + 0.01, \n",
    "                f'{precision:.1%}', ha='center', fontweight='bold')\n",
    "    \n",
    "    # Graphique des temps\n",
    "    barres2 = ax2.bar(noms, temps, color=couleurs, alpha=0.7)\n",
    "    ax2.set_ylabel('Temps (secondes)')\n",
    "    ax2.set_title('â±ï¸ Temps d\\'entraÃ®nement', fontweight='bold')\n",
    "    \n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for barre, t in zip(barres2, temps):\n",
    "        ax2.text(barre.get_x() + barre.get_width()/2, barre.get_height() + 0.5, \n",
    "                f'{t:.1f}s', ha='center', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualiser_resultats(resultats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Test sur des Phrases SpÃ©cifiques\n",
    "\n",
    "Testons nos modÃ¨les sur des phrases oÃ¹ la mÃ©moire Ã  long terme est cruciale :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour prÃ©dire le sentiment\n",
    "def predire_sentiment(phrase, modele, tokenizer, max_length):\n",
    "    sequence = tokenizer.texts_to_sequences([phrase])\n",
    "    sequence_paddee = pad_sequences(sequence, maxlen=max_length)\n",
    "    score = modele.predict(sequence_paddee, verbose=0)[0, 0]\n",
    "    \n",
    "    if score > 0.5:\n",
    "        return \"ğŸ˜Š POSITIF\", score\n",
    "    else:\n",
    "        return \"ğŸ˜ NÃ‰GATIF\", 1 - score\n",
    "\n",
    "# Phrases test pour Ã©valuer la mÃ©moire\n",
    "phrases_test = [\n",
    "    # Phrase oÃ¹ l'info importante est au dÃ©but\n",
    "    \"Excellent ce produit mÃªme si l'emballage pourrait Ãªtre amÃ©liorÃ© et que la livraison a pris du temps\",\n",
    "    \n",
    "    # Phrase oÃ¹ l'info importante est Ã  la fin\n",
    "    \"Ce produit a un emballage ordinaire une prÃ©sentation basique mais une qualitÃ© absolument exceptionnelle\",\n",
    "    \n",
    "    # Phrase avec nÃ©gation au milieu\n",
    "    \"Au dÃ©but ce film semblait ennuyeux mais finalement c'Ã©tait vraiment fantastique\",\n",
    "    \n",
    "    # Phrase courte pour comparaison\n",
    "    \"Film fantastique excellent\",\n",
    "    \n",
    "    # Phrase nÃ©gative complexe\n",
    "    \"DÃ©cevant ce produit malgrÃ© un bel emballage et de bonnes promesses marketing mais qualitÃ© nulle\"\n",
    "]\n",
    "\n",
    "# Vrais labels (pour vÃ©rification)\n",
    "vrais_labels = [1, 1, 1, 1, 0]  # 1=positif, 0=nÃ©gatif\n",
    "\n",
    "print(\"ğŸ§ª TEST SUR PHRASES COMPLEXES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, phrase in enumerate(phrases_test):\n",
    "    vrai_sentiment = \"ğŸ˜Š POSITIF\" if vrais_labels[i] == 1 else \"ğŸ˜ NÃ‰GATIF\"\n",
    "    \n",
    "    print(f\"\\nğŸ“ Phrase {i+1}: '{phrase[:50]}...'\")\n",
    "    print(f\"   Vrai sentiment: {vrai_sentiment}\")\n",
    "    print(\"   PrÃ©dictions:\")\n",
    "    \n",
    "    for nom, resultat in resultats.items():\n",
    "        modele = resultat['modele']\n",
    "        sentiment_pred, confidence = predire_sentiment(phrase, modele, tokenizer, MAX_LENGTH)\n",
    "        \n",
    "        # VÃ©rifier si c'est correct\n",
    "        correct = \"âœ…\" if (sentiment_pred == \"ğŸ˜Š POSITIF\" and vrais_labels[i] == 1) or \\\n",
    "                        (sentiment_pred == \"ğŸ˜ NÃ‰GATIF\" and vrais_labels[i] == 0) else \"âŒ\"\n",
    "        \n",
    "        print(f\"     {nom}: {sentiment_pred} ({confidence:.1%}) {correct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Analyse AvancÃ©e : Ã‰volution pendant l'EntraÃ®nement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser l'Ã©volution de l'entraÃ®nement\n",
    "def visualiser_entrainement(resultats):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    couleurs = {'ğŸ”´ RNN': 'red', 'ğŸ”µ LSTM': 'blue', 'ğŸŸ¢ GRU': 'green'}\n",
    "    \n",
    "    for nom, resultat in resultats.items():\n",
    "        historique = resultat['historique']\n",
    "        couleur = couleurs[nom]\n",
    "        \n",
    "        # Accuracy\n",
    "        ax1.plot(historique.history['accuracy'], label=f'{nom} (train)', \n",
    "                color=couleur, linewidth=2)\n",
    "        ax1.plot(historique.history['val_accuracy'], label=f'{nom} (val)', \n",
    "                color=couleur, linewidth=2, linestyle='--')\n",
    "    \n",
    "    ax1.set_title('ğŸ“ˆ Ã‰volution de la PrÃ©cision', fontweight='bold')\n",
    "    ax1.set_xlabel('Ã‰poque')\n",
    "    ax1.set_ylabel('PrÃ©cision')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    for nom, resultat in resultats.items():\n",
    "        historique = resultat['historique']\n",
    "        couleur = couleurs[nom]\n",
    "        \n",
    "        # Loss\n",
    "        ax2.plot(historique.history['loss'], label=f'{nom} (train)', \n",
    "                color=couleur, linewidth=2)\n",
    "        ax2.plot(historique.history['val_loss'], label=f'{nom} (val)', \n",
    "                color=couleur, linewidth=2, linestyle='--')\n",
    "    \n",
    "    ax2.set_title('ğŸ“‰ Ã‰volution de la Loss', fontweight='bold')\n",
    "    ax2.set_xlabel('Ã‰poque')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualiser_entrainement(resultats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Quand Utiliser Quoi ?\n",
    "\n",
    "### Guide Pratique de Choix :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau de recommandations\n",
    "def afficher_guide_choix():\n",
    "    print(\"ğŸ¯ GUIDE DE CHOIX : RNN vs LSTM vs GRU\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    situations = [\n",
    "        {\n",
    "            'situation': \"ğŸ”¤ Phrases courtes (< 10 mots)\",\n",
    "            'recommandation': \"RNN basique suffit\",\n",
    "            'raison': \"Pas besoin de mÃ©moire complexe\"\n",
    "        },\n",
    "        {\n",
    "            'situation': \"ğŸ“š Textes longs (> 20 mots)\", \n",
    "            'recommandation': \"LSTM ou GRU\",\n",
    "            'raison': \"MÃ©moire Ã  long terme nÃ©cessaire\"\n",
    "        },\n",
    "        {\n",
    "            'situation': \"âš¡ Besoin de rapiditÃ©\",\n",
    "            'recommandation': \"GRU\",\n",
    "            'raison': \"Plus rapide que LSTM, performances similaires\"\n",
    "        },\n",
    "        {\n",
    "            'situation': \"ğŸ¯ Maximum de prÃ©cision\",\n",
    "            'recommandation': \"LSTM\",\n",
    "            'raison': \"Souvent lÃ©gÃ¨rement meilleur que GRU\"\n",
    "        },\n",
    "        {\n",
    "            'situation': \"ğŸ’¾ MÃ©moire limitÃ©e\",\n",
    "            'recommandation': \"GRU\",\n",
    "            'raison': \"Moins de paramÃ¨tres que LSTM\"\n",
    "        },\n",
    "        {\n",
    "            'situation': \"ğŸ”„ Traduction/Seq2Seq\",\n",
    "            'recommandation': \"LSTM\",\n",
    "            'raison': \"Excelle dans les tÃ¢ches sÃ©quence-Ã -sÃ©quence\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for situation in situations:\n",
    "        print(f\"\\n{situation['situation']}\")\n",
    "        print(f\"  â†’ {situation['recommandation']}\")\n",
    "        print(f\"  ğŸ’¡ {situation['raison']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ† RÃˆGLE D'OR : Commencez par GRU, puis testez LSTM si besoin !\")\n",
    "\n",
    "afficher_guide_choix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Bonus : LSTM Bidirectionnel\n",
    "\n",
    "**L'idÃ©e** : Et si on lisait la phrase dans les deux sens ?\n",
    "- ğŸ“– Un LSTM lit de gauche Ã  droite\n",
    "- ğŸ“– Un autre LSTM lit de droite Ã  gauche  \n",
    "- ğŸ§  On combine les deux pour avoir une vision complÃ¨te !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Bidirectionnel\n",
    "def creer_lstm_bidirectionnel(vocab_size, embedding_dim, hidden_dim, max_length):\n",
    "    \"\"\"\n",
    "    LSTM qui lit dans les deux sens\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "        layers.Bidirectional(layers.LSTM(hidden_dim, dropout=0.3)),  # ğŸ”„ Bidirectionnel !\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# CrÃ©er et tester le modÃ¨le bidirectionnel\n",
    "print(\"ğŸ”„ Test du LSTM Bidirectionnel...\")\n",
    "\n",
    "lstm_bidirectionnel = creer_lstm_bidirectionnel(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, MAX_LENGTH)\n",
    "\n",
    "# Comparer le nombre de paramÃ¨tres\n",
    "nb_params_normal = resultats['ğŸ”µ LSTM']['modele'].count_params()\n",
    "nb_params_bidirect = lstm_bidirectionnel.count_params()\n",
    "\n",
    "print(f\"ğŸ“Š LSTM normal:        {nb_params_normal:,} paramÃ¨tres\")\n",
    "print(f\"ğŸ“Š LSTM bidirectionnel: {nb_params_bidirect:,} paramÃ¨tres\")\n",
    "print(f\"ğŸ“Š Augmentation:       {(nb_params_bidirect/nb_params_normal - 1)*100:.0f}%\")\n",
    "\n",
    "# EntraÃ®ner rapidement\n",
    "resultat_bidirect = entrainer_et_evaluer(\n",
    "    lstm_bidirectionnel, \"ğŸ”„ LSTM Bidirectionnel\", \n",
    "    X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ† Comparaison finale:\")\n",
    "print(f\"   ğŸ”µ LSTM normal:        {resultats['ğŸ”µ LSTM']['precision']:.1%}\")\n",
    "print(f\"   ğŸ”„ LSTM bidirectionnel: {resultat_bidirect['precision']:.1%}\")\n",
    "\n",
    "if resultat_bidirect['precision'] > resultats['ğŸ”µ LSTM']['precision']:\n",
    "    print(\"   ğŸ’¡ Le bidirectionnel gagne ! ğŸ‰\")\n",
    "else:\n",
    "    print(\"   ğŸ’¡ Pas d'amÃ©lioration significative cette fois.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ RÃ©sumÃ© et Conclusions\n",
    "\n",
    "### ğŸ† Ce que nous avons dÃ©couvert :\n",
    "\n",
    "1. **RNN basiques** ğŸ”´ :\n",
    "   - âœ… Simples et rapides\n",
    "   - âŒ Oublient rapidement (problÃ¨me du gradient qui disparaÃ®t)\n",
    "   - ğŸ¯ **Usage** : Phrases courtes, prototypage rapide\n",
    "\n",
    "2. **LSTM** ğŸ”µ :\n",
    "   - âœ… Excellente mÃ©moire Ã  long terme (3 portes)\n",
    "   - âœ… RÃ©sout le problÃ¨me du gradient qui disparaÃ®t\n",
    "   - âŒ Plus lent et plus complexe\n",
    "   - ğŸ¯ **Usage** : Textes longs, tÃ¢ches complexes, traduction\n",
    "\n",
    "3. **GRU** ğŸŸ¢ :\n",
    "   - âœ… Bon compromis performance/simplicitÃ© (2 portes)\n",
    "   - âœ… Plus rapide que LSTM\n",
    "   - âœ… Moins de paramÃ¨tres\n",
    "   - ğŸ¯ **Usage** : Premier choix pour la plupart des tÃ¢ches\n",
    "\n",
    "### ğŸ’¡ Conseils pratiques :\n",
    "\n",
    "- **DÃ©butant** : Commencez par GRU\n",
    "- **Performance max** : Testez LSTM si GRU ne suffit pas\n",
    "- **Vitesse importante** : Restez sur GRU\n",
    "- **Phrases trÃ¨s longues** : LSTM bidirectionnel\n",
    "\n",
    "### ğŸš€ Prochaines Ã©tapes :\n",
    "\n",
    "1. **Attention Mechanisms** : Pour se concentrer sur les parties importantes\n",
    "2. **Transformers** : L'architecture qui a rÃ©volutionnÃ© le NLP\n",
    "3. **BERT, GPT** : Les modÃ¨les prÃ©-entraÃ®nÃ©s modernes\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ‰ FÃ©licitations !\n",
    "\n",
    "Vous maÃ®trisez maintenant :\n",
    "- âœ… La diffÃ©rence entre RNN, LSTM et GRU\n",
    "- âœ… Comment choisir le bon modÃ¨le\n",
    "- âœ… L'implÃ©mentation avec TensorFlow\n",
    "- âœ… L'Ã©valuation sur des tÃ¢ches complexes\n",
    "\n",
    "**Vous Ãªtes prÃªts pour les architectures encore plus avancÃ©es ! ğŸš€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}