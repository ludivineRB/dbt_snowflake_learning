{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM et GRU - Version Super Simple ! ğŸ˜Š\n",
    "\n",
    "## ğŸ¤·â€â™‚ï¸ Le problÃ¨me avec les RNN normaux\n",
    "\n",
    "Vous vous souvenez des RNN du notebook prÃ©cÃ©dent ? Ils avaient un gros problÃ¨me :\n",
    "\n",
    "**Ils oublient vite !** ğŸ¤¦â€â™‚ï¸\n",
    "\n",
    "### Exemple :\n",
    "```\n",
    "Phrase : \"Ce film Ã©tait nul au dÃ©but mais en fait c'Ã©tait gÃ©nial\"\n",
    "\n",
    "RNN normal :\n",
    "- Lit \"Ce film Ã©tait nul\" â†’ Pense \"film nul\"\n",
    "- Lit \"au dÃ©but mais\" â†’ Commence Ã  oublier \"nul\"\n",
    "- Lit \"en fait c'Ã©tait gÃ©nial\" â†’ Se souvient surtout de \"gÃ©nial\"\n",
    "\n",
    "RÃ©sultat : Ã‡a marche... par chance ! ğŸ€\n",
    "\n",
    "Mais si la phrase Ã©tait plus longue, le RNN oublierait le dÃ©but !\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ La solution : LSTM et GRU\n",
    "\n",
    "### LSTM = RNN avec une meilleure mÃ©moire\n",
    "\n",
    "**L'idÃ©e simple :** \n",
    "- âœ… Garder les infos importantes\n",
    "- âŒ Oublier les infos inutiles\n",
    "- ğŸ¯ DÃ©cider quoi montrer en sortie\n",
    "\n",
    "### GRU = Version simplifiÃ©e du LSTM\n",
    "\n",
    "**L'idÃ©e :** Faire la mÃªme chose que LSTM mais plus simple !\n",
    "\n",
    "---\n",
    "\n",
    "### Analogie de la mÃ©moire ğŸ§ \n",
    "\n",
    "Imaginez votre cerveau quand vous lisez :\n",
    "\n",
    "**RNN normal :**\n",
    "```\n",
    "Mot 1: \"Ce\" â†’ Je retiens \"Ce\"\n",
    "Mot 2: \"film\" â†’ J'oublie \"Ce\", je retiens \"film\"\n",
    "Mot 3: \"Ã©tait\" â†’ J'oublie \"film\", je retiens \"Ã©tait\"\n",
    "...\n",
    "```\n",
    "\n",
    "**LSTM/GRU :**\n",
    "```\n",
    "Mot 1: \"Ce\" â†’ Je retiens \"Ce\"\n",
    "Mot 2: \"film\" â†’ Je garde \"Ce\" ET j'ajoute \"film\"\n",
    "Mot 3: \"Ã©tait\" â†’ Je garde ce qui est important et j'ajoute \"Ã©tait\"\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation\n",
    "!pip install tensorflow numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"âœ… Tout est prÃªt !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ CrÃ©ons nos 3 modÃ¨les\n",
    "\n",
    "On va faire 3 modÃ¨les :\n",
    "1. **RNN** - Le modÃ¨le de base (qui oublie)\n",
    "2. **LSTM** - Avec bonne mÃ©moire\n",
    "3. **GRU** - Avec bonne mÃ©moire mais plus simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creer_rnn():\n",
    "    \"\"\"RNN normal (qui oublie vite)\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Embedding(1000, 50, input_length=20),  # Convertit mots en nombres\n",
    "        layers.SimpleRNN(32),                         # RNN avec 32 neurones\n",
    "        layers.Dense(1, activation='sigmoid')         # Sortie : positif ou nÃ©gatif\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def creer_lstm():\n",
    "    \"\"\"LSTM (bonne mÃ©moire)\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Embedding(1000, 50, input_length=20),\n",
    "        layers.LSTM(32),                              # LSTM au lieu de RNN\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def creer_gru():\n",
    "    \"\"\"GRU (bonne mÃ©moire, plus simple)\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Embedding(1000, 50, input_length=20),\n",
    "        layers.GRU(32),                               # GRU au lieu de RNN\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# CrÃ©er les modÃ¨les\n",
    "rnn_model = creer_rnn()\n",
    "lstm_model = creer_lstm()\n",
    "gru_model = creer_gru()\n",
    "\n",
    "print(\"âœ… 3 modÃ¨les crÃ©Ã©s !\")\n",
    "print(f\"RNN:  {rnn_model.count_params():,} paramÃ¨tres\")\n",
    "print(f\"LSTM: {lstm_model.count_params():,} paramÃ¨tres\")\n",
    "print(f\"GRU:  {gru_model.count_params():,} paramÃ¨tres\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Plus de paramÃ¨tres = plus complexe mais potentiellement meilleur\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ CrÃ©ons des donnÃ©es simples\n",
    "\n",
    "On va faire des phrases oÃ¹ il faut bien se souvenir du dÃ©but pour comprendre la fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phrases oÃ¹ il faut se souvenir du dÃ©but\n",
    "phrases_positives = [\n",
    "    \"Super film mÃªme si long\",\n",
    "    \"Excellent produit malgrÃ© prix Ã©levÃ©\",\n",
    "    \"GÃ©nial service mÃªme avec attente\",\n",
    "    \"Fantastique expÃ©rience malgrÃ© problÃ¨mes dÃ©but\",\n",
    "    \"Parfait rÃ©sultat mÃªme si difficile\",\n",
    "    \"Magnifique spectacle malgrÃ© salle bruyante\",\n",
    "    \"DÃ©licieux repas mÃªme si service lent\",\n",
    "    \"Formidable cours malgrÃ© professeur strict\",\n",
    "    \"Incroyable voyage mÃªme avec retards\",\n",
    "    \"Merveilleux livre malgrÃ© pages nombreuses\"\n",
    "]\n",
    "\n",
    "phrases_negatives = [\n",
    "    \"Nul film mÃªme si acteurs connus\",\n",
    "    \"Mauvais produit malgrÃ© belle publicitÃ©\",\n",
    "    \"Horrible service mÃªme avec sourires\",\n",
    "    \"DÃ©cevant rÃ©sultat malgrÃ© promesses\",\n",
    "    \"Catastrophique expÃ©rience mÃªme si cher\",\n",
    "    \"Ennuyeux spectacle malgrÃ© beau thÃ©Ã¢tre\",\n",
    "    \"DÃ©goutant repas mÃªme si joli restaurant\",\n",
    "    \"Inutile cours malgrÃ© bon professeur\",\n",
    "    \"RatÃ© voyage mÃªme avec beau temps\",\n",
    "    \"Barbant livre malgrÃ© belle couverture\"\n",
    "]\n",
    "\n",
    "# Combiner\n",
    "toutes_phrases = phrases_positives + phrases_negatives\n",
    "labels = [1] * len(phrases_positives) + [0] * len(phrases_negatives)  # 1=positif, 0=nÃ©gatif\n",
    "\n",
    "# Multiplier pour avoir plus de donnÃ©es\n",
    "toutes_phrases = toutes_phrases * 10  # 200 phrases au total\n",
    "labels = labels * 10\n",
    "\n",
    "print(f\"ğŸ“Š {len(toutes_phrases)} phrases crÃ©Ã©es\")\n",
    "print(f\"ğŸ“Š {sum(labels)} positives, {len(labels)-sum(labels)} nÃ©gatives\")\n",
    "\n",
    "print(\"\\nğŸ“ Exemples:\")\n",
    "print(\"Positif:\", phrases_positives[0])\n",
    "print(\"NÃ©gatif:\", phrases_negatives[0])\n",
    "\n",
    "print(\"\\nğŸ’¡ Remarquez: Le mot important est au DÃ‰BUT de chaque phrase !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrÃ©parer les donnÃ©es pour l'entraÃ®nement\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(toutes_phrases)\n",
    "\n",
    "# Convertir en nombres\n",
    "sequences = tokenizer.texts_to_sequences(toutes_phrases)\n",
    "X = pad_sequences(sequences, maxlen=20)  # Toutes les phrases = 20 mots max\n",
    "y = np.array(labels)\n",
    "\n",
    "# Diviser train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"âœ… DonnÃ©es prÃªtes !\")\n",
    "print(f\"EntraÃ®nement: {len(X_train)} phrases\")\n",
    "print(f\"Test: {len(X_test)} phrases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ Le grand test !\n",
    "\n",
    "On va entraÃ®ner nos 3 modÃ¨les et voir qui est le meilleur !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction simple pour entraÃ®ner un modÃ¨le\n",
    "def entrainer_modele(model, nom):\n",
    "    print(f\"\\nğŸš€ EntraÃ®nement {nom}...\")\n",
    "    \n",
    "    # PrÃ©parer le modÃ¨le\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # EntraÃ®ner\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=5,           # Seulement 5 fois pour aller vite\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        verbose=0           # Pas d'affichage dÃ©taillÃ©\n",
    "    )\n",
    "    \n",
    "    # Tester\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    precision = score[1]  # L'accuracy\n",
    "    \n",
    "    print(f\"âœ… {nom}: {precision:.1%} de prÃ©cision\")\n",
    "    return precision, history\n",
    "\n",
    "# EntraÃ®ner les 3 modÃ¨les\n",
    "resultats = {}\n",
    "\n",
    "precision_rnn, hist_rnn = entrainer_modele(rnn_model, \"RNN\")\n",
    "resultats[\"RNN\"] = precision_rnn\n",
    "\n",
    "precision_lstm, hist_lstm = entrainer_modele(lstm_model, \"LSTM\") \n",
    "resultats[\"LSTM\"] = precision_lstm\n",
    "\n",
    "precision_gru, hist_gru = entrainer_modele(gru_model, \"GRU\")\n",
    "resultats[\"GRU\"] = precision_gru\n",
    "\n",
    "print(\"\\nğŸ† RÃ‰SULTATS FINAUX:\")\n",
    "print(\"=\" * 30)\n",
    "for modele, precision in sorted(resultats.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{modele}: {precision:.1%}\")\n",
    "\n",
    "# Trouver le gagnant\n",
    "gagnant = max(resultats, key=resultats.get)\n",
    "print(f\"\\nğŸ¥‡ Le gagnant est: {gagnant} !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphique simple des rÃ©sultats\n",
    "noms = list(resultats.keys())\n",
    "scores = list(resultats.values())\n",
    "couleurs = ['red', 'blue', 'green']\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "barres = plt.bar(noms, scores, color=couleurs, alpha=0.7)\n",
    "\n",
    "# Ajouter les pourcentages sur les barres\n",
    "for barre, score in zip(barres, scores):\n",
    "    plt.text(barre.get_x() + barre.get_width()/2, barre.get_height() + 0.01, \n",
    "             f'{score:.1%}', ha='center', fontweight='bold', fontsize=12)\n",
    "\n",
    "plt.title('ğŸ† Comparaison des modÃ¨les', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('PrÃ©cision')\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ’¡ Plus la barre est haute, mieux c'est !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª Test sur de nouvelles phrases\n",
    "\n",
    "Testons nos modÃ¨les sur des phrases qu'ils n'ont jamais vues !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour prÃ©dire\n",
    "def predire(phrase, model):\n",
    "    # Convertir la phrase en nombres\n",
    "    sequence = tokenizer.texts_to_sequences([phrase])\n",
    "    sequence_paddee = pad_sequences(sequence, maxlen=20)\n",
    "    \n",
    "    # PrÃ©dire\n",
    "    score = model.predict(sequence_paddee, verbose=0)[0, 0]\n",
    "    \n",
    "    if score > 0.5:\n",
    "        return \"ğŸ˜Š POSITIF\", score\n",
    "    else:\n",
    "        return \"ğŸ˜ NÃ‰GATIF\", 1-score\n",
    "\n",
    "# Phrases de test\n",
    "phrases_test = [\n",
    "    \"Superbe film mÃªme si un peu long\",          # Positif\n",
    "    \"Affreux restaurant malgrÃ© belle dÃ©coration\", # NÃ©gatif  \n",
    "    \"Parfait weekend mÃªme avec pluie\",           # Positif\n",
    "    \"Horrible voyage malgrÃ© beau temps\"          # NÃ©gatif\n",
    "]\n",
    "\n",
    "vrais_sentiments = [\"ğŸ˜Š POSITIF\", \"ğŸ˜ NÃ‰GATIF\", \"ğŸ˜Š POSITIF\", \"ğŸ˜ NÃ‰GATIF\"]\n",
    "\n",
    "print(\"ğŸ§ª TEST SUR NOUVELLES PHRASES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, phrase in enumerate(phrases_test):\n",
    "    print(f\"\\nğŸ“ Phrase: '{phrase}'\")\n",
    "    print(f\"   Vrai sentiment: {vrais_sentiments[i]}\")\n",
    "    print(\"   PrÃ©dictions:\")\n",
    "    \n",
    "    # Tester avec chaque modÃ¨le\n",
    "    for nom, model in [(\"RNN\", rnn_model), (\"LSTM\", lstm_model), (\"GRU\", gru_model)]:\n",
    "        sentiment, confiance = predire(phrase, model)\n",
    "        \n",
    "        # VÃ©rifier si c'est correct\n",
    "        if sentiment == vrais_sentiments[i]:\n",
    "            resultat = \"âœ…\"\n",
    "        else:\n",
    "            resultat = \"âŒ\"\n",
    "        \n",
    "        print(f\"     {nom:4s}: {sentiment} ({confiance:.1%}) {resultat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Pourquoi LSTM/GRU sont meilleurs ?\n",
    "\n",
    "### Visualisation simple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explication visuelle simple\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# RNN normal\n",
    "ax1.set_title('ğŸ”´ RNN Normal', fontsize=14, fontweight='bold')\n",
    "mots = ['Super', 'film', 'mÃªme', 'si', 'long']\n",
    "memoire_rnn = [1.0, 0.7, 0.4, 0.2, 0.1]  # La mÃ©moire diminue\n",
    "\n",
    "ax1.bar(mots, memoire_rnn, color='red', alpha=0.7)\n",
    "ax1.set_ylabel('MÃ©moire du mot \"Super\"')\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.text(2, 0.8, 'ğŸ˜° Oublie\\n\"Super\"!', ha='center', fontsize=12, \n",
    "         bbox=dict(boxstyle=\"round\", facecolor='white', alpha=0.8))\n",
    "\n",
    "# LSTM/GRU\n",
    "ax2.set_title('ğŸ”µ LSTM/GRU', fontsize=14, fontweight='bold')\n",
    "memoire_lstm = [1.0, 0.9, 0.9, 0.8, 0.8]  # La mÃ©moire reste\n",
    "\n",
    "ax2.bar(mots, memoire_lstm, color='blue', alpha=0.7)\n",
    "ax2.set_ylabel('MÃ©moire du mot \"Super\"')\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.text(2, 0.8, 'ğŸ˜Š Se souvient\\nde \"Super\"!', ha='center', fontsize=12,\n",
    "         bbox=dict(boxstyle=\"round\", facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ’¡ C'est pour Ã§a que LSTM/GRU sont meilleurs sur nos phrases !\")\n",
    "print(\"   Ils se souviennent du mot important du dÃ©but.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ RÃ©sumÃ© Super Simple\n",
    "\n",
    "### Ce qu'on a appris :\n",
    "\n",
    "1. **RNN normal** ğŸ”´ :\n",
    "   - âœ… Simple et rapide\n",
    "   - âŒ Oublie vite le dÃ©but des phrases\n",
    "   - ğŸ‘ Bon pour phrases courtes\n",
    "\n",
    "2. **LSTM** ğŸ”µ :\n",
    "   - âœ… Se souvient bien du dÃ©but\n",
    "   - âœ… TrÃ¨s bon sur phrases longues\n",
    "   - âŒ Un peu plus lent\n",
    "\n",
    "3. **GRU** ğŸŸ¢ :\n",
    "   - âœ… Se souvient bien (comme LSTM)\n",
    "   - âœ… Plus simple que LSTM\n",
    "   - âœ… Plus rapide que LSTM\n",
    "\n",
    "### ğŸ’¡ Conseil simple :\n",
    "\n",
    "**Utilisez GRU !** ğŸ¯\n",
    "\n",
    "C'est le meilleur compromis :\n",
    "- Aussi bon que LSTM\n",
    "- Plus simple\n",
    "- Plus rapide\n",
    "\n",
    "### ğŸš€ Dans la vraie vie :\n",
    "\n",
    "- **Phrases courtes** (tweets) â†’ RNN suffit\n",
    "- **Phrases longues** (articles) â†’ GRU ou LSTM\n",
    "- **Pas sÃ»r** â†’ Commencez par GRU !\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ‰ FÃ©licitations !\n",
    "\n",
    "Vous savez maintenant :\n",
    "- âœ… Pourquoi RNN oublient\n",
    "- âœ… Comment LSTM/GRU rÃ©solvent le problÃ¨me\n",
    "- âœ… Quand utiliser quoi\n",
    "- âœ… Comment les coder avec TensorFlow\n",
    "\n",
    "**Vous Ãªtes prÃªts pour la suite ! ğŸš€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}