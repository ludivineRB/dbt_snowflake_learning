# 04 - Apache Spark et traitement de donnÃ©es

[â† 03 - Notebooks](03-notebooks-langages.md) | [ğŸ  Accueil](README.md) | [05 - Delta Lake et gestion des donnÃ©es â†’](05-delta-lake.md)

---

## ğŸ¯ Objectifs d'apprentissage

- Comprendre l'architecture et les concepts d'Apache Spark
- MaÃ®triser les DataFrames et Datasets
- Effectuer des transformations et actions sur les donnÃ©es
- Utiliser Spark SQL pour requÃªter les donnÃ©es
- Optimiser les performances des requÃªtes

## 1. Architecture Apache Spark

Spark distribue le calcul sur plusieurs nÅ“uds (Driver + Workers).

## 2. DataFrames et Datasets

Un DataFrame est une collection distribuÃ©e de donnÃ©es organisÃ©e en colonnes nommÃ©es.

```python
# CrÃ©ation depuis CSV
df_csv = spark.read.csv(
    "/path/to/data.csv",
    header=True,
    inferSchema=True
)
```

## 3. Transformations et Actions

- **Transformations (Lazy)** : select(), filter(), groupBy()
- **Actions (Eager)** : show(), count(), collect()

## 4. Spark SQL

```python
df.createOrReplaceTempView("employees")
result = spark.sql("SELECT * FROM employees WHERE age > 30")
```

## 5. Optimisation des performances

- **Partitionnement**
- **Mise en cache** (cache(), persist())
- **Broadcast Join**

---

[â† 03 - Notebooks](03-notebooks-langages.md) | [ğŸ  Accueil](README.md) | [05 - Delta Lake et gestion des donnÃ©es â†’](05-delta-lake.md)
