## üéØ Objectifs d'apprentissage

- Comprendre MLflow et son r√¥le dans le ML lifecycle
- Tracker des exp√©riences ML avec MLflow Tracking
- G√©rer des mod√®les avec MLflow Model Registry
- D√©ployer et servir des mod√®les ML
- Utiliser AutoML pour acc√©l√©rer le d√©veloppement
- Impl√©menter MLOps sur Databricks

## 1. Introduction √† MLflow

MLflow est une **plateforme open source** pour g√©rer l'int√©gralit√© du cycle de vie du Machine Learning. Databricks int√®gre nativement MLflow avec des fonctionnalit√©s avanc√©es.

### Composants de MLflow

#### MLflow Tracking

Enregistrement des exp√©riences, param√®tres, m√©triques et artefacts

#### MLflow Projects

Format standardis√© pour packager le code ML r√©utilisable

#### MLflow Models

Format standard pour packager les mod√®les ML

#### Model Registry

Store centralis√© pour g√©rer les versions et le lifecycle des mod√®les

```bash
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ML LIFECYCLE WITH MLFLOW                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ
‚îÇ  ‚îÇ Data Prep     ‚îÇ ‚îÄ‚îÄ‚îÄ‚ñ∂ ‚îÇ Experimentation‚îÇ                  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ
‚îÇ                                  ‚îÇ                           ‚îÇ
‚îÇ                                  ‚ñº                           ‚îÇ
‚îÇ                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îÇ
‚îÇ                         ‚îÇ MLflow Tracking‚îÇ                   ‚îÇ
‚îÇ                         ‚îÇ  ‚Ä¢ Params      ‚îÇ                   ‚îÇ
‚îÇ                         ‚îÇ  ‚Ä¢ Metrics     ‚îÇ                   ‚îÇ
‚îÇ                         ‚îÇ  ‚Ä¢ Models      ‚îÇ                   ‚îÇ
‚îÇ                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ
‚îÇ                                 ‚îÇ                            ‚îÇ
‚îÇ                                 ‚ñº                            ‚îÇ
‚îÇ                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îÇ
‚îÇ                        ‚îÇ Model Registry ‚îÇ                    ‚îÇ
‚îÇ                        ‚îÇ  ‚Ä¢ None        ‚îÇ                    ‚îÇ
‚îÇ                        ‚îÇ  ‚Ä¢ Staging     ‚îÇ                    ‚îÇ
‚îÇ                        ‚îÇ  ‚Ä¢ Production  ‚îÇ                    ‚îÇ
‚îÇ                        ‚îÇ  ‚Ä¢ Archived    ‚îÇ                    ‚îÇ
‚îÇ                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îÇ
‚îÇ                                ‚îÇ                             ‚îÇ
‚îÇ                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ                     ‚ñº                     ‚ñº                 ‚îÇ
‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ              ‚îÇ Batch Infer ‚îÇ      ‚îÇ Real-time   ‚îÇ          ‚îÇ
‚îÇ              ‚îÇ             ‚îÇ      ‚îÇ Serving     ‚îÇ          ‚îÇ
‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## 2. MLflow Tracking

### Enregistrer une exp√©rience simple

```bash
import mlflow
import mlflow.sklearn
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score
import pandas as pd

# Charger les donn√©es
df = spark.read.table("customer_churn").toPandas()
X = df.drop("churn", axis=1)
y = df["churn"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# D√©marrer une run MLflow
with mlflow.start_run(run_name="rf_baseline") as run:

# Log des param√®tres
    n_estimators = 100
    max_depth = 10

    mlflow.log_param("n_estimators", n_estimators)
    mlflow.log_param("max_depth", max_depth)
    mlflow.log_param("model_type", "RandomForest")

# Entra√Ænement
    model = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        random_state=42
    )
    model.fit(X_train, y_train)

# Pr√©dictions
    y_pred = model.predict(X_test)

# Log des m√©triques
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    mlflow.log_metric("accuracy", accuracy)
    mlflow.log_metric("f1_score", f1)

# Log du mod√®le
    mlflow.sklearn.log_model(
        model,
        "model",
        registered_model_name="customer_churn_classifier"
    )

# Log d'artefacts (fichiers)
    import matplotlib.pyplot as plt
    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot()
    plt.savefig("confusion_matrix.png")
    mlflow.log_artifact("confusion_matrix.png")

    print(f"Run ID: {run.info.run_id}")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"F1 Score: {f1:.4f}")
```

### Tracking avec plusieurs exp√©riences

```bash
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier

# Cr√©er ou r√©cup√©rer une exp√©rience
experiment_name = "/Users/me@company.com/churn_prediction"
mlflow.set_experiment(experiment_name)

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Random Forest": RandomForestClassifier(n_estimators=100),
    "Gradient Boosting": GradientBoostingClassifier(n_estimators=100),
    "XGBoost": XGBClassifier(n_estimators=100, use_label_encoder=False)
}

results = []

for model_name, model in models.items():
    with mlflow.start_run(run_name=model_name):

# Tags pour organisation
        mlflow.set_tag("model_family", model_name.split()[0])
        mlflow.set_tag("developer", "data_team")

# Entra√Ænement
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

# M√©triques
        accuracy = accuracy_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)

        mlflow.log_metric("accuracy", accuracy)
        mlflow.log_metric("f1_score", f1)

# Log mod√®le
        mlflow.sklearn.log_model(model, "model")

        results.append({
            "model": model_name,
            "accuracy": accuracy,
            "f1_score": f1
        })

        print(f"{model_name}: Accuracy={accuracy:.4f}, F1={f1:.4f}")

# Comparer les r√©sultats
results_df = pd.DataFrame(results).sort_values("f1_score", ascending=False)
display(results_df)
```

### Rechercher et comparer des runs

```bash
# Rechercher des runs par filtre
from mlflow.tracking import MlflowClient

client = MlflowClient()

# Obtenir l'exp√©rience
experiment = client.get_experiment_by_name(experiment_name)

# Rechercher les runs avec un filtre
runs = mlflow.search_runs(
    experiment_ids=[experiment.experiment_id],
    filter_string="metrics.accuracy > 0.85",
    order_by=["metrics.f1_score DESC"],
    max_results=10
)

display(runs[["run_id", "start_time", "params.model_type", "metrics.accuracy", "metrics.f1_score"]])

# Obtenir les d√©tails d'un run sp√©cifique
run_id = "abc123..."
run = client.get_run(run_id)
print(f"Param√®tres: {run.data.params}")
print(f"M√©triques: {run.data.metrics}")
```

## 3. MLflow Model Registry

Le Model Registry est un store centralis√© pour g√©rer les versions et le lifecycle des mod√®les ML.

### Enregistrer un mod√®le

```bash
# M√©thode 1 : Lors du log
with mlflow.start_run():
    mlflow.sklearn.log_model(
        model,
        "model",
        registered_model_name="customer_churn_classifier"
    )

# M√©thode 2 : Depuis un run existant
run_id = "abc123..."
model_uri = f"runs:/{run_id}/model"

mlflow.register_model(
    model_uri=model_uri,
    name="customer_churn_classifier"
)
```

### G√©rer les versions et stages

| Stage | Description | Utilisation |
| --- | --- | --- |
| **None** | Nouvellement enregistr√© | Mod√®le en d√©veloppement |
| **Staging** | En test/validation | Tests UAT, A/B testing |
| **Production** | D√©ploy√© en production | Serving en production |
| **Archived** | Archiv√©/obsol√®te | Mod√®les retir√©s |

```bash
from mlflow.tracking import MlflowClient

client = MlflowClient()
model_name = "customer_churn_classifier"

# Promouvoir une version en Staging
client.transition_model_version_stage(
    name=model_name,
    version=3,
    stage="Staging",
    archive_existing_versions=False
)

# Promouvoir en Production (et archiver les anciennes versions)
client.transition_model_version_stage(
    name=model_name,
    version=3,
    stage="Production",
    archive_existing_versions=True  # Archive les anciennes versions en Production
)

# Ajouter une description
client.update_model_version(
    name=model_name,
    version=3,
    description="Mod√®le entra√Æn√© sur donn√©es Q1 2024, accuracy=0.92, d√©ploy√© le 2024-01-15"
)

# Lister toutes les versions
versions = client.search_model_versions(f"name='{model_name}'")
for v in versions:
    print(f"Version {v.version}: {v.current_stage} - {v.description}")
```

### Charger un mod√®le depuis le Registry

```bash
# Charger la version Production
model_production = mlflow.pyfunc.load_model(
    model_uri=f"models:/{model_name}/Production"
)

# Charger une version sp√©cifique
model_v3 = mlflow.pyfunc.load_model(
    model_uri=f"models:/{model_name}/3"
)

# Pr√©diction
predictions = model_production.predict(X_test)
```

## 4. AutoML avec Databricks

Databricks AutoML automatise l'entra√Ænement et le tuning de mod√®les ML pour acc√©l√©rer le d√©veloppement.

### Utiliser AutoML via l'interface

#### Lancer une exp√©rience AutoML

1. Dans la barre lat√©rale, cliquez sur `Machine Learning`
2. Cliquez sur `AutoML`
3. S√©lectionnez votre table de donn√©es
4. Choisissez le type de probl√®me :
   - Classification
   - Regression
   - Forecasting
5. S√©lectionnez la colonne cible (label)
6. Configurez les param√®tres avanc√©s (optionnel)
7. Cliquez sur `Start AutoML`

### AutoML avec Python API

```bash
from databricks import automl

# Configuration AutoML pour classification
summary = automl.classify(
    dataset=df,
    target_col="churn",
    primary_metric="f1",
    timeout_minutes=30,
    max_trials=20
)

# R√©sultats
print(f"Best trial: {summary.best_trial}")
print(f"Best model URI: {summary.best_trial.model_path}")
print(f"Best F1 score: {summary.best_trial.metrics['test_f1_score']}")

# Le meilleur mod√®le est automatiquement enregistr√© dans MLflow
# Vous pouvez le charger et l'utiliser
best_model = mlflow.pyfunc.load_model(summary.best_trial.model_path)
```

### Ce que fait AutoML

#### Data Preprocessing

- Feature engineering automatique
- Encodage de variables cat√©gorielles
- Gestion des valeurs manquantes

#### Model Selection

- Teste plusieurs algorithmes
- Hyperparameter tuning
- Cross-validation

#### Explainability

- Feature importance
- SHAP values
- Visualisations

#### Notebooks Generated

- Data exploration
- Best model notebook
- Code r√©utilisable

## 5. D√©ploiement et serving

### Batch Inference

```bash
# Charger le mod√®le Production
model = mlflow.pyfunc.load_model(f"models:/{model_name}/Production")

# Charger de nouvelles donn√©es
new_data = spark.read.table("new_customers")
new_data_pandas = new_data.toPandas()

# Pr√©dictions batch
predictions = model.predict(new_data_pandas)

# Ajouter les pr√©dictions au DataFrame
new_data_pandas["churn_prediction"] = predictions
new_data_pandas["prediction_date"] = pd.Timestamp.now()

# Sauvegarder les r√©sultats
spark.createDataFrame(new_data_pandas) \
    .write \
    .format("delta") \
    .mode("append") \
    .saveAsTable("churn_predictions")
```

### Model Serving (Real-time)

```bash
# Via l'interface Databricks
# 1. Aller dans Machine Learning ‚Üí Models
# 2. S√©lectionner votre mod√®le
# 3. Onglet "Serving"
# 4. Cliquer "Enable Serving"
# 5. Configurer : Workload size, Scale-out

# Une fois d√©ploy√©, vous obtenez une API REST endpoint

# Appeler le endpoint
import requests
import json

# Token d'authentification Databricks
token = dbutils.notebook.entry_point.getDbutils() \
    .notebook().getContext().apiToken().get()

# Endpoint du mod√®le
serving_endpoint = "https:///serving-endpoints/customer_churn_classifier/invocations"

# Donn√©es d'entr√©e
input_data = {
    "dataframe_records": [
        {"age": 35, "tenure": 12, "monthly_charges": 65.5, "total_charges": 786.0},
        {"age": 42, "tenure": 24, "monthly_charges": 89.3, "total_charges": 2143.2}
    ]
}

# Requ√™te
response = requests.post(
    serving_endpoint,
    headers={"Authorization": f"Bearer {token}"},
    json=input_data
)

predictions = response.json()
print(predictions)
# Output: {"predictions": [0, 1]}
```

### Utilisation via Spark UDF (Inference distribu√©e)

```bash
import mlflow.pyfunc

# Cr√©er une UDF depuis le mod√®le
model_udf = mlflow.pyfunc.spark_udf(
    spark,
    model_uri=f"models:/{model_name}/Production",
    result_type="double"
)

# Appliquer le mod√®le sur un grand DataFrame Spark
large_df = spark.read.table("all_customers")

predictions_df = large_df.withColumn(
    "churn_prediction",
    model_udf(*[col(c) for c in feature_cols])
)

display(predictions_df)

# Sauvegarder
predictions_df.write.format("delta").mode("overwrite").saveAsTable("customer_predictions")
```

## 6. MLOps et CI/CD

### Workflow MLOps complet

```bash
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      MLOPS WORKFLOW                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                               ‚îÇ
‚îÇ  1. [Development]                                            ‚îÇ
‚îÇ     ‚Ä¢ Feature Engineering                                    ‚îÇ
‚îÇ     ‚Ä¢ Model Training (MLflow Tracking)                       ‚îÇ
‚îÇ     ‚Ä¢ Experimentation                                        ‚îÇ
‚îÇ                   ‚îÇ                                          ‚îÇ
‚îÇ                   ‚ñº                                          ‚îÇ
‚îÇ  2. [Version Control]                                        ‚îÇ
‚îÇ     ‚Ä¢ Git commit (code + config)                             ‚îÇ
‚îÇ     ‚Ä¢ Register Model in MLflow Registry                      ‚îÇ
‚îÇ                   ‚îÇ                                          ‚îÇ
‚îÇ                   ‚ñº                                          ‚îÇ
‚îÇ  3. [CI/CD Pipeline]                                         ‚îÇ
‚îÇ     ‚Ä¢ Run unit tests                                         ‚îÇ
‚îÇ     ‚Ä¢ Train model on CI                                      ‚îÇ
‚îÇ     ‚Ä¢ Model validation tests                                 ‚îÇ
‚îÇ                   ‚îÇ                                          ‚îÇ
‚îÇ                   ‚ñº                                          ‚îÇ
‚îÇ  4. [Staging Deployment]                                     ‚îÇ
‚îÇ     ‚Ä¢ Transition to "Staging"                                ‚îÇ
‚îÇ     ‚Ä¢ A/B testing                                            ‚îÇ
‚îÇ     ‚Ä¢ Performance monitoring                                 ‚îÇ
‚îÇ                   ‚îÇ                                          ‚îÇ
‚îÇ                   ‚ñº                                          ‚îÇ
‚îÇ  5. [Production Deployment]                                  ‚îÇ
‚îÇ     ‚Ä¢ Transition to "Production"                             ‚îÇ
‚îÇ     ‚Ä¢ Enable Model Serving                                   ‚îÇ
‚îÇ     ‚Ä¢ Monitor metrics                                        ‚îÇ
‚îÇ                   ‚îÇ                                          ‚îÇ
‚îÇ                   ‚ñº                                          ‚îÇ
‚îÇ  6. [Monitoring & Retraining]                                ‚îÇ
‚îÇ     ‚Ä¢ Data drift detection                                   ‚îÇ
‚îÇ     ‚Ä¢ Performance degradation alerts                         ‚îÇ
‚îÇ     ‚Ä¢ Trigger retraining pipeline                            ‚îÇ
‚îÇ                                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Exemple de workflow automatis√©

```bash
# Notebook 1: Training Pipeline
import mlflow
from datetime import datetime

# Configuration
model_name = "customer_churn_classifier"
min_accuracy_threshold = 0.85

# Entra√Ænement
with mlflow.start_run(run_name=f"training_{datetime.now().strftime('%Y%m%d')}"):

# ... code d'entra√Ænement ...

# Enregistrer le mod√®le
    if accuracy > min_accuracy_threshold:
        model_version = mlflow.register_model(
            model_uri=f"runs:/{mlflow.active_run().info.run_id}/model",
            name=model_name
        )

# Transition automatique vers Staging
        client.transition_model_version_stage(
            name=model_name,
            version=model_version.version,
            stage="Staging"
        )

        print(f"Mod√®le version {model_version.version} d√©ploy√© en Staging")
    else:
        print(f"Accuracy {accuracy} < seuil {min_accuracy_threshold}. Mod√®le non d√©ploy√©.")
```

```bash
# Notebook 2: Validation et promotion
from mlflow.tracking import MlflowClient

client = MlflowClient()

# R√©cup√©rer la derni√®re version Staging
staging_versions = client.get_latest_versions(model_name, stages=["Staging"])
staging_version = staging_versions[0]

# Charger et tester sur validation set
model = mlflow.pyfunc.load_model(f"models:/{model_name}/Staging")
val_predictions = model.predict(X_val)
val_accuracy = accuracy_score(y_val, val_predictions)

# Promotion vers Production si validation OK
if val_accuracy > 0.90:
    client.transition_model_version_stage(
        name=model_name,
        version=staging_version.version,
        stage="Production",
        archive_existing_versions=True
    )

# Notification
    print(f"‚úÖ Mod√®le version {staging_version.version} d√©ploy√© en Production!")
# Envoyer email/Slack notification
else:
    print(f"‚ùå Validation √©chou√©e. Accuracy: {val_accuracy}")
```

### Monitoring des mod√®les

```bash
# D√©tecter le data drift
from scipy.stats import ks_2samp

# Donn√©es d'entra√Ænement
train_data = spark.read.table("training_data").toPandas()

# Donn√©es de production r√©centes
prod_data = spark.read.table("production_inference") \
    .filter("prediction_date >= current_date() - 7") \
    .toPandas()

# Test de Kolmogorov-Smirnov pour chaque feature
drift_detected = False
for col in feature_cols:
    statistic, p_value = ks_2samp(train_data[col], prod_data[col])

    if p_value < 0.05:  # Seuil de significativit√©
        print(f"‚ö†Ô∏è Data drift d√©tect√© sur {col}: p-value={p_value:.4f}")
        drift_detected = True

if drift_detected:
    print("D√©clenchement du pipeline de retraining...")
# Trigger retraining job via API
```

### üìå Points cl√©s √† retenir

- MLflow g√®re l'int√©gralit√© du ML lifecycle : tracking, registry, serving
- Tracking enregistre param√®tres, m√©triques, mod√®les et artefacts
- Model Registry centralise la gestion des versions avec stages (None/Staging/Production/Archived)
- AutoML acc√©l√®re le d√©veloppement avec tuning automatique
- D√©ploiement flexible : batch inference ou real-time serving
- MLOps workflow complet avec CI/CD et monitoring
- Int√©gration native Databricks pour scalabilit√© et performance

#### üéâ F√©licitations !

Vous avez compl√©t√© la formation Azure Databricks ! Vous ma√Ætrisez maintenant :

- ‚úÖ L'architecture et les concepts de Databricks
- ‚úÖ La configuration et gestion des clusters
- ‚úÖ Les notebooks et langages multiples
- ‚úÖ Le traitement de donn√©es avec Spark
- ‚úÖ Delta Lake pour des donn√©es fiables
- ‚úÖ L'orchestration avec Workflows
- ‚úÖ Le Machine Learning avec MLflow

**Prochaines √©tapes :** Mettez en pratique ces comp√©tences sur des projets r√©els et explorez les fonctionnalit√©s avanc√©es comme Delta Live Tables, Unity Catalog, et Lakehouse Monitoring.