## ğŸ¯ Objectifs d'Apprentissage

- Comprendre HDInsight, le service Hadoop managÃ© d'Azure
- CrÃ©er un cluster Hadoop sur Azure pas Ã  pas
- Configurer le stockage Azure pour HDFS
- ExÃ©cuter des jobs MapReduce sur Azure
- Monitorer et gÃ©rer le cluster

## â˜ï¸ 1. Introduction Ã  Azure HDInsight

### Qu'est-ce que HDInsight ?

**Azure HDInsight** est un service cloud managÃ© qui facilite le dÃ©ploiement et la gestion
de clusters Hadoop, Spark, Hive, HBase, et d'autres frameworks Big Data sur Microsoft Azure.

#### âœ… Avantages

- DÃ©ploiement rapide (minutes vs heures)
- ScalabilitÃ© Ã©lastique
- Paiement Ã  l'usage
- Maintenance simplifiÃ©e

#### ğŸ’° ModÃ¨le de Tarification

- Facturation par nÅ“ud/heure
- ArrÃªt du cluster pour Ã©conomiser
- Stockage Azure facturÃ© sÃ©parÃ©ment

#### ğŸ”§ Types de Clusters

- Hadoop (MapReduce, HDFS, YARN)
- Spark (traitement in-memory)
- HBase (NoSQL)
- Interactive Query (Hive LLAP)

#### ğŸ’¾ Stockage

- Azure Blob Storage
- Azure Data Lake Storage Gen2
- Compatible HDFS

#### PrÃ©requis

- Un compte Microsoft Azure (essai gratuit disponible)
- CrÃ©dits Azure (200$ offerts pour les nouveaux comptes)
- Un abonnement Azure actif

## ğŸš€ 2. CrÃ©ation d'un Compte Azure (si nÃ©cessaire)

### Ã‰tape 1 : S'inscrire sur Azure

```bash
# 1. Aller sur https://azure.microsoft.com/free/
# 2. Cliquer sur "Commencer gratuitement"
# 3. Se connecter avec un compte Microsoft (ou en crÃ©er un)
# 4. Remplir les informations de facturation (carte requise mais pas dÃ©bitÃ©e)
# 5. VÃ©rifier votre identitÃ© par tÃ©lÃ©phone
# 6. Accepter les conditions
```

#### CrÃ©dits Gratuits

Nouveau compte Azure = **200$ de crÃ©dits valables 30 jours** + services gratuits 12 mois

### Ã‰tape 2 : AccÃ©der au Portail Azure

1. Se connecter sur <https://portal.azure.com>
2. VÃ©rifier que votre abonnement est actif (menu "Abonnements")
3. Vous Ãªtes prÃªt Ã  crÃ©er votre cluster !

## ğŸ”§ 3. CrÃ©ation d'un Cluster HDInsight - Pas Ã  Pas

### Ã‰tape 1 : CrÃ©er un Groupe de Ressources

#### Qu'est-ce qu'un Groupe de Ressources ?

Un conteneur logique qui regroupe toutes les ressources Azure liÃ©es (cluster, stockage, rÃ©seau).
Permet de gÃ©rer et supprimer facilement toutes les ressources d'un projet.

```bash
# Dans le Portail Azure :

1. Cliquer sur "Groupes de ressources" dans le menu
2. Cliquer sur "+ CrÃ©er"
3. Remplir les informations :
   - Abonnement : Votre abonnement Azure
   - Nom du groupe : hadoop-formation-rg
   - RÃ©gion : France Central (ou la plus proche)
4. Cliquer sur "VÃ©rifier + crÃ©er"
5. Cliquer sur "CrÃ©er"
```

### Ã‰tape 2 : CrÃ©er un Compte de Stockage Azure

Le cluster HDInsight a besoin d'un stockage pour HDFS.

```bash
# Dans le Portail Azure :

1. Cliquer sur "+ CrÃ©er une ressource"
2. Rechercher "Compte de stockage"
3. Cliquer sur "CrÃ©er"
4. Remplir :
   - Groupe de ressources : hadoop-formation-rg
   - Nom du compte : hadoopstorage[votreID] (doit Ãªtre unique)
   - RÃ©gion : France Central
   - Performances : Standard
   - Redondance : LRS (Stockage localement redondant)
5. Cliquer sur "VÃ©rifier + crÃ©er"
6. Cliquer sur "CrÃ©er"
7. Attendre la fin du dÃ©ploiement (1-2 minutes)
```

### Ã‰tape 3 : CrÃ©er un Conteneur Blob

```bash
# Une fois le compte de stockage crÃ©Ã© :

1. Aller dans le compte de stockage crÃ©Ã©
2. Dans le menu Ã  gauche, cliquer sur "Conteneurs"
3. Cliquer sur "+ Conteneur"
4. Nom : hadoop-data
5. Niveau d'accÃ¨s public : PrivÃ©
6. Cliquer sur "CrÃ©er"
```

### Ã‰tape 4 : CrÃ©er le Cluster HDInsight

```bash
# Dans le Portail Azure :

1. Cliquer sur "+ CrÃ©er une ressource"
2. Rechercher "HDInsight"
3. Cliquer sur "Azure HDInsight"
4. Cliquer sur "CrÃ©er"

# Onglet "Informations de base" :
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- Abonnement : Votre abonnement
- Groupe de ressources : hadoop-formation-rg
- Nom du cluster : hadoop-cluster-[votreID]
- RÃ©gion : France Central
- Type de cluster : Hadoop
- Version : Hadoop 3.1.1 (ou la plus rÃ©cente)
- Nom d'utilisateur du cluster : admin
- Mot de passe : [CrÃ©er un mot de passe fort]
  (ex: Hadoop@2025!)
- Nom d'utilisateur SSH : sshuser
- Utiliser le mÃªme mot de passe : Oui

Cliquer sur "Suivant : Stockage"

# Onglet "Stockage" :
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- Type de stockage principal : Azure Storage
- MÃ©thode de sÃ©lection : SÃ©lectionner dans la liste
- Compte de stockage : hadoopstorage[votreID]
- Conteneur : hadoop-data
- IdentitÃ© managÃ©e : (laisser par dÃ©faut)

Cliquer sur "Suivant : SÃ©curitÃ© + rÃ©seau"

# Onglet "SÃ©curitÃ© + rÃ©seau" :
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- Laisser les paramÃ¨tres par dÃ©faut
Cliquer sur "Suivant : Configuration + tarification"

# Onglet "Configuration + tarification" :
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
- Type de nÅ“ud : Standard_D3_v2 (ou Standard_D4_v2)
- Nombre de nÅ“uds Worker : 2
- Nombre de nÅ“uds Head : 2 (dÃ©faut)

Cliquer sur "Suivant : Ã‰tiquettes" (optionnel)
Cliquer sur "Suivant : VÃ©rifier + crÃ©er"
VÃ©rifier le rÃ©capitulatif
Cliquer sur "CrÃ©er"
```

#### â±ï¸ Temps de CrÃ©ation

La crÃ©ation du cluster prend entre **15 et 30 minutes**.
Vous pouvez suivre la progression dans les notifications (icÃ´ne cloche en haut Ã  droite).

#### ğŸ’° Attention aux CoÃ»ts

Un cluster HDInsight avec 2 nÅ“uds worker coÃ»te environ **5-10â‚¬/jour**.
Pensez Ã  **supprimer le cluster** aprÃ¨s vos tests pour Ã©viter les frais !

## ğŸ”Œ 4. Connexion au Cluster

### MÃ©thode 1 : Interface Web Ambari

```bash
# Une fois le cluster crÃ©Ã© :

1. Aller dans votre cluster HDInsight
2. Dans le menu Ã  gauche, cliquer sur "Tableaux de bord du cluster"
3. Cliquer sur "Ambari home"
4. Se connecter avec :
   - Utilisateur : admin
   - Mot de passe : [le mot de passe que vous avez crÃ©Ã©]

# URL directe :
https://hadoop-cluster-[votreID].azurehdinsight.net
```

### MÃ©thode 2 : SSH vers le NÅ“ud Head

```bash
# Depuis votre terminal local :

ssh sshuser@hadoop-cluster-[votreID]-ssh.azurehdinsight.net

# Entrer le mot de passe SSH
# Vous Ãªtes maintenant connectÃ© au nÅ“ud Head du cluster !

# VÃ©rifier Hadoop
hadoop version

# VÃ©rifier HDFS
hdfs dfs -ls /

# VÃ©rifier YARN
yarn node -list
```

## ğŸ“‚ 5. Utiliser le Stockage Azure avec Hadoop

### Azure Blob Storage comme HDFS

HDInsight utilise Azure Blob Storage comme systÃ¨me de fichiers par dÃ©faut,
compatible avec les commandes HDFS.

#### Format des Chemins

```bash
# Format WASB (Windows Azure Storage Blob)
wasb://[conteneur]@[compte-stockage].blob.core.windows.net/[chemin]

# Exemple :
wasb://hadoop-data@hadoopstorage123.blob.core.windows.net/user/data

# Format court (si c'est le stockage par dÃ©faut)
/user/data
```

#### Commandes HDFS sur Azure Storage

```bash
# Lister les fichiers
hdfs dfs -ls /

# CrÃ©er un rÃ©pertoire
hdfs dfs -mkdir /user/sshuser/test

# CrÃ©er un fichier local et le copier
echo "Hello Azure Hadoop" > test.txt
hdfs dfs -put test.txt /user/sshuser/

# Lire le fichier
hdfs dfs -cat /user/sshuser/test.txt

# Le fichier est stockÃ© dans Azure Blob Storage !
# Vous pouvez le voir dans le Portail Azure :
# Compte de stockage â†’ Conteneurs â†’ hadoop-data
```

## ğŸ¯ 6. ExÃ©cuter un Job MapReduce sur Azure

### Exemple : WordCount en Python

#### Ã‰tape 1 : CrÃ©er les Scripts Python

```bash
# ConnectÃ© en SSH au cluster

# CrÃ©er mapper.py
cat > mapper.py << 'EOF'
#!/usr/bin/env python3
import sys

for line in sys.stdin:
    line = line.strip()
    words = line.split()
    for word in words:
        print(f"{word}\t1")
EOF

# CrÃ©er reducer.py
cat > reducer.py << 'EOF'
#!/usr/bin/env python3
import sys

current_word = None
current_count = 0

for line in sys.stdin:
    line = line.strip()
    word, count = line.split('\t')
    count = int(count)

    if current_word == word:
        current_count += count
    else:
        if current_word:
            print(f"{current_word}\t{current_count}")
        current_word = word
        current_count = count

if current_word:
    print(f"{current_word}\t{current_count}")
EOF

# Rendre exÃ©cutables
chmod +x mapper.py reducer.py
```

#### Ã‰tape 2 : PrÃ©parer les DonnÃ©es

```bash
# CrÃ©er un fichier de test
cat > input.txt << EOF
Azure Hadoop HDInsight
Cloud Computing with Hadoop
Big Data on Azure
EOF

# CrÃ©er le rÃ©pertoire dans HDFS (Azure Storage)
hdfs dfs -mkdir -p /user/sshuser/wordcount/input

# Copier le fichier
hdfs dfs -put input.txt /user/sshuser/wordcount/input/

# VÃ©rifier
hdfs dfs -cat /user/sshuser/wordcount/input/input.txt
```

#### Ã‰tape 3 : Lancer le Job

```bash
# Lancer le job Hadoop Streaming
hadoop jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar \
    -input /user/sshuser/wordcount/input \
    -output /user/sshuser/wordcount/output \
    -mapper mapper.py \
    -reducer reducer.py \
    -file mapper.py \
    -file reducer.py

# Voir les rÃ©sultats
hdfs dfs -cat /user/sshuser/wordcount/output/part-00000
```

#### Ã‰tape 4 : Suivre le Job dans YARN

```bash
# URL YARN ResourceManager :
https://hadoop-cluster-[votreID].azurehdinsight.net/yarnui

# Se connecter avec :
- Utilisateur : admin
- Mot de passe : [votre mot de passe]
```

## ğŸ“Š 7. Utiliser Hive sur HDInsight

### Connexion Ã  Hive

```bash
# Depuis SSH sur le cluster
beeline -u 'jdbc:hive2://localhost:10001/;transportMode=http'

# Ou connectez-vous Ã  Hive View dans Ambari
```

### Exemple de RequÃªtes Hive

```bash
-- CrÃ©er une table
CREATE TABLE sales (
    product STRING,
    quantity INT,
    price DOUBLE
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE;

-- Charger des donnÃ©es depuis Azure Storage
LOAD DATA INPATH '/user/sshuser/sales.csv' INTO TABLE sales;

-- RequÃªte
SELECT product, SUM(quantity * price) as revenue
FROM sales
GROUP BY product
ORDER BY revenue DESC;
```

## ğŸ” 8. Monitoring et Gestion

### Interfaces de Monitoring

| Interface | URL | Utilisation |
| --- | --- | --- |
| Ambari | https://[cluster].azurehdinsight.net | Gestion complÃ¨te du cluster |
| YARN UI | https://[cluster].azurehdinsight.net/yarnui | Suivi des jobs YARN |
| Job History | https://[cluster].azurehdinsight.net/jobhistory | Historique des jobs |
| Portail Azure | portal.azure.com | MÃ©triques et alertes |

### Scaler le Cluster

```bash
# Dans le Portail Azure :

1. Aller dans votre cluster HDInsight
2. Menu Ã  gauche â†’ "Taille du cluster"
3. Modifier le nombre de nÅ“uds Worker (2 Ã  10+)
4. Cliquer sur "Enregistrer"
5. Le scaling prend 5-10 minutes
```

## ğŸ—‘ï¸ 9. Nettoyage et Suppression

#### âš ï¸ Important : Ã‰viter les Frais

AprÃ¨s vos tests, **supprimez le cluster** pour arrÃªter la facturation !
Le stockage Azure (quelques centimes) peut Ãªtre conservÃ© si vous voulez garder vos donnÃ©es.

### Supprimer le Cluster

```bash
# MÃ©thode 1 : Portail Azure
1. Aller dans votre cluster HDInsight
2. Cliquer sur "Supprimer" en haut
3. Taper le nom du cluster pour confirmer
4. Cliquer sur "Supprimer"

# MÃ©thode 2 : Azure CLI
az hdinsight delete --name hadoop-cluster-[votreID] --resource-group hadoop-formation-rg

# Pour tout supprimer (cluster + stockage + groupe de ressources) :
az group delete --name hadoop-formation-rg --yes
```

### VÃ©rifier les CoÃ»ts

```bash
# Dans le Portail Azure :

1. Menu â†’ "Cost Management + Billing"
2. â†’ "Cost analysis"
3. VÃ©rifier les coÃ»ts par ressource
4. VÃ©rifier qu'aucune ressource n'est en cours d'exÃ©cution
```

## ğŸ“ RÃ©sumÃ© de la Partie 7

### Points ClÃ©s Ã  Retenir

- Azure HDInsight = Hadoop managÃ© dans le cloud
- CrÃ©ation d'un cluster en 15-30 minutes via le Portail Azure
- Azure Blob Storage remplace HDFS (compatible)
- MÃªme commandes Hadoop que sur un cluster local
- Interfaces Ambari et YARN pour la gestion et le monitoring
- Scaling facile du nombre de nÅ“uds
- âš ï¸ Supprimer le cluster aprÃ¨s usage pour Ã©viter les frais

#### âœ… PrÃªt pour la Suite ?

Vous savez maintenant dÃ©ployer Hadoop sur Azure ! Dans la partie suivante, nous allons pratiquer pas Ã  pas avec des exercices guidÃ©s.