## ğŸ¯ Objectifs d'Apprentissage

- Comprendre l'architecture master/slave de HDFS
- MaÃ®triser les concepts de NameNode et DataNode
- ApprÃ©hender la rÃ©plication et la tolÃ©rance aux pannes
- Utiliser les commandes HDFS essentielles

## ğŸ“š 1. Qu'est-ce que HDFS ?

**HDFS** (Hadoop Distributed File System) est le systÃ¨me de fichiers distribuÃ© de Hadoop.
C'est un systÃ¨me conÃ§u pour stocker de trÃ¨s grandes quantitÃ©s de donnÃ©es sur plusieurs machines tout en
offrant une tolÃ©rance aux pannes et un dÃ©bit Ã©levÃ©.

### Principes de Conception

#### ğŸ’ª TolÃ©rance aux Pannes

Les pannes matÃ©rielles sont la norme, pas l'exception. HDFS dÃ©tecte et rÃ©cupÃ¨re automatiquement.

#### ğŸ“ˆ ScalabilitÃ©

ConÃ§u pour s'adapter Ã  des centaines ou milliers de nÅ“uds dans un cluster.

#### ğŸ“Š Gros Fichiers

OptimisÃ© pour stocker des fichiers de plusieurs gigaoctets Ã  tÃ©raoctets.

#### ğŸ”„ AccÃ¨s Streaming

ConÃ§u pour des lectures sÃ©quentielles rapides plutÃ´t que des accÃ¨s alÃ©atoires.

#### ğŸ’» MatÃ©riel Standard

Fonctionne sur du matÃ©riel commodity (bon marchÃ©), pas de serveurs spÃ©cialisÃ©s requis.

#### âœï¸ Write Once, Read Many

Les fichiers sont Ã©crits une fois et lus plusieurs fois. Pas de modifications en place.

#### Analogie

Imaginez une bibliothÃ¨que oÃ¹ les livres (donnÃ©es) sont rÃ©partis dans plusieurs bÃ¢timents (DataNodes).
Il y a un catalogue central (NameNode) qui sait exactement dans quel bÃ¢timent se trouve chaque livre.
Chaque livre existe en plusieurs exemplaires dans diffÃ©rents bÃ¢timents pour Ã©viter la perte.

## ğŸ—ï¸ 2. Architecture de HDFS

### Vue d'Ensemble

HDFS suit une architecture **Master/Slave** (ou Master/Worker) :

```bash
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           CLIENT                                â”‚
â”‚                    (Application Hadoop)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                          â”‚
         â”‚ MÃ©tadonnÃ©es                             â”‚ DonnÃ©es
         â†“                                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     NAMENODE       â”‚ â† Heartbeat &     â”‚     DATANODES        â”‚
â”‚   (Master/MaÃ®tre)  â”‚   Block Reports â†’ â”‚   (Slaves/Workers)   â”‚
â”‚                    â”‚                    â”‚                      â”‚
â”‚ - MÃ©tadonnÃ©es      â”‚                    â”‚  DataNode 1          â”‚
â”‚ - Arborescence     â”‚                    â”‚  DataNode 2          â”‚
â”‚ - Localisation     â”‚                    â”‚  DataNode 3          â”‚
â”‚   des blocs        â”‚                    â”‚  DataNode N          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SECONDARY NAMENODE â”‚
â”‚   (Checkpoint)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Composants Principaux

#### ğŸ¯ NameNode (Master)

Le NameNode est le **maÃ®tre** du cluster HDFS. Il gÃ¨re :

- **MÃ©tadonnÃ©es** : Structure de l'arborescence des fichiers et rÃ©pertoires
- **Namespace** : Noms de fichiers, permissions, propriÃ©taires
- **Mapping des blocs** : Quelle partie de fichier est stockÃ©e oÃ¹
- **Heartbeats** : Surveillance de l'Ã©tat des DataNodes
- **RÃ©plication** : DÃ©cisions sur oÃ¹ rÃ©pliquer les blocs

#### Point de DÃ©faillance Unique (SPOF)

Le NameNode est critique ! Si le NameNode tombe en panne, tout le cluster devient inaccessible.
Solution : **High Availability (HA)** avec un NameNode de secours.

#### ğŸ’¾ DataNodes (Slaves)

Les DataNodes sont les **esclaves/workers** qui :

- Stockent physiquement les donnÃ©es sous forme de blocs
- Servent les requÃªtes de lecture et d'Ã©criture des clients
- Envoient des heartbeats au NameNode toutes les 3 secondes
- Envoient des block reports (liste de blocs stockÃ©s) rÃ©guliÃ¨rement
- ExÃ©cutent les instructions du NameNode (rÃ©plication, suppression)

#### ğŸ”„ Secondary NameNode

**Attention :** Ce n'est PAS un NameNode de backup !

Le Secondary NameNode :

- Fusionne pÃ©riodiquement les fichiers FSImage et EditLog
- CrÃ©e des checkpoints pour accÃ©lÃ©rer le redÃ©marrage du NameNode
- RÃ©duit la charge du NameNode principal

*Note : En production, on utilise plutÃ´t la configuration High Availability avec un Standby NameNode.*

## ğŸ§© 3. Blocs et RÃ©plication

### Concept de Blocs

Dans HDFS, les fichiers sont dÃ©coupÃ©s en **blocs** de taille fixe.

| Version Hadoop | Taille de Bloc par DÃ©faut |
| --- | --- |
| Hadoop 1.x | 64 MB |
| Hadoop 2.x et 3.x | 128 MB |

#### Exemple

Un fichier de 300 MB sera dÃ©coupÃ© en :

- Bloc 1 : 128 MB
- Bloc 2 : 128 MB
- Bloc 3 : 44 MB (reste du fichier)

### Pourquoi des Blocs Aussi Gros ?

#### ğŸ“‰ Minimiser les MÃ©tadonnÃ©es

Moins de blocs = moins de mÃ©tadonnÃ©es Ã  gÃ©rer dans le NameNode

#### âš¡ Optimiser le DÃ©bit

Transferts sÃ©quentiels longs = meilleur dÃ©bit rÃ©seau et disque

#### ğŸ” RÃ©duire le Seek Time

Moins de dÃ©placements de la tÃªte de lecture sur le disque

### RÃ©plication des Blocs

Chaque bloc est **rÃ©pliquÃ©** sur plusieurs DataNodes pour assurer la tolÃ©rance aux pannes.
Le facteur de rÃ©plication par dÃ©faut est **3**.

```bash
Fichier original (300 MB)
         â†“
DÃ©coupage en blocs
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Bloc A â”‚ Bloc B â”‚ Bloc C â”‚
â”‚ 128 MB â”‚ 128 MB â”‚ 44 MB  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
RÃ©plication (facteur 3)

Rack 1              Rack 2              Rack 3
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DataNode 1  â”‚    â”‚ DataNode 3  â”‚    â”‚ DataNode 5  â”‚
â”‚ A, B        â”‚    â”‚ A, C        â”‚    â”‚ B, C        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ DataNode 2  â”‚    â”‚ DataNode 4  â”‚    â”‚ DataNode 6  â”‚
â”‚ B, C        â”‚    â”‚ A, B        â”‚    â”‚ A           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### StratÃ©gie de Placement des RÃ©pliques

### ğŸ¯ Politique par DÃ©faut (Rack Awareness)

- **RÃ©plique 1** : Sur le nÅ“ud local (ou alÃ©atoire si Ã©criture depuis l'extÃ©rieur)
- **RÃ©plique 2** : Sur un nÅ“ud d'un rack diffÃ©rent
- **RÃ©plique 3** : Sur un autre nÅ“ud du mÃªme rack que la rÃ©plique 2

**Avantages :** Balance entre fiabilitÃ© (tolÃ©rance aux pannes de rack) et
performance rÃ©seau (2 rÃ©pliques sur le mÃªme rack = moins de bande passante inter-rack).

## âš™ï¸ 4. Lecture et Ã‰criture dans HDFS

### Processus de Lecture

```bash
1. Client demande au NameNode les mÃ©tadonnÃ©es du fichier
   â†“
2. NameNode retourne la liste des blocs et leur localisation
   â†“
3. Client contacte directement les DataNodes pour lire les blocs
   â†“
4. Client reÃ§oit les donnÃ©es et les assemble
```

#### Optimisation

Le client lit toujours depuis le DataNode le plus proche (mÃªme rack, puis mÃªme datacenter).
Cela minimise la latence et la consommation de bande passante rÃ©seau.

### Processus d'Ã‰criture

```bash
1. Client demande au NameNode de crÃ©er un nouveau fichier
   â†“
2. NameNode vÃ©rifie les permissions et crÃ©e l'entrÃ©e
   â†“
3. Client dÃ©coupe le fichier en blocs et demande les DataNodes cibles
   â†“
4. NameNode fournit une liste de DataNodes pour chaque bloc
   â†“
5. Client envoie le premier bloc au premier DataNode
   â†“
6. Le DataNode rÃ©plique automatiquement vers les autres DataNodes (pipeline)
   â†“
7. Une fois tous les blocs Ã©crits et rÃ©pliquÃ©s, le fichier est "fermÃ©"
```

#### Pipeline de RÃ©plication

```bash
Client  â†’  DataNode 1  â†’  DataNode 2  â†’  DataNode 3
                â†“              â†“              â†“
              ACK 1  â†  ACK 2  â†  ACK 3
```

Les donnÃ©es sont envoyÃ©es en pipeline : pendant que DataNode 1 reÃ§oit le bloc, il commence
dÃ©jÃ  Ã  l'envoyer Ã  DataNode 2, qui l'envoie Ã  DataNode 3. C'est trÃ¨s efficace !

## ğŸ’» 5. Commandes HDFS Essentielles

HDFS propose des commandes similaires aux commandes Unix pour manipuler les fichiers.

### Format GÃ©nÃ©ral

```bash
hdfs dfs -<commande> <arguments>
# ou
hadoop fs -<commande> <arguments>
```

### Commandes de Base

| Commande | Description | Exemple |
| --- | --- | --- |
| ls | Lister les fichiers et rÃ©pertoires | `hdfs dfs -ls /user/data` |
| mkdir | CrÃ©er un rÃ©pertoire | `hdfs dfs -mkdir /user/mydir` |
| put | Copier un fichier local vers HDFS | `hdfs dfs -put data.txt /user/data/` |
| get | Copier un fichier HDFS vers local | `hdfs dfs -get /user/data/result.txt .` |
| cat | Afficher le contenu d'un fichier | `hdfs dfs -cat /user/data/log.txt` |
| rm | Supprimer un fichier | `hdfs dfs -rm /user/data/old.txt` |
| rm -r | Supprimer un rÃ©pertoire | `hdfs dfs -rm -r /user/data/olddir` |
| cp | Copier dans HDFS | `hdfs dfs -cp /src/file.txt /dest/` |
| mv | DÃ©placer/renommer dans HDFS | `hdfs dfs -mv /old/path /new/path` |
| du | Taille des fichiers/rÃ©pertoires | `hdfs dfs -du -h /user/data` |
| df | Espace disque disponible | `hdfs dfs -df -h` |

### Commandes AvancÃ©es

| Commande | Description | Exemple |
| --- | --- | --- |
| copyFromLocal | Copier local â†’ HDFS (idem put) | `hdfs dfs -copyFromLocal data.txt /user/` |
| copyToLocal | Copier HDFS â†’ local (idem get) | `hdfs dfs -copyToLocal /user/data.txt .` |
| getmerge | Fusionner plusieurs fichiers HDFS en un seul local | `hdfs dfs -getmerge /user/logs/* output.log` |
| tail | Afficher la fin d'un fichier | `hdfs dfs -tail /user/logs/app.log` |
| chmod | Changer les permissions | `hdfs dfs -chmod 755 /user/data` |
| chown | Changer le propriÃ©taire | `hdfs dfs -chown user:group /user/data` |
| setrep | Modifier le facteur de rÃ©plication | `hdfs dfs -setrep -w 5 /user/important.txt` |
| stat | Afficher les statistiques d'un fichier | `hdfs dfs -stat %r /user/data.txt` |

#### Exercice Pratique : Commandes HDFS

Ã€ faire dans votre environnement Hadoop (vous le configurerez dans la Partie 6) :

1. CrÃ©er un rÃ©pertoire `/user/votrenom/tp1`
2. CrÃ©er un fichier local contenant "Hello Hadoop" et le copier dans HDFS
3. Lister le contenu du rÃ©pertoire dans HDFS
4. Afficher le contenu du fichier depuis HDFS
5. VÃ©rifier le facteur de rÃ©plication du fichier
6. Modifier le facteur de rÃ©plication Ã  5
7. Supprimer le fichier

## ğŸ›¡ï¸ 6. TolÃ©rance aux Pannes

### MÃ©canismes de Protection

#### ğŸ’“ Heartbeats

Les DataNodes envoient des heartbeats au NameNode toutes les 3 secondes. Si pas de heartbeat pendant 10 minutes â†’ DataNode considÃ©rÃ© comme mort.

#### ğŸ”„ RÃ©-rÃ©plication Automatique

Si un DataNode tombe, le NameNode lance automatiquement la rÃ©plication des blocs manquants vers d'autres DataNodes.

#### âœ… Checksums

Chaque bloc est accompagnÃ© d'un checksum CRC-32. Ã€ chaque lecture, le checksum est vÃ©rifiÃ© pour dÃ©tecter la corruption.

#### ğŸ“¸ Snapshots

PossibilitÃ© de crÃ©er des snapshots en lecture seule de l'arborescence HDFS pour la protection des donnÃ©es.

### ScÃ©narios de Panne

| Type de Panne | Impact | RÃ©cupÃ©ration |
| --- | --- | --- |
| Panne d'un DataNode | Faible - DonnÃ©es toujours accessibles via rÃ©pliques | Automatique - RÃ©-rÃ©plication des blocs |
| Panne d'un Rack | Faible - RÃ©pliques sur autres racks | Automatique - RÃ©-rÃ©plication |
| Corruption de Bloc | Faible - Lecture depuis rÃ©plique saine | Automatique - Bloc corrompu supprimÃ© et rÃ©-rÃ©pliquÃ© |
| Panne du NameNode | **Critique** - Cluster inaccessible | Manuelle (sans HA) ou Automatique (avec HA) |

## ğŸ“ RÃ©sumÃ© de la Partie 2

### Points ClÃ©s Ã  Retenir

- HDFS utilise une architecture Master (NameNode) / Slaves (DataNodes)
- Les fichiers sont dÃ©coupÃ©s en blocs de 128 MB (par dÃ©faut)
- Chaque bloc est rÃ©pliquÃ© 3 fois par dÃ©faut pour la tolÃ©rance aux pannes
- Le NameNode gÃ¨re les mÃ©tadonnÃ©es, les DataNodes stockent les donnÃ©es
- Les commandes HDFS sont similaires aux commandes Unix
- HDFS est optimisÃ© pour les gros fichiers et les accÃ¨s sÃ©quentiels
- La rÃ©plication et les checksums assurent la fiabilitÃ© des donnÃ©es

#### âœ… PrÃªt pour la Suite ?

Vous maÃ®trisez maintenant HDFS, le systÃ¨me de stockage de Hadoop. Dans la partie suivante, nous dÃ©couvrirons **MapReduce**, le paradigme de traitement parallÃ¨le des donnÃ©es.