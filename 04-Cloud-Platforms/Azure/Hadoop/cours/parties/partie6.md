## üéØ Objectifs d'Apprentissage

- Comprendre les modes de d√©ploiement Hadoop
- Installer Hadoop en mode Pseudo-distribu√©
- Configurer HDFS et YARN
- D√©marrer et arr√™ter les services Hadoop
- V√©rifier l'installation

## üîß 1. Modes de D√©ploiement

| Mode | Description | Cas d'Usage |
| --- | --- | --- |
| **Standalone** | Processus unique, pas de HDFS ni YARN | D√©veloppement, d√©bogage local |
| **Pseudo-distribu√©** | Tous les d√©mons sur une seule machine | Apprentissage, tests, d√©veloppement |
| **Distribu√©** | Cluster multi-n≈ìuds (production) | Production, environnements r√©els |

#### Pour ce TP

Nous allons installer Hadoop en **mode Pseudo-distribu√©** sur une machine Linux unique.
C'est le meilleur mode pour apprendre car il simule un vrai cluster avec tous les d√©mons Hadoop.

## üìã 2. Pr√©requis

### Environnement Requis

#### üíª Syst√®me d'Exploitation

Linux (Ubuntu, CentOS, Debian) ou macOS

#### ‚òï Java

OpenJDK 8 ou 11 (JDK 8 recommand√© pour Hadoop 3.x)

#### üîë SSH

OpenSSH install√© et configur√©

#### üíæ Ressources

Minimum 4 GB RAM, 20 GB disque

### Installation de Java

```bash
# Ubuntu/Debian
sudo apt update
sudo apt install openjdk-8-jdk -y

# CentOS/RHEL
sudo yum install java-1.8.0-openjdk-devel -y

# V√©rifier l'installation
java -version

# Configurer JAVA_HOME
echo 'export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64' >> ~/.bashrc
echo 'export PATH=$PATH:$JAVA_HOME/bin' >> ~/.bashrc
source ~/.bashrc
```

### Configuration SSH sans mot de passe

```bash
# Installer SSH (si n√©cessaire)
sudo apt install openssh-server openssh-client -y

# G√©n√©rer une cl√© SSH
ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa

# Autoriser la connexion sans mot de passe
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
chmod 0600 ~/.ssh/authorized_keys

# Tester
ssh localhost
# Tapez 'exit' pour quitter
```

## üì• 3. T√©l√©chargement et Installation de Hadoop

### T√©l√©charger Hadoop

```bash
# Aller dans le r√©pertoire home
cd ~

# T√©l√©charger Hadoop 3.3.6 (version stable)
wget https://downloads.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz

# Extraire l'archive
tar -xzvf hadoop-3.3.6.tar.gz

# Renommer pour simplifier
mv hadoop-3.3.6 hadoop

# Supprimer l'archive
rm hadoop-3.3.6.tar.gz
```

### Configurer les Variables d'Environnement

```bash
# Ajouter √† ~/.bashrc
cat >> ~/.bashrc << 'EOF'
# Hadoop Environment Variables
export HADOOP_HOME=$HOME/hadoop
export HADOOP_INSTALL=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"
EOF

# Recharger le fichier
source ~/.bashrc

# V√©rifier
hadoop version
```

## ‚öôÔ∏è 4. Configuration de Hadoop

Les fichiers de configuration se trouvent dans `$HADOOP_HOME/etc/hadoop/`

### 1. hadoop-env.sh

```bash
# √âditer le fichier
nano $HADOOP_HOME/etc/hadoop/hadoop-env.sh

# Ajouter/modifier cette ligne :
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
```

### 2. core-site.xml

```bash
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- URI du syst√®me de fichiers par d√©faut (HDFS NameNode) -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>

    <!-- R√©pertoire temporaire -->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/home/<votreuser>/hadoop_tmp</value>
    </property>
</configuration>
```

#### Important

Remplacez `<votreuser>` par votre nom d'utilisateur Linux.

### 3. hdfs-site.xml

```bash
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- Facteur de r√©plication (1 car une seule machine) -->
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>

    <!-- R√©pertoire du NameNode -->
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/home/<votreuser>/hadoop_data/namenode</value>
    </property>

    <!-- R√©pertoire du DataNode -->
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/home/<votreuser>/hadoop_data/datanode</value>
    </property>
</configuration>
```

### 4. mapred-site.xml

```bash
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <!-- Framework MapReduce utilise YARN -->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>

    <!-- ApplicationMaster pour MapReduce -->
    <property>
        <name>yarn.app.mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
    </property>

    <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
    </property>

    <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
    </property>
</configuration>
```

### 5. yarn-site.xml

```bash
<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <!-- Classe du shuffle handler pour MapReduce -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>

    <!-- ResourceManager hostname -->
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>localhost</value>
    </property>

    <!-- M√©moire disponible pour YARN (ajuster selon vos ressources) -->
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>4096</value>
    </property>

    <!-- VCores disponibles -->
    <property>
        <name>yarn.nodemanager.resource.cpu-vcores</name>
        <value>2</value>
    </property>
</configuration>
```

### Cr√©er les R√©pertoires

```bash
# Cr√©er les r√©pertoires de donn√©es
mkdir -p ~/hadoop_tmp
mkdir -p ~/hadoop_data/namenode
mkdir -p ~/hadoop_data/datanode
```

## üöÄ 5. D√©marrage de Hadoop

### Formater le NameNode

#### ‚ö†Ô∏è Attention

Ne formater qu'√† la **premi√®re installation**. Formater √† nouveau supprime toutes les donn√©es HDFS !

```bash
# Formater le NameNode
hdfs namenode -format

# Vous devriez voir : "Storage directory ... has been successfully formatted."
```

### D√©marrer HDFS

```bash
# D√©marrer NameNode et DataNode
start-dfs.sh

# V√©rifier les processus actifs
jps

# Vous devriez voir :
# - NameNode
# - DataNode
# - SecondaryNameNode
# - Jps
```

### D√©marrer YARN

```bash
# D√©marrer ResourceManager et NodeManager
start-yarn.sh

# V√©rifier avec jps
jps

# Vous devriez maintenant voir en plus :
# - ResourceManager
# - NodeManager
```

### Arr√™ter Hadoop

```bash
# Arr√™ter YARN
stop-yarn.sh

# Arr√™ter HDFS
stop-dfs.sh

# Ou tout arr√™ter d'un coup
stop-all.sh
```

## ‚úÖ 6. V√©rification de l'Installation

### 1. Interfaces Web

| Service | URL | Description |
| --- | --- | --- |
| NameNode | <http://localhost:9870> | Interface HDFS |
| ResourceManager | <http://localhost:8088> | Interface YARN |
| Secondary NameNode | <http://localhost:9868> | Checkpoint NameNode |

### 2. Tests en Ligne de Commande

```bash
# Cr√©er un r√©pertoire dans HDFS
hdfs dfs -mkdir -p /user/$USER

# Cr√©er un fichier de test local
echo "Hello Hadoop World" > test.txt

# Copier le fichier dans HDFS
hdfs dfs -put test.txt /user/$USER/

# Lister les fichiers
hdfs dfs -ls /user/$USER/

# Afficher le contenu
hdfs dfs -cat /user/$USER/test.txt

# Voir l'espace disque HDFS
hdfs dfs -df -h

# Rapport HDFS
hdfs dfsadmin -report
```

### 3. Test avec un Job MapReduce

```bash
# Pr√©parer les donn√©es d'entr√©e
hdfs dfs -mkdir -p /user/$USER/wordcount/input
echo "Hello Hadoop Hello World" > words.txt
echo "Hadoop is powerful" >> words.txt
hdfs dfs -put words.txt /user/$USER/wordcount/input/

# Ex√©cuter l'exemple WordCount fourni avec Hadoop
hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \
    wordcount \
    /user/$USER/wordcount/input \
    /user/$USER/wordcount/output

# Voir les r√©sultats
hdfs dfs -cat /user/$USER/wordcount/output/part-r-00000

# R√©sultat attendu :
# Hadoop  2
# Hello   2
# World   1
# is      1
# powerful 1
```

## üõ†Ô∏è 7. D√©pannage

### Probl√®mes Courants

#### Les d√©mons ne d√©marrent pas

**V√©rifier les logs :**

```bash
# Logs dans $HADOOP_HOME/logs/
tail -f $HADOOP_HOME/logs/hadoop-*-namenode-*.log
```

**Causes fr√©quentes :**

- JAVA\_HOME mal configur√©
- Ports d√©j√† utilis√©s
- SSH sans mot de passe non configur√©
- Permissions incorrectes sur les r√©pertoires

#### DataNode ne se connecte pas au NameNode

**Solutions :**

```bash
# Arr√™ter tout
stop-all.sh

# Nettoyer les donn√©es
rm -rf ~/hadoop_data/*
rm -rf ~/hadoop_tmp/*

# Reformater
hdfs namenode -format

# Red√©marrer
start-dfs.sh
start-yarn.sh
```

#### Commandes Utiles de Diagnostic

```bash
# V√©rifier les processus Java en cours
jps

# Tester la connectivit√© SSH
ssh localhost

# V√©rifier les ports ouverts
netstat -tuln | grep -E '9870|8088|9000'

# Voir la version de Hadoop
hadoop version

# Rapport d√©taill√© HDFS
hdfs dfsadmin -report
```

## üîí 8. Bonnes Pratiques et S√©curit√©

#### üìä Monitoring

- Consulter r√©guli√®rement les UI web
- Surveiller les logs
- V√©rifier l'espace disque HDFS

#### üíæ Backups

- Sauvegarder les donn√©es critiques
- Exporter les m√©tadonn√©es du NameNode
- Documenter la configuration

#### üîê S√©curit√©

- Configurer Kerberos en production
- Utiliser des ACLs HDFS
- S√©curiser les ports avec firewall

#### ‚ö° Performance

- Ajuster la m√©moire YARN
- Optimiser le facteur de r√©plication
- Utiliser la compression

## üìù R√©sum√© de la Partie 6

### Points Cl√©s √† Retenir

- 3 modes de d√©ploiement : Standalone, Pseudo-distribu√©, Distribu√©
- Pr√©requis : Java, SSH, ressources syst√®me suffisantes
- Configuration principale via 5 fichiers XML dans etc/hadoop/
- Formater le NameNode uniquement √† la premi√®re installation
- D√©marrage : start-dfs.sh puis start-yarn.sh
- V√©rification via interfaces web (ports 9870 et 8088) et commandes CLI
- Les logs sont essentiels pour le d√©pannage

#### üéâ F√©licitations !

Vous avez termin√© le cours Hadoop ! Vous √™tes maintenant capable d'installer, configurer et utiliser
un cluster Hadoop. Pour mettre en pratique vos connaissances, passez au **Brief pratique**
qui vous guidera dans la cr√©ation d'un pipeline Big Data complet.