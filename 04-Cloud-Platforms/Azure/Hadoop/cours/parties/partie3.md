## ðŸŽ¯ Objectifs d'Apprentissage

- Comprendre le paradigme de programmation MapReduce
- MaÃ®triser les phases Map, Shuffle et Reduce
- Ã‰crire un job MapReduce en Java
- Optimiser les performances MapReduce

## ðŸ“š 1. Qu'est-ce que MapReduce ?

**MapReduce** est un modÃ¨le de programmation pour traiter et gÃ©nÃ©rer de grands ensembles
de donnÃ©es de maniÃ¨re parallÃ¨le et distribuÃ©e sur un cluster.

#### Principe Fondamental

L'idÃ©e : **"Diviser pour rÃ©gner"** (Divide and Conquer)

- DÃ©couper un gros problÃ¨me en petits problÃ¨mes indÃ©pendants
- Traiter ces petits problÃ¨mes en parallÃ¨le
- Combiner les rÃ©sultats pour obtenir le rÃ©sultat final

### Les Deux Fonctions Principales

#### ðŸ—ºï¸ Map

Traite les donnÃ©es d'entrÃ©e et produit des paires clÃ©-valeur intermÃ©diaires

`map: (K1, V1) â†’ list(K2, V2)`

#### ðŸ”½ Reduce

Regroupe les valeurs par clÃ© et produit le rÃ©sultat final

`reduce: (K2, list(V2)) â†’ list(K3, V3)`

### Exemple Conceptuel : Compter des Mots

```bash
EntrÃ©e :
  "Hello World"
  "Hello Hadoop"
  "Hadoop MapReduce"

Phase MAP :
  Hello â†’ 1
  World â†’ 1
  Hello â†’ 1
  Hadoop â†’ 1
  Hadoop â†’ 1
  MapReduce â†’ 1

Phase SHUFFLE & SORT :
  Hadoop â†’ [1, 1]
  Hello â†’ [1, 1]
  MapReduce â†’ [1]
  World â†’ [1]

Phase REDUCE :
  Hadoop â†’ 2
  Hello â†’ 2
  MapReduce â†’ 1
  World â†’ 1
```

## ðŸ”„ 2. Architecture et Flux d'ExÃ©cution

### Vue d'Ensemble

```bash
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      HDFS INPUT DATA                            â”‚
â”‚        Fichiers dÃ©coupÃ©s en blocs (splits)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     MAP PHASE                                   â”‚
â”‚  Mapper 1   Mapper 2   Mapper 3   Mapper N                     â”‚
â”‚  (K1,V1)    (K1,V1)    (K1,V1)    (K1,V1)                      â”‚
â”‚    â†“          â†“          â†“          â†“                           â”‚
â”‚  (K2,V2)    (K2,V2)    (K2,V2)    (K2,V2)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SHUFFLE & SORT PHASE                               â”‚
â”‚    Regroupement et tri des paires par clÃ©                       â”‚
â”‚         (K2, list(V2))                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     REDUCE PHASE                                â”‚
â”‚  Reducer 1  Reducer 2  Reducer 3  Reducer M                    â”‚
â”‚  (K2,[V2])  (K2,[V2])  (K2,[V2])  (K2,[V2])                    â”‚
â”‚    â†“          â†“          â†“          â†“                           â”‚
â”‚  (K3,V3)    (K3,V3)    (K3,V3)    (K3,V3)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HDFS OUTPUT DATA                             â”‚
â”‚              RÃ©sultats finaux stockÃ©s                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Les Phases en DÃ©tail

#### 1ï¸âƒ£ Input Splits

Les donnÃ©es d'entrÃ©e sont divisÃ©es en **splits** (morceaux) logiques.

- Par dÃ©faut, 1 split = 1 bloc HDFS (128 MB)
- Chaque split est traitÃ© par un mapper
- Les mappers s'exÃ©cutent lÃ  oÃ¹ les donnÃ©es sont stockÃ©es (data locality)

#### 2ï¸âƒ£ Map Phase

Chaque mapper traite un split de donnÃ©es :

- Lit les donnÃ©es ligne par ligne (ou enregistrement par enregistrement)
- Applique la fonction `map()` dÃ©finie par l'utilisateur
- Ã‰met des paires clÃ©-valeur intermÃ©diaires
- Les rÃ©sultats sont Ã©crits dans un buffer en mÃ©moire

#### 3ï¸âƒ£ Shuffle & Sort Phase

Phase critique gÃ©rÃ©e automatiquement par Hadoop :

- **Partitioning** : Les paires (K2,V2) sont partitionnÃ©es par clÃ© vers les reducers
- **Sorting** : Les clÃ©s sont triÃ©es
- **Grouping** : Les valeurs avec la mÃªme clÃ© sont regroupÃ©es
- **Transfer** : Les donnÃ©es sont transfÃ©rÃ©es via le rÃ©seau vers les reducers

*Cette phase consomme beaucoup de ressources rÃ©seau et disque.*

#### 4ï¸âƒ£ Reduce Phase

Chaque reducer traite un ensemble de clÃ©s :

- ReÃ§oit les paires (K2, list(V2)) triÃ©es
- Applique la fonction `reduce()` dÃ©finie par l'utilisateur
- Ã‰met les paires clÃ©-valeur finales (K3, V3)
- Ã‰crit les rÃ©sultats dans HDFS

## ðŸ’» 3. WordCount : L'Exemple Classique avec Python

Le "Hello World" de MapReduce : compter les occurrences de chaque mot dans un corpus de texte.

#### Hadoop Streaming

**Hadoop Streaming** permet d'Ã©crire des jobs MapReduce en Python (ou tout autre langage).
Les scripts lisent depuis stdin et Ã©crivent vers stdout.

### Code Python Complet

#### mapper.py

```bash
#!/usr/bin/env python3
"""
Mapper pour WordCount
Lit les lignes depuis stdin, dÃ©coupe en mots et Ã©met (mot, 1)
"""
import sys

def main():
# Lire depuis stdin
    for line in sys.stdin:
# Supprimer les espaces en dÃ©but/fin
        line = line.strip()

# DÃ©couper la ligne en mots
        words = line.split()

# Ã‰mettre (mot, 1) pour chaque mot
        for word in words:
# Format: clÃ©\tvaleur
            print(f"{word}\t1")

if __name__ == "__main__":
    main()
```

#### reducer.py

```bash
#!/usr/bin/env python3
"""
Reducer pour WordCount
ReÃ§oit les paires (mot, 1) triÃ©es par clÃ© et calcule la somme
"""
import sys

def main():
    current_word = None
    current_count = 0

# Lire depuis stdin
    for line in sys.stdin:
# Supprimer les espaces
        line = line.strip()

# Parser la ligne (format: mot\t1)
        try:
            word, count = line.split('\t')
            count = int(count)
        except ValueError:
# Ignorer les lignes mal formÃ©es
            continue

# Hadoop trie les clÃ©s, donc les mÃªmes mots sont consÃ©cutifs
        if current_word == word:
            current_count += count
        else:
# Nouveau mot rencontrÃ©
            if current_word:
# Ã‰mettre le rÃ©sultat pour le mot prÃ©cÃ©dent
                print(f"{current_word}\t{current_count}")

            current_word = word
            current_count = count

# Ã‰mettre le dernier mot
    if current_word:
        print(f"{current_word}\t{current_count}")

if __name__ == "__main__":
    main()
```

### Test Local (avant Hadoop)

```bash
# Rendre les scripts exÃ©cutables
chmod +x mapper.py reducer.py

# Test du mapper seul
echo "Hello World Hello Hadoop" | ./mapper.py

# Sortie attendue:
# Hello   1
# World   1
# Hello   1
# Hadoop  1

# Test complet avec tri (simule Hadoop)
echo "Hello World Hello Hadoop" | ./mapper.py | sort -k1,1 | ./reducer.py

# Sortie attendue:
# Hadoop  1
# Hello   2
# World   1
```

### ExÃ©cution sur Hadoop

#### PrÃ©parer les DonnÃ©es

```bash
# CrÃ©er un fichier de test
cat > input.txt << EOF
Hello World Hello Hadoop
Hadoop is powerful
Python and Hadoop
EOF

# CrÃ©er le rÃ©pertoire dans HDFS
hdfs dfs -mkdir -p /user/$USER/wordcount/input

# Copier le fichier dans HDFS
hdfs dfs -put input.txt /user/$USER/wordcount/input/

# VÃ©rifier
hdfs dfs -cat /user/$USER/wordcount/input/input.txt
```

#### Lancer le Job MapReduce avec Hadoop Streaming

```bash
# ExÃ©cuter le job Hadoop Streaming
hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \
    -input /user/$USER/wordcount/input \
    -output /user/$USER/wordcount/output \
    -mapper mapper.py \
    -reducer reducer.py \
    -file mapper.py \
    -file reducer.py

# Voir les rÃ©sultats
hdfs dfs -cat /user/$USER/wordcount/output/part-00000

# RÃ©sultat attendu :
# Hadoop  3
# Hello   2
# Python  1
# World   1
# and     1
# is      1
# powerful 1
```

#### Avantages de Python avec Hadoop

- âœ… Code plus simple et lisible que Java
- âœ… Pas de compilation nÃ©cessaire
- âœ… Riche Ã©cosystÃ¨me de librairies Python
- âœ… Test facile en local avant Hadoop
- âœ… IdÃ©al pour le prototypage rapide

## âš¡ 4. Optimisations MapReduce

### Combiner

#### Qu'est-ce qu'un Combiner ?

Un **Combiner** est comme un "mini-reducer" qui s'exÃ©cute localement sur chaque mapper
pour rÃ©duire la quantitÃ© de donnÃ©es transfÃ©rÃ©es durant la phase Shuffle.

```bash
// Dans le Driver
job.setCombinerClass(WordCountReducer.class);
```

**Avantage :** Pour WordCount, au lieu de transfÃ©rer ["Hello"â†’1, "Hello"â†’1, "Hello"â†’1],
on transfÃ¨re juste ["Hello"â†’3].

### Partitioner PersonnalisÃ©

Le **Partitioner** dÃ©cide quel reducer recevra quelle clÃ©.
Par dÃ©faut : `HashPartitioner` utilise le hashcode de la clÃ©.

```bash
public class CustomPartitioner extends Partitioner<Text, IntWritable> {
    @Override
    public int getPartition(Text key, IntWritable value, int numPartitions) {
        // Exemple : mots commenÃ§ant par A-M â†’ Reducer 0
        //           mots commenÃ§ant par N-Z â†’ Reducer 1
        char firstLetter = key.toString().charAt(0);
        if (firstLetter >= 'A' && firstLetter <= 'M') {
            return 0 % numPartitions;
        } else {
            return 1 % numPartitions;
        }
    }
}
```

### Compression

Compresser les donnÃ©es intermÃ©diaires et de sortie rÃ©duit l'utilisation disque et rÃ©seau.

```bash
// Compression des donnÃ©es intermÃ©diaires (Map output)
conf.setBoolean("mapreduce.map.output.compress", true);
conf.setClass("mapreduce.map.output.compress.codec",
              SnappyCodec.class, CompressionCodec.class);

// Compression de la sortie finale
FileOutputFormat.setCompressOutput(job, true);
FileOutputFormat.setOutputCompressorClass(job, GzipCodec.class);
```

### Autres Optimisations

| Technique | Description | Impact |
| --- | --- | --- |
| **Augmenter le nombre de reducers** | Plus de reducers = plus de parallÃ©lisme | âš¡ Performance accrue si le cluster le permet |
| **RÃ©utiliser la JVM** | Ã‰viter le coÃ»t de dÃ©marrage de JVM pour chaque tÃ¢che | â±ï¸ RÃ©duction du temps de lancement |
| **ExÃ©cution spÃ©culative** | Relancer les tÃ¢ches lentes sur d'autres nÅ“uds | ðŸš€ RÃ©duit l'impact des "stragglers" |
| **Buffer d'Ã©criture Map** | Augmenter `mapreduce.task.io.sort.mb` | ðŸ’¾ Moins de spills sur disque |

## ðŸ“Š 5. Patterns MapReduce Courants

### 1. Filtering (Filtrage)

Garder seulement les enregistrements qui rÃ©pondent Ã  un critÃ¨re.

**Exemple :** Filtrer les logs d'erreur

- Map : Si ligne contient "ERROR" â†’ Ã©mettre
- Reduce : Peut Ãªtre omis (identity reducer)

### 2. Summarization (AgrÃ©gation)

Calculer des statistiques agrÃ©gÃ©es (count, sum, avg, min, max).

**Exemple :** Statistiques par utilisateur

- Map : (user\_id, metric) â†’ Ã©mettre
- Reduce : Calculer somme, moyenne, etc.

### 3. Joining (Jointure)

Joindre deux datasets sur une clÃ© commune.

**Reduce-side join :**

- Map : Ã‰mettre (clÃ©\_commune, valeur\_avec\_tag)
- Reduce : Regrouper et joindre les valeurs avec la mÃªme clÃ©

### 4. Sorting (Tri)

Trier des donnÃ©es Ã  grande Ã©chelle.

- Map : Ã‰mettre (clÃ©\_de\_tri, enregistrement)
- Reduce : Peut Ãªtre identity (le tri est fait durant Shuffle)

### 5. Top N

Trouver les N premiers Ã©lÃ©ments.

- Map : Garder top N localement, Ã©mettre
- Reduce : Fusionner et garder top N global

## âš ï¸ 6. Limites de MapReduce

#### ðŸŒ Latence Ã‰levÃ©e

Pas adaptÃ© au temps rÃ©el. Temps de dÃ©marrage et I/O disque importants.

#### ðŸ’¾ I/O Intensif

Ã‰crit et lit beaucoup sur disque (HDFS), pas en mÃ©moire.

#### ðŸ”— Jobs ChaÃ®nÃ©s Complexes

Difficile de chaÃ®ner plusieurs jobs MapReduce efficacement.

#### ðŸ“ˆ Pas AdaptÃ© aux Graphes

Algorithmes itÃ©ratifs (ML, graphes) sont inefficaces.

#### Alternative : Apache Spark

**Spark** a Ã©tÃ© crÃ©Ã© pour pallier les limites de MapReduce :

- Traitement en mÃ©moire (100x plus rapide)
- API plus simple et expressive
- Support natif du streaming, ML, graphes
- Compatible avec HDFS et YARN

*Cependant, MapReduce reste utilisÃ© pour certains cas d'usage batch intensifs.*

## ðŸ“ RÃ©sumÃ© de la Partie 3

### Points ClÃ©s Ã  Retenir

- MapReduce suit le paradigme "Diviser pour rÃ©gner"
- 3 phases principales : Map, Shuffle & Sort, Reduce
- WordCount est l'exemple canonique de MapReduce
- Les Combiners rÃ©duisent le trafic rÃ©seau
- La compression amÃ©liore les performances
- MapReduce est excellent pour le batch mais pas pour le temps rÃ©el
- Spark est souvent prÃ©fÃ©rÃ© pour les nouveaux projets

#### âœ… PrÃªt pour la Suite ?

Vous maÃ®trisez maintenant MapReduce ! Dans la partie suivante, nous dÃ©couvrirons **YARN**, le gestionnaire de ressources qui orchestre l'exÃ©cution des applications Hadoop.