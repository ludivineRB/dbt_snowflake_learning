## ğŸ¯ Objectifs de la Formation

- Comprendre l'architecture et les composants de l'Ã©cosystÃ¨me Hadoop
- MaÃ®triser HDFS pour le stockage distribuÃ© de donnÃ©es
- Utiliser MapReduce pour le traitement parallÃ¨le
- DÃ©couvrir YARN et la gestion des ressources
- Manipuler les outils de l'Ã©cosystÃ¨me Hadoop (Hive, Pig, HBase)
- Installer et configurer un cluster Hadoop

## ğŸ“š Programme de la Formation

### Jour 1 : Fondamentaux Hadoop

**â±ï¸ DurÃ©e :** 7 heures

#### ğŸ”¹ Partie 1 : Introduction Ã  Hadoop (1h30)

- Qu'est-ce que le Big Data ?
- Historique et origine de Hadoop
- Architecture gÃ©nÃ©rale de Hadoop
- Les 3 V du Big Data
- Cas d'usage et entreprises utilisatrices

[Commencer la Partie 1 â†’](parties/partie1.md)

#### ğŸ”¹ Partie 2 : Architecture HDFS (2h)

- Principes du systÃ¨me de fichiers distribuÃ©
- Architecture NameNode / DataNode
- RÃ©plication et tolÃ©rance aux pannes
- Commandes HDFS essentielles
- TP : Manipulation de fichiers dans HDFS

[Commencer la Partie 2 â†’](parties/partie2.md)

#### ğŸ”¹ Partie 3 : MapReduce (3h30)

- Paradigme de programmation MapReduce
- Phases Map, Shuffle et Reduce
- Ã‰criture de jobs MapReduce en Python avec Hadoop Streaming
- Optimisation des performances
- TP : CrÃ©er un job WordCount en Python

[Commencer la Partie 3 â†’](parties/partie3.md)

### Jour 2 : Ã‰cosystÃ¨me et Pratique

**â±ï¸ DurÃ©e :** 7 heures

#### ğŸ”¹ Partie 4 : YARN - Yet Another Resource Negotiator (1h30)

- Architecture de YARN
- ResourceManager et NodeManager
- Gestion des applications et des conteneurs
- Scheduling et allocation de ressources
- Monitoring avec YARN UI

[Commencer la Partie 4 â†’](parties/partie4.md)

#### ğŸ”¹ Partie 5 : Ã‰cosystÃ¨me Hadoop (3h)

- Apache Hive : SQL sur Hadoop
- Apache Pig : Langage de scripting
- Apache HBase : Base de donnÃ©es NoSQL
- Apache Sqoop : Import/Export de donnÃ©es
- Apache Flume : Collecte de logs
- TP : RequÃªtes Hive et scripts Pig

[Commencer la Partie 5 â†’](parties/partie5.md)

#### ğŸ”¹ Partie 6 : Installation et Configuration (2h30)

- Modes de dÃ©ploiement (Standalone, Pseudo-distribuÃ©, DistribuÃ©)
- Installation d'Hadoop sur Linux
- Configuration des fichiers core-site.xml, hdfs-site.xml
- Configuration de YARN
- SÃ©curitÃ© et bonnes pratiques
- TP : Installer un cluster Hadoop

[Commencer la Partie 6 â†’](parties/partie6.md)

### Jour 3 : Cloud et Pratique AvancÃ©e

**â±ï¸ DurÃ©e :** 6h30

#### ğŸ”¹ Partie 7 : DÃ©ploiement Hadoop sur Azure (2h30)

- Introduction Ã  Azure HDInsight
- CrÃ©ation d'un cluster Hadoop sur Azure pas Ã  pas
- Configuration du stockage Azure pour HDFS
- ExÃ©cution de jobs MapReduce sur Azure
- Monitoring et gestion du cluster
- TP : DÃ©ployer et utiliser Hadoop sur Azure

[Commencer la Partie 7 â†’](parties/partie7.md)

#### ğŸ”¹ Partie 8 : Exercices Pratiques GuidÃ©s (4h)

- Exercice 1 : Manipulation avancÃ©e HDFS
- Exercice 2 : Job MapReduce - Analyse de logs
- Exercice 3 : Analyse avec Hive (requÃªtes SQL)
- Exercice 4 : Job MapReduce avancÃ© - Top N
- Exercice 5 : DÃ©pannage et rÃ©solution de problÃ¨mes
- TP : Pratique pas Ã  pas complÃ¨te

[Commencer la Partie 8 â†’](parties/partie8.md)

## ğŸ’¼ Public Cible

#### ğŸ‘¨â€ğŸ’» Data Engineers

DÃ©veloppez vos compÃ©tences en traitement distribuÃ© de donnÃ©es massives

#### ğŸ“Š Data Analysts

Comprenez l'infrastructure qui alimente vos analyses Big Data

#### ğŸ—ï¸ Architectes Data

Concevez des solutions Big Data scalables et performantes

#### âš™ï¸ DevOps

MaÃ®trisez le dÃ©ploiement et la maintenance de clusters Hadoop

## ğŸ”§ PrÃ©requis

#### Connaissances requises

- Bases de Linux et ligne de commande
- Notions de programmation Python (recommandÃ©)
- ComprÃ©hension des concepts de bases de donnÃ©es
- Connaissance de base en SQL (pour la partie Hive)

#### Configuration matÃ©rielle recommandÃ©e

- 8 Go de RAM minimum (16 Go recommandÃ©)
- 20 Go d'espace disque libre
- Processeur multi-cÅ“urs
- VM ou environnement Linux

## ğŸ“– MÃ©thodologie PÃ©dagogique

### ğŸ“ Approche Pratique

- 40% thÃ©orie / 60% pratique
- Travaux pratiques guidÃ©s aprÃ¨s chaque partie
- Projet fil rouge : Pipeline de traitement de donnÃ©es
- Exercices inspirÃ©s de cas rÃ©els d'entreprise
- Documentation et ressources complÃ©mentaires

## ğŸ¯ Ã‰valuation

| Type d'Ã©valuation | Format | Coefficient |
| --- | --- | --- |
| Travaux pratiques | Exercices tout au long de la formation | 40% |
| Projet final | Brief pratique - Pipeline Big Data complet | 60% |

## ğŸš€ Pour Commencer

#### Avant de dÃ©buter

Assurez-vous d'avoir accÃ¨s Ã  un environnement Linux (VM, WSL, ou Linux natif) pour les travaux pratiques. Un guide d'installation sera fourni dans la Partie 6.

[### ğŸ¬ Commencer la Formation

Partie 1 : Introduction Ã  Hadoop et au Big Data

Commencer â†’](parties/partie1.md)