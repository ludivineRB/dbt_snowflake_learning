{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¥ Avanc√© | ‚è± 60 min | üîë Concepts : merge, pivot, apply, window functions, MultiIndex\n",
    "\n",
    "# Pandas Avanc√© : Transformations et Optimisations\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "√Ä la fin de ce notebook, vous serez capable de :\n",
    "- Fusionner plusieurs DataFrames (merge, join, concat)\n",
    "- Pivoter et remodeler les donn√©es\n",
    "- Appliquer des fonctions personnalis√©es\n",
    "- Utiliser les window functions (rolling, expanding, ewm)\n",
    "- Manipuler les MultiIndex\n",
    "- G√©rer les valeurs manquantes\n",
    "- Optimiser la m√©moire et les performances\n",
    "\n",
    "## Pr√©requis\n",
    "\n",
    "- Pandas bases (Series, DataFrame, groupby)\n",
    "- NumPy\n",
    "- Compr√©hension des concepts de bases de donn√©es (jointures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Pandas version : {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fil Rouge : Dataset E-commerce + Clients\n",
    "\n",
    "Nous r√©utilisons le dataset de ventes et ajoutons une table clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset des commandes (comme pr√©c√©demment)\n",
    "np.random.seed(42)\n",
    "\n",
    "data_orders = {\n",
    "    \"order_id\": range(1, 101),\n",
    "    \"date\": pd.date_range(\"2024-01-01\", periods=100, freq=\"D\"),\n",
    "    \"product\": [\"Laptop\", \"Phone\", \"Tablet\", \"Headphones\", \"Monitor\"] * 20,\n",
    "    \"category\": [\"Electronics\", \"Electronics\", \"Electronics\", \"Audio\", \"Electronics\"] * 20,\n",
    "    \"quantity\": [1, 2, 1, 3, 1, 2, 1, 4, 1, 2] * 10,\n",
    "    \"unit_price\": [999.99, 699.99, 449.99, 79.99, 349.99] * 20,\n",
    "    \"customer_id\": [f\"C{i:03d}\" for i in range(1, 101)],\n",
    "    \"city\": [\"Paris\", \"Lyon\", \"Marseille\", \"Toulouse\", \"Bordeaux\"] * 20,\n",
    "}\n",
    "\n",
    "df_orders = pd.DataFrame(data_orders)\n",
    "df_orders[\"total\"] = df_orders[\"quantity\"] * df_orders[\"unit_price\"]\n",
    "\n",
    "# Nouveau : table clients\n",
    "rng = np.random.default_rng(42)\n",
    "data_customers = {\n",
    "    \"customer_id\": [f\"C{i:03d}\" for i in range(1, 121)],  # Plus de clients que de commandes\n",
    "    \"name\": [f\"Client {i}\" for i in range(1, 121)],\n",
    "    \"email\": [f\"client{i}@example.com\" for i in range(1, 121)],\n",
    "    \"signup_date\": pd.date_range(\"2023-01-01\", periods=120, freq=\"3D\"),\n",
    "    \"segment\": rng.choice([\"Premium\", \"Standard\", \"Basic\"], size=120, p=[0.2, 0.5, 0.3]),\n",
    "    \"country\": [\"France\"] * 120,\n",
    "}\n",
    "\n",
    "df_customers = pd.DataFrame(data_customers)\n",
    "\n",
    "print(\"Orders:\", df_orders.shape)\n",
    "print(\"Customers:\", df_customers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Merge : Fusionner des DataFrames\n",
    "\n",
    "Les jointures, comme en SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INNER JOIN : uniquement les lignes pr√©sentes dans les deux tables\n",
    "df_inner = pd.merge(df_orders, df_customers, on='customer_id', how='inner')\n",
    "print(f\"Inner join: {df_inner.shape}\")\n",
    "print(df_inner.head())\n",
    "\n",
    "# LEFT JOIN : toutes les lignes de gauche, correspondances de droite\n",
    "df_left = pd.merge(df_orders, df_customers, on='customer_id', how='left')\n",
    "print(f\"\\nLeft join: {df_left.shape}\")\n",
    "\n",
    "# RIGHT JOIN : toutes les lignes de droite, correspondances de gauche\n",
    "df_right = pd.merge(df_orders, df_customers, on='customer_id', how='right')\n",
    "print(f\"Right join: {df_right.shape}\")\n",
    "print(f\"Clients sans commande: {df_right['order_id'].isna().sum()}\")\n",
    "\n",
    "# OUTER JOIN : toutes les lignes des deux tables\n",
    "df_outer = pd.merge(df_orders, df_customers, on='customer_id', how='outer')\n",
    "print(f\"\\nOuter join: {df_outer.shape}\")\n",
    "\n",
    "# Merge avec noms de colonnes diff√©rents\n",
    "df_customers_renamed = df_customers.rename(columns={'customer_id': 'cust_id'})\n",
    "df_merge_diff = pd.merge(\n",
    "    df_orders, \n",
    "    df_customers_renamed, \n",
    "    left_on='customer_id', \n",
    "    right_on='cust_id'\n",
    ")\n",
    "print(f\"\\nMerge avec colonnes diff√©rentes: {df_merge_diff.shape}\")\n",
    "\n",
    "# Merge sur plusieurs colonnes\n",
    "# (exemple fictif)\n",
    "df_orders_copy = df_orders.copy()\n",
    "df_orders_copy['country'] = 'France'\n",
    "df_multi = pd.merge(\n",
    "    df_orders_copy, \n",
    "    df_customers, \n",
    "    on=['customer_id', 'country']\n",
    ")\n",
    "print(f\"\\nMerge multi-colonnes: {df_multi.shape}\")\n",
    "\n",
    "# Suffixes pour les colonnes en conflit\n",
    "df_merge_suffix = pd.merge(\n",
    "    df_orders, \n",
    "    df_customers, \n",
    "    on='customer_id',\n",
    "    suffixes=('_order', '_customer')\n",
    ")\n",
    "print(f\"\\nColonnes apr√®s merge:\")\n",
    "print(df_merge_suffix.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Concat : Empiler des DataFrames\n",
    "\n",
    "Combiner des DataFrames verticalement ou horizontalement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er des sous-ensembles\n",
    "df1 = df_orders.iloc[:30]\n",
    "df2 = df_orders.iloc[30:60]\n",
    "df3 = df_orders.iloc[60:]\n",
    "\n",
    "# Concat vertical (empiler)\n",
    "df_concat = pd.concat([df1, df2, df3], axis=0)\n",
    "print(f\"Concat vertical: {df_concat.shape}\")\n",
    "print(f\"Index: {df_concat.index.tolist()[:10]}...\")\n",
    "\n",
    "# Reset index apr√®s concat\n",
    "df_concat_reset = pd.concat([df1, df2, df3], axis=0, ignore_index=True)\n",
    "print(f\"\\nAvec ignore_index: {df_concat_reset.index.tolist()[:10]}...\")\n",
    "\n",
    "# Concat horizontal (joindre c√¥te √† c√¥te)\n",
    "df_left = df_orders[['order_id', 'product', 'total']].head()\n",
    "df_right = df_orders[['customer_id', 'city']].head()\n",
    "df_concat_h = pd.concat([df_left, df_right], axis=1)\n",
    "print(f\"\\nConcat horizontal:\")\n",
    "print(df_concat_h)\n",
    "\n",
    "# Concat avec keys (MultiIndex)\n",
    "df_with_keys = pd.concat(\n",
    "    [df1, df2, df3], \n",
    "    keys=['Q1', 'Q2', 'Q3'],\n",
    "    names=['quarter', 'row']\n",
    ")\n",
    "print(f\"\\nAvec keys (MultiIndex):\")\n",
    "print(df_with_keys.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pivot Table : Tableaux Crois√©s Dynamiques\n",
    "\n",
    "R√©organiser les donn√©es pour l'analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot simple : produit x ville\n",
    "pivot = df_orders.pivot_table(\n",
    "    values='total',\n",
    "    index='product',\n",
    "    columns='city',\n",
    "    aggfunc='sum'\n",
    ")\n",
    "print(\"Ventes par produit et ville:\")\n",
    "print(pivot)\n",
    "\n",
    "# Avec plusieurs agr√©gations\n",
    "pivot_multi = df_orders.pivot_table(\n",
    "    values='total',\n",
    "    index='product',\n",
    "    columns='city',\n",
    "    aggfunc=['sum', 'mean', 'count']\n",
    ")\n",
    "print(\"\\nPlusieurs agr√©gations:\")\n",
    "print(pivot_multi)\n",
    "\n",
    "# Avec marges (totaux)\n",
    "pivot_margins = df_orders.pivot_table(\n",
    "    values='total',\n",
    "    index='product',\n",
    "    columns='city',\n",
    "    aggfunc='sum',\n",
    "    margins=True,\n",
    "    margins_name='TOTAL'\n",
    ")\n",
    "print(\"\\nAvec marges:\")\n",
    "print(pivot_margins)\n",
    "\n",
    "# Pivot avec dates (agr√©gation temporelle)\n",
    "df_orders['month'] = df_orders['date'].dt.to_period('M')\n",
    "pivot_time = df_orders.pivot_table(\n",
    "    values='total',\n",
    "    index='month',\n",
    "    columns='product',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "print(\"\\nVentes mensuelles par produit:\")\n",
    "print(pivot_time.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Melt : Inverse du Pivot (Wide ‚Üí Long)\n",
    "\n",
    "Transformer un format large en format long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er un DataFrame large\n",
    "df_wide = df_orders.pivot_table(\n",
    "    values='total',\n",
    "    index='order_id',\n",
    "    columns='product',\n",
    "    aggfunc='sum'\n",
    ").reset_index().head(10)\n",
    "\n",
    "print(\"Format wide:\")\n",
    "print(df_wide)\n",
    "\n",
    "# Melt : wide ‚Üí long\n",
    "df_long = df_wide.melt(\n",
    "    id_vars='order_id',\n",
    "    var_name='product',\n",
    "    value_name='total'\n",
    ")\n",
    "print(\"\\nFormat long (apr√®s melt):\")\n",
    "print(df_long.head(15))\n",
    "\n",
    "# Supprimer les valeurs NaN\n",
    "df_long_clean = df_long.dropna()\n",
    "print(f\"\\nApr√®s nettoyage: {len(df_long)} ‚Üí {len(df_long_clean)} lignes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Apply : Appliquer des Fonctions\n",
    "\n",
    "Appliquer une fonction √† chaque √©l√©ment, ligne ou colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply() sur une Series\n",
    "def categorize_price(price):\n",
    "    if price < 100:\n",
    "        return 'Low'\n",
    "    elif price < 500:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "df_orders['price_category'] = df_orders['unit_price'].apply(categorize_price)\n",
    "print(\"Cat√©gories de prix:\")\n",
    "print(df_orders[['product', 'unit_price', 'price_category']].head())\n",
    "\n",
    "# apply() avec lambda\n",
    "df_orders['total_rounded'] = df_orders['total'].apply(lambda x: round(x, 0))\n",
    "print(\"\\nTotaux arrondis:\")\n",
    "print(df_orders[['total', 'total_rounded']].head())\n",
    "\n",
    "# apply() sur DataFrame (par ligne)\n",
    "def calculate_discount(row):\n",
    "    if row['total'] > 1000:\n",
    "        return row['total'] * 0.1\n",
    "    return 0\n",
    "\n",
    "df_orders['discount'] = df_orders.apply(calculate_discount, axis=1)\n",
    "print(\"\\nRemises calcul√©es:\")\n",
    "print(df_orders[df_orders['discount'] > 0][['order_id', 'total', 'discount']].head())\n",
    "\n",
    "# apply() sur colonnes (axis=0)\n",
    "numeric_cols = ['quantity', 'unit_price', 'total']\n",
    "stats = df_orders[numeric_cols].apply(np.mean)\n",
    "print(\"\\nMoyennes par colonne:\")\n",
    "print(stats)\n",
    "\n",
    "# ATTENTION : apply() peut √™tre lent\n",
    "# Pr√©f√©rer les op√©rations vectoris√©es quand possible\n",
    "print(\"\\n‚ö†Ô∏è Performance:\")\n",
    "print(\"apply() est pratique mais peut √™tre lent sur de gros DataFrames\")\n",
    "print(\"Pr√©f√©rer les op√©rations vectoris√©es (np.where, masques bool√©ens, etc.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Map et Replace\n",
    "\n",
    "Remplacer des valeurs de mani√®re efficace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map() : remplacer selon un dictionnaire\n",
    "city_mapping = {\n",
    "    'Paris': 'IDF',\n",
    "    'Lyon': 'ARA',\n",
    "    'Marseille': 'PACA',\n",
    "    'Toulouse': 'OCC',\n",
    "    'Bordeaux': 'NAQ'\n",
    "}\n",
    "\n",
    "df_orders['region'] = df_orders['city'].map(city_mapping)\n",
    "print(\"Mapping ville ‚Üí r√©gion:\")\n",
    "print(df_orders[['city', 'region']].head())\n",
    "\n",
    "# map() avec fonction\n",
    "df_orders['product_upper'] = df_orders['product'].map(str.upper)\n",
    "print(\"\\nProduits en majuscules:\")\n",
    "print(df_orders[['product', 'product_upper']].head())\n",
    "\n",
    "# replace() : remplacement simple\n",
    "df_test = df_orders.copy()\n",
    "df_test['category'] = df_test['category'].replace('Electronics', 'Tech')\n",
    "print(\"\\nApr√®s replace:\")\n",
    "print(df_test['category'].value_counts())\n",
    "\n",
    "# replace() avec dictionnaire\n",
    "df_test['category'] = df_test['category'].replace({\n",
    "    'Tech': 'Technology',\n",
    "    'Audio': 'Sound'\n",
    "})\n",
    "print(\"\\nApr√®s replace multiple:\")\n",
    "print(df_test['category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Window Functions : Rolling, Expanding, EWM\n",
    "\n",
    "Calculs sur des fen√™tres glissantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©parer les donn√©es : ventes quotidiennes\n",
    "daily_sales = df_orders.groupby('date')['total'].sum().reset_index()\n",
    "daily_sales = daily_sales.sort_values('date')\n",
    "\n",
    "print(\"Ventes quotidiennes:\")\n",
    "print(daily_sales.head(10))\n",
    "\n",
    "# Rolling : moyenne mobile sur 7 jours\n",
    "daily_sales['rolling_7d'] = daily_sales['total'].rolling(window=7).mean()\n",
    "print(\"\\nAvec moyenne mobile 7j:\")\n",
    "print(daily_sales.head(10))\n",
    "\n",
    "# Rolling avec min_periods\n",
    "daily_sales['rolling_7d_min3'] = daily_sales['total'].rolling(\n",
    "    window=7, \n",
    "    min_periods=3\n",
    ").mean()\n",
    "print(\"\\nAvec min_periods=3:\")\n",
    "print(daily_sales.head(10))\n",
    "\n",
    "# Autres agr√©gations rolling\n",
    "daily_sales['rolling_max'] = daily_sales['total'].rolling(window=7).max()\n",
    "daily_sales['rolling_std'] = daily_sales['total'].rolling(window=7).std()\n",
    "\n",
    "print(\"\\nStatistiques rolling:\")\n",
    "print(daily_sales[['date', 'total', 'rolling_7d', 'rolling_max', 'rolling_std']].tail(10))\n",
    "\n",
    "# Expanding : moyenne cumulative\n",
    "daily_sales['expanding_mean'] = daily_sales['total'].expanding().mean()\n",
    "print(\"\\nMoyenne cumulative:\")\n",
    "print(daily_sales[['date', 'total', 'expanding_mean']].head(10))\n",
    "\n",
    "# EWM : moyenne mobile exponentielle\n",
    "daily_sales['ewm'] = daily_sales['total'].ewm(span=7).mean()\n",
    "print(\"\\nMoyenne mobile exponentielle:\")\n",
    "print(daily_sales[['date', 'total', 'rolling_7d', 'ewm']].tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. MultiIndex : Index Hi√©rarchiques\n",
    "\n",
    "Organiser les donn√©es avec plusieurs niveaux d'index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er un MultiIndex avec groupby\n",
    "df_multi = df_orders.groupby(['city', 'product'])['total'].agg(['sum', 'mean', 'count'])\n",
    "print(\"DataFrame avec MultiIndex:\")\n",
    "print(df_multi)\n",
    "print(f\"\\nType d'index: {type(df_multi.index)}\")\n",
    "print(f\"Niveaux: {df_multi.index.names}\")\n",
    "\n",
    "# Acc√®s avec MultiIndex\n",
    "print(\"\\nVentes √† Paris:\")\n",
    "print(df_multi.loc['Paris'])\n",
    "\n",
    "print(\"\\nLaptops √† Paris:\")\n",
    "print(df_multi.loc[('Paris', 'Laptop')])\n",
    "\n",
    "# S√©lection avec slice\n",
    "print(\"\\nParis et Lyon:\")\n",
    "print(df_multi.loc[['Paris', 'Lyon']])\n",
    "\n",
    "# reset_index : transformer l'index en colonnes\n",
    "df_flat = df_multi.reset_index()\n",
    "print(\"\\nApr√®s reset_index:\")\n",
    "print(df_flat.head())\n",
    "\n",
    "# set_index : cr√©er un MultiIndex\n",
    "df_multi_again = df_flat.set_index(['city', 'product'])\n",
    "print(\"\\nRecr√©√© avec set_index:\")\n",
    "print(df_multi_again.head())\n",
    "\n",
    "# Tri d'un MultiIndex\n",
    "df_multi_sorted = df_multi.sort_index(level=[0, 1])\n",
    "print(\"\\nTri√©:\")\n",
    "print(df_multi_sorted.head(10))\n",
    "\n",
    "# Op√©rations sur niveaux\n",
    "print(\"\\nSomme par ville (level=0):\")\n",
    "print(df_multi.sum(level=0))\n",
    "\n",
    "print(\"\\nSomme par produit (level=1):\")\n",
    "print(df_multi.sum(level=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Gestion des Valeurs Manquantes\n",
    "\n",
    "D√©tecter, supprimer et imputer les valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er des valeurs manquantes\n",
    "df_na = df_orders.copy()\n",
    "df_na.loc[5:10, 'quantity'] = np.nan\n",
    "df_na.loc[15:20, 'city'] = np.nan\n",
    "df_na.loc[25, 'total'] = np.nan\n",
    "\n",
    "# D√©tecter les valeurs manquantes\n",
    "print(\"Valeurs manquantes par colonne:\")\n",
    "print(df_na.isna().sum())\n",
    "\n",
    "print(\"\\nPourcentage de valeurs manquantes:\")\n",
    "print((df_na.isna().sum() / len(df_na) * 100).round(2))\n",
    "\n",
    "# Lignes avec au moins une valeur manquante\n",
    "print(f\"\\nLignes avec NaN: {df_na.isna().any(axis=1).sum()}\")\n",
    "\n",
    "# Lignes compl√®tes (sans NaN)\n",
    "print(f\"Lignes compl√®tes: {df_na.notna().all(axis=1).sum()}\")\n",
    "\n",
    "# dropna() : supprimer les lignes/colonnes avec NaN\n",
    "df_dropped_rows = df_na.dropna()\n",
    "print(f\"\\nApr√®s dropna(): {len(df_na)} ‚Üí {len(df_dropped_rows)} lignes\")\n",
    "\n",
    "df_dropped_cols = df_na.dropna(axis=1)\n",
    "print(f\"Colonnes conserv√©es: {df_dropped_cols.columns.tolist()}\")\n",
    "\n",
    "# dropna() avec seuil\n",
    "df_dropped_thresh = df_na.dropna(thresh=8)  # au moins 8 valeurs non-NaN\n",
    "print(f\"\\nAvec thresh=8: {len(df_na)} ‚Üí {len(df_dropped_thresh)} lignes\")\n",
    "\n",
    "# fillna() : imputer les valeurs manquantes\n",
    "df_filled = df_na.copy()\n",
    "df_filled['quantity'] = df_filled['quantity'].fillna(0)\n",
    "df_filled['city'] = df_filled['city'].fillna('Unknown')\n",
    "print(\"\\nApr√®s fillna:\")\n",
    "print(df_filled.isna().sum())\n",
    "\n",
    "# Imputation par la moyenne/m√©diane\n",
    "df_filled['total'] = df_filled['total'].fillna(df_filled['total'].median())\n",
    "print(\"\\nApr√®s imputation par la m√©diane:\")\n",
    "print(df_filled.isna().sum())\n",
    "\n",
    "# Forward fill et backward fill\n",
    "df_ff = df_na.copy()\n",
    "df_ff['city'] = df_ff['city'].fillna(method='ffill')  # propager en avant\n",
    "print(\"\\nForward fill:\")\n",
    "print(df_ff.loc[13:23, ['order_id', 'city']])\n",
    "\n",
    "df_bf = df_na.copy()\n",
    "df_bf['city'] = df_bf['city'].fillna(method='bfill')  # propager en arri√®re\n",
    "print(\"\\nBackward fill:\")\n",
    "print(df_bf.loc[13:23, ['order_id', 'city']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Gestion des Dates\n",
    "\n",
    "Manipulation puissante des dates avec Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion en datetime\n",
    "df_dates = pd.DataFrame({\n",
    "    'date_str': ['2024-01-01', '2024-02-15', '2024-03-30'],\n",
    "    'value': [100, 200, 300]\n",
    "})\n",
    "\n",
    "df_dates['date'] = pd.to_datetime(df_dates['date_str'])\n",
    "print(\"Conversion en datetime:\")\n",
    "print(df_dates.dtypes)\n",
    "\n",
    "# dt accessor : extraire des composants\n",
    "df_orders['year'] = df_orders['date'].dt.year\n",
    "df_orders['month'] = df_orders['date'].dt.month\n",
    "df_orders['day'] = df_orders['date'].dt.day\n",
    "df_orders['dayofweek'] = df_orders['date'].dt.dayofweek  # 0=lundi\n",
    "df_orders['dayname'] = df_orders['date'].dt.day_name()\n",
    "df_orders['quarter'] = df_orders['date'].dt.quarter\n",
    "\n",
    "print(\"\\nComposants de date:\")\n",
    "print(df_orders[['date', 'year', 'month', 'day', 'dayname', 'quarter']].head())\n",
    "\n",
    "# Calculs avec dates\n",
    "df_orders['days_since_start'] = (df_orders['date'] - df_orders['date'].min()).dt.days\n",
    "print(\"\\nJours depuis le d√©but:\")\n",
    "print(df_orders[['date', 'days_since_start']].head())\n",
    "\n",
    "# Resample : agr√©gation temporelle\n",
    "df_resampled = df_orders.set_index('date').resample('W')['total'].sum()\n",
    "print(\"\\nVentes hebdomadaires:\")\n",
    "print(df_resampled.head())\n",
    "\n",
    "# Resample avec plusieurs agr√©gations\n",
    "df_resampled_multi = df_orders.set_index('date').resample('M').agg({\n",
    "    'total': 'sum',\n",
    "    'quantity': 'sum',\n",
    "    'order_id': 'count'\n",
    "})\n",
    "print(\"\\nVentes mensuelles:\")\n",
    "print(df_resampled_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Optimisation M√©moire\n",
    "\n",
    "R√©duire l'empreinte m√©moire des DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher l'usage m√©moire\n",
    "print(\"Usage m√©moire par colonne:\")\n",
    "print(df_orders.memory_usage(deep=True))\n",
    "print(f\"\\nTotal: {df_orders.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "\n",
    "# Optimiser les types num√©riques\n",
    "df_optimized = df_orders.copy()\n",
    "\n",
    "# int64 ‚Üí int32 (si les valeurs le permettent)\n",
    "df_optimized['order_id'] = df_optimized['order_id'].astype('int32')\n",
    "df_optimized['quantity'] = df_optimized['quantity'].astype('int8')\n",
    "\n",
    "# float64 ‚Üí float32\n",
    "df_optimized['unit_price'] = df_optimized['unit_price'].astype('float32')\n",
    "df_optimized['total'] = df_optimized['total'].astype('float32')\n",
    "\n",
    "print(\"\\nApr√®s optimisation num√©rique:\")\n",
    "print(df_optimized.memory_usage(deep=True))\n",
    "print(f\"Total: {df_optimized.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "\n",
    "# category dtype pour les colonnes r√©p√©titives\n",
    "df_optimized['product'] = df_optimized['product'].astype('category')\n",
    "df_optimized['category'] = df_optimized['category'].astype('category')\n",
    "df_optimized['city'] = df_optimized['city'].astype('category')\n",
    "\n",
    "print(\"\\nApr√®s conversion en category:\")\n",
    "print(df_optimized.memory_usage(deep=True))\n",
    "print(f\"Total: {df_optimized.memory_usage(deep=True).sum() / 1024:.2f} KB\")\n",
    "\n",
    "# Comparaison\n",
    "before = df_orders.memory_usage(deep=True).sum() / 1024\n",
    "after = df_optimized.memory_usage(deep=True).sum() / 1024\n",
    "print(f\"\\nR√©duction: {before:.2f} KB ‚Üí {after:.2f} KB ({(1 - after/before)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Pi√®ges Courants\n",
    "\n",
    "### Pi√®ge 1 : Apply() Lent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Cr√©er un DataFrame de test\n",
    "df_test = pd.DataFrame({\n",
    "    'value': range(100000)\n",
    "})\n",
    "\n",
    "# ‚ùå Avec apply()\n",
    "start = time.time()\n",
    "df_test['squared_apply'] = df_test['value'].apply(lambda x: x ** 2)\n",
    "time_apply = time.time() - start\n",
    "\n",
    "# ‚úÖ Avec op√©ration vectoris√©e\n",
    "start = time.time()\n",
    "df_test['squared_vectorized'] = df_test['value'] ** 2\n",
    "time_vectorized = time.time() - start\n",
    "\n",
    "print(f\"apply(): {time_apply:.4f}s\")\n",
    "print(f\"vectorized: {time_vectorized:.4f}s\")\n",
    "print(f\"Speedup: {time_apply/time_vectorized:.1f}x\")\n",
    "print(\"\\n‚úÖ Pr√©f√©rer les op√©rations vectoris√©es !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pi√®ge 2 : Oublier copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå Sans copy()\n",
    "df_original = pd.DataFrame({'A': [1, 2, 3]})\n",
    "df_reference = df_original  # r√©f√©rence, pas copie\n",
    "df_reference.loc[0, 'A'] = 999\n",
    "\n",
    "print(\"‚ùå Sans copy():\")\n",
    "print(\"Original:\", df_original['A'].tolist())\n",
    "print(\"L'original a √©t√© modifi√© !\\n\")\n",
    "\n",
    "# ‚úÖ Avec copy()\n",
    "df_original = pd.DataFrame({'A': [1, 2, 3]})\n",
    "df_copy = df_original.copy()\n",
    "df_copy.loc[0, 'A'] = 999\n",
    "\n",
    "print(\"‚úÖ Avec copy():\")\n",
    "print(\"Original:\", df_original['A'].tolist())\n",
    "print(\"Copie:\", df_copy['A'].tolist())\n",
    "print(\"L'original est intact !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pi√®ge 3 : inplace Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå inplace=True (deprecated dans de nombreuses fonctions)\n",
    "# df.dropna(inplace=True)  # √Ä √©viter\n",
    "\n",
    "# ‚úÖ R√©assignation\n",
    "df_clean = df_na.dropna()\n",
    "# ou\n",
    "df_na = df_na.dropna()\n",
    "\n",
    "print(\"‚úÖ Utiliser la r√©assignation au lieu de inplace\")\n",
    "print(\"Plus clair et compatible avec le cha√Ænage de m√©thodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Mini-Exercices\n",
    "\n",
    "### Exercice 1 : Merge avec Table Clients\n",
    "\n",
    "1. Faites un left join entre `df_orders` et `df_customers`\n",
    "2. Calculez le nombre de commandes par segment de client (Premium, Standard, Basic)\n",
    "3. Calculez le chiffre d'affaires moyen par segment\n",
    "4. Identifiez les clients qui n'ont pass√© aucune commande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2 : Pivot des Ventes par Mois/Produit\n",
    "\n",
    "1. Cr√©ez un pivot table montrant les ventes totales par mois (lignes) et produit (colonnes)\n",
    "2. Ajoutez les totaux (marges)\n",
    "3. Identifiez le mois avec les meilleures ventes pour chaque produit\n",
    "4. Calculez la croissance mensuelle pour chaque produit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 3 : Rolling Average\n",
    "\n",
    "1. Calculez les ventes quotidiennes totales\n",
    "2. Ajoutez une moyenne mobile sur 7 jours\n",
    "3. Ajoutez une moyenne mobile sur 30 jours\n",
    "4. Identifiez les jours o√π les ventes sont sup√©rieures √† la moyenne mobile 7j\n",
    "5. Calculez l'√©cart-type mobile sur 7 jours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Solutions des Exercices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Exercice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Left join\n",
    "df_merged = pd.merge(df_orders, df_customers, on='customer_id', how='left')\n",
    "print(\"1. Apr√®s merge:\", df_merged.shape)\n",
    "\n",
    "# 2. Commandes par segment\n",
    "commandes_par_segment = df_merged.groupby('segment')['order_id'].count()\n",
    "print(\"\\n2. Commandes par segment:\")\n",
    "print(commandes_par_segment)\n",
    "\n",
    "# 3. CA moyen par segment\n",
    "ca_par_segment = df_merged.groupby('segment')['total'].mean()\n",
    "print(\"\\n3. CA moyen par segment:\")\n",
    "print(ca_par_segment)\n",
    "\n",
    "# 4. Clients sans commande\n",
    "df_all_customers = pd.merge(df_customers, df_orders, on='customer_id', how='left')\n",
    "clients_sans_commande = df_all_customers[df_all_customers['order_id'].isna()]\n",
    "print(f\"\\n4. Clients sans commande: {clients_sans_commande['customer_id'].nunique()}\")\n",
    "print(clients_sans_commande[['customer_id', 'name', 'segment']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Exercice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©parer les donn√©es avec mois\n",
    "df_with_month = df_orders.copy()\n",
    "df_with_month['month'] = df_with_month['date'].dt.to_period('M')\n",
    "\n",
    "# 1. Pivot table\n",
    "pivot_monthly = df_with_month.pivot_table(\n",
    "    values='total',\n",
    "    index='month',\n",
    "    columns='product',\n",
    "    aggfunc='sum',\n",
    "    margins=True,  # 2. Avec marges\n",
    "    margins_name='TOTAL'\n",
    ")\n",
    "print(\"1-2. Pivot avec marges:\")\n",
    "print(pivot_monthly)\n",
    "\n",
    "# 3. Meilleur mois par produit\n",
    "print(\"\\n3. Meilleur mois par produit:\")\n",
    "for product in pivot_monthly.columns[:-1]:  # Exclure TOTAL\n",
    "    best_month = pivot_monthly[product].idxmax()\n",
    "    best_value = pivot_monthly[product].max()\n",
    "    print(f\"{product}: {best_month} ({best_value:.2f}‚Ç¨)\")\n",
    "\n",
    "# 4. Croissance mensuelle\n",
    "pivot_growth = pivot_monthly.drop('TOTAL').pct_change() * 100\n",
    "print(\"\\n4. Croissance mensuelle (%)\")\n",
    "print(pivot_growth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Exercice 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ventes quotidiennes\n",
    "daily = df_orders.groupby('date')['total'].sum().reset_index()\n",
    "daily = daily.sort_values('date')\n",
    "\n",
    "# 2-3. Moyennes mobiles\n",
    "daily['ma_7d'] = daily['total'].rolling(window=7, min_periods=1).mean()\n",
    "daily['ma_30d'] = daily['total'].rolling(window=30, min_periods=1).mean()\n",
    "\n",
    "print(\"1-3. Ventes avec moyennes mobiles:\")\n",
    "print(daily.tail(10))\n",
    "\n",
    "# 4. Jours au-dessus de MA 7j\n",
    "daily['above_ma'] = daily['total'] > daily['ma_7d']\n",
    "nb_above = daily['above_ma'].sum()\n",
    "print(f\"\\n4. Jours au-dessus de MA 7j: {nb_above} ({nb_above/len(daily)*100:.1f}%)\")\n",
    "\n",
    "# 5. √âcart-type mobile\n",
    "daily['std_7d'] = daily['total'].rolling(window=7, min_periods=1).std()\n",
    "\n",
    "print(\"\\n5. Avec √©cart-type mobile:\")\n",
    "print(daily[['date', 'total', 'ma_7d', 'std_7d']].tail(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
