{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercices : Data Engineering avec Python\n",
    "\n",
    "ðŸ”´ **Avance** | â± **2h** | ðŸ“š **Sections validees : 06-Data-Engineering**\n",
    "\n",
    "## Objectifs\n",
    "- Manipuler des donnees avec Pandas\n",
    "- Valider des donnees avec Pydantic\n",
    "- Creer des pipelines de transformation\n",
    "- Utiliser DuckDB pour des requetes SQL\n",
    "- Exporter en format Parquet\n",
    "\n",
    "## Projet : Analyse de Donnees E-commerce\n",
    "Vous allez travailler avec un dataset de commandes e-commerce et creer un pipeline complet de traitement de donnees.\n",
    "\n",
    "## Sections couvertes\n",
    "1. Exploration avec Pandas (1 exercice)\n",
    "2. Agregations et transformations (1 exercice)\n",
    "3. Validation avec Pydantic (1 exercice)\n",
    "4. Pipeline complet (1 exercice)\n",
    "5. Analyse avec DuckDB (1 exercice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Preparation : Creation du Dataset\n",
    "\n",
    "Creez le dataset de demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Seed pour la reproductibilite\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generer 100 commandes sur 100 jours\n",
    "data = {\n",
    "    \"order_id\": range(1, 101),\n",
    "    \"date\": [datetime(2024, 1, 1) + timedelta(days=i) for i in range(100)],\n",
    "    \"product\": [\"Laptop\", \"Phone\", \"Tablet\", \"Headphones\", \"Monitor\"] * 20,\n",
    "    \"category\": [\"Electronics\", \"Electronics\", \"Electronics\", \"Audio\", \"Electronics\"] * 20,\n",
    "    \"quantity\": [1, 2, 1, 3, 1, 2, 1, 4, 1, 2] * 10,\n",
    "    \"unit_price\": [999.99, 699.99, 449.99, 79.99, 349.99] * 20,\n",
    "    \"customer_id\": [f\"C{i:03d}\" for i in range(1, 101)],\n",
    "    \"city\": [\"Paris\", \"Lyon\", \"Marseille\", \"Toulouse\", \"Bordeaux\"] * 20,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df[\"total\"] = df[\"quantity\"] * df[\"unit_price\"]\n",
    "\n",
    "# Ajouter quelques valeurs manquantes et aberrantes pour le realisme\n",
    "df.loc[5, 'city'] = None\n",
    "df.loc[10, 'quantity'] = -1  # Valeur aberrante\n",
    "df.loc[15, 'unit_price'] = 0  # Prix invalide\n",
    "\n",
    "print(f\"Dataset cree : {len(df)} commandes\")\n",
    "print(f\"Periode : {df['date'].min()} a {df['date'].max()}\")\n",
    "print(f\"\\nApercu :\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercice 1 : Exploration avec Pandas (FACILE)\n",
    "\n",
    "Explorez le dataset et repondez aux questions suivantes :\n",
    "\n",
    "1. Combien de commandes au total ?\n",
    "2. Quelles sont les colonnes et leurs types ?\n",
    "3. Y a-t-il des valeurs manquantes ?\n",
    "4. Statistiques descriptives sur les colonnes numeriques\n",
    "5. Filtrer les commandes avec un total > 1000 EUR\n",
    "6. Trier par date decroissante\n",
    "\n",
    "Utilisez : `info()`, `describe()`, `isnull()`, `sum()`, `query()`, `sort_values()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "print(\"=== EXPLORATION DU DATASET ===\")\n",
    "\n",
    "# 1. Nombre de commandes\n",
    "print(f\"\\n1. Nombre de commandes : {len(df)}\")\n",
    "\n",
    "# 2. Colonnes et types\n",
    "print(\"\\n2. Informations sur les colonnes :\")\n",
    "print(df.info())\n",
    "\n",
    "# 3. Valeurs manquantes\n",
    "print(\"\\n3. Valeurs manquantes :\")\n",
    "valeurs_manquantes = df.isnull().sum()\n",
    "print(valeurs_manquantes[valeurs_manquantes > 0])\n",
    "\n",
    "# 4. Statistiques descriptives\n",
    "print(\"\\n4. Statistiques descriptives :\")\n",
    "print(df.describe())\n",
    "\n",
    "# Statistiques supplementaires\n",
    "print(\"\\nChiffre d'affaires total :\", f\"{df['total'].sum():,.2f} EUR\")\n",
    "print(\"Panier moyen :\", f\"{df['total'].mean():.2f} EUR\")\n",
    "print(\"Panier median :\", f\"{df['total'].median():.2f} EUR\")\n",
    "\n",
    "# 5. Filtrer les commandes > 1000 EUR\n",
    "print(\"\\n5. Commandes > 1000 EUR :\")\n",
    "commandes_importantes = df[df['total'] > 1000]\n",
    "print(f\"Nombre : {len(commandes_importantes)}\")\n",
    "print(commandes_importantes[['order_id', 'product', 'quantity', 'total']].head())\n",
    "\n",
    "# Alternative avec query\n",
    "commandes_importantes_v2 = df.query('total > 1000')\n",
    "print(f\"\\nVerification avec query() : {len(commandes_importantes_v2)} commandes\")\n",
    "\n",
    "# 6. Trier par date decroissante\n",
    "print(\"\\n6. Dernieres commandes (triees par date) :\")\n",
    "df_trie = df.sort_values('date', ascending=False)\n",
    "print(df_trie[['order_id', 'date', 'product', 'total']].head())\n",
    "\n",
    "# Analyses supplementaires\n",
    "print(\"\\n=== ANALYSES SUPPLEMENTAIRES ===\")\n",
    "\n",
    "# Repartition par produit\n",
    "print(\"\\nNombre de commandes par produit :\")\n",
    "print(df['product'].value_counts())\n",
    "\n",
    "# Repartition par ville\n",
    "print(\"\\nNombre de commandes par ville :\")\n",
    "print(df['city'].value_counts())\n",
    "\n",
    "# Top 5 des plus grosses commandes\n",
    "print(\"\\nTop 5 des plus grosses commandes :\")\n",
    "print(df.nlargest(5, 'total')[['order_id', 'product', 'quantity', 'total']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercice 2 : Agregations et Transformations (MOYEN)\n",
    "\n",
    "Creez les analyses suivantes avec `groupby()` et agregations :\n",
    "\n",
    "1. **CA par produit** : Chiffre d'affaires total par produit\n",
    "2. **CA par ville** : Chiffre d'affaires total par ville\n",
    "3. **CA par mois** : Extraire le mois de la date et calculer le CA mensuel\n",
    "4. **Quantites moyennes** : Quantite moyenne commandee par produit\n",
    "5. **Analyse croisee** : CA par produit et par ville (pivot table)\n",
    "6. **Top 3 produits** : Les 3 produits les plus vendus par ville\n",
    "\n",
    "Bonus : Visualisez avec matplotlib ou plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "print(\"=== AGREGATIONS ET TRANSFORMATIONS ===\")\n",
    "\n",
    "# 1. CA par produit\n",
    "print(\"\\n1. CA par produit :\")\n",
    "ca_par_produit = df.groupby('product')['total'].sum().sort_values(ascending=False)\n",
    "print(ca_par_produit)\n",
    "print(f\"\\nProduit le plus vendu : {ca_par_produit.index[0]} ({ca_par_produit.iloc[0]:,.2f} EUR)\")\n",
    "\n",
    "# 2. CA par ville\n",
    "print(\"\\n2. CA par ville :\")\n",
    "ca_par_ville = df.groupby('city')['total'].sum().sort_values(ascending=False)\n",
    "print(ca_par_ville)\n",
    "\n",
    "# 3. CA par mois\n",
    "print(\"\\n3. CA par mois :\")\n",
    "df['mois'] = df['date'].dt.to_period('M')\n",
    "ca_par_mois = df.groupby('mois')['total'].sum()\n",
    "print(ca_par_mois)\n",
    "\n",
    "# Calculer la croissance mensuelle\n",
    "print(\"\\nCroissance mensuelle :\")\n",
    "croissance = ca_par_mois.pct_change() * 100\n",
    "print(croissance)\n",
    "\n",
    "# 4. Quantites moyennes par produit\n",
    "print(\"\\n4. Quantites moyennes par produit :\")\n",
    "qty_moyenne = df.groupby('product')['quantity'].agg(['mean', 'sum', 'count'])\n",
    "qty_moyenne.columns = ['Quantite_moyenne', 'Quantite_totale', 'Nb_commandes']\n",
    "print(qty_moyenne)\n",
    "\n",
    "# 5. Analyse croisee : CA par produit et ville\n",
    "print(\"\\n5. CA par produit et ville (pivot table) :\")\n",
    "pivot = df.pivot_table(\n",
    "    values='total',\n",
    "    index='product',\n",
    "    columns='city',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "print(pivot)\n",
    "print(\"\\nTotal par ligne (produit) :\")\n",
    "pivot['TOTAL'] = pivot.sum(axis=1)\n",
    "print(pivot.sort_values('TOTAL', ascending=False))\n",
    "\n",
    "# 6. Top 3 produits par ville\n",
    "print(\"\\n6. Top 3 produits par ville :\")\n",
    "top3_par_ville = (\n",
    "    df.groupby(['city', 'product'])['total']\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    "    .groupby(level=0)\n",
    "    .head(3)\n",
    ")\n",
    "print(top3_par_ville)\n",
    "\n",
    "# Analyses supplementaires\n",
    "print(\"\\n=== ANALYSES SUPPLEMENTAIRES ===\")\n",
    "\n",
    "# Statistiques par categorie\n",
    "print(\"\\nStatistiques par categorie :\")\n",
    "stats_categorie = df.groupby('category').agg({\n",
    "    'total': ['sum', 'mean', 'count'],\n",
    "    'quantity': 'sum'\n",
    "})\n",
    "print(stats_categorie)\n",
    "\n",
    "# Distribution des paniers\n",
    "print(\"\\nDistribution des montants de commandes :\")\n",
    "print(df['total'].describe(percentiles=[.25, .5, .75, .9, .95, .99]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercice 3 : Validation avec Pydantic (MOYEN)\n",
    "\n",
    "Creez un modele Pydantic `Order` pour valider les donnees de commandes :\n",
    "\n",
    "**Modele Order :**\n",
    "- `order_id` : int > 0\n",
    "- `date` : datetime\n",
    "- `product` : str non vide\n",
    "- `category` : str (doit etre dans ['Electronics', 'Audio', 'Accessories'])\n",
    "- `quantity` : int > 0\n",
    "- `unit_price` : float > 0\n",
    "- `customer_id` : str (format \"Cxxx\")\n",
    "- `city` : str non vide\n",
    "- `total` : float (calcule automatiquement)\n",
    "\n",
    "**Validateurs :**\n",
    "- Valider le format du customer_id\n",
    "- Calculer automatiquement le total\n",
    "- Verifier que la date n'est pas dans le futur\n",
    "\n",
    "Testez avec des donnees valides et invalides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "from pydantic import BaseModel, Field, field_validator, model_validator\n",
    "from datetime import datetime\n",
    "from typing import Literal\n",
    "import re\n",
    "\n",
    "class Order(BaseModel):\n",
    "    \"\"\"Modele Pydantic pour une commande e-commerce\"\"\"\n",
    "    \n",
    "    order_id: int = Field(gt=0, description=\"ID de la commande\")\n",
    "    date: datetime\n",
    "    product: str = Field(min_length=1, description=\"Nom du produit\")\n",
    "    category: Literal['Electronics', 'Audio', 'Accessories']\n",
    "    quantity: int = Field(gt=0, description=\"Quantite commandee\")\n",
    "    unit_price: float = Field(gt=0, description=\"Prix unitaire\")\n",
    "    customer_id: str = Field(pattern=r'^C\\d{3}$', description=\"ID client (format Cxxx)\")\n",
    "    city: str = Field(min_length=1, description=\"Ville de livraison\")\n",
    "    total: float = Field(default=0, description=\"Montant total (calcule auto)\")\n",
    "    \n",
    "    @field_validator('date')\n",
    "    @classmethod\n",
    "    def valider_date(cls, v):\n",
    "        \"\"\"Verifie que la date n'est pas dans le futur\"\"\"\n",
    "        if v > datetime.now():\n",
    "            raise ValueError(\"La date ne peut pas etre dans le futur\")\n",
    "        return v\n",
    "    \n",
    "    @field_validator('product')\n",
    "    @classmethod\n",
    "    def valider_product(cls, v):\n",
    "        \"\"\"Nettoie et valide le nom du produit\"\"\"\n",
    "        v = v.strip()\n",
    "        if not v:\n",
    "            raise ValueError(\"Le nom du produit ne peut pas etre vide\")\n",
    "        return v\n",
    "    \n",
    "    @model_validator(mode='after')\n",
    "    def calculer_total(self):\n",
    "        \"\"\"Calcule automatiquement le total\"\"\"\n",
    "        self.total = round(self.quantity * self.unit_price, 2)\n",
    "        return self\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"order_id\": 1,\n",
    "                \"date\": \"2024-01-15T10:30:00\",\n",
    "                \"product\": \"Laptop\",\n",
    "                \"category\": \"Electronics\",\n",
    "                \"quantity\": 2,\n",
    "                \"unit_price\": 999.99,\n",
    "                \"customer_id\": \"C001\",\n",
    "                \"city\": \"Paris\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"=== VALIDATION AVEC PYDANTIC ===\")\n",
    "\n",
    "# Test 1 : Commande valide\n",
    "print(\"\\n1. Commande valide :\")\n",
    "try:\n",
    "    order1 = Order(\n",
    "        order_id=1,\n",
    "        date=datetime(2024, 1, 15, 10, 30),\n",
    "        product=\"Laptop\",\n",
    "        category=\"Electronics\",\n",
    "        quantity=2,\n",
    "        unit_price=999.99,\n",
    "        customer_id=\"C001\",\n",
    "        city=\"Paris\"\n",
    "    )\n",
    "    print(f\"OK : {order1}\")\n",
    "    print(f\"Total calcule : {order1.total} EUR\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur : {e}\")\n",
    "\n",
    "# Test 2 : order_id negatif\n",
    "print(\"\\n2. order_id negatif (erreur attendue) :\")\n",
    "try:\n",
    "    order2 = Order(\n",
    "        order_id=-1,\n",
    "        date=datetime(2024, 1, 15),\n",
    "        product=\"Phone\",\n",
    "        category=\"Electronics\",\n",
    "        quantity=1,\n",
    "        unit_price=699.99,\n",
    "        customer_id=\"C002\",\n",
    "        city=\"Lyon\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Erreur attrapee : {e}\")\n",
    "\n",
    "# Test 3 : Quantite nulle\n",
    "print(\"\\n3. Quantite nulle (erreur attendue) :\")\n",
    "try:\n",
    "    order3 = Order(\n",
    "        order_id=3,\n",
    "        date=datetime(2024, 1, 15),\n",
    "        product=\"Tablet\",\n",
    "        category=\"Electronics\",\n",
    "        quantity=0,\n",
    "        unit_price=449.99,\n",
    "        customer_id=\"C003\",\n",
    "        city=\"Marseille\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Erreur attrapee : {e}\")\n",
    "\n",
    "# Test 4 : customer_id invalide\n",
    "print(\"\\n4. customer_id invalide (erreur attendue) :\")\n",
    "try:\n",
    "    order4 = Order(\n",
    "        order_id=4,\n",
    "        date=datetime(2024, 1, 15),\n",
    "        product=\"Headphones\",\n",
    "        category=\"Audio\",\n",
    "        quantity=1,\n",
    "        unit_price=79.99,\n",
    "        customer_id=\"INVALID\",  # Format invalide\n",
    "        city=\"Toulouse\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Erreur attrapee : {e}\")\n",
    "\n",
    "# Test 5 : Date future\n",
    "print(\"\\n5. Date dans le futur (erreur attendue) :\")\n",
    "try:\n",
    "    order5 = Order(\n",
    "        order_id=5,\n",
    "        date=datetime(2030, 1, 1),\n",
    "        product=\"Monitor\",\n",
    "        category=\"Electronics\",\n",
    "        quantity=1,\n",
    "        unit_price=349.99,\n",
    "        customer_id=\"C005\",\n",
    "        city=\"Bordeaux\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Erreur attrapee : {e}\")\n",
    "\n",
    "# Test 6 : Categorie invalide\n",
    "print(\"\\n6. Categorie invalide (erreur attendue) :\")\n",
    "try:\n",
    "    order6 = Order(\n",
    "        order_id=6,\n",
    "        date=datetime(2024, 1, 15),\n",
    "        product=\"Book\",\n",
    "        category=\"Books\",  # Pas dans les categories autorisees\n",
    "        quantity=1,\n",
    "        unit_price=19.99,\n",
    "        customer_id=\"C006\",\n",
    "        city=\"Nice\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Erreur attrapee : {e}\")\n",
    "\n",
    "# Test 7 : Validation d'un batch\n",
    "print(\"\\n7. Validation d'un batch de commandes :\")\n",
    "commandes_test = [\n",
    "    {\"order_id\": 10, \"date\": datetime(2024, 1, 20), \"product\": \"Laptop\", \"category\": \"Electronics\",\n",
    "     \"quantity\": 1, \"unit_price\": 999.99, \"customer_id\": \"C010\", \"city\": \"Paris\"},\n",
    "    {\"order_id\": 11, \"date\": datetime(2024, 1, 21), \"product\": \"Phone\", \"category\": \"Electronics\",\n",
    "     \"quantity\": 2, \"unit_price\": 699.99, \"customer_id\": \"C011\", \"city\": \"Lyon\"},\n",
    "    {\"order_id\": -1, \"date\": datetime(2024, 1, 22), \"product\": \"Invalid\", \"category\": \"Electronics\",\n",
    "     \"quantity\": 1, \"unit_price\": 100, \"customer_id\": \"C012\", \"city\": \"Nice\"},  # Invalide\n",
    "]\n",
    "\n",
    "valides = []\n",
    "invalides = []\n",
    "\n",
    "for cmd_data in commandes_test:\n",
    "    try:\n",
    "        order = Order(**cmd_data)\n",
    "        valides.append(order)\n",
    "    except Exception as e:\n",
    "        invalides.append((cmd_data['order_id'], str(e)))\n",
    "\n",
    "print(f\"Commandes valides : {len(valides)}\")\n",
    "print(f\"Commandes invalides : {len(invalides)}\")\n",
    "if invalides:\n",
    "    print(\"\\nErreurs :\")\n",
    "    for order_id, error in invalides:\n",
    "        print(f\"  Order {order_id} : {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercice 4 : Pipeline Complet (DIFFICILE)\n",
    "\n",
    "Creez un pipeline ETL complet :\n",
    "\n",
    "**Extract :**\n",
    "1. Charger le CSV dans Pandas\n",
    "\n",
    "**Transform :**\n",
    "2. Nettoyer les donnees :\n",
    "   - Supprimer les valeurs manquantes\n",
    "   - Corriger les valeurs aberrantes (quantity < 0, price <= 0)\n",
    "   - Normaliser les villes (capitalize)\n",
    "3. Valider chaque ligne avec Pydantic\n",
    "4. Enrichir avec des colonnes calculees :\n",
    "   - `month` : mois de la commande\n",
    "   - `revenue_category` : \"Low\" (<500), \"Medium\" (500-1000), \"High\" (>1000)\n",
    "   - `is_weekend` : bool (samedi/dimanche)\n",
    "\n",
    "**Load :**\n",
    "5. Exporter en Parquet avec compression\n",
    "6. Sauvegarder un rapport JSON avec les statistiques\n",
    "\n",
    "Creez une fonction `pipeline_etl(input_file, output_dir)` qui execute tout le pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "def pipeline_etl(df_input, output_dir='output'):\n",
    "    \"\"\"\n",
    "    Pipeline ETL complet pour les donnees de commandes\n",
    "    \"\"\"\n",
    "    print(\"=== PIPELINE ETL ===\")\n",
    "    print(f\"Input : {len(df_input)} lignes\\n\")\n",
    "    \n",
    "    # Creer le dossier de sortie\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    rapport = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'input_rows': len(df_input),\n",
    "        'etapes': []\n",
    "    }\n",
    "    \n",
    "    # ========== EXTRACT ==========\n",
    "    print(\"[1/6] EXTRACT : Chargement des donnees\")\n",
    "    df = df_input.copy()\n",
    "    rapport['etapes'].append({'etape': 'extract', 'lignes': len(df)})\n",
    "    \n",
    "    # ========== TRANSFORM - Nettoyage ==========\n",
    "    print(\"[2/6] TRANSFORM : Nettoyage des donnees\")\n",
    "    \n",
    "    # Supprimer les valeurs manquantes\n",
    "    lignes_avant = len(df)\n",
    "    df = df.dropna()\n",
    "    lignes_supprimees_na = lignes_avant - len(df)\n",
    "    print(f\"  - Valeurs manquantes : {lignes_supprimees_na} lignes supprimees\")\n",
    "    \n",
    "    # Corriger les valeurs aberrantes\n",
    "    lignes_avant = len(df)\n",
    "    df = df[(df['quantity'] > 0) & (df['unit_price'] > 0)]\n",
    "    lignes_supprimees_aberrantes = lignes_avant - len(df)\n",
    "    print(f\"  - Valeurs aberrantes : {lignes_supprimees_aberrantes} lignes supprimees\")\n",
    "    \n",
    "    # Normaliser les villes\n",
    "    df['city'] = df['city'].str.strip().str.capitalize()\n",
    "    print(f\"  - Villes normalisees\")\n",
    "    \n",
    "    # Recalculer le total\n",
    "    df['total'] = df['quantity'] * df['unit_price']\n",
    "    \n",
    "    rapport['etapes'].append({\n",
    "        'etape': 'nettoyage',\n",
    "        'lignes_supprimees_na': lignes_supprimees_na,\n",
    "        'lignes_supprimees_aberrantes': lignes_supprimees_aberrantes,\n",
    "        'lignes_restantes': len(df)\n",
    "    })\n",
    "    \n",
    "    # ========== TRANSFORM - Validation Pydantic ==========\n",
    "    print(\"[3/6] TRANSFORM : Validation Pydantic\")\n",
    "    \n",
    "    lignes_valides = []\n",
    "    lignes_invalides = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            # Convertir la ligne en dict et valider\n",
    "            order_data = {\n",
    "                'order_id': int(row['order_id']),\n",
    "                'date': row['date'],\n",
    "                'product': row['product'],\n",
    "                'category': row['category'],\n",
    "                'quantity': int(row['quantity']),\n",
    "                'unit_price': float(row['unit_price']),\n",
    "                'customer_id': row['customer_id'],\n",
    "                'city': row['city']\n",
    "            }\n",
    "            order = Order(**order_data)\n",
    "            lignes_valides.append(idx)\n",
    "        except Exception as e:\n",
    "            lignes_invalides.append((idx, str(e)))\n",
    "    \n",
    "    print(f\"  - Lignes valides : {len(lignes_valides)}\")\n",
    "    print(f\"  - Lignes invalides : {len(lignes_invalides)}\")\n",
    "    \n",
    "    # Garder seulement les lignes valides\n",
    "    df = df.loc[lignes_valides]\n",
    "    \n",
    "    rapport['etapes'].append({\n",
    "        'etape': 'validation',\n",
    "        'lignes_valides': len(lignes_valides),\n",
    "        'lignes_invalides': len(lignes_invalides)\n",
    "    })\n",
    "    \n",
    "    # ========== TRANSFORM - Enrichissement ==========\n",
    "    print(\"[4/6] TRANSFORM : Enrichissement\")\n",
    "    \n",
    "    # Extraire le mois\n",
    "    df['month'] = df['date'].dt.to_period('M').astype(str)\n",
    "    \n",
    "    # Categorie de revenu\n",
    "    def categoriser_revenu(total):\n",
    "        if total < 500:\n",
    "            return 'Low'\n",
    "        elif total <= 1000:\n",
    "            return 'Medium'\n",
    "        else:\n",
    "            return 'High'\n",
    "    \n",
    "    df['revenue_category'] = df['total'].apply(categoriser_revenu)\n",
    "    \n",
    "    # Weekend\n",
    "    df['is_weekend'] = df['date'].dt.dayofweek.isin([5, 6])\n",
    "    \n",
    "    print(f\"  - Colonnes ajoutees : month, revenue_category, is_weekend\")\n",
    "    \n",
    "    rapport['etapes'].append({\n",
    "        'etape': 'enrichissement',\n",
    "        'colonnes_ajoutees': ['month', 'revenue_category', 'is_weekend']\n",
    "    })\n",
    "    \n",
    "    # ========== LOAD - Export Parquet ==========\n",
    "    print(\"[5/6] LOAD : Export Parquet\")\n",
    "    \n",
    "    parquet_path = output_path / 'orders_clean.parquet'\n",
    "    df.to_parquet(parquet_path, compression='snappy', index=False)\n",
    "    \n",
    "    file_size = parquet_path.stat().st_size / 1024  # KB\n",
    "    print(f\"  - Fichier : {parquet_path}\")\n",
    "    print(f\"  - Taille : {file_size:.2f} KB\")\n",
    "    \n",
    "    rapport['output_file'] = str(parquet_path)\n",
    "    rapport['file_size_kb'] = round(file_size, 2)\n",
    "    \n",
    "    # ========== LOAD - Rapport ==========\n",
    "    print(\"[6/6] LOAD : Generation du rapport\")\n",
    "    \n",
    "    # Statistiques finales\n",
    "    statistiques = {\n",
    "        'nb_commandes': len(df),\n",
    "        'ca_total': float(df['total'].sum()),\n",
    "        'panier_moyen': float(df['total'].mean()),\n",
    "        'nb_clients': df['customer_id'].nunique(),\n",
    "        'nb_produits': df['product'].nunique(),\n",
    "        'nb_villes': df['city'].nunique(),\n",
    "        'periode': {\n",
    "            'debut': df['date'].min().isoformat(),\n",
    "            'fin': df['date'].max().isoformat()\n",
    "        },\n",
    "        'repartition_revenue_category': df['revenue_category'].value_counts().to_dict(),\n",
    "        'commandes_weekend': int(df['is_weekend'].sum()),\n",
    "        'top_3_produits': df.groupby('product')['total'].sum().nlargest(3).to_dict()\n",
    "    }\n",
    "    \n",
    "    rapport['statistiques'] = statistiques\n",
    "    rapport['output_rows'] = len(df)\n",
    "    \n",
    "    # Sauvegarder le rapport\n",
    "    rapport_path = output_path / 'pipeline_report.json'\n",
    "    with open(rapport_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(rapport, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"  - Rapport : {rapport_path}\")\n",
    "    \n",
    "    # ========== RÃ©sumÃ© ==========\n",
    "    print(\"\\n=== RESUME ===\")\n",
    "    print(f\"Lignes input : {rapport['input_rows']}\")\n",
    "    print(f\"Lignes output : {rapport['output_rows']}\")\n",
    "    print(f\"Taux de succes : {rapport['output_rows']/rapport['input_rows']*100:.1f}%\")\n",
    "    print(f\"\\nCA total : {statistiques['ca_total']:,.2f} EUR\")\n",
    "    print(f\"Panier moyen : {statistiques['panier_moyen']:.2f} EUR\")\n",
    "    print(f\"Clients uniques : {statistiques['nb_clients']}\")\n",
    "    \n",
    "    return df, rapport\n",
    "\n",
    "\n",
    "# Executer le pipeline\n",
    "df_clean, rapport = pipeline_etl(df)\n",
    "\n",
    "# Afficher un apercu\n",
    "print(\"\\n=== APERCU DES DONNEES NETTOYEES ===\")\n",
    "print(df_clean.head(10))\n",
    "\n",
    "print(\"\\n=== NOUVELLES COLONNES ===\")\n",
    "print(df_clean[['order_id', 'date', 'total', 'month', 'revenue_category', 'is_weekend']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercice 5 : Analyse avec DuckDB (DIFFICILE)\n",
    "\n",
    "Utilisez DuckDB pour des requetes SQL sur le fichier Parquet :\n",
    "\n",
    "**Requetes a implementer :**\n",
    "\n",
    "1. **Top 5 des produits** par CA total\n",
    "2. **CA mensuel** avec croissance MoM (Month over Month)\n",
    "3. **Analyse par ville** : CA, nombre de commandes, panier moyen\n",
    "4. **Cohort analysis** : clients par mois de premiere commande\n",
    "5. **Window functions** : Rang des produits par ville selon le CA\n",
    "6. **Analyse weekend vs semaine** : comparaison des performances\n",
    "\n",
    "Utilisez des requetes SQL avancees avec window functions, CTEs, et agregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "import duckdb\n",
    "\n",
    "print(\"=== ANALYSE AVEC DUCKDB ===\")\n",
    "\n",
    "# Connexion DuckDB (en memoire)\n",
    "conn = duckdb.connect()\n",
    "\n",
    "# Charger le Parquet\n",
    "parquet_file = 'output/orders_clean.parquet'\n",
    "print(f\"\\nChargement : {parquet_file}\\n\")\n",
    "\n",
    "# ========== Requete 1 : Top 5 produits ==========\n",
    "print(\"1. TOP 5 DES PRODUITS PAR CA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query1 = f\"\"\"\n",
    "SELECT \n",
    "    product,\n",
    "    COUNT(*) as nb_commandes,\n",
    "    SUM(quantity) as quantite_totale,\n",
    "    ROUND(SUM(total), 2) as ca_total,\n",
    "    ROUND(AVG(total), 2) as panier_moyen\n",
    "FROM '{parquet_file}'\n",
    "GROUP BY product\n",
    "ORDER BY ca_total DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "result1 = conn.execute(query1).df()\n",
    "print(result1.to_string(index=False))\n",
    "\n",
    "# ========== Requete 2 : CA mensuel avec croissance ==========\n",
    "print(\"\\n\\n2. CA MENSUEL AVEC CROISSANCE MoM\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query2 = f\"\"\"\n",
    "WITH monthly_revenue AS (\n",
    "    SELECT \n",
    "        month,\n",
    "        COUNT(*) as nb_commandes,\n",
    "        ROUND(SUM(total), 2) as ca_total\n",
    "    FROM '{parquet_file}'\n",
    "    GROUP BY month\n",
    "    ORDER BY month\n",
    ")\n",
    "SELECT \n",
    "    month,\n",
    "    nb_commandes,\n",
    "    ca_total,\n",
    "    LAG(ca_total) OVER (ORDER BY month) as ca_mois_precedent,\n",
    "    ROUND(\n",
    "        (ca_total - LAG(ca_total) OVER (ORDER BY month)) / \n",
    "        LAG(ca_total) OVER (ORDER BY month) * 100, \n",
    "        2\n",
    "    ) as croissance_pct\n",
    "FROM monthly_revenue\n",
    "\"\"\"\n",
    "\n",
    "result2 = conn.execute(query2).df()\n",
    "print(result2.to_string(index=False))\n",
    "\n",
    "# ========== Requete 3 : Analyse par ville ==========\n",
    "print(\"\\n\\n3. ANALYSE PAR VILLE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query3 = f\"\"\"\n",
    "SELECT \n",
    "    city,\n",
    "    COUNT(*) as nb_commandes,\n",
    "    COUNT(DISTINCT customer_id) as nb_clients,\n",
    "    ROUND(SUM(total), 2) as ca_total,\n",
    "    ROUND(AVG(total), 2) as panier_moyen,\n",
    "    ROUND(SUM(total) * 100.0 / SUM(SUM(total)) OVER (), 2) as pct_ca_total\n",
    "FROM '{parquet_file}'\n",
    "GROUP BY city\n",
    "ORDER BY ca_total DESC\n",
    "\"\"\"\n",
    "\n",
    "result3 = conn.execute(query3).df()\n",
    "print(result3.to_string(index=False))\n",
    "\n",
    "# ========== Requete 4 : Cohort analysis ==========\n",
    "print(\"\\n\\n4. COHORT ANALYSIS : Premiere commande par client\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query4 = f\"\"\"\n",
    "WITH first_order AS (\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        MIN(month) as cohort_month,\n",
    "        MIN(date) as first_order_date\n",
    "    FROM '{parquet_file}'\n",
    "    GROUP BY customer_id\n",
    ")\n",
    "SELECT \n",
    "    cohort_month,\n",
    "    COUNT(DISTINCT customer_id) as nb_nouveaux_clients,\n",
    "    ROUND(AVG(CAST(strftime(first_order_date, '%d') AS INTEGER)), 1) as jour_moyen\n",
    "FROM first_order\n",
    "GROUP BY cohort_month\n",
    "ORDER BY cohort_month\n",
    "\"\"\"\n",
    "\n",
    "result4 = conn.execute(query4).df()\n",
    "print(result4.to_string(index=False))\n",
    "\n",
    "# ========== Requete 5 : Rang des produits par ville ==========\n",
    "print(\"\\n\\n5. RANG DES PRODUITS PAR VILLE (TOP 2 PAR VILLE)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query5 = f\"\"\"\n",
    "WITH product_city_revenue AS (\n",
    "    SELECT \n",
    "        city,\n",
    "        product,\n",
    "        ROUND(SUM(total), 2) as ca_total,\n",
    "        ROW_NUMBER() OVER (PARTITION BY city ORDER BY SUM(total) DESC) as rang\n",
    "    FROM '{parquet_file}'\n",
    "    GROUP BY city, product\n",
    ")\n",
    "SELECT \n",
    "    city,\n",
    "    rang,\n",
    "    product,\n",
    "    ca_total\n",
    "FROM product_city_revenue\n",
    "WHERE rang <= 2\n",
    "ORDER BY city, rang\n",
    "\"\"\"\n",
    "\n",
    "result5 = conn.execute(query5).df()\n",
    "print(result5.to_string(index=False))\n",
    "\n",
    "# ========== Requete 6 : Weekend vs Semaine ==========\n",
    "print(\"\\n\\n6. ANALYSE WEEKEND VS SEMAINE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query6 = f\"\"\"\n",
    "SELECT \n",
    "    CASE \n",
    "        WHEN is_weekend THEN 'Weekend'\n",
    "        ELSE 'Semaine'\n",
    "    END as periode,\n",
    "    COUNT(*) as nb_commandes,\n",
    "    ROUND(SUM(total), 2) as ca_total,\n",
    "    ROUND(AVG(total), 2) as panier_moyen,\n",
    "    ROUND(AVG(quantity), 2) as quantite_moyenne,\n",
    "    ROUND(SUM(total) * 100.0 / SUM(SUM(total)) OVER (), 2) as pct_ca\n",
    "FROM '{parquet_file}'\n",
    "GROUP BY is_weekend\n",
    "ORDER BY periode DESC\n",
    "\"\"\"\n",
    "\n",
    "result6 = conn.execute(query6).df()\n",
    "print(result6.to_string(index=False))\n",
    "\n",
    "# ========== Requete BONUS : Analyse de revenue_category ==========\n",
    "print(\"\\n\\nBONUS : ANALYSE PAR CATEGORIE DE REVENU\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query_bonus = f\"\"\"\n",
    "SELECT \n",
    "    revenue_category,\n",
    "    COUNT(*) as nb_commandes,\n",
    "    ROUND(SUM(total), 2) as ca_total,\n",
    "    ROUND(MIN(total), 2) as montant_min,\n",
    "    ROUND(MAX(total), 2) as montant_max,\n",
    "    ROUND(AVG(total), 2) as montant_moyen,\n",
    "    ROUND(SUM(total) * 100.0 / SUM(SUM(total)) OVER (), 2) as pct_ca\n",
    "FROM '{parquet_file}'\n",
    "GROUP BY revenue_category\n",
    "ORDER BY \n",
    "    CASE revenue_category \n",
    "        WHEN 'Low' THEN 1 \n",
    "        WHEN 'Medium' THEN 2 \n",
    "        WHEN 'High' THEN 3 \n",
    "    END\n",
    "\"\"\"\n",
    "\n",
    "result_bonus = conn.execute(query_bonus).df()\n",
    "print(result_bonus.to_string(index=False))\n",
    "\n",
    "# Fermer la connexion\n",
    "conn.close()\n",
    "\n",
    "print(\"\\n\\n=== ANALYSE TERMINEE ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusion\n",
    "\n",
    "Felicitations ! Vous avez complete un projet complet de data engineering.\n",
    "\n",
    "### Competences acquises :\n",
    "\n",
    "**Pandas :**\n",
    "- Exploration de donnees (info, describe, value_counts)\n",
    "- Manipulation et transformation (groupby, pivot_table)\n",
    "- Agregations avancees\n",
    "\n",
    "**Pydantic :**\n",
    "- Validation de schemas de donnees\n",
    "- Validateurs personnalises\n",
    "- Gestion d'erreurs de validation\n",
    "\n",
    "**Pipeline ETL :**\n",
    "- Extract : chargement de donnees\n",
    "- Transform : nettoyage, validation, enrichissement\n",
    "- Load : export Parquet, generation de rapports\n",
    "\n",
    "**DuckDB :**\n",
    "- Requetes SQL sur fichiers Parquet\n",
    "- Window functions (ROW_NUMBER, LAG)\n",
    "- CTEs (Common Table Expressions)\n",
    "- Agregations et analyses complexes\n",
    "\n",
    "### Pour aller plus loin :\n",
    "- Implementer un systeme de logging\n",
    "- Ajouter des tests unitaires\n",
    "- Creer des visualisations avec matplotlib/plotly\n",
    "- Scheduler le pipeline avec Apache Airflow\n",
    "- Deployer sur le cloud (AWS S3, GCP BigQuery)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
