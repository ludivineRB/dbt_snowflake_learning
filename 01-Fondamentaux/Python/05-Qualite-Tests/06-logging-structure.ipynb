{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üî¥ Avanc√© | ‚è± 45 min | üîë Concepts : logging, JSON logging, Datadog/Splunk ready\n",
    "\n",
    "# 06 - Logging Structur√© et Production-Ready\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "- Comprendre pourquoi `print()` n'est pas suffisant\n",
    "- Ma√Ætriser le module **logging** de Python\n",
    "- Configurer des **niveaux** et **handlers** appropri√©s\n",
    "- Impl√©menter du **JSON logging** pour les outils modernes (Datadog, Splunk, ELK)\n",
    "- Appliquer les bonnes pratiques de logging en production\n",
    "\n",
    "## Pr√©requis\n",
    "\n",
    "- Python 3.8+\n",
    "- Compr√©hension des concepts de base (fonctions, classes)\n",
    "- Familiarit√© avec JSON (optionnel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. print() vs logging : Pourquoi logger ?\n",
    "\n",
    "### Limites de print()\n",
    "\n",
    "```python\n",
    "# ‚ùå Probl√®mes avec print()\n",
    "print(\"Starting process...\")           # Pas de timestamp\n",
    "print(\"User:\", user_id)                # Pas de niveau de gravit√©\n",
    "print(\"ERROR: Database connection\")    # M√©lang√© avec stdout\n",
    "```\n",
    "\n",
    "### Avantages du logging\n",
    "\n",
    "| Fonctionnalit√© | print() | logging |\n",
    "|----------------|---------|----------|\n",
    "| **Niveaux** (DEBUG, INFO, ERROR) | ‚ùå | ‚úÖ |\n",
    "| **Timestamp automatique** | ‚ùå | ‚úÖ |\n",
    "| **Filtrage** par niveau | ‚ùå | ‚úÖ |\n",
    "| **Multiples destinations** (fichier, console, API) | ‚ùå | ‚úÖ |\n",
    "| **Rotation de logs** | ‚ùå | ‚úÖ |\n",
    "| **Contexte** (module, ligne, fonction) | ‚ùå | ‚úÖ |\n",
    "| **Production-ready** | ‚ùå | ‚úÖ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Module logging : Les bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configuration basique\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Utilisation\n",
    "logging.debug(\"Message de debug (ne s'affiche pas car level=INFO)\")\n",
    "logging.info(\"Information importante\")\n",
    "logging.warning(\"Attention !\")\n",
    "logging.error(\"Une erreur s'est produite\")\n",
    "logging.critical(\"Erreur critique !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Les 5 niveaux de logging\n",
    "\n",
    "| Niveau | Valeur | Quand l'utiliser ? | Exemple |\n",
    "|--------|--------|-------------------|----------|\n",
    "| **DEBUG** | 10 | Informations de d√©bogage d√©taill√©es | \"Variable x = 42\", \"Entr√©e dans fonction()\" |\n",
    "| **INFO** | 20 | Confirmation que tout fonctionne | \"Serveur d√©marr√© sur port 8000\" |\n",
    "| **WARNING** | 30 | Quelque chose d'inattendu, mais pas grave | \"Disque presque plein (80%)\" |\n",
    "| **ERROR** | 40 | Erreur grave, mais le programme continue | \"√âchec de connexion √† la DB\" |\n",
    "| **CRITICAL** | 50 | Erreur qui arr√™te le programme | \"M√©moire √©puis√©e, arr√™t imminent\" |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Configurer pour afficher tous les niveaux\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(levelname)-8s - %(message)s'\n",
    ")\n",
    "\n",
    "logging.debug(\"D√©tails pour le d√©bogage\")\n",
    "logging.info(\"Info g√©n√©rale\")\n",
    "logging.warning(\"Avertissement\")\n",
    "logging.error(\"Erreur\")\n",
    "logging.critical(\"Critique !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Formatage des logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Format personnalis√©\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s | %(levelname)-8s | %(name)s | %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"Message avec format personnalis√©\")\n",
    "logger.error(\"Une erreur avec timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributs de formatage disponibles\n",
    "\n",
    "| Attribut | Description | Exemple |\n",
    "|----------|-------------|----------|\n",
    "| `%(asctime)s` | Timestamp | `2024-02-08 14:30:00` |\n",
    "| `%(levelname)s` | Niveau | `INFO`, `ERROR` |\n",
    "| `%(name)s` | Nom du logger | `__main__`, `myapp.module` |\n",
    "| `%(message)s` | Message | `User logged in` |\n",
    "| `%(funcName)s` | Nom de la fonction | `process_data` |\n",
    "| `%(lineno)d` | Num√©ro de ligne | `42` |\n",
    "| `%(pathname)s` | Chemin complet du fichier | `/app/main.py` |\n",
    "| `%(filename)s` | Nom du fichier | `main.py` |\n",
    "| `%(process)d` | ID du processus | `12345` |\n",
    "| `%(thread)d` | ID du thread | `67890` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loggers par module : Bonne pratique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile user_service.py\n",
    "\"\"\"Service utilisateur.\"\"\"\n",
    "import logging\n",
    "\n",
    "# ‚úÖ BON : Logger par module\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def create_user(username):\n",
    "    \"\"\"Cr√©e un utilisateur.\"\"\"\n",
    "    logger.info(f\"Creating user: {username}\")\n",
    "    # ...\n",
    "    logger.debug(f\"User {username} created successfully\")\n",
    "\n",
    "def delete_user(user_id):\n",
    "    \"\"\"Supprime un utilisateur.\"\"\"\n",
    "    logger.warning(f\"Deleting user {user_id}\")\n",
    "    # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile database.py\n",
    "\"\"\"Module database.\"\"\"\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def connect():\n",
    "    \"\"\"Connexion √† la DB.\"\"\"\n",
    "    logger.info(\"Connecting to database...\")\n",
    "    # ...\n",
    "    logger.info(\"Database connected\")\n",
    "\n",
    "def query(sql):\n",
    "    \"\"\"Ex√©cute une requ√™te.\"\"\"\n",
    "    logger.debug(f\"Executing query: {sql}\")\n",
    "    # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s | %(levelname)-8s | %(name)-20s | %(message)s'\n",
    ")\n",
    "\n",
    "# Importer les modules\n",
    "import user_service\n",
    "import database\n",
    "\n",
    "# Utiliser les fonctions\n",
    "database.connect()\n",
    "user_service.create_user(\"alice\")\n",
    "database.query(\"SELECT * FROM users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Handlers : Destinations multiples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Cr√©er un logger\n",
    "logger = logging.getLogger('my_app')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Handler 1 : Console (INFO et au-dessus)\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "console_format = logging.Formatter('%(levelname)s - %(message)s')\n",
    "console_handler.setFormatter(console_format)\n",
    "\n",
    "# Handler 2 : Fichier (DEBUG et au-dessus)\n",
    "file_handler = logging.FileHandler('app.log')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_format = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n",
    "file_handler.setFormatter(file_format)\n",
    "\n",
    "# Handler 3 : Fichier d'erreurs (ERROR et au-dessus)\n",
    "error_handler = logging.FileHandler('errors.log')\n",
    "error_handler.setLevel(logging.ERROR)\n",
    "error_handler.setFormatter(file_format)\n",
    "\n",
    "# Ajouter les handlers\n",
    "logger.addHandler(console_handler)\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(error_handler)\n",
    "\n",
    "# Tester\n",
    "logger.debug(\"Debug message (seulement dans app.log)\")\n",
    "logger.info(\"Info message (console + app.log)\")\n",
    "logger.error(\"Error message (console + app.log + errors.log)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier le contenu des fichiers\n",
    "!echo \"=== app.log ===\"\n",
    "!cat app.log\n",
    "!echo \"\\n=== errors.log ===\"\n",
    "!cat errors.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types de handlers courants\n",
    "\n",
    "| Handler | Usage |\n",
    "|---------|-------|\n",
    "| `StreamHandler` | Console (stdout/stderr) |\n",
    "| `FileHandler` | Fichier simple |\n",
    "| `RotatingFileHandler` | Fichier avec rotation par taille |\n",
    "| `TimedRotatingFileHandler` | Fichier avec rotation par temps |\n",
    "| `SocketHandler` | Envoi via socket r√©seau |\n",
    "| `HTTPHandler` | Envoi via HTTP |\n",
    "| `SMTPHandler` | Envoi par email |\n",
    "| `SysLogHandler` | Syslog syst√®me |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Rotation de logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging.handlers import RotatingFileHandler, TimedRotatingFileHandler\n",
    "\n",
    "logger = logging.getLogger('rotating_app')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Rotation par taille : max 1MB, garder 5 backups\n",
    "size_handler = RotatingFileHandler(\n",
    "    'app_size.log',\n",
    "    maxBytes=1024 * 1024,  # 1 MB\n",
    "    backupCount=5\n",
    ")\n",
    "size_handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))\n",
    "logger.addHandler(size_handler)\n",
    "\n",
    "# Rotation par temps : nouveau fichier chaque jour, garder 7 jours\n",
    "time_handler = TimedRotatingFileHandler(\n",
    "    'app_daily.log',\n",
    "    when='midnight',\n",
    "    interval=1,\n",
    "    backupCount=7\n",
    ")\n",
    "time_handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s'))\n",
    "logger.addHandler(time_handler)\n",
    "\n",
    "# Tester\n",
    "for i in range(10):\n",
    "    logger.info(f\"Log message {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Configuration avec dictConfig\n",
    "\n",
    "Pour des configurations complexes, utilisez `dictConfig`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import logging.config\n",
    "\n",
    "LOGGING_CONFIG = {\n",
    "    'version': 1,\n",
    "    'disable_existing_loggers': False,\n",
    "    \n",
    "    'formatters': {\n",
    "        'detailed': {\n",
    "            'format': '%(asctime)s | %(levelname)-8s | %(name)s | %(funcName)s:%(lineno)d | %(message)s'\n",
    "        },\n",
    "        'simple': {\n",
    "            'format': '%(levelname)s - %(message)s'\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'handlers': {\n",
    "        'console': {\n",
    "            'class': 'logging.StreamHandler',\n",
    "            'level': 'INFO',\n",
    "            'formatter': 'simple',\n",
    "            'stream': 'ext://sys.stdout',\n",
    "        },\n",
    "        'file': {\n",
    "            'class': 'logging.handlers.RotatingFileHandler',\n",
    "            'level': 'DEBUG',\n",
    "            'formatter': 'detailed',\n",
    "            'filename': 'app_dictconfig.log',\n",
    "            'maxBytes': 10485760,  # 10MB\n",
    "            'backupCount': 3,\n",
    "        },\n",
    "        'error_file': {\n",
    "            'class': 'logging.FileHandler',\n",
    "            'level': 'ERROR',\n",
    "            'formatter': 'detailed',\n",
    "            'filename': 'errors_dictconfig.log',\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'loggers': {\n",
    "        'my_app': {\n",
    "            'level': 'DEBUG',\n",
    "            'handlers': ['console', 'file', 'error_file'],\n",
    "            'propagate': False,\n",
    "        },\n",
    "        'third_party': {\n",
    "            'level': 'WARNING',  # Moins verbeux pour les libs tierces\n",
    "            'handlers': ['console'],\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'root': {\n",
    "        'level': 'INFO',\n",
    "        'handlers': ['console', 'file'],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Appliquer la configuration\n",
    "logging.config.dictConfig(LOGGING_CONFIG)\n",
    "\n",
    "# Utiliser\n",
    "logger = logging.getLogger('my_app')\n",
    "logger.debug(\"Debug message\")\n",
    "logger.info(\"Info message\")\n",
    "logger.error(\"Error message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. JSON Logging : Production-ready\n",
    "\n",
    "Pour les outils modernes (Datadog, Splunk, ELK), utilisez du JSON structur√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-json-logger -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pythonjsonlogger import jsonlogger\n",
    "\n",
    "# Cr√©er un logger avec JSON formatter\n",
    "logger = logging.getLogger('json_app')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Handler avec JSON formatter\n",
    "handler = logging.StreamHandler()\n",
    "formatter = jsonlogger.JsonFormatter(\n",
    "    '%(asctime)s %(levelname)s %(name)s %(funcName)s %(lineno)d %(message)s'\n",
    ")\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Utiliser\n",
    "logger.info(\"User logged in\", extra={\"user_id\": 123, \"ip\": \"192.168.1.1\"})\n",
    "logger.error(\"Database error\", extra={\"error_code\": \"DB001\", \"table\": \"users\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Logging avec contexte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import uuid\n",
    "from pythonjsonlogger import jsonlogger\n",
    "\n",
    "class StructuredLogger:\n",
    "    \"\"\"Logger structur√© avec contexte.\"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.logger = logging.getLogger(name)\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "        \n",
    "        handler = logging.StreamHandler()\n",
    "        formatter = jsonlogger.JsonFormatter(\n",
    "            '%(asctime)s %(levelname)s %(name)s %(message)s'\n",
    "        )\n",
    "        handler.setFormatter(formatter)\n",
    "        self.logger.addHandler(handler)\n",
    "        \n",
    "        # Contexte global\n",
    "        self.context = {}\n",
    "    \n",
    "    def set_context(self, **kwargs):\n",
    "        \"\"\"D√©finit le contexte global.\"\"\"\n",
    "        self.context.update(kwargs)\n",
    "    \n",
    "    def _log(self, level, message, **extra):\n",
    "        \"\"\"Log avec contexte.\"\"\"\n",
    "        log_data = {**self.context, **extra}\n",
    "        getattr(self.logger, level)(message, extra=log_data)\n",
    "    \n",
    "    def info(self, message, **extra):\n",
    "        self._log('info', message, **extra)\n",
    "    \n",
    "    def error(self, message, **extra):\n",
    "        self._log('error', message, **extra)\n",
    "\n",
    "# Utilisation\n",
    "logger = StructuredLogger('my_service')\n",
    "\n",
    "# D√©finir un contexte global (ex: request ID)\n",
    "request_id = str(uuid.uuid4())\n",
    "logger.set_context(request_id=request_id, environment=\"production\")\n",
    "\n",
    "# Tous les logs incluent le contexte\n",
    "logger.info(\"Processing request\", user_id=123)\n",
    "logger.info(\"Querying database\", query=\"SELECT * FROM users\")\n",
    "logger.error(\"Database timeout\", error_code=\"TIMEOUT\", timeout_seconds=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Bonnes pratiques\n",
    "\n",
    "### 1. Logger par module, pas en global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå MAUVAIS\n",
    "import logging\n",
    "logging.info(\"Message\")  # Logger root\n",
    "\n",
    "# ‚úÖ BON\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"Message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Ne JAMAIS logger de secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå DANGER : Secrets dans les logs\n",
    "logger.info(f\"Connecting with password: {password}\")\n",
    "logger.debug(f\"API key: {api_key}\")\n",
    "\n",
    "# ‚úÖ BON : Masquer les secrets\n",
    "logger.info(\"Connecting with password: ******\")\n",
    "logger.debug(\"API key: {}...{}\".format(api_key[:4], api_key[-4:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Utiliser le bon niveau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå MAUVAIS : Tout en INFO\n",
    "logger.info(\"Variable x = 42\")  # Devrait √™tre DEBUG\n",
    "logger.info(\"Database crashed\")  # Devrait √™tre ERROR ou CRITICAL\n",
    "\n",
    "# ‚úÖ BON : Niveau appropri√©\n",
    "logger.debug(\"Variable x = 42\")\n",
    "logger.error(\"Database crashed\", extra={\"error\": str(e)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Logging paresseux (lazy logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå MAUVAIS : Formatage inutile si DEBUG d√©sactiv√©\n",
    "logger.debug(f\"User data: {expensive_function()}\")\n",
    "\n",
    "# ‚úÖ BON : Lazy evaluation\n",
    "logger.debug(\"User data: %s\", expensive_function())\n",
    "# expensive_function() n'est appel√©e que si DEBUG est activ√©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Ne pas logger dans des boucles intensives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå MAUVAIS : 1 million de logs\n",
    "for i in range(1_000_000):\n",
    "    logger.debug(f\"Processing item {i}\")\n",
    "\n",
    "# ‚úÖ BON : Logger √† intervalles\n",
    "for i in range(1_000_000):\n",
    "    if i % 10000 == 0:\n",
    "        logger.info(f\"Processed {i} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Alternative : Loguru (mention)\n",
    "\n",
    "**Loguru** est une alternative moderne qui simplifie le logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install loguru -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "\n",
    "# Configuration simple\n",
    "logger.add(\"loguru_app.log\", rotation=\"500 MB\", retention=\"10 days\")\n",
    "\n",
    "# Utilisation\n",
    "logger.info(\"Loguru info\")\n",
    "logger.debug(\"Loguru debug\")\n",
    "logger.error(\"Loguru error\")\n",
    "\n",
    "# Contexte automatique\n",
    "logger.info(\"User {user} logged in\", user=\"alice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pi√®ges courants\n",
    "\n",
    "### 1. Logger au mauvais niveau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå MAUVAIS\n",
    "logger.error(\"Starting application\")  # Ce n'est pas une erreur !\n",
    "logger.info(\"Database connection failed\")  # Devrait √™tre ERROR\n",
    "\n",
    "# ‚úÖ BON\n",
    "logger.info(\"Starting application\")\n",
    "logger.error(\"Database connection failed\", exc_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Logging dans des boucles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå MAUVAIS : Millions de logs\n",
    "for row in df.iterrows():\n",
    "    logger.debug(f\"Processing row {row}\")\n",
    "\n",
    "# ‚úÖ BON : Logs agr√©g√©s\n",
    "logger.info(f\"Processing {len(df)} rows\")\n",
    "# ... traitement ...\n",
    "logger.info(f\"Processed {len(df)} rows successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Oublier exc_info pour les exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå MAUVAIS : Pas de stack trace\n",
    "try:\n",
    "    1 / 0\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error: {e}\")\n",
    "\n",
    "# ‚úÖ BON : Avec stack trace\n",
    "try:\n",
    "    1 / 0\n",
    "except Exception as e:\n",
    "    logger.error(\"Division by zero\", exc_info=True)\n",
    "    # Ou : logger.exception(\"Division by zero\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Exercices\n",
    "\n",
    "### Exercice 1 : Configurer un logger JSON\n",
    "\n",
    "Cr√©ez un logger qui :\n",
    "- √âcrit en JSON dans un fichier\n",
    "- Inclut timestamp, niveau, message, et contexte personnalis√©\n",
    "- Utilise la rotation de fichiers (max 5MB, 3 backups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre solution ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2 : Logger pour un pipeline data\n",
    "\n",
    "Cr√©ez un syst√®me de logging pour un pipeline de donn√©es qui :\n",
    "- Loggue le d√©but et la fin de chaque √©tape\n",
    "- Loggue les m√©triques (nombre de lignes trait√©es, temps d'ex√©cution)\n",
    "- Loggue les erreurs avec contexte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre solution ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 3 : Masquer les donn√©es sensibles\n",
    "\n",
    "Cr√©ez un formatter personnalis√© qui masque automatiquement les mots de passe et tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre solution ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Exercice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "from pythonjsonlogger import jsonlogger\n",
    "\n",
    "# Cr√©er le logger\n",
    "logger = logging.getLogger('json_exercise')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Handler avec rotation\n",
    "handler = RotatingFileHandler(\n",
    "    'exercise1.log',\n",
    "    maxBytes=5 * 1024 * 1024,  # 5MB\n",
    "    backupCount=3\n",
    ")\n",
    "\n",
    "# JSON Formatter\n",
    "formatter = jsonlogger.JsonFormatter(\n",
    "    '%(asctime)s %(levelname)s %(name)s %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Test\n",
    "logger.info(\"Application started\", extra={\"version\": \"1.0.0\", \"env\": \"production\"})\n",
    "logger.debug(\"Processing data\", extra={\"rows\": 1000, \"columns\": 50})\n",
    "logger.error(\"Database error\", extra={\"error_code\": \"DB001\", \"table\": \"users\"})\n",
    "\n",
    "print(\"Logs √©crits dans exercise1.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Exercice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "from pythonjsonlogger import jsonlogger\n",
    "\n",
    "# Configuration\n",
    "logger = logging.getLogger('data_pipeline')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "handler = logging.StreamHandler()\n",
    "formatter = jsonlogger.JsonFormatter('%(asctime)s %(levelname)s %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "class DataPipeline:\n",
    "    \"\"\"Pipeline de donn√©es avec logging.\"\"\"\n",
    "    \n",
    "    def __init__(self, pipeline_id):\n",
    "        self.pipeline_id = pipeline_id\n",
    "        self.logger = logging.getLogger(f'data_pipeline.{pipeline_id}')\n",
    "    \n",
    "    def run_step(self, step_name, func, *args, **kwargs):\n",
    "        \"\"\"Ex√©cute une √©tape avec logging.\"\"\"\n",
    "        self.logger.info(\n",
    "            f\"Starting step: {step_name}\",\n",
    "            extra={\"step\": step_name, \"pipeline_id\": self.pipeline_id}\n",
    "        )\n",
    "        \n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            duration = time.time() - start_time\n",
    "            \n",
    "            self.logger.info(\n",
    "                f\"Completed step: {step_name}\",\n",
    "                extra={\n",
    "                    \"step\": step_name,\n",
    "                    \"pipeline_id\": self.pipeline_id,\n",
    "                    \"duration_seconds\": round(duration, 2),\n",
    "                    \"rows_processed\": len(result) if hasattr(result, '__len__') else None\n",
    "                }\n",
    "            )\n",
    "            return result\n",
    "        \n",
    "        except Exception as e:\n",
    "            duration = time.time() - start_time\n",
    "            self.logger.error(\n",
    "                f\"Failed step: {step_name}\",\n",
    "                extra={\n",
    "                    \"step\": step_name,\n",
    "                    \"pipeline_id\": self.pipeline_id,\n",
    "                    \"duration_seconds\": round(duration, 2),\n",
    "                    \"error\": str(e),\n",
    "                    \"error_type\": type(e).__name__\n",
    "                },\n",
    "                exc_info=True\n",
    "            )\n",
    "            raise\n",
    "\n",
    "# Utilisation\n",
    "pipeline = DataPipeline(\"pipeline_001\")\n",
    "\n",
    "def extract():\n",
    "    time.sleep(0.1)\n",
    "    return [1, 2, 3, 4, 5]\n",
    "\n",
    "def transform(data):\n",
    "    time.sleep(0.1)\n",
    "    return [x * 2 for x in data]\n",
    "\n",
    "data = pipeline.run_step(\"extract\", extract)\n",
    "transformed = pipeline.run_step(\"transform\", transform, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Exercice 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "\n",
    "class SensitiveDataFormatter(logging.Formatter):\n",
    "    \"\"\"Formatter qui masque les donn√©es sensibles.\"\"\"\n",
    "    \n",
    "    # Patterns √† masquer\n",
    "    PATTERNS = [\n",
    "        (re.compile(r'password[\"\\s:=]+[\"\\']?([^\"\\s]+)[\"\\']?', re.IGNORECASE), 'password=******'),\n",
    "        (re.compile(r'token[\"\\s:=]+[\"\\']?([^\"\\s]+)[\"\\']?', re.IGNORECASE), 'token=******'),\n",
    "        (re.compile(r'api[_-]?key[\"\\s:=]+[\"\\']?([^\"\\s]+)[\"\\']?', re.IGNORECASE), 'api_key=******'),\n",
    "        (re.compile(r'secret[\"\\s:=]+[\"\\']?([^\"\\s]+)[\"\\']?', re.IGNORECASE), 'secret=******'),\n",
    "    ]\n",
    "    \n",
    "    def format(self, record):\n",
    "        \"\"\"Formate le message en masquant les donn√©es sensibles.\"\"\"\n",
    "        # Formatter le message normalement\n",
    "        original = super().format(record)\n",
    "        \n",
    "        # Masquer les patterns sensibles\n",
    "        masked = original\n",
    "        for pattern, replacement in self.PATTERNS:\n",
    "            masked = pattern.sub(replacement, masked)\n",
    "        \n",
    "        return masked\n",
    "\n",
    "# Configuration\n",
    "logger = logging.getLogger('secure_app')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "handler = logging.StreamHandler()\n",
    "formatter = SensitiveDataFormatter('%(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Test\n",
    "logger.info(\"User login with password=super_secret_123\")\n",
    "logger.info(\"API call with api_key=sk_live_abcdefghijklmnop\")\n",
    "logger.info(\"Token: Bearer xyz789abc\")\n",
    "logger.info(\"Normal message without secrets\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
