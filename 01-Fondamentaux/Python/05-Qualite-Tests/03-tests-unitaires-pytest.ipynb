{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö° Interm√©diaire | ‚è± 60 min | üîë Concepts : pytest, assert, fixtures, parametrize, mocking\n",
    "\n",
    "# 03 - Tests Unitaires avec pytest\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "- Comprendre pourquoi les tests sont essentiels\n",
    "- Ma√Ætriser **pytest**, le framework de test moderne\n",
    "- Utiliser les **fixtures** pour du setup/teardown r√©utilisable\n",
    "- Param√©trer les tests avec **@pytest.mark.parametrize**\n",
    "- Utiliser le **mocking** pour isoler le code test√©\n",
    "- Organiser une suite de tests professionnelle\n",
    "\n",
    "## Pr√©requis\n",
    "\n",
    "- Python 3.7+\n",
    "- Connaissance de base de Python\n",
    "- Comprendre les fonctions et les classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pourquoi tester ?\n",
    "\n",
    "### Les 3 piliers des tests\n",
    "\n",
    "#### 1. Confiance\n",
    "Les tests vous donnent la **confiance** que votre code fonctionne comme pr√©vu.\n",
    "\n",
    "#### 2. R√©gression\n",
    "Les tests d√©tectent les **r√©gressions** : quand un changement casse du code existant.\n",
    "\n",
    "#### 3. Documentation\n",
    "Les tests servent de **documentation vivante** : ils montrent comment utiliser votre code.\n",
    "\n",
    "### Le co√ªt de ne pas tester\n",
    "\n",
    "- Bugs en production\n",
    "- Peur de refactoriser\n",
    "- Temps pass√© √† d√©boguer manuellement\n",
    "- Perte de confiance de l'√©quipe\n",
    "\n",
    "### ROI des tests\n",
    "\n",
    "```\n",
    "Temps pour √©crire un test    : 5-15 minutes\n",
    "Temps pour d√©boguer en prod  : 2-8 heures\n",
    "Co√ªt d'un bug en production  : $$$$\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. pytest vs unittest\n",
    "\n",
    "### unittest (biblioth√®que standard)\n",
    "\n",
    "```python\n",
    "import unittest\n",
    "\n",
    "class TestCalculatrice(unittest.TestCase):\n",
    "    def test_addition(self):\n",
    "        self.assertEqual(2 + 2, 4)\n",
    "```\n",
    "\n",
    "### pytest (moderne et pythonic)\n",
    "\n",
    "```python\n",
    "def test_addition():\n",
    "    assert 2 + 2 == 4\n",
    "```\n",
    "\n",
    "### Pourquoi pytest ?\n",
    "\n",
    "- ‚úÖ Syntaxe simple : `assert` natif\n",
    "- ‚úÖ Pas besoin de classes\n",
    "- ‚úÖ Fixtures puissantes\n",
    "- ‚úÖ Plugins riches\n",
    "- ‚úÖ Meilleurs messages d'erreur\n",
    "- ‚úÖ Compatible avec unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation de pytest\n",
    "!pip install pytest pytest-cov -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Premier test avec pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile calculatrice.py\n",
    "\"\"\"Module calculatrice pour d√©monstration de tests.\"\"\"\n",
    "\n",
    "def addition(a, b):\n",
    "    \"\"\"Additionne deux nombres.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "def soustraction(a, b):\n",
    "    \"\"\"Soustrait b de a.\"\"\"\n",
    "    return a - b\n",
    "\n",
    "def multiplication(a, b):\n",
    "    \"\"\"Multiplie deux nombres.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "def division(a, b):\n",
    "    \"\"\"Divise a par b.\"\"\"\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Division par z√©ro impossible\")\n",
    "    return a / b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test_calculatrice.py\n",
    "\"\"\"Tests pour le module calculatrice.\"\"\"\n",
    "import pytest\n",
    "from calculatrice import addition, soustraction, multiplication, division\n",
    "\n",
    "def test_addition():\n",
    "    \"\"\"Test de l'addition.\"\"\"\n",
    "    assert addition(2, 3) == 5\n",
    "    assert addition(-1, 1) == 0\n",
    "    assert addition(0, 0) == 0\n",
    "\n",
    "def test_soustraction():\n",
    "    \"\"\"Test de la soustraction.\"\"\"\n",
    "    assert soustraction(5, 3) == 2\n",
    "    assert soustraction(0, 5) == -5\n",
    "\n",
    "def test_multiplication():\n",
    "    \"\"\"Test de la multiplication.\"\"\"\n",
    "    assert multiplication(3, 4) == 12\n",
    "    assert multiplication(-2, 3) == -6\n",
    "    assert multiplication(0, 100) == 0\n",
    "\n",
    "def test_division():\n",
    "    \"\"\"Test de la division.\"\"\"\n",
    "    assert division(10, 2) == 5\n",
    "    assert division(7, 2) == 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex√©cuter les tests\n",
    "!pytest test_calculatrice.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convention de nommage\n",
    "\n",
    "pytest d√©couvre automatiquement les tests en suivant ces conventions :\n",
    "\n",
    "- **Fichiers** : `test_*.py` ou `*_test.py`\n",
    "- **Fonctions** : `def test_*():`\n",
    "- **Classes** : `class Test*:`\n",
    "- **M√©thodes** : `def test_*():`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. pytest.raises : Tester les exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test_exceptions.py\n",
    "\"\"\"Tests des exceptions.\"\"\"\n",
    "import pytest\n",
    "from calculatrice import division\n",
    "\n",
    "def test_division_par_zero():\n",
    "    \"\"\"Test que la division par z√©ro l√®ve une exception.\"\"\"\n",
    "    with pytest.raises(ValueError):\n",
    "        division(10, 0)\n",
    "\n",
    "def test_division_par_zero_message():\n",
    "    \"\"\"Test que le message d'erreur est correct.\"\"\"\n",
    "    with pytest.raises(ValueError, match=\"Division par z√©ro\"):\n",
    "        division(10, 0)\n",
    "\n",
    "def test_division_par_zero_detailed():\n",
    "    \"\"\"Test avec acc√®s √† l'exception.\"\"\"\n",
    "    with pytest.raises(ValueError) as exc_info:\n",
    "        division(10, 0)\n",
    "    \n",
    "    assert \"z√©ro\" in str(exc_info.value)\n",
    "    assert exc_info.type == ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_exceptions.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fixtures : Setup/Teardown r√©utilisable\n",
    "\n",
    "Les **fixtures** permettent de pr√©parer l'environnement de test et de le nettoyer apr√®s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test_fixtures.py\n",
    "\"\"\"D√©monstration des fixtures pytest.\"\"\"\n",
    "import pytest\n",
    "\n",
    "# Fixture simple\n",
    "@pytest.fixture\n",
    "def nombres_exemple():\n",
    "    \"\"\"Fixture qui retourne une liste de nombres.\"\"\"\n",
    "    return [1, 2, 3, 4, 5]\n",
    "\n",
    "# Fixture avec setup et teardown\n",
    "@pytest.fixture\n",
    "def fichier_temporaire():\n",
    "    \"\"\"Fixture qui cr√©e et supprime un fichier temporaire.\"\"\"\n",
    "    import tempfile\n",
    "    import os\n",
    "    \n",
    "    # Setup\n",
    "    fd, path = tempfile.mkstemp()\n",
    "    print(f\"\\nCr√©ation fichier: {path}\")\n",
    "    \n",
    "    # Le test utilise la fixture\n",
    "    yield path\n",
    "    \n",
    "    # Teardown\n",
    "    os.close(fd)\n",
    "    os.unlink(path)\n",
    "    print(f\"\\nSuppression fichier: {path}\")\n",
    "\n",
    "def test_somme(nombres_exemple):\n",
    "    \"\"\"Test utilisant la fixture nombres_exemple.\"\"\"\n",
    "    assert sum(nombres_exemple) == 15\n",
    "\n",
    "def test_longueur(nombres_exemple):\n",
    "    \"\"\"Autre test utilisant la m√™me fixture.\"\"\"\n",
    "    assert len(nombres_exemple) == 5\n",
    "\n",
    "def test_fichier(fichier_temporaire):\n",
    "    \"\"\"Test utilisant la fixture fichier_temporaire.\"\"\"\n",
    "    with open(fichier_temporaire, 'w') as f:\n",
    "        f.write(\"test data\")\n",
    "    \n",
    "    with open(fichier_temporaire, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    assert content == \"test data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_fixtures.py -v -s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scopes des fixtures\n",
    "\n",
    "Les fixtures peuvent avoir diff√©rents scopes :\n",
    "\n",
    "| Scope | Description | Utilisation |\n",
    "|-------|-------------|-------------|\n",
    "| `function` | Par d√©faut, recr√©√©e pour chaque test | Donn√©es de test simples |\n",
    "| `class` | Une fois par classe de tests | Tests group√©s |\n",
    "| `module` | Une fois par fichier de test | Connexion DB (co√ªteuse) |\n",
    "| `session` | Une fois pour toute la suite de tests | Configuration globale |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test_fixture_scopes.py\n",
    "\"\"\"D√©monstration des scopes de fixtures.\"\"\"\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture(scope=\"function\")\n",
    "def compteur_function():\n",
    "    \"\"\"Fixture function scope (d√©faut).\"\"\"\n",
    "    print(\"\\nSetup function fixture\")\n",
    "    return {\"count\": 0}\n",
    "\n",
    "@pytest.fixture(scope=\"module\")\n",
    "def compteur_module():\n",
    "    \"\"\"Fixture module scope.\"\"\"\n",
    "    print(\"\\nSetup module fixture (une fois)\")\n",
    "    return {\"count\": 0}\n",
    "\n",
    "def test_un(compteur_function, compteur_module):\n",
    "    compteur_function[\"count\"] += 1\n",
    "    compteur_module[\"count\"] += 1\n",
    "    print(f\"Test 1 - function: {compteur_function['count']}, module: {compteur_module['count']}\")\n",
    "\n",
    "def test_deux(compteur_function, compteur_module):\n",
    "    compteur_function[\"count\"] += 1\n",
    "    compteur_module[\"count\"] += 1\n",
    "    print(f\"Test 2 - function: {compteur_function['count']}, module: {compteur_module['count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_fixture_scopes.py -v -s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. @pytest.mark.parametrize : Tester plusieurs cas\n",
    "\n",
    "Plut√¥t que d'√©crire plusieurs tests similaires, utilisez `parametrize` !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test_parametrize.py\n",
    "\"\"\"D√©monstration de @pytest.mark.parametrize.\"\"\"\n",
    "import pytest\n",
    "from calculatrice import addition, division\n",
    "\n",
    "# Test param√©tr√© simple\n",
    "@pytest.mark.parametrize(\"a,b,resultat_attendu\", [\n",
    "    (2, 3, 5),\n",
    "    (0, 0, 0),\n",
    "    (-1, 1, 0),\n",
    "    (10, -5, 5),\n",
    "    (100, 200, 300),\n",
    "])\n",
    "def test_addition_parametree(a, b, resultat_attendu):\n",
    "    \"\"\"Test de l'addition avec plusieurs cas.\"\"\"\n",
    "    assert addition(a, b) == resultat_attendu\n",
    "\n",
    "# Test param√©tr√© avec IDs personnalis√©s\n",
    "@pytest.mark.parametrize(\"a,b,resultat_attendu\", [\n",
    "    (10, 2, 5),\n",
    "    (7, 2, 3.5),\n",
    "    (-10, 2, -5),\n",
    "], ids=[\"entiers\", \"decimaux\", \"negatifs\"])\n",
    "def test_division_parametree(a, b, resultat_attendu):\n",
    "    \"\"\"Test de la division avec IDs personnalis√©s.\"\"\"\n",
    "    assert division(a, b) == resultat_attendu\n",
    "\n",
    "# Parametrize multiple\n",
    "@pytest.mark.parametrize(\"a\", [1, 2, 3])\n",
    "@pytest.mark.parametrize(\"b\", [10, 20])\n",
    "def test_combinaisons(a, b):\n",
    "    \"\"\"Test avec toutes les combinaisons de a et b.\"\"\"\n",
    "    # 3 valeurs * 2 valeurs = 6 tests\n",
    "    assert addition(a, b) == a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_parametrize.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Mocking : Isoler le code test√©\n",
    "\n",
    "Le **mocking** permet de remplacer des d√©pendances externes (API, base de donn√©es, fichiers) par des objets contr√¥l√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile api_client.py\n",
    "\"\"\"Client API pour d√©monstration de mocking.\"\"\"\n",
    "import requests\n",
    "\n",
    "def get_user_data(user_id):\n",
    "    \"\"\"R√©cup√®re les donn√©es d'un utilisateur depuis une API.\"\"\"\n",
    "    response = requests.get(f\"https://api.example.com/users/{user_id}\")\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def get_user_name(user_id):\n",
    "    \"\"\"R√©cup√®re le nom d'un utilisateur.\"\"\"\n",
    "    data = get_user_data(user_id)\n",
    "    return data.get(\"name\", \"Inconnu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test_mocking.py\n",
    "\"\"\"Tests avec mocking.\"\"\"\n",
    "import pytest\n",
    "from unittest.mock import Mock, patch, MagicMock\n",
    "from api_client import get_user_name, get_user_data\n",
    "\n",
    "# Test avec patch pour remplacer requests.get\n",
    "@patch('api_client.requests.get')\n",
    "def test_get_user_data(mock_get):\n",
    "    \"\"\"Test avec mock de requests.get.\"\"\"\n",
    "    # Configurer le mock\n",
    "    mock_response = Mock()\n",
    "    mock_response.json.return_value = {\"id\": 1, \"name\": \"Alice\"}\n",
    "    mock_get.return_value = mock_response\n",
    "    \n",
    "    # Appeler la fonction\n",
    "    result = get_user_data(1)\n",
    "    \n",
    "    # V√©rifications\n",
    "    assert result == {\"id\": 1, \"name\": \"Alice\"}\n",
    "    mock_get.assert_called_once_with(\"https://api.example.com/users/1\")\n",
    "\n",
    "# Test avec patch d'une fonction interne\n",
    "@patch('api_client.get_user_data')\n",
    "def test_get_user_name(mock_get_user_data):\n",
    "    \"\"\"Test avec mock de get_user_data.\"\"\"\n",
    "    # Configurer le mock\n",
    "    mock_get_user_data.return_value = {\"id\": 1, \"name\": \"Bob\"}\n",
    "    \n",
    "    # Appeler la fonction\n",
    "    result = get_user_name(1)\n",
    "    \n",
    "    # V√©rifications\n",
    "    assert result == \"Bob\"\n",
    "    mock_get_user_data.assert_called_once_with(1)\n",
    "\n",
    "# Test avec patch comme context manager\n",
    "def test_get_user_name_context_manager():\n",
    "    \"\"\"Test avec patch en context manager.\"\"\"\n",
    "    with patch('api_client.get_user_data') as mock_func:\n",
    "        mock_func.return_value = {\"id\": 2, \"name\": \"Charlie\"}\n",
    "        \n",
    "        result = get_user_name(2)\n",
    "        \n",
    "        assert result == \"Charlie\"\n",
    "\n",
    "# Test avec side_effect pour simuler des exceptions\n",
    "@patch('api_client.requests.get')\n",
    "def test_get_user_data_error(mock_get):\n",
    "    \"\"\"Test avec simulation d'erreur.\"\"\"\n",
    "    mock_get.side_effect = requests.exceptions.RequestException(\"Network error\")\n",
    "    \n",
    "    with pytest.raises(requests.exceptions.RequestException):\n",
    "        get_user_data(999)\n",
    "\n",
    "# Import requests pour le test\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests -q\n",
    "!pytest test_mocking.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principales fonctions de mocking\n",
    "\n",
    "| Fonction | Usage |\n",
    "|----------|-------|\n",
    "| `Mock()` | Cr√©e un objet mock simple |\n",
    "| `MagicMock()` | Mock avec m√©thodes magiques (__str__, __len__, etc.) |\n",
    "| `patch()` | Remplace temporairement un objet |\n",
    "| `return_value` | Valeur retourn√©e par le mock |\n",
    "| `side_effect` | Exception ou liste de valeurs √† retourner |\n",
    "| `assert_called()` | V√©rifie que le mock a √©t√© appel√© |\n",
    "| `assert_called_once()` | V√©rifie qu'il a √©t√© appel√© une seule fois |\n",
    "| `assert_called_with()` | V√©rifie les arguments d'appel |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Markers : Organisation des tests\n",
    "\n",
    "Les **markers** permettent de cat√©goriser et filtrer les tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test_markers.py\n",
    "\"\"\"D√©monstration des markers pytest.\"\"\"\n",
    "import pytest\n",
    "import time\n",
    "\n",
    "@pytest.mark.slow\n",
    "def test_operation_lente():\n",
    "    \"\"\"Test marqu√© comme lent.\"\"\"\n",
    "    time.sleep(0.1)\n",
    "    assert True\n",
    "\n",
    "@pytest.mark.fast\n",
    "def test_operation_rapide():\n",
    "    \"\"\"Test marqu√© comme rapide.\"\"\"\n",
    "    assert 1 + 1 == 2\n",
    "\n",
    "@pytest.mark.skip(reason=\"Fonctionnalit√© pas encore impl√©ment√©e\")\n",
    "def test_future_feature():\n",
    "    \"\"\"Test √† ignorer.\"\"\"\n",
    "    assert False\n",
    "\n",
    "@pytest.mark.skipif(pytest.__version__ < \"7.0\", reason=\"N√©cessite pytest 7+\")\n",
    "def test_nouvelle_fonctionnalite():\n",
    "    \"\"\"Test conditionnel.\"\"\"\n",
    "    assert True\n",
    "\n",
    "@pytest.mark.xfail(reason=\"Bug connu #123\")\n",
    "def test_avec_bug_connu():\n",
    "    \"\"\"Test qui devrait √©chouer (xfail = expected failure).\"\"\"\n",
    "    assert 1 / 0  # On sait que √ßa √©choue\n",
    "\n",
    "@pytest.mark.integration\n",
    "def test_integration_database():\n",
    "    \"\"\"Test d'int√©gration (marker custom).\"\"\"\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex√©cuter tous les tests\n",
    "!pytest test_markers.py -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex√©cuter seulement les tests rapides\n",
    "!pytest test_markers.py -v -m fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex√©cuter sauf les tests lents\n",
    "!pytest test_markers.py -v -m \"not slow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. conftest.py : Partager des fixtures\n",
    "\n",
    "Le fichier `conftest.py` permet de d√©finir des fixtures partag√©es entre plusieurs fichiers de tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile conftest.py\n",
    "\"\"\"Configuration partag√©e pour tous les tests.\"\"\"\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture(scope=\"session\")\n",
    "def config():\n",
    "    \"\"\"Configuration globale pour les tests.\"\"\"\n",
    "    return {\n",
    "        \"api_url\": \"https://api.test.example.com\",\n",
    "        \"timeout\": 30,\n",
    "        \"debug\": True\n",
    "    }\n",
    "\n",
    "@pytest.fixture\n",
    "def sample_data():\n",
    "    \"\"\"Donn√©es d'exemple pour les tests.\"\"\"\n",
    "    return [\n",
    "        {\"id\": 1, \"name\": \"Alice\", \"age\": 30},\n",
    "        {\"id\": 2, \"name\": \"Bob\", \"age\": 25},\n",
    "        {\"id\": 3, \"name\": \"Charlie\", \"age\": 35},\n",
    "    ]\n",
    "\n",
    "@pytest.fixture\n",
    "def mock_database():\n",
    "    \"\"\"Simulation d'une base de donn√©es.\"\"\"\n",
    "    class MockDB:\n",
    "        def __init__(self):\n",
    "            self.data = {}\n",
    "        \n",
    "        def insert(self, key, value):\n",
    "            self.data[key] = value\n",
    "        \n",
    "        def get(self, key):\n",
    "            return self.data.get(key)\n",
    "        \n",
    "        def clear(self):\n",
    "            self.data.clear()\n",
    "    \n",
    "    db = MockDB()\n",
    "    yield db\n",
    "    db.clear()  # Cleanup\n",
    "\n",
    "# Configuration des markers custom\n",
    "def pytest_configure(config):\n",
    "    config.addinivalue_line(\n",
    "        \"markers\", \"slow: marks tests as slow (deselect with '-m \\\"not slow\\\"')\"\n",
    "    )\n",
    "    config.addinivalue_line(\n",
    "        \"markers\", \"fast: marks tests as fast\"\n",
    "    )\n",
    "    config.addinivalue_line(\n",
    "        \"markers\", \"integration: marks tests as integration tests\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test_with_conftest.py\n",
    "\"\"\"Tests utilisant les fixtures de conftest.py.\"\"\"\n",
    "\n",
    "def test_config(config):\n",
    "    \"\"\"Test utilisant la fixture config.\"\"\"\n",
    "    assert config[\"api_url\"] == \"https://api.test.example.com\"\n",
    "    assert config[\"timeout\"] == 30\n",
    "\n",
    "def test_sample_data(sample_data):\n",
    "    \"\"\"Test utilisant la fixture sample_data.\"\"\"\n",
    "    assert len(sample_data) == 3\n",
    "    assert sample_data[0][\"name\"] == \"Alice\"\n",
    "\n",
    "def test_mock_database(mock_database):\n",
    "    \"\"\"Test utilisant la fixture mock_database.\"\"\"\n",
    "    mock_database.insert(\"user:1\", {\"name\": \"Test User\"})\n",
    "    user = mock_database.get(\"user:1\")\n",
    "    assert user[\"name\"] == \"Test User\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_with_conftest.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pi√®ges courants\n",
    "\n",
    "### 1. Tests coupl√©s (d√©pendants les uns des autres)\n",
    "\n",
    "```python\n",
    "# ‚ùå MAUVAIS : Les tests partagent un √©tat\n",
    "compteur = 0\n",
    "\n",
    "def test_un():\n",
    "    global compteur\n",
    "    compteur += 1\n",
    "    assert compteur == 1\n",
    "\n",
    "def test_deux():\n",
    "    global compteur\n",
    "    compteur += 1\n",
    "    assert compteur == 2  # √âchoue si test_un n'est pas ex√©cut√© avant\n",
    "\n",
    "# ‚úÖ BON : Chaque test est ind√©pendant\n",
    "@pytest.fixture\n",
    "def compteur():\n",
    "    return 0\n",
    "\n",
    "def test_un(compteur):\n",
    "    compteur += 1\n",
    "    assert compteur == 1\n",
    "\n",
    "def test_deux(compteur):\n",
    "    compteur += 1\n",
    "    assert compteur == 1  # Toujours OK\n",
    "```\n",
    "\n",
    "### 2. Fixtures trop complexes\n",
    "\n",
    "```python\n",
    "# ‚ùå MAUVAIS : Fixture qui fait trop de choses\n",
    "@pytest.fixture\n",
    "def setup_everything():\n",
    "    # Cr√©e DB, API, fichiers, etc.\n",
    "    # 100 lignes de code...\n",
    "    pass\n",
    "\n",
    "# ‚úÖ BON : Fixtures modulaires\n",
    "@pytest.fixture\n",
    "def database():\n",
    "    # ...\n",
    "\n",
    "@pytest.fixture\n",
    "def api_client():\n",
    "    # ...\n",
    "\n",
    "@pytest.fixture\n",
    "def test_files():\n",
    "    # ...\n",
    "```\n",
    "\n",
    "### 3. Mocker trop (tester l'impl√©mentation)\n",
    "\n",
    "```python\n",
    "# ‚ùå MAUVAIS : Trop de mocking\n",
    "@patch('module.function_a')\n",
    "@patch('module.function_b')\n",
    "@patch('module.function_c')\n",
    "def test_complex(mock_c, mock_b, mock_a):\n",
    "    # On teste les mocks, pas le code !\n",
    "    pass\n",
    "\n",
    "# ‚úÖ BON : Mocker seulement les d√©pendances externes\n",
    "@patch('module.external_api_call')\n",
    "def test_logic(mock_api):\n",
    "    # Tester la logique m√©tier\n",
    "    pass\n",
    "```\n",
    "\n",
    "### 4. Ne pas tester les cas limites\n",
    "\n",
    "```python\n",
    "# ‚ùå MAUVAIS : Tester seulement le cas nominal\n",
    "def test_division():\n",
    "    assert division(10, 2) == 5\n",
    "\n",
    "# ‚úÖ BON : Tester les cas limites\n",
    "@pytest.mark.parametrize(\"a,b,expected\", [\n",
    "    (10, 2, 5),      # Cas normal\n",
    "    (0, 5, 0),       # Z√©ro au num√©rateur\n",
    "    (10, 3, 10/3),   # R√©sultat d√©cimal\n",
    "    (-10, 2, -5),    # N√©gatif\n",
    "])\n",
    "def test_division_complete(a, b, expected):\n",
    "    assert division(a, b) == expected\n",
    "\n",
    "def test_division_par_zero():\n",
    "    with pytest.raises(ValueError):\n",
    "        division(10, 0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Exercices\n",
    "\n",
    "### Exercice 1 : Tester une fonction de validation\n",
    "\n",
    "√âcrivez des tests pour cette fonction de validation d'email :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile email_validator.py\n",
    "import re\n",
    "\n",
    "def valider_email(email):\n",
    "    \"\"\"Valide un email simple.\"\"\"\n",
    "    if not email:\n",
    "        raise ValueError(\"Email vide\")\n",
    "    \n",
    "    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "    if not re.match(pattern, email):\n",
    "        raise ValueError(\"Email invalide\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âcrivez vos tests ici\n",
    "# Testez au moins :\n",
    "# - Emails valides\n",
    "# - Emails invalides\n",
    "# - Email vide\n",
    "# - None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2 : Fixture pour une base de donn√©es mock\n",
    "\n",
    "Cr√©ez une fixture qui simule une base de donn√©es avec insert, get, delete :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre fixture ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 3 : Tests param√©tr√©s\n",
    "\n",
    "√âcrivez un test param√©tr√© pour cette fonction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile string_utils.py\n",
    "def est_palindrome(texte):\n",
    "    \"\"\"V√©rifie si un texte est un palindrome (ignore la casse et les espaces).\"\"\"\n",
    "    texte_nettoye = texte.lower().replace(\" \", \"\")\n",
    "    return texte_nettoye == texte_nettoye[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# √âcrivez un test param√©tr√© avec au moins 5 cas de test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Exercice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test_email_validator.py\n",
    "import pytest\n",
    "from email_validator import valider_email\n",
    "\n",
    "@pytest.mark.parametrize(\"email\", [\n",
    "    \"user@example.com\",\n",
    "    \"john.doe@company.fr\",\n",
    "    \"test+tag@domain.co.uk\",\n",
    "    \"user123@test-domain.com\",\n",
    "])\n",
    "def test_emails_valides(email):\n",
    "    \"\"\"Test des emails valides.\"\"\"\n",
    "    assert valider_email(email) is True\n",
    "\n",
    "@pytest.mark.parametrize(\"email\", [\n",
    "    \"invalid\",\n",
    "    \"@example.com\",\n",
    "    \"user@\",\n",
    "    \"user @example.com\",\n",
    "    \"user@example\",\n",
    "])\n",
    "def test_emails_invalides(email):\n",
    "    \"\"\"Test des emails invalides.\"\"\"\n",
    "    with pytest.raises(ValueError, match=\"Email invalide\"):\n",
    "        valider_email(email)\n",
    "\n",
    "def test_email_vide():\n",
    "    \"\"\"Test avec email vide.\"\"\"\n",
    "    with pytest.raises(ValueError, match=\"Email vide\"):\n",
    "        valider_email(\"\")\n",
    "\n",
    "def test_email_none():\n",
    "    \"\"\"Test avec None.\"\"\"\n",
    "    with pytest.raises(ValueError, match=\"Email vide\"):\n",
    "        valider_email(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_email_validator.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Exercice 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test_database_fixture.py\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def mock_database():\n",
    "    \"\"\"Fixture simulant une base de donn√©es.\"\"\"\n",
    "    class MockDatabase:\n",
    "        def __init__(self):\n",
    "            self.storage = {}\n",
    "        \n",
    "        def insert(self, key, value):\n",
    "            if key in self.storage:\n",
    "                raise ValueError(f\"Cl√© {key} existe d√©j√†\")\n",
    "            self.storage[key] = value\n",
    "        \n",
    "        def get(self, key):\n",
    "            if key not in self.storage:\n",
    "                raise KeyError(f\"Cl√© {key} introuvable\")\n",
    "            return self.storage[key]\n",
    "        \n",
    "        def delete(self, key):\n",
    "            if key not in self.storage:\n",
    "                raise KeyError(f\"Cl√© {key} introuvable\")\n",
    "            del self.storage[key]\n",
    "        \n",
    "        def clear(self):\n",
    "            self.storage.clear()\n",
    "    \n",
    "    db = MockDatabase()\n",
    "    yield db\n",
    "    db.clear()\n",
    "\n",
    "def test_insert(mock_database):\n",
    "    \"\"\"Test de l'insertion.\"\"\"\n",
    "    mock_database.insert(\"key1\", \"value1\")\n",
    "    assert mock_database.get(\"key1\") == \"value1\"\n",
    "\n",
    "def test_get_inexistant(mock_database):\n",
    "    \"\"\"Test get sur cl√© inexistante.\"\"\"\n",
    "    with pytest.raises(KeyError):\n",
    "        mock_database.get(\"nonexistent\")\n",
    "\n",
    "def test_delete(mock_database):\n",
    "    \"\"\"Test de suppression.\"\"\"\n",
    "    mock_database.insert(\"key1\", \"value1\")\n",
    "    mock_database.delete(\"key1\")\n",
    "    with pytest.raises(KeyError):\n",
    "        mock_database.get(\"key1\")\n",
    "\n",
    "def test_insert_duplicate(mock_database):\n",
    "    \"\"\"Test insertion de doublon.\"\"\"\n",
    "    mock_database.insert(\"key1\", \"value1\")\n",
    "    with pytest.raises(ValueError):\n",
    "        mock_database.insert(\"key1\", \"value2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_database_fixture.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution Exercice 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test_palindrome.py\n",
    "import pytest\n",
    "from string_utils import est_palindrome\n",
    "\n",
    "@pytest.mark.parametrize(\"texte,attendu\", [\n",
    "    (\"radar\", True),\n",
    "    (\"kayak\", True),\n",
    "    (\"A man a plan a canal Panama\", True),\n",
    "    (\"Was it a car or a cat I saw\", True),\n",
    "    (\"Engage le jeu que je le gagne\", True),\n",
    "    (\"hello\", False),\n",
    "    (\"python\", False),\n",
    "    (\"\", True),  # Cha√Æne vide est un palindrome\n",
    "    (\"a\", True),  # Un seul caract√®re\n",
    "], ids=[\n",
    "    \"radar\",\n",
    "    \"kayak\",\n",
    "    \"panama\",\n",
    "    \"cat_or_car\",\n",
    "    \"francais\",\n",
    "    \"non_palindrome_hello\",\n",
    "    \"non_palindrome_python\",\n",
    "    \"vide\",\n",
    "    \"un_caractere\",\n",
    "])\n",
    "def test_palindrome(texte, attendu):\n",
    "    \"\"\"Test de la fonction est_palindrome.\"\"\"\n",
    "    assert est_palindrome(texte) == attendu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest test_palindrome.py -v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
