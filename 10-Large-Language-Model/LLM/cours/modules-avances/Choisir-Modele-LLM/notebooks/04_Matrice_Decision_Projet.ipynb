{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Matrice de D√©cision Personnalis√©e - Votre Outil de Choix\n",
    "\n",
    "## üéØ Objectifs\n",
    "- **Cr√©er** votre outil personnalis√© de s√©lection de mod√®les\n",
    "- **Automatiser** le processus de recommandation\n",
    "- **Adapter** les crit√®res √† vos besoins sp√©cifiques\n",
    "- **G√©n√©rer** un rapport de d√©cision justifi√©\n",
    "\n",
    "---\n",
    "\n",
    "## ü§î Pourquoi une Matrice Personnalis√©e ?\n",
    "\n",
    "### Le Probl√®me :\n",
    "- ü§Ø **Trop de variables** : Performance, co√ªt, latence, privacy...\n",
    "- ‚öñÔ∏è **Pond√©ration subjective** : Vos priorit√©s ‚â† celles des autres\n",
    "- üîÑ **√âvolution constante** : Nouveaux mod√®les chaque mois\n",
    "- üìä **D√©cision complexe** : Pas de \"bon\" choix universel\n",
    "\n",
    "### La Solution :\n",
    "Un outil qui :\n",
    "- üìã **Capture vos crit√®res** sp√©cifiques\n",
    "- ü§ñ **Calcule automatiquement** les scores\n",
    "- üìä **Visualise** les trade-offs\n",
    "- üìÑ **G√©n√®re un rapport** justifi√©\n",
    "- üîÑ **Se met √† jour** facilement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Installation et Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (0.13.2)\n",
      "Requirement already satisfied: plotly in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (6.1.2)\n",
      "Requirement already satisfied: ipywidgets in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (8.1.7)\n",
      "Requirement already satisfied: numpy in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (2.2.2)\n",
      "Collecting datetime\n",
      "  Downloading DateTime-5.5-py3-none-any.whl.metadata (33 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from matplotlib) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from plotly) (1.24.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from ipywidgets) (9.3.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from ipywidgets) (3.0.15)\n",
      "Collecting zope.interface (from datetime)\n",
      "  Downloading zope.interface-7.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (44 kB)\n",
      "Requirement already satisfied: decorator in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: setuptools in /Users/guillaume/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from zope.interface->datetime) (75.8.0)\n",
      "Downloading DateTime-5.5-py3-none-any.whl (52 kB)\n",
      "Downloading zope.interface-7.2-cp313-cp313-macosx_11_0_arm64.whl (209 kB)\n",
      "Installing collected packages: zope.interface, datetime\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2/2\u001b[0m [datetime]\n",
      "\u001b[1A\u001b[2KSuccessfully installed datetime-5.5 zope.interface-7.2\n"
     ]
    }
   ],
   "source": [
    "# Installation des d√©pendances\n",
    "!pip install pandas matplotlib seaborn plotly ipywidgets numpy datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports termin√©s !\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Imports termin√©s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üóÉÔ∏è Base de Donn√©es des Mod√®les (Mise √† Jour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Base de donn√©es cr√©√©e avec 10 mod√®les\n",
      "üìã Mod√®les inclus:\n",
      "  ‚Ä¢ GPT-4           (Propri√©taire, OpenAI)\n",
      "  ‚Ä¢ GPT-3.5 Turbo   (Propri√©taire, OpenAI)\n",
      "  ‚Ä¢ Claude 3 Opus   (Propri√©taire, Anthropic)\n",
      "  ‚Ä¢ Claude 3 Sonnet (Propri√©taire, Anthropic)\n",
      "  ‚Ä¢ Gemini Pro      (Propri√©taire, Google)\n",
      "  ‚Ä¢ Llama 2 70B     (Open Source, Meta)\n",
      "  ‚Ä¢ Llama 2 13B     (Open Source, Meta)\n",
      "  ‚Ä¢ Mistral 7B      (Open Source, Mistral AI)\n",
      "  ‚Ä¢ CodeLlama 34B   (Open Source, Meta)\n",
      "  ‚Ä¢ Phi-3 Mini      (Open Source, Microsoft)\n"
     ]
    }
   ],
   "source": [
    "# Base de donn√©es compl√®te et actualis√©e des mod√®les\n",
    "MODELS_DATABASE = {\n",
    "    'GPT-4': {\n",
    "        'type': 'Propri√©taire',\n",
    "        'creator': 'OpenAI',\n",
    "        'release_date': '2023-03',\n",
    "        'context_length': 128000,\n",
    "        'performance_mmlu': 86.4,\n",
    "        'performance_hellaswag': 95.3,\n",
    "        'performance_humaneval': 67.0,\n",
    "        'performance_truthfulqa': 59.0,\n",
    "        'cost_1m_tokens': 30.0,\n",
    "        'latency_avg_seconds': 3.5,\n",
    "        'privacy_score': 2,  # 1-10, 10=local\n",
    "        'integration_difficulty': 1,  # 1-10, 1=tr√®s facile\n",
    "        'scalability_score': 10,  # 1-10, 10=excellent\n",
    "        'specialties': ['G√©n√©raliste Premium', 'Raisonnement Complexe'],\n",
    "        'pros': ['Excellente qualit√©', 'API mature', 'Large √©cosyst√®me'],\n",
    "        'cons': ['Tr√®s co√ªteux', 'Latence √©lev√©e', 'Donn√©es envoy√©es √† OpenAI']\n",
    "    },\n",
    "    \n",
    "    'GPT-3.5 Turbo': {\n",
    "        'type': 'Propri√©taire',\n",
    "        'creator': 'OpenAI',\n",
    "        'release_date': '2022-11',\n",
    "        'context_length': 16385,\n",
    "        'performance_mmlu': 70.0,\n",
    "        'performance_hellaswag': 85.5,\n",
    "        'performance_humaneval': 48.1,\n",
    "        'performance_truthfulqa': 47.3,\n",
    "        'cost_1m_tokens': 1.0,\n",
    "        'latency_avg_seconds': 1.2,\n",
    "        'privacy_score': 2,\n",
    "        'integration_difficulty': 1,\n",
    "        'scalability_score': 10,\n",
    "        'specialties': ['G√©n√©raliste Rapide', 'Bon Rapport Qualit√©/Prix'],\n",
    "        'pros': ['Rapport qualit√©/prix', 'API rapide', 'Largement test√©'],\n",
    "        'cons': ['Qualit√© moindre que GPT-4', 'Donn√©es externalis√©es']\n",
    "    },\n",
    "    \n",
    "    'Claude 3 Opus': {\n",
    "        'type': 'Propri√©taire',\n",
    "        'creator': 'Anthropic',\n",
    "        'release_date': '2024-03',\n",
    "        'context_length': 200000,\n",
    "        'performance_mmlu': 86.8,\n",
    "        'performance_hellaswag': 95.4,\n",
    "        'performance_humaneval': 84.9,\n",
    "        'performance_truthfulqa': 69.3,\n",
    "        'cost_1m_tokens': 15.0,\n",
    "        'latency_avg_seconds': 2.8,\n",
    "        'privacy_score': 2,\n",
    "        'integration_difficulty': 2,\n",
    "        'scalability_score': 9,\n",
    "        'specialties': ['S√©curit√©', 'Analyse de Documents', '√âthique'],\n",
    "        'pros': ['Tr√®s s√©curis√©', 'Long contexte', 'Excellent en analyse'],\n",
    "        'cons': ['Co√ªteux', 'Parfois trop prudent', 'API moins mature']\n",
    "    },\n",
    "    \n",
    "    'Claude 3 Sonnet': {\n",
    "        'type': 'Propri√©taire',\n",
    "        'creator': 'Anthropic',\n",
    "        'release_date': '2024-03',\n",
    "        'context_length': 200000,\n",
    "        'performance_mmlu': 79.0,\n",
    "        'performance_hellaswag': 89.0,\n",
    "        'performance_humaneval': 73.0,\n",
    "        'performance_truthfulqa': 58.5,\n",
    "        'cost_1m_tokens': 3.0,\n",
    "        'latency_avg_seconds': 1.8,\n",
    "        'privacy_score': 2,\n",
    "        'integration_difficulty': 2,\n",
    "        'scalability_score': 9,\n",
    "        'specialties': ['√âquilibr√©', 'Professionnel', 'Analyse'],\n",
    "        'pros': ['Bon √©quilibre', 'Long contexte', 'S√©curis√©'],\n",
    "        'cons': ['API r√©cente', 'Moins cr√©atif que GPT-4']\n",
    "    },\n",
    "    \n",
    "    'Gemini Pro': {\n",
    "        'type': 'Propri√©taire',\n",
    "        'creator': 'Google',\n",
    "        'release_date': '2023-12',\n",
    "        'context_length': 32768,\n",
    "        'performance_mmlu': 83.7,\n",
    "        'performance_hellaswag': 92.0,\n",
    "        'performance_humaneval': 32.3,\n",
    "        'performance_truthfulqa': 47.3,\n",
    "        'cost_1m_tokens': 2.5,\n",
    "        'latency_avg_seconds': 2.0,\n",
    "        'privacy_score': 2,\n",
    "        'integration_difficulty': 3,\n",
    "        'scalability_score': 8,\n",
    "        'specialties': ['Multimodal', 'Int√©gration Google', 'Recherche'],\n",
    "        'pros': ['Multimodal natif', 'Int√©gration Google', 'Prix comp√©titif'],\n",
    "        'cons': ['√âcosyst√®me moins mature', 'Performance code moyenne']\n",
    "    },\n",
    "    \n",
    "    'Llama 2 70B': {\n",
    "        'type': 'Open Source',\n",
    "        'creator': 'Meta',\n",
    "        'release_date': '2023-07',\n",
    "        'context_length': 4096,\n",
    "        'performance_mmlu': 68.9,\n",
    "        'performance_hellaswag': 87.3,\n",
    "        'performance_humaneval': 29.9,\n",
    "        'performance_truthfulqa': 52.8,\n",
    "        'cost_1m_tokens': 0.0,  # Open source\n",
    "        'hosting_cost_monthly': 2000,  # GPU A100 x2\n",
    "        'latency_avg_seconds': 5.0,\n",
    "        'privacy_score': 10,\n",
    "        'integration_difficulty': 7,\n",
    "        'scalability_score': 6,\n",
    "        'specialties': ['G√©n√©raliste Open Source', 'Personnalisable'],\n",
    "        'pros': ['Contr√¥le total', 'Donn√©es priv√©es', 'Fine-tuning facile'],\n",
    "        'cons': ['Infrastructure complexe', 'Support communautaire']\n",
    "    },\n",
    "    \n",
    "    'Llama 2 13B': {\n",
    "        'type': 'Open Source',\n",
    "        'creator': 'Meta',\n",
    "        'release_date': '2023-07',\n",
    "        'context_length': 4096,\n",
    "        'performance_mmlu': 54.8,\n",
    "        'performance_hellaswag': 82.1,\n",
    "        'performance_humaneval': 18.3,\n",
    "        'performance_truthfulqa': 47.1,\n",
    "        'cost_1m_tokens': 0.0,\n",
    "        'hosting_cost_monthly': 800,  # GPU A100\n",
    "        'latency_avg_seconds': 2.5,\n",
    "        'privacy_score': 10,\n",
    "        'integration_difficulty': 6,\n",
    "        'scalability_score': 7,\n",
    "        'specialties': ['G√©n√©raliste Compact', 'Bon Compromis'],\n",
    "        'pros': ['√âquilibre taille/performance', 'Moins cher √† h√©berger'],\n",
    "        'cons': ['Performance limit√©e', 'Setup technique']\n",
    "    },\n",
    "    \n",
    "    'Mistral 7B': {\n",
    "        'type': 'Open Source',\n",
    "        'creator': 'Mistral AI',\n",
    "        'release_date': '2023-09',\n",
    "        'context_length': 32768,\n",
    "        'performance_mmlu': 62.5,\n",
    "        'performance_hellaswag': 83.3,\n",
    "        'performance_humaneval': 29.8,\n",
    "        'performance_truthfulqa': 50.3,\n",
    "        'cost_1m_tokens': 0.0,\n",
    "        'hosting_cost_monthly': 300,  # RTX 4090\n",
    "        'latency_avg_seconds': 1.0,\n",
    "        'privacy_score': 10,\n",
    "        'integration_difficulty': 5,\n",
    "        'scalability_score': 8,\n",
    "        'specialties': ['Compact Efficace', 'Europ√©en', 'Rapide'],\n",
    "        'pros': ['Tr√®s rapide', 'Excellent rapport taille/perf', 'Fran√ßais'],\n",
    "        'cons': ['Contexte limit√© vs gros mod√®les', 'Communaut√© plus petite']\n",
    "    },\n",
    "    \n",
    "    'CodeLlama 34B': {\n",
    "        'type': 'Open Source',\n",
    "        'creator': 'Meta',\n",
    "        'release_date': '2023-08',\n",
    "        'context_length': 16384,\n",
    "        'performance_mmlu': 53.7,\n",
    "        'performance_hellaswag': 76.2,\n",
    "        'performance_humaneval': 48.0,\n",
    "        'performance_truthfulqa': 43.6,\n",
    "        'cost_1m_tokens': 0.0,\n",
    "        'hosting_cost_monthly': 1500,  # GPU sp√©cialis√©\n",
    "        'latency_avg_seconds': 4.0,\n",
    "        'privacy_score': 10,\n",
    "        'integration_difficulty': 6,\n",
    "        'scalability_score': 6,\n",
    "        'specialties': ['Code', 'Programmation', 'Debugging'],\n",
    "        'pros': ['Excellent pour le code', 'Open source', 'Sp√©cialis√©'],\n",
    "        'cons': ['Faible sur t√¢ches g√©n√©rales', 'Gros en taille']\n",
    "    },\n",
    "    \n",
    "    'Phi-3 Mini': {\n",
    "        'type': 'Open Source',\n",
    "        'creator': 'Microsoft',\n",
    "        'release_date': '2024-04',\n",
    "        'context_length': 128000,\n",
    "        'performance_mmlu': 68.8,\n",
    "        'performance_hellaswag': 82.4,\n",
    "        'performance_humaneval': 62.2,\n",
    "        'performance_truthfulqa': 44.1,\n",
    "        'cost_1m_tokens': 0.0,\n",
    "        'hosting_cost_monthly': 200,  # GPU consumer\n",
    "        'latency_avg_seconds': 0.8,\n",
    "        'privacy_score': 10,\n",
    "        'integration_difficulty': 4,\n",
    "        'scalability_score': 9,\n",
    "        'specialties': ['Ultra Compact', 'Edge Computing', 'Mobile'],\n",
    "        'pros': ['Tr√®s petit et rapide', 'Long contexte', 'Edge deployment'],\n",
    "        'cons': ['Performance limit√©e vs gros mod√®les', 'Nouveau']\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"üìä Base de donn√©es cr√©√©e avec {len(MODELS_DATABASE)} mod√®les\")\n",
    "print(\"üìã Mod√®les inclus:\")\n",
    "for model_name, data in MODELS_DATABASE.items():\n",
    "    print(f\"  ‚Ä¢ {model_name:15s} ({data['type']}, {data['creator']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßÆ Calculateur de Score Avanc√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßÆ Calculateur de d√©cision initialis√© !\n"
     ]
    }
   ],
   "source": [
    "class LLMDecisionMatrix:\n",
    "    \"\"\"\n",
    "    Matrice de d√©cision avanc√©e pour la s√©lection de mod√®les LLM\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, models_database):\n",
    "        self.models_db = models_database\n",
    "        self.criteria_weights = {}\n",
    "        self.user_profile = {}\n",
    "        self.results = None\n",
    "    \n",
    "    def set_user_profile(self, profile):\n",
    "        \"\"\"\n",
    "        D√©finit le profil utilisateur avec contraintes et pr√©f√©rences\n",
    "        \"\"\"\n",
    "        self.user_profile = profile\n",
    "        \n",
    "    def set_criteria_weights(self, weights):\n",
    "        \"\"\"\n",
    "        D√©finit la pond√©ration des crit√®res (somme = 1.0)\n",
    "        \"\"\"\n",
    "        total = sum(weights.values())\n",
    "        self.criteria_weights = {k: v/total for k, v in weights.items()}\n",
    "    \n",
    "    def calculate_cost_score(self, model_data, monthly_requests):\n",
    "        \"\"\"\n",
    "        Calcule le score de co√ªt (0-100, 100=gratuit/tr√®s bon march√©)\n",
    "        \"\"\"\n",
    "        if model_data['type'] == 'Open Source':\n",
    "            # Co√ªt fixe d'h√©bergement\n",
    "            monthly_cost = model_data.get('hosting_cost_monthly', 500)\n",
    "        else:\n",
    "            # Co√ªt proportionnel API\n",
    "            avg_tokens_per_request = 1000  # Estimation\n",
    "            monthly_tokens = monthly_requests * avg_tokens_per_request\n",
    "            monthly_cost = (monthly_tokens / 1_000_000) * model_data['cost_1m_tokens']\n",
    "        \n",
    "        # Normaliser (co√ªt max arbitraire: 5000$/mois = score 0)\n",
    "        max_acceptable_cost = 5000\n",
    "        if monthly_cost == 0:\n",
    "            return 100\n",
    "        \n",
    "        score = max(0, 100 - (monthly_cost / max_acceptable_cost * 100))\n",
    "        return min(100, score)\n",
    "    \n",
    "    def calculate_performance_score(self, model_data):\n",
    "        \"\"\"\n",
    "        Calcule le score de performance pond√©r√© selon les besoins\n",
    "        \"\"\"\n",
    "        # Pond√©ration selon le type d'usage\n",
    "        task_weights = {\n",
    "            'general': {'mmlu': 0.4, 'hellaswag': 0.3, 'truthfulqa': 0.3},\n",
    "            'code': {'humaneval': 0.6, 'mmlu': 0.2, 'hellaswag': 0.2},\n",
    "            'creative': {'hellaswag': 0.4, 'mmlu': 0.3, 'truthfulqa': 0.3},\n",
    "            'analytical': {'mmlu': 0.5, 'truthfulqa': 0.3, 'hellaswag': 0.2}\n",
    "        }\n",
    "        \n",
    "        task_type = self.user_profile.get('primary_task', 'general')\n",
    "        weights = task_weights.get(task_type, task_weights['general'])\n",
    "        \n",
    "        score = (\n",
    "            model_data['performance_mmlu'] * weights.get('mmlu', 0) +\n",
    "            model_data['performance_hellaswag'] * weights.get('hellaswag', 0) +\n",
    "            model_data['performance_humaneval'] * weights.get('humaneval', 0) +\n",
    "            model_data['performance_truthfulqa'] * weights.get('truthfulqa', 0)\n",
    "        )\n",
    "        \n",
    "        return min(100, score)\n",
    "    \n",
    "    def calculate_speed_score(self, model_data):\n",
    "        \"\"\"\n",
    "        Calcule le score de vitesse (0-100, 100=tr√®s rapide)\n",
    "        \"\"\"\n",
    "        # Latence max acceptable: 10 secondes = score 0\n",
    "        max_latency = 10.0\n",
    "        latency = model_data['latency_avg_seconds']\n",
    "        \n",
    "        score = max(0, 100 - (latency / max_latency * 100))\n",
    "        return score\n",
    "    \n",
    "    def calculate_privacy_score(self, model_data):\n",
    "        \"\"\"\n",
    "        Score de confidentialit√© (d√©j√† 0-10, normaliser √† 0-100)\n",
    "        \"\"\"\n",
    "        return model_data['privacy_score'] * 10\n",
    "    \n",
    "    def calculate_integration_score(self, model_data):\n",
    "        \"\"\"\n",
    "        Score de facilit√© d'int√©gration (0-100, 100=tr√®s facile)\n",
    "        \"\"\"\n",
    "        # Inverser la difficult√© (1=facile, 10=difficile)\n",
    "        difficulty = model_data['integration_difficulty']\n",
    "        score = (11 - difficulty) * 10\n",
    "        return min(100, score)\n",
    "    \n",
    "    def apply_constraints(self, model_data):\n",
    "        \"\"\"\n",
    "        Applique les contraintes hard (√©liminatoires)\n",
    "        \"\"\"\n",
    "        constraints = self.user_profile.get('constraints', {})\n",
    "        \n",
    "        # Contrainte de budget\n",
    "        max_monthly_budget = constraints.get('max_monthly_budget')\n",
    "        if max_monthly_budget:\n",
    "            monthly_requests = self.user_profile.get('monthly_requests', 10000)\n",
    "            if model_data['type'] == 'Open Source':\n",
    "                cost = model_data.get('hosting_cost_monthly', 500)\n",
    "            else:\n",
    "                avg_tokens = 1000\n",
    "                monthly_tokens = monthly_requests * avg_tokens\n",
    "                cost = (monthly_tokens / 1_000_000) * model_data['cost_1m_tokens']\n",
    "            \n",
    "            if cost > max_monthly_budget:\n",
    "                return False\n",
    "        \n",
    "        # Contrainte de privacy\n",
    "        min_privacy = constraints.get('min_privacy_score', 0)\n",
    "        if model_data['privacy_score'] < min_privacy:\n",
    "            return False\n",
    "        \n",
    "        # Contrainte de latence\n",
    "        max_latency = constraints.get('max_latency_seconds')\n",
    "        if max_latency and model_data['latency_avg_seconds'] > max_latency:\n",
    "            return False\n",
    "        \n",
    "        # Contrainte de performance minimum\n",
    "        min_performance = constraints.get('min_mmlu_score', 0)\n",
    "        if model_data['performance_mmlu'] < min_performance:\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def calculate_overall_score(self, model_name, model_data):\n",
    "        \"\"\"\n",
    "        Calcule le score global pond√©r√©\n",
    "        \"\"\"\n",
    "        # V√©rifier les contraintes\n",
    "        if not self.apply_constraints(model_data):\n",
    "            return None  # Mod√®le √©limin√©\n",
    "        \n",
    "        monthly_requests = self.user_profile.get('monthly_requests', 10000)\n",
    "        \n",
    "        # Calculer tous les scores\n",
    "        scores = {\n",
    "            'performance': self.calculate_performance_score(model_data),\n",
    "            'cost': self.calculate_cost_score(model_data, monthly_requests),\n",
    "            'speed': self.calculate_speed_score(model_data),\n",
    "            'privacy': self.calculate_privacy_score(model_data),\n",
    "            'integration': self.calculate_integration_score(model_data)\n",
    "        }\n",
    "        \n",
    "        # Score global pond√©r√©\n",
    "        overall_score = sum(\n",
    "            scores[criterion] * weight \n",
    "            for criterion, weight in self.criteria_weights.items()\n",
    "            if criterion in scores\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'overall_score': overall_score,\n",
    "            'scores': scores,\n",
    "            'model_data': model_data\n",
    "        }\n",
    "    \n",
    "    def run_analysis(self):\n",
    "        \"\"\"\n",
    "        Lance l'analyse compl√®te\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for model_name, model_data in self.models_db.items():\n",
    "            result = self.calculate_overall_score(model_name, model_data)\n",
    "            if result:  # Pas √©limin√© par les contraintes\n",
    "                results.append(result)\n",
    "        \n",
    "        # Trier par score d√©croissant\n",
    "        results.sort(key=lambda x: x['overall_score'], reverse=True)\n",
    "        \n",
    "        self.results = results\n",
    "        return results\n",
    "\n",
    "# Cr√©er l'instance\n",
    "decision_matrix = LLMDecisionMatrix(MODELS_DATABASE)\n",
    "print(\"üßÆ Calculateur de d√©cision initialis√© !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Interface de Configuration Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ CONFIGURATEUR DE PROFIL UTILISATEUR\n",
      "==================================================\n",
      "üìã 1. D√©finissez votre profil d'usage:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bba728d0e64847ad1cb6b3d2742307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Usage principal:', options=(('G√©n√©raliste (chatbot, QA)', 'general'), ('G√©n√©ration de co‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909d4477f2504d51ba89172cee73fad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=10000, description='Requ√™tes/mois:', max=1000000, min=100, step=1000, style=SliderStyle(descri‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí∞ 2. Contraintes budg√©taires:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22786742e27e45d8a8b8cd996a5a4946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1000, description='Budget max $/mois:', max=10000, step=100, style=SliderStyle(description_wid‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîí 3. Exigences techniques:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d51043364d4afe9df2fd14c45452ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Privacy:', options=(('Aucune exigence (APIs OK)', 0), ('Pr√©f√©rence donn√©es priv√©es', 5),‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28e4537b4e549328c5395026206d670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=5.0, description='Latence max (s):', max=10.0, min=0.5, step=0.5, style=SliderStyle(descript‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b262b96c5a943709e04c8cbb7b0feab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=50, description='MMLU min (%):', max=90, min=30, step=5, style=SliderStyle(description_width='‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interface interactive pour d√©finir le profil utilisateur\n",
    "\n",
    "print(\"üéØ CONFIGURATEUR DE PROFIL UTILISATEUR\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Type d'usage principal\n",
    "usage_type = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('G√©n√©raliste (chatbot, QA)', 'general'),\n",
    "        ('G√©n√©ration de code', 'code'),\n",
    "        ('Cr√©atif (√©criture, marketing)', 'creative'),\n",
    "        ('Analytique (r√©sum√©s, recherche)', 'analytical')\n",
    "    ],\n",
    "    value='general',\n",
    "    description='Usage principal:'\n",
    ")\n",
    "\n",
    "# 2. Volume d'usage\n",
    "monthly_requests = widgets.IntSlider(\n",
    "    value=10000,\n",
    "    min=100,\n",
    "    max=1000000,\n",
    "    step=1000,\n",
    "    description='Requ√™tes/mois:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# 3. Budget maximum\n",
    "max_budget = widgets.IntSlider(\n",
    "    value=1000,\n",
    "    min=0,\n",
    "    max=10000,\n",
    "    step=100,\n",
    "    description='Budget max $/mois:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# 4. Exigences de privacy\n",
    "privacy_requirement = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('Aucune exigence (APIs OK)', 0),\n",
    "        ('Pr√©f√©rence donn√©es priv√©es', 5),\n",
    "        ('Exigence donn√©es locales', 8)\n",
    "    ],\n",
    "    value=0,\n",
    "    description='Privacy:'\n",
    ")\n",
    "\n",
    "# 5. Tol√©rance latence\n",
    "max_latency = widgets.FloatSlider(\n",
    "    value=5.0,\n",
    "    min=0.5,\n",
    "    max=10.0,\n",
    "    step=0.5,\n",
    "    description='Latence max (s):',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# 6. Performance minimum\n",
    "min_performance = widgets.IntSlider(\n",
    "    value=50,\n",
    "    min=30,\n",
    "    max=90,\n",
    "    step=5,\n",
    "    description='MMLU min (%):',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "print(\"üìã 1. D√©finissez votre profil d'usage:\")\n",
    "display(usage_type, monthly_requests)\n",
    "\n",
    "print(\"\\nüí∞ 2. Contraintes budg√©taires:\")\n",
    "display(max_budget)\n",
    "\n",
    "print(\"\\nüîí 3. Exigences techniques:\")\n",
    "display(privacy_requirement, max_latency, min_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öñÔ∏è POND√âRATION DES CRIT√àRES\n",
      "==================================================\n",
      "R√©partissez 100 points entre les crit√®res selon vos priorit√©s:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba4b4aacae1478098af105609e72e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=25, description='Performance (%):', max=60, style=SliderStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae88a896b175401eb78ae2e79d718117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=25, description='Co√ªt (%):', max=60, style=SliderStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9bcdec91114ccba764d827b86a9577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=20, description='Vitesse (%):', max=60, style=SliderStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f133c4e68948d1bac1f8b87979fb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=15, description='Privacy (%):', max=60, style=SliderStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8256f1d8d64e8eb5b4142594380221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=15, description='Int√©gration (%):', max=60, style=SliderStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b17dca86ba43389c0502f73b575be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>Total: 100%</b>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interface pour pond√©rer les crit√®res\n",
    "print(\"\\n‚öñÔ∏è POND√âRATION DES CRIT√àRES\")\n",
    "print(\"=\" * 50)\n",
    "print(\"R√©partissez 100 points entre les crit√®res selon vos priorit√©s:\")\n",
    "\n",
    "# Sliders pour les poids\n",
    "weight_performance = widgets.IntSlider(\n",
    "    value=25,\n",
    "    min=0,\n",
    "    max=60,\n",
    "    description='Performance (%):',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "weight_cost = widgets.IntSlider(\n",
    "    value=25,\n",
    "    min=0,\n",
    "    max=60,\n",
    "    description='Co√ªt (%):',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "weight_speed = widgets.IntSlider(\n",
    "    value=20,\n",
    "    min=0,\n",
    "    max=60,\n",
    "    description='Vitesse (%):',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "weight_privacy = widgets.IntSlider(\n",
    "    value=15,\n",
    "    min=0,\n",
    "    max=60,\n",
    "    description='Privacy (%):',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "weight_integration = widgets.IntSlider(\n",
    "    value=15,\n",
    "    min=0,\n",
    "    max=60,\n",
    "    description='Int√©gration (%):',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Widget pour afficher le total\n",
    "total_display = widgets.HTML(value=\"<b>Total: 100%</b>\")\n",
    "\n",
    "def update_total(*args):\n",
    "    total = (weight_performance.value + weight_cost.value + weight_speed.value + \n",
    "             weight_privacy.value + weight_integration.value)\n",
    "    color = \"green\" if total == 100 else \"red\"\n",
    "    total_display.value = f\"<b style='color: {color}'>Total: {total}%</b>\"\n",
    "\n",
    "# Lier les widgets\n",
    "for widget in [weight_performance, weight_cost, weight_speed, weight_privacy, weight_integration]:\n",
    "    widget.observe(update_total, 'value')\n",
    "\n",
    "display(weight_performance, weight_cost, weight_speed, weight_privacy, weight_integration, total_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ 4. Lancer l'analyse:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ebedd8c177412f8d58f6bc4c546fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description=\"üöÄ Lancer l'Analyse\", layout=Layout(height='40px', width='200px'), ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d77f405138a47d9b3455caecfac0791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bouton pour lancer l'analyse\n",
    "analyze_button = widgets.Button(\n",
    "    description='üöÄ Lancer l\\'Analyse',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='200px', height='40px')\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def run_analysis(button):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        \n",
    "        # V√©rifier que les poids totalisent 100\n",
    "        total_weight = (weight_performance.value + weight_cost.value + weight_speed.value + \n",
    "                       weight_privacy.value + weight_integration.value)\n",
    "        \n",
    "        if total_weight != 100:\n",
    "            print(f\"‚ùå Erreur: Les poids doivent totaliser 100% (actuellement {total_weight}%)\")\n",
    "            return\n",
    "        \n",
    "        print(\"üîÑ Analyse en cours...\")\n",
    "        \n",
    "        # Configurer le profil utilisateur\n",
    "        user_profile = {\n",
    "            'primary_task': usage_type.value,\n",
    "            'monthly_requests': monthly_requests.value,\n",
    "            'constraints': {\n",
    "                'max_monthly_budget': max_budget.value,\n",
    "                'min_privacy_score': privacy_requirement.value,\n",
    "                'max_latency_seconds': max_latency.value,\n",
    "                'min_mmlu_score': min_performance.value\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Configurer les poids\n",
    "        criteria_weights = {\n",
    "            'performance': weight_performance.value / 100,\n",
    "            'cost': weight_cost.value / 100,\n",
    "            'speed': weight_speed.value / 100,\n",
    "            'privacy': weight_privacy.value / 100,\n",
    "            'integration': weight_integration.value / 100\n",
    "        }\n",
    "        \n",
    "        # Lancer l'analyse\n",
    "        decision_matrix.set_user_profile(user_profile)\n",
    "        decision_matrix.set_criteria_weights(criteria_weights)\n",
    "        results = decision_matrix.run_analysis()\n",
    "        \n",
    "        print(\"‚úÖ Analyse termin√©e !\")\n",
    "        print(f\"üìä {len(results)} mod√®les √©valu√©s (apr√®s filtrage des contraintes)\")\n",
    "        \n",
    "        if not results:\n",
    "            print(\"‚ùå Aucun mod√®le ne satisfait vos contraintes. Essayez de les assouplir.\")\n",
    "            return\n",
    "        \n",
    "        # Stocker globalement pour visualisation\n",
    "        global analysis_results, user_config\n",
    "        analysis_results = results\n",
    "        user_config = {\n",
    "            'profile': user_profile,\n",
    "            'weights': criteria_weights\n",
    "        }\n",
    "        \n",
    "        print(\"\\nüéØ R√âSULTATS PR√âLIMINAIRES:\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        for i, result in enumerate(results[:5], 1):\n",
    "            medal = ['ü•á', 'ü•à', 'ü•â', '4Ô∏è‚É£', '5Ô∏è‚É£'][i-1]\n",
    "            print(f\"{medal} {result['model']:15s}: {result['overall_score']:.1f}/100\")\n",
    "        \n",
    "        print(\"\\nüìä Ex√©cutez la cellule suivante pour voir les visualisations d√©taill√©es.\")\n",
    "\n",
    "analyze_button.on_click(run_analysis)\n",
    "\n",
    "print(\"\\nüéØ 4. Lancer l'analyse:\")\n",
    "display(analyze_button, output_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Visualisations et Rapport D√©taill√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Veuillez d'abord lancer l'analyse dans la section pr√©c√©dente.\n"
     ]
    }
   ],
   "source": [
    "# V√©rifier si l'analyse a √©t√© lanc√©e\n",
    "try:\n",
    "    analysis_results\n",
    "    user_config\n",
    "except NameError:\n",
    "    print(\"‚ö†Ô∏è Veuillez d'abord lancer l'analyse dans la section pr√©c√©dente.\")\n",
    "    analysis_results = None\n",
    "\n",
    "if analysis_results:\n",
    "    # Pr√©parer les donn√©es pour visualisation\n",
    "    viz_data = []\n",
    "    \n",
    "    for result in analysis_results:\n",
    "        row = {\n",
    "            'Model': result['model'],\n",
    "            'Overall_Score': result['overall_score'],\n",
    "            'Performance': result['scores']['performance'],\n",
    "            'Cost': result['scores']['cost'],\n",
    "            'Speed': result['scores']['speed'],\n",
    "            'Privacy': result['scores']['privacy'],\n",
    "            'Integration': result['scores']['integration'],\n",
    "            'Type': result['model_data']['type'],\n",
    "            'Creator': result['model_data']['creator']\n",
    "        }\n",
    "        viz_data.append(row)\n",
    "    \n",
    "    df_viz = pd.DataFrame(viz_data)\n",
    "    \n",
    "    # 1. Graphique principal des scores\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\n",
    "            'Scores Globaux', 'Comparaison par Crit√®re',\n",
    "            'Performance vs Co√ªt', 'Vitesse vs Privacy'\n",
    "        ),\n",
    "        specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "               [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}]]\n",
    "    )\n",
    "    \n",
    "    # Score global\n",
    "    colors = ['#FF6B6B' if t == 'Propri√©taire' else '#4ECDC4' for t in df_viz['Type']]\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=df_viz['Model'],\n",
    "            y=df_viz['Overall_Score'],\n",
    "            marker_color=colors,\n",
    "            name='Score Global'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Scores par crit√®re (heatmap style)\n",
    "    criteria_cols = ['Performance', 'Cost', 'Speed', 'Privacy', 'Integration']\n",
    "    \n",
    "    for i, criterion in enumerate(criteria_cols):\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=df_viz['Model'],\n",
    "                y=df_viz[criterion],\n",
    "                name=criterion,\n",
    "                visible='legendonly' if i > 0 else True\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "    \n",
    "    # Performance vs Co√ªt\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_viz['Performance'],\n",
    "            y=df_viz['Cost'],\n",
    "            mode='markers+text',\n",
    "            text=df_viz['Model'].str[:8],  # Nom court\n",
    "            textposition='top center',\n",
    "            marker=dict(\n",
    "                size=df_viz['Overall_Score']/5,\n",
    "                color=df_viz['Overall_Score'],\n",
    "                colorscale='RdYlGn',\n",
    "                showscale=True\n",
    "            ),\n",
    "            name='Performance vs Co√ªt'\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Vitesse vs Privacy\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_viz['Speed'],\n",
    "            y=df_viz['Privacy'],\n",
    "            mode='markers+text',\n",
    "            text=df_viz['Model'].str[:8],\n",
    "            textposition='top center',\n",
    "            marker=dict(\n",
    "                size=df_viz['Overall_Score']/5,\n",
    "                color=df_viz['Overall_Score'],\n",
    "                colorscale='RdYlGn'\n",
    "            ),\n",
    "            name='Vitesse vs Privacy'\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"üìä Analyse Compl√®te des Mod√®les LLM\",\n",
    "        height=800,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    # Mettre √† jour les axes\n",
    "    fig.update_xaxes(title_text=\"Mod√®les\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Score Global\", row=1, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Performance\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Co√ªt\", row=2, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Vitesse\", row=2, col=2)\n",
    "    fig.update_yaxes(title_text=\"Privacy\", row=2, col=2)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    print(\"üí° Guide de lecture :\")\n",
    "    print(\"  üî¥ Rouge = Mod√®les propri√©taires\")\n",
    "    print(\"  üü¢ Vert = Mod√®les open source\")\n",
    "    print(\"  üíé Taille des bulles = Score global\")\n",
    "    print(\"  üåà Couleur des bulles = Score global (vert=meilleur)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ RAPPORT D√âTAILL√â - TOP 3 RECOMMANDATIONS\n",
      "============================================================\n",
      "\n",
      "ü•á RECOMMANDATION #1: Phi-3 Mini\n",
      "==================================================\n",
      "üìä Score Global: 84.3/100\n",
      "üè¢ Cr√©ateur: Microsoft (Open Source)\n",
      "üìÖ Sortie: 2024-04\n",
      "üìè Contexte: 128,000 tokens\n",
      "\n",
      "üìà Scores par Crit√®re:\n",
      "  ‚Ä¢ Performance :  65.5/100 (poids:   25%, contribution:  16.4)\n",
      "  ‚Ä¢ Cost        :  96.0/100 (poids:   25%, contribution:  24.0)\n",
      "  ‚Ä¢ Speed       :  92.0/100 (poids:   20%, contribution:  18.4)\n",
      "  ‚Ä¢ Privacy     : 100.0/100 (poids:   15%, contribution:  15.0)\n",
      "  ‚Ä¢ Integration :  70.0/100 (poids:   15%, contribution:  10.5)\n",
      "\n",
      "‚ö° Performances Techniques:\n",
      "  ‚Ä¢ MMLU:  68.8%\n",
      "  ‚Ä¢ HumanEval:  62.2%\n",
      "  ‚Ä¢ Latence:   0.8s\n",
      "  ‚Ä¢ Co√ªt estim√©: $200 (h√©bergement/mois)\n",
      "\n",
      "‚úÖ Points Forts:\n",
      "  ‚Ä¢ Tr√®s petit et rapide\n",
      "  ‚Ä¢ Long contexte\n",
      "  ‚Ä¢ Edge deployment\n",
      "\n",
      "‚ùå Points d'Attention:\n",
      "  ‚Ä¢ Performance limit√©e vs gros mod√®les\n",
      "  ‚Ä¢ Nouveau\n",
      "\n",
      "üéØ Sp√©cialit√©s: Ultra Compact, Edge Computing, Mobile\n",
      "--------------------------------------------------\n",
      "\n",
      "ü•à RECOMMANDATION #2: Mistral 7B\n",
      "==================================================\n",
      "üìä Score Global: 81.8/100\n",
      "üè¢ Cr√©ateur: Mistral AI (Open Source)\n",
      "üìÖ Sortie: 2023-09\n",
      "üìè Contexte: 32,768 tokens\n",
      "\n",
      "üìà Scores par Crit√®re:\n",
      "  ‚Ä¢ Performance :  65.1/100 (poids:   25%, contribution:  16.3)\n",
      "  ‚Ä¢ Cost        :  94.0/100 (poids:   25%, contribution:  23.5)\n",
      "  ‚Ä¢ Speed       :  90.0/100 (poids:   20%, contribution:  18.0)\n",
      "  ‚Ä¢ Privacy     : 100.0/100 (poids:   15%, contribution:  15.0)\n",
      "  ‚Ä¢ Integration :  60.0/100 (poids:   15%, contribution:   9.0)\n",
      "\n",
      "‚ö° Performances Techniques:\n",
      "  ‚Ä¢ MMLU:  62.5%\n",
      "  ‚Ä¢ HumanEval:  29.8%\n",
      "  ‚Ä¢ Latence:   1.0s\n",
      "  ‚Ä¢ Co√ªt estim√©: $300 (h√©bergement/mois)\n",
      "\n",
      "‚úÖ Points Forts:\n",
      "  ‚Ä¢ Tr√®s rapide\n",
      "  ‚Ä¢ Excellent rapport taille/perf\n",
      "  ‚Ä¢ Fran√ßais\n",
      "\n",
      "‚ùå Points d'Attention:\n",
      "  ‚Ä¢ Contexte limit√© vs gros mod√®les\n",
      "  ‚Ä¢ Communaut√© plus petite\n",
      "\n",
      "üéØ Sp√©cialit√©s: Compact Efficace, Europ√©en, Rapide\n",
      "--------------------------------------------------\n",
      "\n",
      "ü•â RECOMMANDATION #3: Llama 2 13B\n",
      "==================================================\n",
      "üìä Score Global: 73.7/100\n",
      "üè¢ Cr√©ateur: Meta (Open Source)\n",
      "üìÖ Sortie: 2023-07\n",
      "üìè Contexte: 4,096 tokens\n",
      "\n",
      "üìà Scores par Crit√®re:\n",
      "  ‚Ä¢ Performance :  60.7/100 (poids:   25%, contribution:  15.2)\n",
      "  ‚Ä¢ Cost        :  84.0/100 (poids:   25%, contribution:  21.0)\n",
      "  ‚Ä¢ Speed       :  75.0/100 (poids:   20%, contribution:  15.0)\n",
      "  ‚Ä¢ Privacy     : 100.0/100 (poids:   15%, contribution:  15.0)\n",
      "  ‚Ä¢ Integration :  50.0/100 (poids:   15%, contribution:   7.5)\n",
      "\n",
      "‚ö° Performances Techniques:\n",
      "  ‚Ä¢ MMLU:  54.8%\n",
      "  ‚Ä¢ HumanEval:  18.3%\n",
      "  ‚Ä¢ Latence:   2.5s\n",
      "  ‚Ä¢ Co√ªt estim√©: $800 (h√©bergement/mois)\n",
      "\n",
      "‚úÖ Points Forts:\n",
      "  ‚Ä¢ √âquilibre taille/performance\n",
      "  ‚Ä¢ Moins cher √† h√©berger\n",
      "\n",
      "‚ùå Points d'Attention:\n",
      "  ‚Ä¢ Performance limit√©e\n",
      "  ‚Ä¢ Setup technique\n",
      "\n",
      "üéØ Sp√©cialit√©s: G√©n√©raliste Compact, Bon Compromis\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Rapport d√©taill√© du TOP 3\n",
    "if analysis_results:\n",
    "    print(\"üèÜ RAPPORT D√âTAILL√â - TOP 3 RECOMMANDATIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, result in enumerate(analysis_results[:3], 1):\n",
    "        medal = ['ü•á', 'ü•à', 'ü•â'][i-1]\n",
    "        model_name = result['model']\n",
    "        model_data = result['model_data']\n",
    "        scores = result['scores']\n",
    "        \n",
    "        print(f\"\\n{medal} RECOMMANDATION #{i}: {model_name}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Informations g√©n√©rales\n",
    "        print(f\"üìä Score Global: {result['overall_score']:.1f}/100\")\n",
    "        print(f\"üè¢ Cr√©ateur: {model_data['creator']} ({model_data['type']})\")\n",
    "        print(f\"üìÖ Sortie: {model_data['release_date']}\")\n",
    "        print(f\"üìè Contexte: {model_data['context_length']:,} tokens\")\n",
    "        \n",
    "        # Scores d√©taill√©s\n",
    "        print(f\"\\nüìà Scores par Crit√®re:\")\n",
    "        for criterion, score in scores.items():\n",
    "            weight = user_config['weights'][criterion] * 100\n",
    "            contribution = score * user_config['weights'][criterion]\n",
    "            print(f\"  ‚Ä¢ {criterion.capitalize():12s}: {score:5.1f}/100 (poids: {weight:4.0f}%, contribution: {contribution:5.1f})\")\n",
    "        \n",
    "        # M√©triques techniques\n",
    "        print(f\"\\n‚ö° Performances Techniques:\")\n",
    "        print(f\"  ‚Ä¢ MMLU: {model_data['performance_mmlu']:5.1f}%\")\n",
    "        print(f\"  ‚Ä¢ HumanEval: {model_data['performance_humaneval']:5.1f}%\")\n",
    "        print(f\"  ‚Ä¢ Latence: {model_data['latency_avg_seconds']:5.1f}s\")\n",
    "        \n",
    "        # Co√ªt estim√©\n",
    "        monthly_requests = user_config['profile']['monthly_requests']\n",
    "        if model_data['type'] == 'Open Source':\n",
    "            cost = model_data.get('hosting_cost_monthly', 500)\n",
    "            cost_type = \"h√©bergement/mois\"\n",
    "        else:\n",
    "            avg_tokens = 1000\n",
    "            monthly_tokens = monthly_requests * avg_tokens\n",
    "            cost = (monthly_tokens / 1_000_000) * model_data['cost_1m_tokens']\n",
    "            cost_type = \"API/mois\"\n",
    "        \n",
    "        print(f\"  ‚Ä¢ Co√ªt estim√©: ${cost:,.0f} ({cost_type})\")\n",
    "        \n",
    "        # Points forts et faibles\n",
    "        print(f\"\\n‚úÖ Points Forts:\")\n",
    "        for pro in model_data['pros']:\n",
    "            print(f\"  ‚Ä¢ {pro}\")\n",
    "        \n",
    "        print(f\"\\n‚ùå Points d'Attention:\")\n",
    "        for con in model_data['cons']:\n",
    "            print(f\"  ‚Ä¢ {con}\")\n",
    "        \n",
    "        # Sp√©cialit√©s\n",
    "        print(f\"\\nüéØ Sp√©cialit√©s: {', '.join(model_data['specialties'])}\")\n",
    "        \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÑ G√©n√©ration du Rapport Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# üìã RAPPORT DE D√âCISION LLM\n",
       "**G√©n√©r√© le:** 2025-06-15 18:24\n",
       "\n",
       "## üéØ Profil Utilisateur\n",
       "\n",
       "### Contexte d'Usage\n",
       "- **Type d'usage principal:** general\n",
       "- **Volume mensuel:** 1,000,000 requ√™tes\n",
       "- **Budget maximum:** $1,000/mois\n",
       "\n",
       "### Contraintes Techniques\n",
       "- **Privacy minimum:** 0/10\n",
       "- **Latence maximum:** 5.000000000000001s\n",
       "- **Performance minimum:** 50% MMLU\n",
       "\n",
       "### Pond√©ration des Crit√®res\n",
       "- **Performance:** 25%\n",
       "- **Cost:** 25%\n",
       "- **Speed:** 20%\n",
       "- **Privacy:** 15%\n",
       "- **Integration:** 15%\n",
       "\n",
       "## üèÜ RECOMMANDATION PRINCIPALE\n",
       "\n",
       "### Phi-3 Mini\n",
       "**Score Global:** 84.3/100\n",
       "\n",
       "**Pourquoi ce choix ?**\n",
       "- Excellent en cost (96/100)\n",
       "- Excellent en speed (92/100)\n",
       "- Excellent en privacy (100/100)\n",
       "- Tr√®s bon en integration (70/100)\n",
       "\n",
       "**Co√ªt Estim√©:** $200/mois en h√©bergement (co√ªt fixe)\n",
       "\n",
       "## üîÑ Alternatives √† Consid√©rer\n",
       "\n",
       "### #2: Mistral 7B (Score: 81.8/100)\n",
       "**Cas d'usage:** Compact Efficace, Europ√©en, Rapide\n",
       "\n",
       "### #3: Llama 2 13B (Score: 73.7/100)\n",
       "**Cas d'usage:** G√©n√©raliste Compact, Bon Compromis\n",
       "\n",
       "### #4: GPT-3.5 Turbo (Score: 72.6/100)\n",
       "**Cas d'usage:** G√©n√©raliste Rapide, Bon Rapport Qualit√©/Prix\n",
       "\n",
       "## üìä Analyse Comparative\n",
       "\n",
       "| Mod√®le | Score Global | Performance | Co√ªt | Vitesse | Privacy |\n",
       "|--------|--------------|-------------|------|---------|----------|\n",
       "| Phi-3 Mini | 84.3 | 65 | 96 | 92 | 100 |\n",
       "| Mistral 7B | 81.8 | 65 | 94 | 90 | 100 |\n",
       "| Llama 2 13B | 73.7 | 61 | 84 | 75 | 100 |\n",
       "| GPT-3.5 Turbo | 72.6 | 68 | 80 | 88 | 20 |\n",
       "\n",
       "## üéØ Prochaines √âtapes\n",
       "\n",
       "### 1. Phase de Test (2 semaines)\n",
       "- Impl√©menter un POC avec le mod√®le recommand√©\n",
       "- Tester sur vos donn√©es r√©elles\n",
       "- Mesurer performance et co√ªt effectifs\n",
       "\n",
       "### 2. Validation (2 semaines)\n",
       "- Comparer avec l'alternative #2\n",
       "- √âvaluer la satisfaction utilisateur\n",
       "- Valider les projections de co√ªt\n",
       "\n",
       "### 3. D√©ploiement\n",
       "- Mise en production progressive\n",
       "- Monitoring des m√©triques cl√©s\n",
       "- Plan de mont√©e en charge\n",
       "\n",
       "### 4. R√©√©valuation (6 mois)\n",
       "- Nouveaux mod√®les disponibles\n",
       "- √âvolution des besoins\n",
       "- Optimisation des co√ªts\n",
       "\n",
       "---\n",
       "\n",
       "*Rapport g√©n√©r√© automatiquement par le Module 8.5 - Matrice de D√©cision LLM*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40287a799cd4a9b916bc14b4e57711b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='üíæ Sauvegarder le Rapport', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# G√©n√©rateur de rapport personnalis√©\n",
    "def generate_decision_report():\n",
    "    if not analysis_results:\n",
    "        return \"‚ö†Ô∏è Aucune analyse disponible. Lancez d'abord l'analyse.\"\n",
    "    \n",
    "    report = f\"\"\"\n",
    "# üìã RAPPORT DE D√âCISION LLM\n",
    "**G√©n√©r√© le:** {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
    "\n",
    "## üéØ Profil Utilisateur\n",
    "\n",
    "### Contexte d'Usage\n",
    "- **Type d'usage principal:** {user_config['profile']['primary_task']}\n",
    "- **Volume mensuel:** {user_config['profile']['monthly_requests']:,} requ√™tes\n",
    "- **Budget maximum:** ${user_config['profile']['constraints']['max_monthly_budget']:,}/mois\n",
    "\n",
    "### Contraintes Techniques\n",
    "- **Privacy minimum:** {user_config['profile']['constraints']['min_privacy_score']}/10\n",
    "- **Latence maximum:** {user_config['profile']['constraints']['max_latency_seconds']}s\n",
    "- **Performance minimum:** {user_config['profile']['constraints']['min_mmlu_score']}% MMLU\n",
    "\n",
    "### Pond√©ration des Crit√®res\n",
    "\"\"\"\n",
    "    \n",
    "    for criterion, weight in user_config['weights'].items():\n",
    "        report += f\"- **{criterion.capitalize()}:** {weight*100:.0f}%\\n\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "## üèÜ RECOMMANDATION PRINCIPALE\n",
    "\n",
    "### {analysis_results[0]['model']}\n",
    "**Score Global:** {analysis_results[0]['overall_score']:.1f}/100\n",
    "\n",
    "**Pourquoi ce choix ?**\n",
    "\"\"\"\n",
    "    \n",
    "    best_model = analysis_results[0]\n",
    "    best_scores = best_model['scores']\n",
    "    \n",
    "    # Identifier les points forts\n",
    "    strengths = []\n",
    "    for criterion, score in best_scores.items():\n",
    "        if score >= 80:\n",
    "            strengths.append(f\"Excellent en {criterion.lower()} ({score:.0f}/100)\")\n",
    "        elif score >= 70:\n",
    "            strengths.append(f\"Tr√®s bon en {criterion.lower()} ({score:.0f}/100)\")\n",
    "    \n",
    "    for strength in strengths:\n",
    "        report += f\"- {strength}\\n\"\n",
    "    \n",
    "    # Co√ªt estim√©\n",
    "    best_model_data = best_model['model_data']\n",
    "    monthly_requests = user_config['profile']['monthly_requests']\n",
    "    \n",
    "    if best_model_data['type'] == 'Open Source':\n",
    "        cost = best_model_data.get('hosting_cost_monthly', 500)\n",
    "        cost_detail = f\"${cost:,.0f}/mois en h√©bergement (co√ªt fixe)\"\n",
    "    else:\n",
    "        avg_tokens = 1000\n",
    "        monthly_tokens = monthly_requests * avg_tokens\n",
    "        cost = (monthly_tokens / 1_000_000) * best_model_data['cost_1m_tokens']\n",
    "        cost_detail = f\"${cost:,.0f}/mois en API ({monthly_tokens/1000:.0f}K tokens)\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "**Co√ªt Estim√©:** {cost_detail}\n",
    "\n",
    "## üîÑ Alternatives √† Consid√©rer\n",
    "\"\"\"\n",
    "    \n",
    "    for i, result in enumerate(analysis_results[1:4], 2):\n",
    "        report += f\"\"\"\n",
    "### #{i}: {result['model']} (Score: {result['overall_score']:.1f}/100)\n",
    "**Cas d'usage:** {', '.join(result['model_data']['specialties'])}\\n\"\"\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "## üìä Analyse Comparative\n",
    "\n",
    "| Mod√®le | Score Global | Performance | Co√ªt | Vitesse | Privacy |\n",
    "|--------|--------------|-------------|------|---------|----------|\n",
    "\"\"\"\n",
    "    \n",
    "    for result in analysis_results[:5]:\n",
    "        scores = result['scores']\n",
    "        report += f\"| {result['model']} | {result['overall_score']:.1f} | {scores['performance']:.0f} | {scores['cost']:.0f} | {scores['speed']:.0f} | {scores['privacy']:.0f} |\\n\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "## üéØ Prochaines √âtapes\n",
    "\n",
    "### 1. Phase de Test (2 semaines)\n",
    "- Impl√©menter un POC avec le mod√®le recommand√©\n",
    "- Tester sur vos donn√©es r√©elles\n",
    "- Mesurer performance et co√ªt effectifs\n",
    "\n",
    "### 2. Validation (2 semaines)\n",
    "- Comparer avec l'alternative #{2}\n",
    "- √âvaluer la satisfaction utilisateur\n",
    "- Valider les projections de co√ªt\n",
    "\n",
    "### 3. D√©ploiement\n",
    "- Mise en production progressive\n",
    "- Monitoring des m√©triques cl√©s\n",
    "- Plan de mont√©e en charge\n",
    "\n",
    "### 4. R√©√©valuation (6 mois)\n",
    "- Nouveaux mod√®les disponibles\n",
    "- √âvolution des besoins\n",
    "- Optimisation des co√ªts\n",
    "\n",
    "---\n",
    "\n",
    "*Rapport g√©n√©r√© automatiquement par le Module 8.5 - Matrice de D√©cision LLM*\n",
    "\"\"\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "# G√©n√©rer et afficher le rapport\n",
    "if analysis_results:\n",
    "    final_report = generate_decision_report()\n",
    "    \n",
    "    # Afficher le rapport\n",
    "    from IPython.display import Markdown\n",
    "    display(Markdown(final_report))\n",
    "    \n",
    "    # Option de sauvegarde\n",
    "    save_button = widgets.Button(\n",
    "        description='üíæ Sauvegarder le Rapport',\n",
    "        button_style='info'\n",
    "    )\n",
    "    \n",
    "    def save_report(button):\n",
    "        filename = f\"rapport_decision_llm_{datetime.now().strftime('%Y%m%d_%H%M')}.md\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(final_report)\n",
    "        print(f\"‚úÖ Rapport sauvegard√©: {filename}\")\n",
    "    \n",
    "    save_button.on_click(save_report)\n",
    "    display(save_button)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Lancez d'abord l'analyse pour g√©n√©rer le rapport.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Outil de Mise √† Jour des Donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß MISE √Ä JOUR DE LA BASE DE DONN√âES\n",
      "==================================================\n",
      "Cet outil vous permet d'ajouter de nouveaux mod√®les ou de mettre √† jour les donn√©es existantes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90585b70ef604b5981d15890bba985f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Nom du mod√®le:', placeholder='Ex: GPT-5')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c5ec56f7c7474bbe4f068712027c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Type:', options=('Propri√©taire', 'Open Source'), value='Propri√©taire')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015520e530104881b82ce9c338fdc4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Cr√©ateur:', placeholder='Ex: OpenAI')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9280042128bf4cf5a29940a9eee6931f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=70.0, description='MMLU Score:', min=20.0, style=SliderStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a8e4bcf1074143a73d3fd67bdbb09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=5.0, description='Co√ªt $/1M tokens:', max=50.0, style=SliderStyle(description_width='initial‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c40fa17199401f91fb60322ba46cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=2.0, description='Latence (s):', max=10.0, min=0.1, style=SliderStyle(description_width='ini‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5dee88b45844228e365d4908d1e620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='‚ûï Ajouter le Mod√®le', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí° Apr√®s avoir ajout√© un mod√®le, relancez l'analyse pour l'inclure dans les recommandations.\n"
     ]
    }
   ],
   "source": [
    "# Interface pour ajouter/modifier des mod√®les\n",
    "print(\"üîß MISE √Ä JOUR DE LA BASE DE DONN√âES\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Cet outil vous permet d'ajouter de nouveaux mod√®les ou de mettre √† jour les donn√©es existantes.\")\n",
    "\n",
    "# Formulaire simple pour ajouter un mod√®le\n",
    "new_model_name = widgets.Text(\n",
    "    description='Nom du mod√®le:',\n",
    "    placeholder='Ex: GPT-5'\n",
    ")\n",
    "\n",
    "new_model_type = widgets.Dropdown(\n",
    "    options=['Propri√©taire', 'Open Source'],\n",
    "    description='Type:'\n",
    ")\n",
    "\n",
    "new_model_creator = widgets.Text(\n",
    "    description='Cr√©ateur:',\n",
    "    placeholder='Ex: OpenAI'\n",
    ")\n",
    "\n",
    "new_model_mmlu = widgets.FloatSlider(\n",
    "    value=70.0,\n",
    "    min=20.0,\n",
    "    max=100.0,\n",
    "    description='MMLU Score:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "new_model_cost = widgets.FloatSlider(\n",
    "    value=5.0,\n",
    "    min=0.0,\n",
    "    max=50.0,\n",
    "    description='Co√ªt $/1M tokens:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "new_model_latency = widgets.FloatSlider(\n",
    "    value=2.0,\n",
    "    min=0.1,\n",
    "    max=10.0,\n",
    "    description='Latence (s):',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "add_model_button = widgets.Button(\n",
    "    description='‚ûï Ajouter le Mod√®le',\n",
    "    button_style='success'\n",
    ")\n",
    "\n",
    "def add_new_model(button):\n",
    "    if not new_model_name.value:\n",
    "        print(\"‚ùå Veuillez saisir un nom de mod√®le\")\n",
    "        return\n",
    "    \n",
    "    # Ajouter le nouveau mod√®le √† la base\n",
    "    MODELS_DATABASE[new_model_name.value] = {\n",
    "        'type': new_model_type.value,\n",
    "        'creator': new_model_creator.value,\n",
    "        'release_date': datetime.now().strftime('%Y-%m'),\n",
    "        'context_length': 32768,  # Valeur par d√©faut\n",
    "        'performance_mmlu': new_model_mmlu.value,\n",
    "        'performance_hellaswag': new_model_mmlu.value * 1.1,  # Estimation\n",
    "        'performance_humaneval': new_model_mmlu.value * 0.8,  # Estimation\n",
    "        'performance_truthfulqa': new_model_mmlu.value * 0.7,  # Estimation\n",
    "        'cost_1m_tokens': new_model_cost.value,\n",
    "        'latency_avg_seconds': new_model_latency.value,\n",
    "        'privacy_score': 2 if new_model_type.value == 'Propri√©taire' else 10,\n",
    "        'integration_difficulty': 2,\n",
    "        'scalability_score': 8,\n",
    "        'specialties': ['G√©n√©raliste'],\n",
    "        'pros': ['Nouveau mod√®le'],\n",
    "        'cons': ['Peu de retours d\\'exp√©rience']\n",
    "    }\n",
    "    \n",
    "    # Recr√©er la matrice avec les nouvelles donn√©es\n",
    "    global decision_matrix\n",
    "    decision_matrix = LLMDecisionMatrix(MODELS_DATABASE)\n",
    "    \n",
    "    print(f\"‚úÖ Mod√®le '{new_model_name.value}' ajout√© avec succ√®s !\")\n",
    "    print(f\"üìä Base de donn√©es mise √† jour: {len(MODELS_DATABASE)} mod√®les\")\n",
    "    \n",
    "    # R√©initialiser le formulaire\n",
    "    new_model_name.value = ''\n",
    "    new_model_creator.value = ''\n",
    "    new_model_mmlu.value = 70.0\n",
    "    new_model_cost.value = 5.0\n",
    "    new_model_latency.value = 2.0\n",
    "\n",
    "add_model_button.on_click(add_new_model)\n",
    "\n",
    "display(new_model_name, new_model_type, new_model_creator)\n",
    "display(new_model_mmlu, new_model_cost, new_model_latency)\n",
    "display(add_model_button)\n",
    "\n",
    "print(\"\\nüí° Apr√®s avoir ajout√© un mod√®le, relancez l'analyse pour l'inclure dans les recommandations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Conclusion et Utilisation Future\n",
    "\n",
    "### üéâ F√©licitations !\n",
    "\n",
    "Vous avez cr√©√© votre **outil personnalis√© de s√©lection de mod√®les LLM** !\n",
    "\n",
    "### ‚úÖ Ce que vous avez maintenant :\n",
    "\n",
    "1. **üßÆ Calculateur multicrit√®res** adapt√© √† vos besoins\n",
    "2. **üìä Visualisations interactives** pour comprendre les trade-offs\n",
    "3. **üìÑ Rapport de d√©cision** professionnel et justifi√©\n",
    "4. **üîÑ Outil √©volutif** pour int√©grer de nouveaux mod√®les\n",
    "5. **üéØ M√©thodologie reproductible** pour futures d√©cisions\n",
    "\n",
    "### üöÄ Comment Utiliser cet Outil :\n",
    "\n",
    "#### üìÖ Utilisation Ponctuelle\n",
    "- **Nouveau projet** : D√©finir profil + contraintes ‚Üí Analyse ‚Üí D√©cision\n",
    "- **Changement d'usage** : Ajuster les poids ‚Üí Nouvelle recommandation\n",
    "- **Nouveau budget** : Modifier contraintes ‚Üí R√©√©valuer options\n",
    "\n",
    "#### üîÑ Utilisation R√©currente\n",
    "- **Veille mensuelle** : Ajouter nouveaux mod√®les ‚Üí Comparer avec actuel\n",
    "- **Optimisation co√ªts** : R√©√©valuer avec volume r√©el ‚Üí Identifier √©conomies\n",
    "- **√âvolution besoins** : Ajuster profil ‚Üí Valider choix actuel\n",
    "\n",
    "### üîß Am√©liorations Possibles :\n",
    "\n",
    "1. **üîå Int√©gration APIs** : Tests automatiques de nouveaux mod√®les\n",
    "2. **üìä M√©triques avanc√©es** : Benchmarks sp√©cialis√©s par domaine\n",
    "3. **ü§ñ ML pour recommandation** : Apprentissage des pr√©f√©rences\n",
    "4. **üì± Interface web** : D√©ploiement pour √©quipe compl√®te\n",
    "5. **üîÑ Auto-update** : Synchronisation avec leaderboards publics\n",
    "\n",
    "### üí° Bonnes Pratiques :\n",
    "\n",
    "- **üß™ Toujours tester** la recommandation sur vos donn√©es r√©elles\n",
    "- **üìä Mesurer** performance et co√ªt effectifs vs pr√©dictions\n",
    "- **üîÑ R√©√©valuer** tous les 6 mois (√©volution rapide du domaine)\n",
    "- **üìù Documenter** vos crit√®res de d√©cision pour la prochaine fois\n",
    "- **üë• Impliquer** les utilisateurs finaux dans l'√©valuation\n",
    "\n",
    "---\n",
    "\n",
    "### üéä Fin du Module 8.5 !\n",
    "\n",
    "Vous ma√Ætrisez maintenant **l'art du choix des mod√®les LLM** :\n",
    "- ‚úÖ **Panorama complet** des mod√®les disponibles\n",
    "- ‚úÖ **Crit√®res d'√©valuation** objectifs et mesurables  \n",
    "- ‚úÖ **Tests pratiques** sur cas d'usage r√©els\n",
    "- ‚úÖ **Outil de d√©cision** personnalis√© et √©volutif\n",
    "\n",
    "**üöÄ Vous √™tes pr√™ts pour les modules suivants sur l'utilisation optimale des LLM !**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
