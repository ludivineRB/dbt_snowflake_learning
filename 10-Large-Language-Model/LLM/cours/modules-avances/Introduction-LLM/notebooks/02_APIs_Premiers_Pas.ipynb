{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”Œ Notebook 2 - APIs et Premiers Pas\n",
    "\n",
    "## ğŸ¯ Objectifs\n",
    "- Configurer et utiliser les APIs des principaux fournisseurs LLM\n",
    "- MaÃ®triser l'authentification et la gestion des clÃ©s API\n",
    "- Effectuer vos premiers appels API avec OpenAI, Anthropic et Google\n",
    "- GÃ©rer les erreurs et optimiser les coÃ»ts\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Sommaire\n",
    "1. [ğŸ”‘ Configuration des APIs](#config)\n",
    "2. [ğŸš€ OpenAI API - Premiers Pas](#openai)\n",
    "3. [ğŸ¤– Anthropic Claude API](#anthropic)\n",
    "4. [ğŸ” Google Gemini API](#google)\n",
    "5. [âš ï¸ Gestion des Erreurs](#errors)\n",
    "6. [ğŸ’° Optimisation des CoÃ»ts](#costs)\n",
    "7. [ğŸ¯ Comparaison Pratique](#comparison)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"config\"></a>\n",
    "## ğŸ”‘ 1. Configuration des APIs\n",
    "\n",
    "### ğŸ›¡ï¸ SÃ©curitÃ© des ClÃ©s API\n",
    "\n",
    "**âš ï¸ IMPORTANT : Jamais de clÃ©s en dur dans le code !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… python-dotenv dÃ©jÃ  installÃ©\n",
      "ğŸ”§ Initialisation de la Configuration API...\n",
      "ğŸ”‘ Configuration des ClÃ©s API via fichier .env\n",
      "=======================================================\n",
      "ğŸ“ Fichier .env trouvÃ© : .env\n",
      "\n",
      "ğŸ“Š Statut des APIs :\n",
      "------------------------------\n",
      "âœ… OPENAI API configurÃ©e (clÃ© dÃ©tectÃ©e)\n",
      "âœ… ANTHROPIC API configurÃ©e (clÃ© dÃ©tectÃ©e)\n",
      "âœ… GOOGLE API configurÃ©e (clÃ© dÃ©tectÃ©e)\n",
      "\n",
      "ğŸ‰ 3 API(s) configurÃ©e(s) avec succÃ¨s !\n",
      "ğŸ”’ Vos clÃ©s sont sÃ©curisÃ©es dans le fichier .env\n",
      "\n",
      "ğŸ”’ SÃ©curisation du fichier .env...\n",
      "âœ… .env ajoutÃ© au .gitignore pour la sÃ©curitÃ©\n",
      "\n",
      "ğŸš€ APIs disponibles : openai, anthropic, google\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, List, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Installation et import de python-dotenv\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    print(\"âœ… python-dotenv dÃ©jÃ  installÃ©\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ“¦ Installation de python-dotenv...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"python-dotenv\"])\n",
    "    from dotenv import load_dotenv\n",
    "    print(\"âœ… python-dotenv installÃ© avec succÃ¨s\")\n",
    "\n",
    "# Configuration sÃ©curisÃ©e des clÃ©s API avec .env\n",
    "def setup_api_keys():\n",
    "    \"\"\"\n",
    "    Configuration sÃ©curisÃ©e des clÃ©s API en utilisant un fichier .env\n",
    "    \"\"\"\n",
    "    print(\"ğŸ”‘ Configuration des ClÃ©s API via fichier .env\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    # Chercher le fichier .env\n",
    "    env_paths = [\n",
    "        '.env',  # Dans le rÃ©pertoire courant\n",
    "        '../.env',  # Dans le rÃ©pertoire parent\n",
    "        '../../.env',  # Deux niveaux au-dessus\n",
    "        os.path.expanduser('~/.env'),  # Dans le home directory\n",
    "    ]\n",
    "    \n",
    "    env_found = False\n",
    "    for env_path in env_paths:\n",
    "        if os.path.exists(env_path):\n",
    "            print(f\"ğŸ“ Fichier .env trouvÃ© : {env_path}\")\n",
    "            load_dotenv(env_path)\n",
    "            env_found = True\n",
    "            break\n",
    "    \n",
    "    if not env_found:\n",
    "        print(\"âš ï¸ Aucun fichier .env trouvÃ©\")\n",
    "        print(\"ğŸ’¡ CrÃ©ation d'un fichier .env recommandÃ©e...\")\n",
    "        \n",
    "        # CrÃ©er un fichier .env exemple\n",
    "        env_content = \"\"\"# ClÃ©s API - Remplacez par vos vraies clÃ©s\n",
    "OPENAI_API_KEY=sk-your-openai-key-here\n",
    "ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here\n",
    "GOOGLE_API_KEY=AIza-your-google-key-here\n",
    "\n",
    "# Autres configurations optionnelles\n",
    "# MODEL_PREFERENCE=gpt-3.5-turbo\n",
    "# DEFAULT_MAX_TOKENS=150\n",
    "\"\"\"\n",
    "        \n",
    "        with open('.env', 'w') as f:\n",
    "            f.write(env_content)\n",
    "        \n",
    "        print(\"âœ… Fichier .env crÃ©Ã© avec un template\")\n",
    "        print(\"ğŸ”§ Ã‰ditez le fichier .env avec vos vraies clÃ©s API\")\n",
    "        \n",
    "        # Recharger aprÃ¨s crÃ©ation\n",
    "        load_dotenv('.env')\n",
    "    \n",
    "    # RÃ©cupÃ©ration des clÃ©s depuis les variables d'environnement\n",
    "    api_keys = {\n",
    "        'openai': os.getenv('OPENAI_API_KEY'),\n",
    "        'anthropic': os.getenv('ANTHROPIC_API_KEY'), \n",
    "        'google': os.getenv('GOOGLE_API_KEY')\n",
    "    }\n",
    "    \n",
    "    # VÃ©rification des clÃ©s disponibles\n",
    "    print(f\"\\nğŸ“Š Statut des APIs :\")\n",
    "    print(\"-\" * 30)\n",
    "    available_apis = []\n",
    "    \n",
    "    for provider, key in api_keys.items():\n",
    "        if key and key != f\"{provider}-your-key-here\" and not key.startswith('sk-your-') and not key.startswith('AIza-your-'):\n",
    "            available_apis.append(provider)\n",
    "            print(f\"âœ… {provider.upper()} API configurÃ©e (clÃ© dÃ©tectÃ©e)\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ {provider.upper()} API non configurÃ©e (mode simulation)\")\n",
    "    \n",
    "    if available_apis:\n",
    "        print(f\"\\nğŸ‰ {len(available_apis)} API(s) configurÃ©e(s) avec succÃ¨s !\")\n",
    "        print(\"ğŸ”’ Vos clÃ©s sont sÃ©curisÃ©es dans le fichier .env\")\n",
    "    else:\n",
    "        print(\"\\nğŸ­ Mode simulation activÃ© pour toutes les APIs\")\n",
    "        print(\"ğŸ’¡ Ã‰ditez le fichier .env avec vos vraies clÃ©s pour les activer\")\n",
    "    \n",
    "    # VÃ©rification du fichier .gitignore\n",
    "    check_gitignore()\n",
    "    \n",
    "    return api_keys, available_apis\n",
    "\n",
    "def check_gitignore():\n",
    "    \"\"\"\n",
    "    VÃ©rifie et met Ã  jour le .gitignore pour sÃ©curiser le .env\n",
    "    \"\"\"\n",
    "    gitignore_path = '.gitignore'\n",
    "    env_in_gitignore = False\n",
    "    \n",
    "    if os.path.exists(gitignore_path):\n",
    "        with open(gitignore_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            if '.env' in content:\n",
    "                env_in_gitignore = True\n",
    "    \n",
    "    if not env_in_gitignore:\n",
    "        print(\"\\nğŸ”’ SÃ©curisation du fichier .env...\")\n",
    "        gitignore_content = \"\\n# Variables d'environnement (clÃ©s API)\\n.env\\n.env.local\\n.env.*.local\\n\"\n",
    "        \n",
    "        with open(gitignore_path, 'a') as f:\n",
    "            f.write(gitignore_content)\n",
    "        \n",
    "        print(\"âœ… .env ajoutÃ© au .gitignore pour la sÃ©curitÃ©\")\n",
    "    else:\n",
    "        print(\"âœ… .env dÃ©jÃ  protÃ©gÃ© dans .gitignore\")\n",
    "\n",
    "# Configuration\n",
    "print(\"ğŸ”§ Initialisation de la Configuration API...\")\n",
    "API_KEYS, AVAILABLE_APIS = setup_api_keys()\n",
    "\n",
    "print(f\"\\nğŸš€ APIs disponibles : {', '.join(AVAILABLE_APIS) if AVAILABLE_APIS else 'Mode simulation'}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Affichage d'aide si aucune API configurÃ©e\n",
    "if not AVAILABLE_APIS:\n",
    "    print(\"\\nğŸ’¡ Pour configurer vos APIs :\")\n",
    "    print(\"1. Ouvrez le fichier .env crÃ©Ã©\")\n",
    "    print(\"2. Remplacez les clÃ©s d'exemple par vos vraies clÃ©s\")\n",
    "    print(\"3. Relancez cette cellule\")\n",
    "    print(\"\\nğŸ“ Emplacement du fichier : ./env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”§ Configuration avec Fichier .env\n",
    "\n",
    "Le notebook utilise maintenant un fichier `.env` pour gÃ©rer vos clÃ©s API de maniÃ¨re sÃ©curisÃ©e.\n",
    "\n",
    "#### ğŸ“ **Fichier .env crÃ©Ã© automatiquement**\n",
    "\n",
    "Si aucun fichier `.env` n'existe, le notebook en crÃ©e un avec ce contenu :\n",
    "\n",
    "```bash\n",
    "# ClÃ©s API - Remplacez par vos vraies clÃ©s\n",
    "OPENAI_API_KEY=sk-your-openai-key-here\n",
    "ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here\n",
    "GOOGLE_API_KEY=AIza-your-google-key-here\n",
    "\n",
    "# Autres configurations optionnelles\n",
    "# MODEL_PREFERENCE=gpt-3.5-turbo\n",
    "# DEFAULT_MAX_TOKENS=150\n",
    "```\n",
    "\n",
    "#### âœï¸ **Comment configurer vos clÃ©s :**\n",
    "\n",
    "1. **Ouvrez le fichier `.env`** crÃ©Ã© dans le mÃªme dossier que ce notebook\n",
    "2. **Remplacez les valeurs d'exemple** par vos vraies clÃ©s API :\n",
    "   ```bash\n",
    "   OPENAI_API_KEY=sk-proj-votre-vraie-clÃ©-openai-ici\n",
    "   ANTHROPIC_API_KEY=sk-ant-votre-vraie-clÃ©-anthropic-ici\n",
    "   GOOGLE_API_KEY=AIza-votre-vraie-clÃ©-google-ici\n",
    "   ```\n",
    "3. **Sauvegardez le fichier**\n",
    "4. **Relancez la cellule de configuration** ci-dessus\n",
    "\n",
    "#### ğŸ”’ **SÃ©curitÃ© automatique :**\n",
    "\n",
    "- âœ… Le fichier `.env` est automatiquement ajoutÃ© au `.gitignore`\n",
    "- âœ… Vos clÃ©s ne seront jamais commitÃ©es dans Git\n",
    "- âœ… Le notebook cherche le `.env` dans plusieurs emplacements\n",
    "- âœ… Gestion Ã©lÃ©gante si certaines clÃ©s manquent\n",
    "\n",
    "#### ğŸ¯ **Avantages de cette approche :**\n",
    "\n",
    "- ğŸš€ **Plus rapide** : Pas de saisie Ã  chaque exÃ©cution\n",
    "- ğŸ”’ **Plus sÃ©curisÃ©** : ClÃ©s dans un fichier protÃ©gÃ©\n",
    "- ğŸ”„ **RÃ©utilisable** : MÃªme fichier pour tous vos projets\n",
    "- ğŸ“ **Professionnel** : Standard de l'industrie\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”§ Guide de DÃ©pannage des APIs\n",
    "\n",
    "Si vous avez des erreurs lors de la validation, voici comment les rÃ©soudre :\n",
    "\n",
    "#### ğŸ¤– **ProblÃ¨mes Anthropic (Erreur 400)**\n",
    "- âœ… **VÃ©rifiez le format** : La clÃ© doit commencer par `sk-ant-`\n",
    "- âœ… **Compte actif** : Connectez-vous sur [console.anthropic.com](https://console.anthropic.com/) \n",
    "- âœ… **CrÃ©dits disponibles** : VÃ©rifiez votre solde et ajoutez des crÃ©dits si nÃ©cessaire\n",
    "- âœ… **API activÃ©e** : Assurez-vous d'avoir accÃ¨s Ã  l'API Claude\n",
    "\n",
    "#### ğŸ” **ProblÃ¨mes Google (Erreur 404)**\n",
    "- âœ… **Format correct** : La clÃ© doit commencer par `AIza`\n",
    "- âœ… **API activÃ©e** : Allez sur [AI Studio](https://aistudio.google.com/) et activez l'API\n",
    "- âœ… **RÃ©gion supportÃ©e** : Gemini n'est pas disponible partout\n",
    "- âœ… **Quota configurÃ©** : VÃ©rifiez vos quotas sur Google Cloud Console\n",
    "\n",
    "#### ğŸš€ **OpenAI fonctionne parfaitement !**\n",
    "Excellente nouvelle ! Vous pouvez utiliser toutes les fonctionnalitÃ©s OpenAI du notebook.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"openai\"></a>\n",
    "## ğŸš€ 2. OpenAI API - Premiers Pas\n",
    "\n",
    "### Installation et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OpenAI library dÃ©jÃ  installÃ©e\n",
      "ğŸ”Œ Client OpenAI configurÃ©\n"
     ]
    }
   ],
   "source": [
    "# Installation des bibliothÃ¨ques\n",
    "try:\n",
    "    import openai\n",
    "    print(\"âœ… OpenAI library dÃ©jÃ  installÃ©e\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ“¦ Installation d'OpenAI...\")\n",
    "    !pip install openai\n",
    "    import openai\n",
    "\n",
    "# Configuration du client OpenAI\n",
    "def create_openai_client():\n",
    "    \"\"\"CrÃ©e un client OpenAI sÃ©curisÃ©\"\"\"\n",
    "    if API_KEYS['openai']:\n",
    "        client = openai.OpenAI(api_key=API_KEYS['openai'])\n",
    "        print(\"ğŸ”Œ Client OpenAI configurÃ©\")\n",
    "        return client\n",
    "    else:\n",
    "        print(\"âš ï¸ ClÃ© OpenAI manquante - mode simulation\")\n",
    "        return None\n",
    "\n",
    "openai_client = create_openai_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¬ Premier Appel avec OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"anthropic\"></a>\n",
    "## ğŸ¤– 3. Anthropic Claude API\n",
    "\n",
    "### Configuration de Claude\n",
    "\n",
    "**âš ï¸ ProblÃ¨mes frÃ©quents avec Anthropic :**\n",
    "- ğŸ”’ **Compte requis** : Besoin d'un compte actif avec crÃ©dits\n",
    "- ğŸŒ **Restrictions gÃ©ographiques** : Pas disponible partout  \n",
    "- ğŸ’³ **CrÃ©dits obligatoires** : Minimum ~5$ pour utiliser l'API\n",
    "- ğŸ“‹ **Processus de validation** : Peut prendre du temps\n",
    "\n",
    "**âœ… Solutions de contournement :**\n",
    "1. **Mode simulation** : Toutes les fonctionnalitÃ©s sont disponibles\n",
    "2. **Focus sur OpenAI** : Excellent pour apprendre les concepts\n",
    "3. **Configuration ultÃ©rieure** : Vous pouvez ajouter Anthropic plus tard\n",
    "\n",
    "**ğŸ’¡ Le notebook fonctionne parfaitement sans Anthropic !**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**âš ï¸ ProblÃ¨mes frÃ©quents avec Anthropic :**\n",
    "- ğŸ”’ **Compte requis** : Besoin d'un compte actif avec crÃ©dits\n",
    "- ğŸŒ **Restrictions gÃ©ographiques** : Pas disponible partout  \n",
    "- ğŸ’³ **CrÃ©dits obligatoires** : Minimum ~5$ pour utiliser l'API\n",
    "- ğŸ“‹ **Processus de validation** : Peut prendre du temps\n",
    "\n",
    "**âœ… Solutions de contournement :**\n",
    "1. **Mode simulation** : Toutes les fonctionnalitÃ©s sont disponibles\n",
    "2. **Focus sur OpenAI** : Excellent pour apprendre les concepts\n",
    "3. **Configuration ultÃ©rieure** : Vous pouvez ajouter Anthropic plus tard\n",
    "\n",
    "**ğŸ’¡ Le notebook fonctionne parfaitement sans Anthropic !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Anthropic library dÃ©jÃ  installÃ©e\n",
      "ğŸ”Œ Client Anthropic configurÃ©\n"
     ]
    }
   ],
   "source": [
    "# Installation d'Anthropic avec gestion d'erreurs amÃ©liorÃ©e\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package_name):\n",
    "    \"\"\"Installe un package de maniÃ¨re robuste\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ Erreur lors de l'installation de {package_name}: {e}\")\n",
    "        return False\n",
    "\n",
    "try:\n",
    "    import anthropic\n",
    "    print(\"âœ… Anthropic library dÃ©jÃ  installÃ©e\")\n",
    "    anthropic_available = True\n",
    "except ImportError:\n",
    "    print(\"ğŸ“¦ Installation d'Anthropic...\")\n",
    "    success = install_package(\"anthropic\")\n",
    "    if success:\n",
    "        try:\n",
    "            import anthropic\n",
    "            print(\"âœ… Anthropic installÃ© avec succÃ¨s\")\n",
    "            anthropic_available = True\n",
    "        except ImportError:\n",
    "            print(\"âŒ Ã‰chec de l'import aprÃ¨s installation\")\n",
    "            anthropic_available = False\n",
    "    else:\n",
    "        print(\"âŒ Ã‰chec de l'installation d'Anthropic\")\n",
    "        anthropic_available = False\n",
    "\n",
    "# Configuration du client Anthropic\n",
    "def create_anthropic_client():\n",
    "    \"\"\"CrÃ©e un client Anthropic sÃ©curisÃ©\"\"\"\n",
    "    if not anthropic_available:\n",
    "        print(\"âš ï¸ BibliothÃ¨que Anthropic non disponible - mode simulation\")\n",
    "        return None\n",
    "    \n",
    "    if API_KEYS['anthropic']:\n",
    "        try:\n",
    "            client = anthropic.Anthropic(api_key=API_KEYS['anthropic'])\n",
    "            print(\"ğŸ”Œ Client Anthropic configurÃ©\")\n",
    "            return client\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erreur configuration Anthropic : {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(\"âš ï¸ ClÃ© Anthropic manquante - mode simulation\")\n",
    "        return None\n",
    "\n",
    "anthropic_client = create_anthropic_client()\n",
    "\n",
    "# Note pour l'utilisateur\n",
    "if not anthropic_available:\n",
    "    print(\"\\nğŸ’¡ Si l'installation Ã©choue, vous pouvez :\")\n",
    "    print(\"   1. Installer manuellement : pip install anthropic\")\n",
    "    print(\"   2. Continuer en mode simulation\")\n",
    "    print(\"   3. Utiliser seulement OpenAI et Google pour l'instant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¬ Premier Appel avec Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Test de l'API Anthropic...\n",
      "ğŸ“¤ Envoi Ã  Claude : Bonjour ! Peux-tu te prÃ©senter en 2 phrases ?\n",
      "âŒ Erreur Anthropic : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}\n",
      "ğŸ­ Basculement vers la simulation...\n",
      "ğŸ­ Simulation Claude pour : Bonjour ! Peux-tu te prÃ©senter en 2 phrases ?\n",
      "\n",
      "ğŸ“¥ RÃ©ponse simulÃ©e (0.80s) :\n",
      "\n",
      "Bonjour ! Je suis Claude, un assistant IA crÃ©Ã© par Anthropic. Je suis conÃ§u pour Ãªtre utile, inoffensif et honnÃªte, et je peux vous aider avec l'analyse, l'Ã©criture, les mathÃ©matiques et bien d'autres tÃ¢ches.\n",
      "\n",
      "ğŸ“Š Usage simulÃ© :\n",
      "  â€¢ Tokens input : 12\n",
      "  â€¢ Tokens output : 48\n",
      "  â€¢ CoÃ»t estimÃ© : $0.000063\n"
     ]
    }
   ],
   "source": [
    "def test_anthropic_api(client, prompt=\"Bonjour ! Peux-tu te prÃ©senter en 2 phrases ?\"):\n",
    "    \"\"\"\n",
    "    Test de base de l'API Anthropic\n",
    "    \"\"\"\n",
    "    if not client:\n",
    "        return simulate_anthropic_response(prompt)\n",
    "    \n",
    "    try:\n",
    "        print(f\"ğŸ“¤ Envoi Ã  Claude : {prompt}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-haiku-20240307\",\n",
    "            max_tokens=150,\n",
    "            temperature=0.7,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        response_time = end_time - start_time\n",
    "        \n",
    "        content = response.content[0].text\n",
    "        usage = response.usage\n",
    "        \n",
    "        print(f\"\\nğŸ“¥ RÃ©ponse Claude ({response_time:.2f}s) :\")\n",
    "        print(f\"\\n{content}\")\n",
    "        print(f\"\\nğŸ“Š Usage :\")\n",
    "        print(f\"  â€¢ Tokens input : {usage.input_tokens}\")\n",
    "        print(f\"  â€¢ Tokens output : {usage.output_tokens}\")\n",
    "        \n",
    "        # Estimation du coÃ»t (Claude Haiku)\n",
    "        cost = (usage.input_tokens * 0.00025 + usage.output_tokens * 0.00125) / 1000\n",
    "        print(f\"  â€¢ CoÃ»t estimÃ© : ${cost:.6f}\")\n",
    "        \n",
    "        return {\n",
    "            'response': content,\n",
    "            'usage': usage,\n",
    "            'response_time': response_time,\n",
    "            'cost': cost\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erreur Anthropic : {e}\")\n",
    "        print(\"ğŸ­ Basculement vers la simulation...\")\n",
    "        return simulate_anthropic_response(prompt)\n",
    "\n",
    "def simulate_anthropic_response(prompt):\n",
    "    \"\"\"Simulation de rÃ©ponse Anthropic\"\"\"\n",
    "    print(f\"ğŸ­ Simulation Claude pour : {prompt}\")\n",
    "    time.sleep(0.8)\n",
    "    \n",
    "    response = \"Bonjour ! Je suis Claude, un assistant IA crÃ©Ã© par Anthropic. Je suis conÃ§u pour Ãªtre utile, inoffensif et honnÃªte, et je peux vous aider avec l'analyse, l'Ã©criture, les mathÃ©matiques et bien d'autres tÃ¢ches.\"\n",
    "    \n",
    "    print(f\"\\nğŸ“¥ RÃ©ponse simulÃ©e (0.80s) :\")\n",
    "    print(f\"\\n{response}\")\n",
    "    print(f\"\\nğŸ“Š Usage simulÃ© :\")\n",
    "    print(f\"  â€¢ Tokens input : 12\")\n",
    "    print(f\"  â€¢ Tokens output : 48\")\n",
    "    print(f\"  â€¢ CoÃ»t estimÃ© : $0.000063\")\n",
    "    \n",
    "    return {\n",
    "        'response': response,\n",
    "        'usage': {'input_tokens': 12, 'output_tokens': 48},\n",
    "        'response_time': 0.8,\n",
    "        'cost': 0.000063\n",
    "    }\n",
    "\n",
    "# Test de l'API Anthropic\n",
    "print(\"ğŸ§ª Test de l'API Anthropic...\")\n",
    "anthropic_result = test_anthropic_api(anthropic_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"google\"></a>\n",
    "## ğŸ” 4. Google Gemini API\n",
    "\n",
    "### Configuration de Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Gemini via requests (plus simple)\n",
    "import requests\n",
    "\n",
    "def test_google_api(api_key, prompt=\"Bonjour ! Peux-tu te prÃ©senter en 2 phrases ?\"):\n",
    "    \"\"\"\n",
    "    Test de base de l'API Google Gemini\n",
    "    \"\"\"\n",
    "    if not api_key:\n",
    "        return simulate_google_response(prompt)\n",
    "    \n",
    "    try:\n",
    "        print(f\"ğŸ“¤ Envoi Ã  Gemini : {prompt}\")\n",
    "        \n",
    "        url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key={api_key}\"\n",
    "        \n",
    "        payload = {\n",
    "            \"contents\": [{\n",
    "                \"parts\": [{\n",
    "                    \"text\": prompt\n",
    "                }]\n",
    "            }],\n",
    "            \"generationConfig\": {\n",
    "                \"temperature\": 0.7,\n",
    "                \"maxOutputTokens\": 150\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        start_time = time.time()\n",
    "        response = requests.post(url, json=payload)\n",
    "        end_time = time.time()\n",
    "        response_time = end_time - start_time\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            content = data['candidates'][0]['content']['parts'][0]['text']\n",
    "            \n",
    "            print(f\"\\nğŸ“¥ RÃ©ponse Gemini ({response_time:.2f}s) :\")\n",
    "            print(f\"\\n{content}\")\n",
    "            print(f\"\\nğŸ“Š Usage (estimation) :\")\n",
    "            print(f\"  â€¢ Tokens approximatifs : ~60\")\n",
    "            print(f\"  â€¢ CoÃ»t estimÃ© : Gratuit (quota)\")\n",
    "            \n",
    "            return {\n",
    "                'response': content,\n",
    "                'response_time': response_time,\n",
    "                'cost': 0.0\n",
    "            }\n",
    "        else:\n",
    "            print(f\"âŒ Erreur Google API : {response.status_code}\")\n",
    "            print(f\"   DÃ©tails : {response.text}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erreur Google : {e}\")\n",
    "        return None\n",
    "\n",
    "def simulate_google_response(prompt):\n",
    "    \"\"\"Simulation de rÃ©ponse Google\"\"\"\n",
    "    print(f\"ğŸ­ Simulation Gemini pour : {prompt}\")\n",
    "    time.sleep(1.2)\n",
    "    \n",
    "    response = \"Bonjour ! Je suis Gemini, un modÃ¨le d'IA dÃ©veloppÃ© par Google. Je peux vous aider avec une variÃ©tÃ© de tÃ¢ches incluant la gÃ©nÃ©ration de texte, l'analyse et la rÃ©solution de problÃ¨mes complexes.\"\n",
    "    \n",
    "    print(f\"\\nğŸ“¥ RÃ©ponse simulÃ©e (1.20s) :\")\n",
    "    print(f\"\\n{response}\")\n",
    "    print(f\"\\nğŸ“Š Usage simulÃ© :\")\n",
    "    print(f\"  â€¢ Tokens approximatifs : ~60\")\n",
    "    print(f\"  â€¢ CoÃ»t estimÃ© : Gratuit (quota)\")\n",
    "    \n",
    "    return {\n",
    "        'response': response,\n",
    "        'response_time': 1.2,\n",
    "        'cost': 0.0\n",
    "    }\n",
    "\n",
    "# Test de l'API Google\n",
    "google_result = test_google_api(API_KEYS['google'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"errors\"></a>\n",
    "## âš ï¸ 5. Gestion des Erreurs\n",
    "\n",
    "### ğŸ›¡ï¸ Gestion Robuste des APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Test de gestion d'erreurs...\n",
      "\n",
      "--- Test OPENAI ---\n",
      "ğŸ”„ Tentative 1/3 pour openai\n",
      "âœ… SuccÃ¨s : La tempÃ©rature en intelligence artificielle correspond Ã  un paramÃ¨tre permettant de contrÃ´ler le niv...\n",
      "\n",
      "--- Test ANTHROPIC ---\n",
      "ğŸ”„ Tentative 1/3 pour anthropic\n",
      "âŒ Erreur BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your cred...\n",
      "ğŸ”§ Erreur technique - tentative suivante\n",
      "ğŸ”„ Tentative 2/3 pour anthropic\n",
      "âŒ Erreur BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your cred...\n",
      "ğŸ”§ Erreur technique - tentative suivante\n",
      "ğŸ”„ Tentative 3/3 pour anthropic\n",
      "âŒ Erreur BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your cred...\n",
      "ğŸ”§ Erreur technique - tentative suivante\n",
      "ğŸ’¥ Ã‰chec aprÃ¨s 3 tentatives\n",
      "âŒ Ã‰chec complet pour anthropic\n"
     ]
    }
   ],
   "source": [
    "def robust_api_call(provider, prompt, max_retries=3):\n",
    "    \"\"\"\n",
    "    Appel API robuste avec gestion d'erreurs et retry\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"ğŸ”„ Tentative {attempt + 1}/{max_retries} pour {provider}\")\n",
    "            \n",
    "            if provider == 'openai':\n",
    "                if not openai_client:\n",
    "                    return simulate_openai_response(prompt)\n",
    "                \n",
    "                response = openai_client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    max_tokens=100,\n",
    "                    temperature=0.7,\n",
    "                    timeout=30\n",
    "                )\n",
    "                return response.choices[0].message.content\n",
    "                \n",
    "            elif provider == 'anthropic':\n",
    "                if not anthropic_client:\n",
    "                    return simulate_anthropic_response(prompt)['response']\n",
    "                \n",
    "                response = anthropic_client.messages.create(\n",
    "                    model=\"claude-3-haiku-20240307\",\n",
    "                    max_tokens=100,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "                )\n",
    "                return response.content[0].text\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_type = type(e).__name__\n",
    "            error_msg = str(e)\n",
    "            \n",
    "            print(f\"âŒ Erreur {error_type} : {error_msg[:100]}...\")\n",
    "            \n",
    "            # DiffÃ©rents types d'erreurs\n",
    "            if \"rate_limit\" in error_msg.lower():\n",
    "                wait_time = 2 ** attempt  # Exponential backoff\n",
    "                print(f\"â³ Rate limit - attente {wait_time}s\")\n",
    "                time.sleep(wait_time)\n",
    "                continue\n",
    "                \n",
    "            elif \"timeout\" in error_msg.lower():\n",
    "                print(f\"â±ï¸ Timeout - tentative suivante\")\n",
    "                continue\n",
    "                \n",
    "            elif \"authentication\" in error_msg.lower():\n",
    "                print(f\"ğŸ”‘ Erreur d'authentification - vÃ©rifiez votre clÃ© API\")\n",
    "                break\n",
    "                \n",
    "            else:\n",
    "                print(f\"ğŸ”§ Erreur technique - tentative suivante\")\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "    \n",
    "    print(f\"ğŸ’¥ Ã‰chec aprÃ¨s {max_retries} tentatives\")\n",
    "    return None\n",
    "\n",
    "# Test de gestion d'erreurs\n",
    "print(\"ğŸ§ª Test de gestion d'erreurs...\")\n",
    "test_prompt = \"Explique-moi le concept de temperature en IA en 1 phrase.\"\n",
    "\n",
    "for provider in ['openai', 'anthropic']:\n",
    "    print(f\"\\n--- Test {provider.upper()} ---\")\n",
    "    result = robust_api_call(provider, test_prompt)\n",
    "    if result:\n",
    "        print(f\"âœ… SuccÃ¨s : {result[:100]}...\")\n",
    "    else:\n",
    "        print(f\"âŒ Ã‰chec complet pour {provider}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Š Types d'Erreurs Communes\n",
    "\n",
    "| Erreur | Cause | Solution |\n",
    "|--------|-------|----------|\n",
    "| `401 Unauthorized` | ClÃ© API invalide | VÃ©rifier la clÃ© |\n",
    "| `429 Rate Limit` | Trop de requÃªtes | Attendre et retry |\n",
    "| `500 Server Error` | ProblÃ¨me serveur | Retry avec backoff |\n",
    "| `Timeout` | RÃ©ponse trop lente | Augmenter timeout |\n",
    "| `Context Length` | Prompt trop long | RÃ©duire la taille |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"costs\"></a>\n",
    "## ğŸ’° 6. Optimisation des CoÃ»ts\n",
    "\n",
    "### ğŸ“Š Calculateur de CoÃ»ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’° Simulateur de CoÃ»ts API\n",
      "==================================================\n",
      "\n",
      "ğŸ’¬ Chatbot simple\n",
      "  Tokens : 50 input + 100 output\n",
      "  CoÃ»ts par appel :\n",
      "    openai     gpt-3.5-turbo   : $0.000175\n",
      "    openai     gpt-4-turbo     : $0.003500\n",
      "    anthropic  claude-3-haiku  : $0.000138\n",
      "    anthropic  claude-3-sonnet : $0.001650\n",
      "    google     gemini-pro      : $0.000175\n",
      "\n",
      "  ğŸ’¡ Pour 1000 appels :\n",
      "    Moins cher : anthropic-claude-3-haiku - $0.14\n",
      "    Plus cher   : openai-gpt-4-turbo - $3.50\n",
      "    Ã‰conomie max : $3.36\n",
      "\n",
      "ğŸ“ GÃ©nÃ©ration longue\n",
      "  Tokens : 100 input + 500 output\n",
      "  CoÃ»ts par appel :\n",
      "    openai     gpt-3.5-turbo   : $0.000800\n",
      "    openai     gpt-4-turbo     : $0.016000\n",
      "    anthropic  claude-3-haiku  : $0.000650\n",
      "    anthropic  claude-3-sonnet : $0.007800\n",
      "    google     gemini-pro      : $0.000800\n",
      "\n",
      "  ğŸ’¡ Pour 1000 appels :\n",
      "    Moins cher : anthropic-claude-3-haiku - $0.65\n",
      "    Plus cher   : openai-gpt-4-turbo - $16.00\n",
      "    Ã‰conomie max : $15.35\n",
      "\n",
      "ğŸ” Analyse de document\n",
      "  Tokens : 1000 input + 200 output\n",
      "  CoÃ»ts par appel :\n",
      "    openai     gpt-3.5-turbo   : $0.000800\n",
      "    openai     gpt-4-turbo     : $0.016000\n",
      "    anthropic  claude-3-haiku  : $0.000500\n",
      "    anthropic  claude-3-sonnet : $0.006000\n",
      "    google     gemini-pro      : $0.000800\n",
      "\n",
      "  ğŸ’¡ Pour 1000 appels :\n",
      "    Moins cher : anthropic-claude-3-haiku - $0.50\n",
      "    Plus cher   : openai-gpt-4-turbo - $16.00\n",
      "    Ã‰conomie max : $15.50\n",
      "\n",
      "ğŸ¤– Assistant complexe\n",
      "  Tokens : 500 input + 800 output\n",
      "  CoÃ»ts par appel :\n",
      "    openai     gpt-3.5-turbo   : $0.001450\n",
      "    openai     gpt-4-turbo     : $0.029000\n",
      "    anthropic  claude-3-haiku  : $0.001125\n",
      "    anthropic  claude-3-sonnet : $0.013500\n",
      "    google     gemini-pro      : $0.001450\n",
      "\n",
      "  ğŸ’¡ Pour 1000 appels :\n",
      "    Moins cher : anthropic-claude-3-haiku - $1.12\n",
      "    Plus cher   : openai-gpt-4-turbo - $29.00\n",
      "    Ã‰conomie max : $27.88\n"
     ]
    }
   ],
   "source": [
    "# Tarifs des APIs (par 1M tokens)\n",
    "PRICING = {\n",
    "    'openai': {\n",
    "        'gpt-3.5-turbo': {'input': 0.50, 'output': 1.50},\n",
    "        'gpt-4': {'input': 30.00, 'output': 60.00},\n",
    "        'gpt-4-turbo': {'input': 10.00, 'output': 30.00}\n",
    "    },\n",
    "    'anthropic': {\n",
    "        'claude-3-haiku': {'input': 0.25, 'output': 1.25},\n",
    "        'claude-3-sonnet': {'input': 3.00, 'output': 15.00},\n",
    "        'claude-3-opus': {'input': 15.00, 'output': 75.00}\n",
    "    },\n",
    "    'google': {\n",
    "        'gemini-pro': {'input': 0.50, 'output': 1.50},\n",
    "        'gemini-ultra': {'input': 10.00, 'output': 30.00}\n",
    "    }\n",
    "}\n",
    "\n",
    "def calculate_cost(provider, model, input_tokens, output_tokens):\n",
    "    \"\"\"\n",
    "    Calcule le coÃ»t d'un appel API\n",
    "    \"\"\"\n",
    "    if provider not in PRICING or model not in PRICING[provider]:\n",
    "        return 0.0\n",
    "    \n",
    "    pricing = PRICING[provider][model]\n",
    "    cost = (input_tokens * pricing['input'] + output_tokens * pricing['output']) / 1_000_000\n",
    "    return cost\n",
    "\n",
    "def cost_comparison_simulator():\n",
    "    \"\"\"\n",
    "    Simulateur de comparaison des coÃ»ts\n",
    "    \"\"\"\n",
    "    print(\"ğŸ’° Simulateur de CoÃ»ts API\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # ScÃ©narios typiques\n",
    "    scenarios = {\n",
    "        \"ğŸ’¬ Chatbot simple\": {\"input\": 50, \"output\": 100},\n",
    "        \"ğŸ“ GÃ©nÃ©ration longue\": {\"input\": 100, \"output\": 500},\n",
    "        \"ğŸ” Analyse de document\": {\"input\": 1000, \"output\": 200},\n",
    "        \"ğŸ¤– Assistant complexe\": {\"input\": 500, \"output\": 800}\n",
    "    }\n",
    "    \n",
    "    for scenario_name, tokens in scenarios.items():\n",
    "        print(f\"\\n{scenario_name}\")\n",
    "        print(f\"  Tokens : {tokens['input']} input + {tokens['output']} output\")\n",
    "        print(\"  CoÃ»ts par appel :\")\n",
    "        \n",
    "        costs = []\n",
    "        \n",
    "        # Calcul pour chaque modÃ¨le\n",
    "        models_to_test = [\n",
    "            ('openai', 'gpt-3.5-turbo'),\n",
    "            ('openai', 'gpt-4-turbo'),\n",
    "            ('anthropic', 'claude-3-haiku'),\n",
    "            ('anthropic', 'claude-3-sonnet'),\n",
    "            ('google', 'gemini-pro')\n",
    "        ]\n",
    "        \n",
    "        for provider, model in models_to_test:\n",
    "            cost = calculate_cost(provider, model, tokens['input'], tokens['output'])\n",
    "            costs.append((f\"{provider}-{model}\", cost))\n",
    "            print(f\"    {provider:10} {model:15} : ${cost:.6f}\")\n",
    "        \n",
    "        # Calcul pour 1000 appels\n",
    "        print(f\"\\n  ğŸ’¡ Pour 1000 appels :\")\n",
    "        costs.sort(key=lambda x: x[1])\n",
    "        cheapest = costs[0]\n",
    "        most_expensive = costs[-1]\n",
    "        \n",
    "        print(f\"    Moins cher : {cheapest[0]} - ${cheapest[1]*1000:.2f}\")\n",
    "        print(f\"    Plus cher   : {most_expensive[0]} - ${most_expensive[1]*1000:.2f}\")\n",
    "        print(f\"    Ã‰conomie max : ${(most_expensive[1] - cheapest[1])*1000:.2f}\")\n",
    "\n",
    "cost_comparison_simulator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ StratÃ©gies d'Optimisation des CoÃ»ts\n",
    "\n",
    "#### ğŸ¯ Choix du ModÃ¨le\n",
    "- **TÃ¢ches simples** â†’ GPT-3.5-turbo, Claude Haiku\n",
    "- **TÃ¢ches complexes** â†’ GPT-4, Claude Sonnet\n",
    "- **TÃ¢ches critiques** â†’ Claude Opus, GPT-4\n",
    "\n",
    "#### âš¡ Optimisations Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ‚ï¸ Prompt optimisÃ© :\n",
      "   Original : ~1400 tokens\n",
      "   OptimisÃ© : ~500 tokens\n",
      "   Ã‰conomie : ~900 tokens\n",
      "\n",
      "Longueur finale : 2003 caractÃ¨res\n"
     ]
    }
   ],
   "source": [
    "def optimize_prompt_cost(prompt, max_input_tokens=1000):\n",
    "    \"\"\"\n",
    "    Optimise un prompt pour rÃ©duire les coÃ»ts\n",
    "    \"\"\"\n",
    "    # Estimation simple des tokens (1 token â‰ˆ 4 caractÃ¨res)\n",
    "    estimated_tokens = len(prompt) // 4\n",
    "    \n",
    "    if estimated_tokens > max_input_tokens:\n",
    "        # Troncature intelligente\n",
    "        max_chars = max_input_tokens * 4\n",
    "        optimized_prompt = prompt[:max_chars] + \"...\"\n",
    "        \n",
    "        print(f\"âœ‚ï¸ Prompt optimisÃ© :\")\n",
    "        print(f\"   Original : ~{estimated_tokens} tokens\")\n",
    "        print(f\"   OptimisÃ© : ~{max_input_tokens} tokens\")\n",
    "        print(f\"   Ã‰conomie : ~{estimated_tokens - max_input_tokens} tokens\")\n",
    "        \n",
    "        return optimized_prompt\n",
    "    else:\n",
    "        print(f\"âœ… Prompt dÃ©jÃ  optimisÃ© : ~{estimated_tokens} tokens\")\n",
    "        return prompt\n",
    "\n",
    "# Test d'optimisation\n",
    "long_prompt = \"\"\"Voici un trÃ¨s long document avec beaucoup de dÃ©tails... \"\"\" * 100\n",
    "optimized = optimize_prompt_cost(long_prompt, max_input_tokens=500)\n",
    "\n",
    "print(f\"\\nLongueur finale : {len(optimized)} caractÃ¨res\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"comparison\"></a>\n",
    "## ğŸ¯ 7. Comparaison Pratique\n",
    "\n",
    "### âš–ï¸ Test Comparatif des APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ­ Test Comparatif : GÃ©nÃ©ration CrÃ©ative\n",
      "============================================================\n",
      "ğŸ“ Prompt : Ã‰cris un court poÃ¨me (4 vers) sur l'intelligence artificielle. \n",
      "Style : optimiste et accessible.\n",
      "\n",
      "============================================================\n",
      "\n",
      "ğŸš€ OpenAI GPT-3.5-turbo\n",
      "------------------------------\n",
      "ğŸ“¤ Envoi Ã  OpenAI : Ã‰cris un court poÃ¨me (4 vers) sur l'intelligence artificielle. \n",
      "Style : optimiste et accessible.\n",
      "\n",
      "ğŸ“¥ RÃ©ponse OpenAI (1.18s) :\n",
      "\n",
      "Dans le monde de demain, l'IA brillera,\n",
      "De ses capacitÃ©s, elle nous Ã©tonnera.\n",
      "Elle sera notre alliÃ©e, pour nous aider,\n",
      "A construire un avenir meilleur, sans jamais se lasser.\n",
      "\n",
      "ğŸ“Š Usage :\n",
      "  â€¢ Tokens prompt : 35\n",
      "  â€¢ Tokens rÃ©ponse : 51\n",
      "  â€¢ Total : 86\n",
      "  â€¢ CoÃ»t estimÃ© : $0.000094\n",
      "\n",
      "\n",
      "ğŸ¤– Anthropic Claude\n",
      "------------------------------\n",
      "ğŸ“¤ Envoi Ã  Claude : Ã‰cris un court poÃ¨me (4 vers) sur l'intelligence artificielle. \n",
      "Style : optimiste et accessible.\n",
      "âŒ Erreur Anthropic : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}\n",
      "ğŸ­ Basculement vers la simulation...\n",
      "ğŸ­ Simulation Claude pour : Ã‰cris un court poÃ¨me (4 vers) sur l'intelligence artificielle. \n",
      "Style : optimiste et accessible.\n",
      "\n",
      "ğŸ“¥ RÃ©ponse simulÃ©e (0.80s) :\n",
      "\n",
      "Bonjour ! Je suis Claude, un assistant IA crÃ©Ã© par Anthropic. Je suis conÃ§u pour Ãªtre utile, inoffensif et honnÃªte, et je peux vous aider avec l'analyse, l'Ã©criture, les mathÃ©matiques et bien d'autres tÃ¢ches.\n",
      "\n",
      "ğŸ“Š Usage simulÃ© :\n",
      "  â€¢ Tokens input : 12\n",
      "  â€¢ Tokens output : 48\n",
      "  â€¢ CoÃ»t estimÃ© : $0.000063\n",
      "\n",
      "\n",
      "ğŸ” Google Gemini\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_google_api' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Lancement du test comparatif\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m comparison_results = \u001b[43mcomparative_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mcomparative_test\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mğŸ” Google Gemini\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m30\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m results[\u001b[33m'\u001b[39m\u001b[33mgoogle\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mtest_google_api\u001b[49m(API_KEYS[\u001b[33m'\u001b[39m\u001b[33mgoogle\u001b[39m\u001b[33m'\u001b[39m], test_prompt)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# RÃ©sumÃ© comparatif\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'test_google_api' is not defined"
     ]
    }
   ],
   "source": [
    "def comparative_test():\n",
    "    \"\"\"\n",
    "    Teste les 3 APIs sur la mÃªme tÃ¢che\n",
    "    \"\"\"\n",
    "    test_prompt = \"\"\"Ã‰cris un court poÃ¨me (4 vers) sur l'intelligence artificielle. \n",
    "Style : optimiste et accessible.\"\"\"\n",
    "    \n",
    "    print(\"ğŸ­ Test Comparatif : GÃ©nÃ©ration CrÃ©ative\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ğŸ“ Prompt : {test_prompt}\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Test OpenAI\n",
    "    print(\"\\nğŸš€ OpenAI GPT-3.5-turbo\")\n",
    "    print(\"-\" * 30)\n",
    "    results['openai'] = test_openai_api(openai_client, test_prompt)\n",
    "    \n",
    "    # Test Anthropic\n",
    "    print(\"\\n\\nğŸ¤– Anthropic Claude\")\n",
    "    print(\"-\" * 30)\n",
    "    results['anthropic'] = test_anthropic_api(anthropic_client, test_prompt)\n",
    "    \n",
    "    # Test Google\n",
    "    print(\"\\n\\nğŸ” Google Gemini\")\n",
    "    print(\"-\" * 30)\n",
    "    results['google'] = test_google_api(API_KEYS['google'], test_prompt)\n",
    "    \n",
    "    # RÃ©sumÃ© comparatif\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ“Š RÃ‰SUMÃ‰ COMPARATIF\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    comparison_data = []\n",
    "    \n",
    "    for provider, result in results.items():\n",
    "        if result:\n",
    "            comparison_data.append({\n",
    "                'Provider': provider.capitalize(),\n",
    "                'Response Time': f\"{result['response_time']:.2f}s\",\n",
    "                'Cost': f\"${result['cost']:.6f}\" if result['cost'] > 0 else \"Gratuit\",\n",
    "                'Quality': \"âœ¨ CrÃ©atif\" if \"poÃ¨me\" in result['response'].lower() else \"ğŸ“ Standard\"\n",
    "            })\n",
    "    \n",
    "    # Affichage du tableau\n",
    "    if comparison_data:\n",
    "        headers = comparison_data[0].keys()\n",
    "        \n",
    "        print(f\"{'Provider':<12} {'Time':<8} {'Cost':<12} {'Quality':<12}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for data in comparison_data:\n",
    "            print(f\"{data['Provider']:<12} {data['Response Time']:<8} {data['Cost']:<12} {data['Quality']:<12}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Lancement du test comparatif\n",
    "comparison_results = comparative_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ† Recommandations par Cas d'Usage\n",
    "\n",
    "| Cas d'Usage | ModÃ¨le RecommandÃ© | Raison |\n",
    "|-------------|------------------|--------|\n",
    "| ğŸ’¬ **Chatbot simple** | GPT-3.5-turbo | Rapport qualitÃ©/prix optimal |\n",
    "| ğŸ“Š **Analyse de donnÃ©es** | Claude Haiku | PrÃ©cision et vitesse |\n",
    "| ğŸ¨ **CrÃ©ation de contenu** | GPT-4 | CrÃ©ativitÃ© supÃ©rieure |\n",
    "| ğŸ’» **GÃ©nÃ©ration de code** | Claude Sonnet | Excellente comprÃ©hension |\n",
    "| ğŸ” **Recherche/RÃ©sumÃ©** | Gemini Pro | Gratuit avec quotas |\n",
    "| ğŸ¯ **TÃ¢ches critiques** | Claude Opus | QualitÃ© maximale |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Exercices Pratiques\n",
    "\n",
    "### ğŸš€ Exercice 1 : Votre Premier Chatbot\n",
    "\n",
    "CrÃ©ez un chatbot simple qui utilise l'API de votre choix :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_chatbot(provider='openai'):\n",
    "    \"\"\"\n",
    "    Chatbot interactif simple\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ¤– Chatbot {provider.upper()} - Tapez 'quit' pour sortir\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    conversation_history = []\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nğŸ‘¤ Vous : \")\n",
    "        \n",
    "        if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"ğŸ‘‹ Au revoir !\")\n",
    "            break\n",
    "        \n",
    "        # Ajout Ã  l'historique\n",
    "        conversation_history.append(f\"Utilisateur : {user_input}\")\n",
    "        \n",
    "        # Appel API (simulÃ©)\n",
    "        if provider == 'openai':\n",
    "            response = simulate_openai_response(user_input)['response']\n",
    "        elif provider == 'anthropic':\n",
    "            response = simulate_anthropic_response(user_input)['response']\n",
    "        else:\n",
    "            response = simulate_google_response(user_input)['response']\n",
    "        \n",
    "        conversation_history.append(f\"Assistant : {response}\")\n",
    "        \n",
    "        print(f\"\\nğŸ¤– Bot : {response}\")\n",
    "        \n",
    "        # Limitation de l'historique\n",
    "        if len(conversation_history) > 10:\n",
    "            conversation_history = conversation_history[-10:]\n",
    "\n",
    "# DÃ©commentez pour tester le chatbot\n",
    "# simple_chatbot('openai')\n",
    "\n",
    "print(\"ğŸ’¡ DÃ©commentez la ligne ci-dessus pour tester le chatbot !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ§ª Exercice 2 : Testeur de TempÃ©rature\n",
    "\n",
    "ExpÃ©rimentez avec diffÃ©rents paramÃ¨tres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_experiment():\n",
    "    \"\"\"\n",
    "    ExpÃ©rimente avec diffÃ©rentes tempÃ©ratures\n",
    "    \"\"\"\n",
    "    prompt = \"Raconte-moi une histoire courte sur un robot qui apprend Ã  cuisiner.\"\n",
    "    temperatures = [0.1, 0.5, 0.9, 1.5]\n",
    "    \n",
    "    print(\"ğŸŒ¡ï¸ ExpÃ©rience : Impact de la TempÃ©rature\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ğŸ“ Prompt : {prompt}\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    for temp in temperatures:\n",
    "        print(f\"\\nğŸŒ¡ï¸ TempÃ©rature : {temp}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Simulation de rÃ©ponses avec diffÃ©rentes tempÃ©ratures\n",
    "        if temp <= 0.3:\n",
    "            response = \"Il Ã©tait une fois un robot cuisinier nommÃ© Chef-Bot. Il suivait prÃ©cisÃ©ment les recettes et crÃ©ait des plats parfaits. Un jour, il apprit Ã  ajuster les Ã©pices selon les goÃ»ts.\"\n",
    "            creativity = \"ğŸ¯ PrÃ©cis et cohÃ©rent\"\n",
    "        elif temp <= 0.7:\n",
    "            response = \"Chef-Bot dÃ©couvrit la cuisine par accident. En mÃ©langeant ingrÃ©dients et curiositÃ©, il crÃ©a des saveurs surprenantes. Sa spÃ©cialitÃ© ? Les gÃ¢teaux aux circuits Ã©lectroniques !\"\n",
    "            creativity = \"âš–ï¸ Ã‰quilibrÃ© crÃ©atif\"\n",
    "        elif temp <= 1.0:\n",
    "            response = \"Un robot rouillÃ© dansait dans la cuisine cosmique ! Ses mains mÃ©talliques jonglaient avec des Ã©toiles-Ã©pices, crÃ©ant des arcs-en-ciel gustatifs pour les licornes affamÃ©es du quartier.\"\n",
    "            creativity = \"ğŸ¨ TrÃ¨s crÃ©atif\"\n",
    "        else:\n",
    "            response = \"BZZZT! Cuisine = ERREUR_404_SAVEUR_INTROUVABLE // Robot.exe.manger(nuages_violets) â†’ EXCEPTION_TEMPORELLE << Pommes_de_terre_quantiques!! >>\"\n",
    "            creativity = \"ğŸŒªï¸ Chaotique\"\n",
    "        \n",
    "        print(f\"ğŸ“ RÃ©ponse : {response}\")\n",
    "        print(f\"ğŸ’¡ Style : {creativity}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ“Š CONCLUSIONS\")\n",
    "    print(\"â€¢ TempÃ©rature basse (0.1-0.3) : RÃ©ponses prÃ©cises et cohÃ©rentes\")\n",
    "    print(\"â€¢ TempÃ©rature moyenne (0.5-0.7) : Ã‰quilibre crÃ©ativitÃ©/cohÃ©rence\")\n",
    "    print(\"â€¢ TempÃ©rature Ã©levÃ©e (0.9-1.2) : TrÃ¨s crÃ©atif mais moins cohÃ©rent\")\n",
    "    print(\"â€¢ TempÃ©rature trÃ¨s Ã©levÃ©e (>1.5) : Chaotique et imprÃ©visible\")\n",
    "\n",
    "temperature_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŠ RÃ©capitulatif du Notebook\n",
    "\n",
    "### âœ… Ce que Vous Avez Appris\n",
    "\n",
    "1. **ğŸ”‘ Configuration sÃ©curisÃ©e** des clÃ©s API\n",
    "2. **ğŸš€ Utilisation pratique** d'OpenAI, Anthropic et Google\n",
    "3. **âš ï¸ Gestion robuste** des erreurs et retry\n",
    "4. **ğŸ’° Optimisation des coÃ»ts** et choix de modÃ¨les\n",
    "5. **âš–ï¸ Comparaison pratique** des diffÃ©rentes APIs\n",
    "\n",
    "### ğŸ¯ CompÃ©tences Acquises\n",
    "\n",
    "- âœ… Configuration d'environnements API sÃ©curisÃ©s\n",
    "- âœ… Appels API avec gestion d'erreurs\n",
    "- âœ… Calcul et optimisation des coÃ»ts\n",
    "- âœ… Choix du bon modÃ¨le selon le cas d'usage\n",
    "- âœ… CrÃ©ation d'un chatbot simple\n",
    "\n",
    "### ğŸš€ Prochaines Ã‰tapes\n",
    "\n",
    "Dans le **Notebook 3**, nous approfondirons :\n",
    "- ğŸ›ï¸ **ParamÃ¨tres avancÃ©s** (temperature, top_p, frequency_penalty)\n",
    "- ğŸ¯ **Optimisation fine** pour diffÃ©rents cas d'usage\n",
    "- ğŸ“Š **Mesure de qualitÃ©** et benchmarking\n",
    "- ğŸ”§ **Techniques d'ingÃ©nierie de prompts**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¡ Conseils pour la Suite\n",
    "\n",
    "1. **ExpÃ©rimentez** avec vos propres prompts\n",
    "2. **Testez** diffÃ©rents modÃ¨les sur la mÃªme tÃ¢che\n",
    "3. **Surveillez** vos coÃ»ts d'API\n",
    "4. **Documentez** vos meilleures configurations\n",
    "5. **Pratiquez** la gestion d'erreurs\n",
    "\n",
    "**PrÃªt pour le Notebook 3 ? ğŸ›ï¸ ParamÃ¨tres et Optimisation vous attend !**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
