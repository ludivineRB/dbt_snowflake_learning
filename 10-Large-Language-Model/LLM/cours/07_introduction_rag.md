---
title: 07_introduction_rag
tags:
  - LLM
  - 10-Large-Language-Model
category: 10-Large-Language-Model
---
# Module 7 : RAG - Donnez une M√©moire Externe √† votre IA

Bienvenue dans cette deuxi√®me journ√©e de formation ! Hier, nous avons appris √† dialoguer avec un LLM et √† lui faire utiliser des outils. Aujourd'hui, nous allons r√©soudre l'un de ses plus grands probl√®mes : son ignorance de vos donn√©es personnelles et du monde r√©cent. Pour cela, nous allons utiliser une technique fondamentale : le **RAG (Retrieval-Augmented Generation)**.

---

## 1. Le Double Handicap d'un LLM Standard

Les grands mod√®les de langage, m√™me les plus performants, ont deux limites majeures qui les emp√™chent d'√™tre vraiment utiles dans un contexte professionnel ou personnel :

1.  **Connaissances Fig√©es dans le Temps** : Un LLM comme Llama 3 a √©t√© entra√Æn√© sur des donn√©es qui s'arr√™tent √† une certaine date. Il ne conna√Æt rien des √©v√©nements r√©cents, des nouvelles de votre entreprise, ou des derniers potins.
2.  **Absence de Connaissances Priv√©es** : Le mod√®le ignore tout de VOS documents. Il n'a jamais lu vos rapports internes, vos notes de projet, votre documentation technique, ou vos emails.

Le RAG est la solution la plus efficace et la plus utilis√©e aujourd'hui pour r√©soudre ces deux probl√®mes en m√™me temps.

---

## 2. Le Principe du RAG : Un Examen √† Livre Ouvert pour l'IA

Le RAG transforme la mani√®re dont le LLM r√©pond √† une question. Au lieu de simplement utiliser ses connaissances internes (sa "m√©moire"), il va suivre un processus intelligent en trois √©tapes :

![Diagramme simple expliquant le processus RAG en 3 √©tapes : Recherche, Augmentation, G√©n√©ration](https://i.imgur.com/uQx05Gk.png)

1.  **Recherche (Retrieval)** :
    * Face √† une question de l'utilisateur ("Quel est le statut du projet Alpha ?"), le syst√®me ne se pr√©cipite pas vers le LLM. Il commence par **rechercher des informations pertinentes** dans une base de connaissances que nous lui avons fournie (un ensemble de PDFs, de fichiers textes, de pages web, etc.).

2.  **Augmentation (Augmented)** :
    * Le syst√®me prend les extraits les plus pertinents trouv√©s √† l'√©tape 1 et les ins√®re dans le prompt, √† c√¥t√© de la question initiale de l'utilisateur. On "augmente" la question avec un contexte factuel et pr√©cis.

3.  **G√©n√©ration (Generation)** :
    * Ce prompt "augment√©" est ensuite envoy√© au LLM. Le mod√®le utilise alors √† la fois ses connaissances g√©n√©rales et, surtout, **le contexte sp√©cifique fourni** pour formuler une r√©ponse pr√©cise et factuelle, bas√©e sur vos documents.

> **üí° Analogie :** Le RAG, c'est comme si vous donniez √† votre LLM le droit de passer un examen **"√† livre ouvert"**. Au lieu de devoir tout m√©moriser, il peut consulter les documents pertinents (vos livres) juste avant de r√©pondre √† chaque question.

---

## 3. L'Architecture d'un Syst√®me RAG

Pour mettre cela en place, nous avons besoin de deux processus principaux qui composent l'architecture RAG :

-   **L'Ingestion de Donn√©es (une seule fois par document)** : C'est le processus de pr√©paration de notre base de connaissances. On prend nos documents, on les d√©coupe en morceaux ("chunks"), on les transforme en vecteurs num√©riques ("embeddings") et on les stocke dans une base de donn√©es sp√©ciale : une **base de donn√©es vectorielle** (comme ChromaDB).

-   **L'Interrogation (√† chaque question)** : C'est le processus en 3 √©tapes (Recherche, Augmentation, G√©n√©ration) d√©crit ci-dessus, qui se produit chaque fois qu'un utilisateur pose une question.

![Architecture RAG standard montrant les deux phases d'ingestion et d'interrogation](https://raw.githubusercontent.com/aws-samples/aws-genai-llm-chatbot/main/docs/images/rag-pattern.png)
*(Source du diagramme : AWS Samples)*

Cette technique est au c≈ìur de la majorit√© des applications d'IA g√©n√©rative professionnelles aujourd'hui car elle permet de r√©duire les "hallucinations" et de fonder les r√©ponses des LLMs sur des faits v√©rifiables.

---

Maintenant que nous avons compris la th√©orie, passons √† la pratique. Dans le prochain module, nous allons construire la premi√®re partie de notre syst√®me RAG : la base de connaissances vectorielle.

**[‚û°Ô∏è Prochain Module : Construire une Base de Connaissances Vectorielle](./08_database_vectorielle.md)**
