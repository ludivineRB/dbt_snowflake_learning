{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e538c8a8",
   "metadata": {},
   "source": [
    "# üß† Module 1 - Introduction aux LLM et √† l‚ÄôIA g√©n√©rative\n",
    "Bienvenue dans ce premier atelier. Aujourd‚Äôhui, nous allons :\n",
    "- D√©couvrir ce qu‚Äôest un mod√®le de langage (LLM)\n",
    "- Utiliser un LLM via l‚ÄôAPI HuggingFace pour g√©n√©rer du texte\n",
    "- Explorer les notions de token, prompt, temp√©rature, top_p\n",
    "\n",
    "üëâ Avant de commencer : cr√©e un compte sur https://huggingface.co et r√©cup√®re un token d'API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4384ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Installer la biblioth√®que transformers\n",
    "!pip install -q transformers accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43daf402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîê Configurer le token HuggingFace (ne pas partager ce token !)\n",
    "from huggingface_hub import login\n",
    "login(token=\"votre_token\")  # Remplacez par votre vrai token personnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29634b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÑ Chargement d‚Äôun mod√®le LLM (par ex : google/flan-t5-base)\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "question = \"Explique ce qu‚Äôest un LLM en langage simple\"\n",
    "print(pipe(question)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936e4e1e",
   "metadata": {},
   "source": [
    "## ‚úçÔ∏è Exercice 1\n",
    "Modifie la variable `question` pour poser une autre question √† ton mod√®le. Exemples :\n",
    "- Qu‚Äôest-ce qu‚Äôun token ?\n",
    "- Donne-moi 3 cas d‚Äôusage des LLM en entreprise.\n",
    "- Explique le r√¥le de l‚Äôattention dans les transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c44c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Bonus : essaie un mod√®le francophone !\n",
    "pipe_fr = pipeline(\"text-generation\", model=\"tiiuae/falcon-7b-instruct\")\n",
    "prompt = \"Quels sont les risques de l‚ÄôIA g√©n√©rative dans l‚Äô√©ducation ?\"\n",
    "print(pipe_fr(prompt, max_new_tokens=100)[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
