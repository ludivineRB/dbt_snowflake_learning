# Exercice 3 : Preprocessing et Pipeline â€” PrÃ©parer les DonnÃ©es Proprement

**Phase 2 â€” Chapitres 6, 7 & 8** | DurÃ©e estimÃ©e : 3h | Niveau : IntermÃ©diaire

---

## ğŸ¯ Objectifs

- Nettoyer un dataset rÃ©el (valeurs manquantes, outliers)
- Appliquer les bons encodages selon le type de variable
- Construire un Pipeline scikit-learn robuste
- DÃ©tecter et corriger un data leakage

---

## ğŸ“‹ Contexte

Votre pipeline de donnÃ©es doit Ãªtre **reproductible** et **sans fuite d'information**. Un collÃ¨gue vous a laissÃ© un notebook avec un pipeline "qui marche"... mais qui contient 3 erreurs critiques de data leakage. Ã€ vous de les trouver et de tout refaire proprement.

---

## ğŸ“ Instructions

### Partie 1 : Nettoyage du dataset churn (45 min)

Chargez `data/clients_churn.csv` et effectuez :

1. **Valeurs manquantes** :
   - Identifiez les colonnes avec des valeurs manquantes
   - Pour les numÃ©riques : testez imputation par mÃ©diane et par moyenne â€” quel impact ?
   - Pour les catÃ©gorielles : imputez par le mode (valeur la plus frÃ©quente)

2. **Valeurs aberrantes** :
   - Utilisez la mÃ©thode IQR sur les variables numÃ©riques
   - Visualisez avec des boxplots
   - DÃ©cidez : supprimer, capper (winsorize), ou garder ?

3. **Doublons** :
   - Y en a-t-il ? Si oui, supprimez-les

### Partie 2 : Feature Engineering (45 min)

4. **Variables catÃ©gorielles** :
   - Identifiez toutes les variables catÃ©gorielles
   - Pour chaque variable, choisissez le bon encodage :
     - One-Hot si < 5 catÃ©gories ET modÃ¨le linÃ©aire
     - Ordinal si ordre naturel (ex: Low < Medium < High)
   - Justifiez chaque choix

5. **Variables numÃ©riques** :
   - Appliquez StandardScaler â€” pourquoi StandardScaler et pas MinMaxScaler ici ?

6. **CrÃ©ez au moins 2 nouvelles features** Ã  partir des donnÃ©es existantes (combinaisons, ratios, bins...)

### Partie 3 : Pipeline scikit-learn (45 min)

7. Construisez un `ColumnTransformer` qui applique :
   - Imputation + Scaling sur les numÃ©riques
   - Imputation + OneHotEncoding sur les catÃ©gorielles

8. Encapsulez dans un `Pipeline` avec un modÃ¨le de votre choix (LogisticRegression pour commencer)

9. VÃ©rifiez que le pipeline fait `fit` uniquement sur le train set

### Partie 4 : Chasse au leakage (45 min)

10. Voici un code piÃ©gÃ©. Trouvez les **3 erreurs de data leakage** :

```python
# CODE PIÃ‰GÃ‰ â€” Trouvez les 3 erreurs !
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

df = pd.read_csv("../data/clients_churn.csv")
X = df.drop("churn", axis=1)
y = df["churn"]

# Erreur 1 quelque part ici...
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Erreur 2 quelque part ici...
X_scaled = pd.DataFrame(X_scaled)
X_scaled['mean_encoded_contract'] = df.groupby('contract')['churn'].transform('mean')

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# Erreur 3 : pensez au random_state et stratify
model = LogisticRegression()
model.fit(X_train, y_train)
print(f"Accuracy: {model.score(X_test, y_test):.4f}")
```

11. RÃ©Ã©crivez le code **sans leakage** en utilisant un Pipeline

---

## ğŸ’¡ Indices

```python
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer

# Erreurs typiques de leakage :
# 1. fit_transform sur TOUT le dataset avant le split
# 2. Target encoding calculÃ© sur tout le dataset
# 3. Pas de stratify dans le train_test_split
```

---

## âœ… CritÃ¨res de rÃ©ussite

- [ ] Les valeurs manquantes sont traitÃ©es avec la bonne stratÃ©gie
- [ ] Les outliers sont identifiÃ©s et traitÃ©s (avec justification)
- [ ] Le ColumnTransformer sÃ©pare correctement numÃ©riques et catÃ©gorielles
- [ ] Le Pipeline fait fit uniquement sur le train set
- [ ] Les 3 erreurs de leakage sont trouvÃ©es et expliquÃ©es
- [ ] Le code final est sans leakage et reproductible
