{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification : Prediction du churn client\n",
    "\n",
    "> Ce notebook est un exemple pratique clef en main pour apprendre les techniques de classification en Machine Learning.\n",
    "> Nous allons predire si un client va quitter l'entreprise (churn) a partir de ses caracteristiques comportementales.\n",
    ">\n",
    "> **Objectifs :**\n",
    "> - Maitriser le pipeline complet d'un projet de classification binaire\n",
    "> - Comparer plusieurs algorithmes (Regression Logistique, Random Forest, XGBoost)\n",
    "> - Comprendre les metriques de classification (accuracy, precision, recall, F1, AUC)\n",
    "> - Optimiser un modele avec GridSearchCV et Pipeline sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cellule 1 : Imports et chargement des donnees\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configuration graphique\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Chargement des donnees\n",
    "df = pd.read_csv(\"../data/clients_churn.csv\")\n",
    "\n",
    "print(f\"Dataset charge avec succes : {df.shape[0]} lignes, {df.shape[1]} colonnes\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cellule 2 : Analyse exploratoire (EDA)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"INFORMATIONS GENERALES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDimensions : {df.shape}\")\n",
    "print(f\"\\nTypes des colonnes :\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VALEURS MANQUANTES\")\n",
    "print(\"=\" * 60)\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATISTIQUES DESCRIPTIVES\")\n",
    "print(\"=\" * 60)\n",
    "print(df.describe().round(2))\n",
    "\n",
    "# Equilibre des classes\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EQUILIBRE DES CLASSES (variable cible : churn)\")\n",
    "print(\"=\" * 60)\n",
    "churn_counts = df[\"churn\"].value_counts()\n",
    "churn_pct = df[\"churn\"].value_counts(normalize=True) * 100\n",
    "\n",
    "for val in churn_counts.index:\n",
    "    label = \"Churn\" if val == 1 else \"Non-churn\"\n",
    "    print(f\"  {label} ({val}) : {churn_counts[val]} clients ({churn_pct[val]:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisations exploratoires\n",
    "\n",
    "Nous allons explorer les distributions des variables selon le statut churn/non-churn\n",
    "pour identifier les facteurs discriminants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cellule 3 : Visualisations\n",
    "# ============================================================\n",
    "\n",
    "# --- Taux de churn par variable categorielle ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for i, col in enumerate([\"canal_acquisition\", \"type_contrat\", \"satisfaction_score\"]):\n",
    "    taux_churn = df.groupby(col)[\"churn\"].mean().sort_values(ascending=False)\n",
    "    taux_churn.plot(kind=\"bar\", ax=axes[i], color=\"#e74c3c\", edgecolor=\"black\", alpha=0.8)\n",
    "    axes[i].set_title(f\"Taux de churn par {col}\")\n",
    "    axes[i].set_ylabel(\"Taux de churn\")\n",
    "    axes[i].set_ylim(0, 1)\n",
    "    axes[i].tick_params(axis=\"x\", rotation=45)\n",
    "    # Ajout des valeurs sur les barres\n",
    "    for j, v in enumerate(taux_churn):\n",
    "        axes[i].text(j, v + 0.02, f\"{v:.0%}\", ha=\"center\", fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Boxplots des variables numeriques par churn ---\n",
    "variables_num = [\"age\", \"revenu_mensuel\", \"anciennete_mois\", \"nb_achats\", \"montant_total\", \"nb_reclamations\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(variables_num):\n",
    "    sns.boxplot(\n",
    "        data=df, x=\"churn\", y=col, ax=axes[i],\n",
    "        palette={0: \"#2ecc71\", 1: \"#e74c3c\"}\n",
    "    )\n",
    "    axes[i].set_title(f\"{col} par statut churn\")\n",
    "    axes[i].set_xticklabels([\"Non-churn\", \"Churn\"])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing des donnees\n",
    "\n",
    "Etapes de preparation :\n",
    "1. **Encodage** des variables categorielles (`canal_acquisition`, `type_contrat`)\n",
    "2. **Standardisation** des variables numeriques (necessaire pour la regression logistique)\n",
    "3. **Split** train/test (80/20 avec stratification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cellule 4 : Preprocessing (encodage, scaling, split)\n",
    "# ============================================================\n",
    "\n",
    "# Copie du dataframe\n",
    "df_model = df.copy()\n",
    "\n",
    "# Encodage des variables categorielles (One-Hot)\n",
    "df_model = pd.get_dummies(df_model, columns=[\"canal_acquisition\", \"type_contrat\"], drop_first=True)\n",
    "\n",
    "print(\"Colonnes apres encodage :\")\n",
    "print(df_model.columns.tolist())\n",
    "\n",
    "# Separation features / target\n",
    "X = df_model.drop(\"churn\", axis=1)\n",
    "y = df_model[\"churn\"]\n",
    "\n",
    "# Split train/test avec stratification (pour conserver les proportions de churn)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardisation des variables numeriques\n",
    "scaler = StandardScaler()\n",
    "colonnes_num = [\"age\", \"revenu_mensuel\", \"anciennete_mois\", \"nb_achats\", \"montant_total\", \"nb_reclamations\", \"satisfaction_score\"]\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[colonnes_num] = scaler.fit_transform(X_train[colonnes_num])\n",
    "X_test_scaled[colonnes_num] = scaler.transform(X_test[colonnes_num])\n",
    "\n",
    "print(f\"\\nTaille du jeu d'entrainement : {X_train.shape[0]} echantillons\")\n",
    "print(f\"Taille du jeu de test : {X_test.shape[0]} echantillons\")\n",
    "print(f\"Nombre de features : {X_train.shape[1]}\")\n",
    "print(f\"\\nDistribution churn dans le train : {y_train.value_counts(normalize=True).to_dict()}\")\n",
    "print(f\"Distribution churn dans le test  : {y_test.value_counts(normalize=True).to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele 1 : Regression logistique\n",
    "\n",
    "La regression logistique est le modele de reference pour la classification binaire.\n",
    "Simple et interpretable, c'est toujours un bon point de depart."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Comprendre les metriques de classification\n\nAvant d'evaluer nos modeles, comprenons ce que chaque metrique signifie. L'analogie la plus parlante est celle du **test medical** :\n\n### L'analogie du test medical\n\nImaginez un test de depistage pour une maladie. Le test peut donner 4 resultats :\n\n```\n                    Le test dit \"Malade\"    Le test dit \"Sain\"\nVraiment malade  →  ✅ Vrai Positif (TP)    ❌ Faux Negatif (FN)\n                    \"Bien detecte !\"        \"Rate ! Danger !\"\n\nVraiment sain    →  ❌ Faux Positif (FP)    ✅ Vrai Negatif (TN)\n                    \"Fausse alarme\"         \"Bien identifie\"\n```\n\nDans notre cas de **churn client** :\n- **Positif** = le client va partir (churn)\n- **Negatif** = le client reste fidele\n\n### Les metriques expliquees avec des mots simples\n\n| Metrique | Question qu'elle pose | Analogie medicale | Notre cas churn |\n|----------|----------------------|-------------------|-----------------|\n| **Accuracy** | \"Quel % de predictions sont correctes ?\" | \"Quel % de diagnostics sont bons ?\" | 85% → 85 clients sur 100 bien classes |\n| **Precision** | \"Quand je dis 'positif', ai-je raison ?\" | \"Quand le test dit 'malade', est-ce vrai ?\" | 70% → sur 10 clients predits churn, 7 partent vraiment |\n| **Recall** | \"Est-ce que je detecte tous les positifs ?\" | \"Est-ce qu'on detecte tous les malades ?\" | 80% → sur 10 clients qui partent, on en detecte 8 |\n| **F1-Score** | \"Compromis entre precision et recall\" | \"Le test est-il fiable ET exhaustif ?\" | Moyenne harmonique des deux |\n| **AUC-ROC** | \"Le modele sait-il distinguer les classes ?\" | \"Le test distingue-t-il bien malades et sains ?\" | 0.5 = hasard, 1.0 = parfait |\n\n### Pourquoi l'accuracy ne suffit pas ?\n\nImaginez : 95% de vos clients sont fideles, seulement 5% partent.\nUn modele qui predit **toujours \"fidele\"** a **95% d'accuracy** ! Mais il ne detecte **aucun** churn. C'est un modele inutile.\n\n> **Regle d'or** : Quand les classes sont desequilibrees (beaucoup plus de \"non\" que de \"oui\"), l'accuracy est trompeuse. Privilegiez le **F1-Score** et l'**AUC-ROC**.\n\n### Matrice de confusion : la carte d'identite du modele\n\nC'est le tableau qui resume TOUTES les predictions du modele :\n\n```\n                    Predit \"reste\"    Predit \"churn\"\nReste vraiment   →      TN               FP (fausse alarme)\nPart vraiment    →      FN (rate !)      TP (bien detecte)\n```\n\n**Ce qu'on veut** : beaucoup de TP et TN (la diagonale), peu de FP et FN.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cellule 5 : Regression logistique + matrice de confusion\n",
    "# ============================================================\n",
    "\n",
    "def evaluer_classification(modele, X_test, y_test, nom_modele, afficher_matrice=True):\n",
    "    \"\"\"Fonction utilitaire pour evaluer un modele de classification.\"\"\"\n",
    "    y_pred = modele.predict(X_test)\n",
    "    y_proba = modele.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"  RESULTATS : {nom_modele}\")\n",
    "    print(f\"{'=' * 50}\")\n",
    "    print(f\"  Accuracy  : {acc:.4f}\")\n",
    "    print(f\"  Precision : {prec:.4f}\")\n",
    "    print(f\"  Recall    : {rec:.4f}\")\n",
    "    print(f\"  F1-Score  : {f1:.4f}\")\n",
    "    print(f\"  AUC-ROC   : {auc:.4f}\")\n",
    "\n",
    "    print(f\"\\n--- Rapport de classification ---\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"Non-churn\", \"Churn\"]))\n",
    "\n",
    "    if afficher_matrice:\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        ConfusionMatrixDisplay.from_estimator(\n",
    "            modele, X_test, y_test,\n",
    "            display_labels=[\"Non-churn\", \"Churn\"],\n",
    "            cmap=\"Blues\", ax=ax\n",
    "        )\n",
    "        ax.set_title(f\"Matrice de confusion - {nom_modele}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return {\n",
    "        \"Modele\": nom_modele,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1-Score\": f1,\n",
    "        \"AUC-ROC\": auc,\n",
    "    }\n",
    "\n",
    "\n",
    "# Entrainement de la regression logistique\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluation\n",
    "resultats = []\n",
    "resultats.append(evaluer_classification(lr, X_test_scaled, y_test, \"Regression Logistique\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele 2 : Random Forest\n",
    "\n",
    "Le Random Forest est un modele d'ensemble base sur des arbres de decision.\n",
    "Il nous permet aussi d'obtenir l'importance des features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cellule 6 : Random Forest + importance des features\n",
    "# ============================================================\n",
    "\n",
    "# Entrainement du Random Forest (pas besoin de scaling pour les arbres)\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation (sur donnees non scalees car arbres)\n",
    "resultats.append(evaluer_classification(rf, X_test, y_test, \"Random Forest\"))\n",
    "\n",
    "# Importance des features\n",
    "print(\"\\n--- Importance des features ---\")\n",
    "importances = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Importance\": rf.feature_importances_\n",
    "}).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.barplot(data=importances, x=\"Importance\", y=\"Feature\", palette=\"RdYlGn_r\", ax=ax)\n",
    "ax.set_title(\"Importance des features - Random Forest\")\n",
    "ax.set_xlabel(\"Importance\")\n",
    "ax.set_ylabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele 3 : Gradient Boosting (equivalent XGBoost avec sklearn)\n",
    "\n",
    "Le Gradient Boosting est un algorithme d'ensemble qui construit les arbres de maniere sequentielle,\n",
    "chaque arbre corrigeant les erreurs du precedent. Nous utilisons ici `GradientBoostingClassifier`\n",
    "de sklearn qui offre des performances similaires a XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "source": "# ============================================================\n# Cellule 7 : Gradient Boosting (XGBoost-like)\n# ============================================================\n\ngb = GradientBoostingClassifier(\n    n_estimators=100,\n    max_depth=5,\n    learning_rate=0.1,\n    random_state=42,\n)\ngb.fit(X_train, y_train)\n\n# Evaluation\nresultats.append(evaluer_classification(gb, X_test, y_test, \"Gradient Boosting\"))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Comparaison des courbes ROC\n\n### C'est quoi une courbe ROC ?\n\nImaginez un **curseur** qu'on fait glisser : a gauche, le modele est tres prudent (peu de fausses alarmes mais rate des churns). A droite, le modele est tres sensible (detecte tout mais beaucoup de fausses alarmes).\n\nLa courbe ROC trace **toutes ces positions du curseur** :\n- **Axe X** = Taux de fausses alarmes (FPR) → on veut le MINIMUM\n- **Axe Y** = Taux de detection (TPR/Recall) → on veut le MAXIMUM\n\n**Comment lire le graphique ?**\n- La ligne en pointilles = un modele qui tire a pile ou face (AUC = 0.5)\n- Plus la courbe est proche du **coin superieur gauche**, meilleur est le modele\n- **AUC** (Area Under Curve) = l'aire sous la courbe. Plus c'est proche de 1, mieux c'est\n\n| AUC | Interpretation |\n|-----|---------------|\n| 0.50 | Le modele tire au hasard |\n| 0.60-0.70 | Mediocre |\n| 0.70-0.80 | Acceptable |\n| 0.80-0.90 | Bon |\n| 0.90-1.00 | Excellent |"
  },
  {
   "cell_type": "code",
   "source": "# ============================================================\n# Cellule 8 : Courbes ROC superposees\n# ============================================================\n\nfig, ax = plt.subplots(figsize=(8, 6))\n\n# Modeles et leurs donnees de test correspondantes\nmodeles_roc = [\n    (lr, X_test_scaled, \"Regression Logistique\", \"#3498db\"),\n    (rf, X_test, \"Random Forest\", \"#2ecc71\"),\n    (gb, X_test, \"Gradient Boosting\", \"#e74c3c\"),\n]\n\nfor modele, X_eval, nom, couleur in modeles_roc:\n    y_proba = modele.predict_proba(X_eval)[:, 1]\n    fpr, tpr, _ = roc_curve(y_test, y_proba)\n    auc = roc_auc_score(y_test, y_proba)\n    ax.plot(fpr, tpr, label=f\"{nom} (AUC = {auc:.3f})\", color=couleur, linewidth=2)\n\n# Ligne de reference (modele aleatoire)\nax.plot([0, 1], [0, 1], \"k--\", linewidth=1, label=\"Modele aleatoire (AUC = 0.500)\")\n\nax.set_xlabel(\"Taux de faux positifs (FPR)\")\nax.set_ylabel(\"Taux de vrais positifs (TPR / Recall)\")\nax.set_title(\"Courbes ROC - Comparaison des modeles\")\nax.legend(loc=\"lower right\")\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Ajustement du seuil de decision\n\n### C'est quoi le seuil ?\n\nLe modele ne predit pas directement \"churn\" ou \"pas churn\". Il donne une **probabilite** : \"ce client a 73% de chances de partir\".\n\nLe **seuil** est la limite a partir de laquelle on decide : si la probabilite depasse le seuil, on dit \"churn\".\n\nPar defaut, le seuil est a **0.5** (50%). Mais on peut le bouger :\n\n```\nSeuil = 0.3 (prudent)         Seuil = 0.7 (strict)\n─────────────────              ─────────────────\n\"Des que c'est > 30%,          \"Seulement si c'est > 70%,\n je considere churn\"            je considere churn\"\n\n→ Detecte PLUS de churns       → Detecte MOINS de churns\n→ Mais plus de fausses alarmes  → Mais chaque alerte est fiable\n→ Meilleur Recall               → Meilleure Precision\n```\n\n### Quel seuil choisir ?\n\nCa depend du **cout metier** :\n\n| Situation | Seuil recommande | Pourquoi |\n|-----------|-----------------|----------|\n| Detecter une maladie grave | **Bas** (0.2-0.3) | Mieux vaut une fausse alarme que rater un malade |\n| Envoyer une promotion couteuse | **Haut** (0.6-0.7) | Chaque envoi coute cher, on veut cibler juste |\n| Detecter le churn client | **Moyen** (0.4-0.5) | Equilibre entre cout de retention et perte de client |\n\n> **A retenir** : Il n'y a pas de \"bon\" seuil universel. Le F1-Score optimal trouve le meilleur compromis, mais la decision finale depend du contexte metier."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cellule 9 : Ajustement du seuil + courbe precision-recall\n",
    "# ============================================================\n",
    "\n",
    "# Utilisation du meilleur modele pour l'analyse du seuil\n",
    "meilleur_modele = gb  # Gradient Boosting\n",
    "y_proba = meilleur_modele.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Courbe precision-recall\n",
    "precision_vals, recall_vals, seuils_pr = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 1. Courbe Precision-Recall\n",
    "axes[0].plot(recall_vals, precision_vals, color=\"#8e44ad\", linewidth=2)\n",
    "axes[0].set_xlabel(\"Recall\")\n",
    "axes[0].set_ylabel(\"Precision\")\n",
    "axes[0].set_title(\"Courbe Precision-Recall\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xlim(0, 1)\n",
    "axes[0].set_ylim(0, 1.05)\n",
    "\n",
    "# 2. Precision et Recall en fonction du seuil\n",
    "axes[1].plot(seuils_pr, precision_vals[:-1], label=\"Precision\", color=\"#3498db\", linewidth=2)\n",
    "axes[1].plot(seuils_pr, recall_vals[:-1], label=\"Recall\", color=\"#e74c3c\", linewidth=2)\n",
    "\n",
    "# Calcul du F1 pour chaque seuil\n",
    "f1_seuils = 2 * (precision_vals[:-1] * recall_vals[:-1]) / (precision_vals[:-1] + recall_vals[:-1] + 1e-10)\n",
    "axes[1].plot(seuils_pr, f1_seuils, label=\"F1-Score\", color=\"#2ecc71\", linewidth=2, linestyle=\"--\")\n",
    "\n",
    "# Seuil optimal (max F1)\n",
    "idx_optimal = np.argmax(f1_seuils)\n",
    "seuil_optimal = seuils_pr[idx_optimal]\n",
    "axes[1].axvline(x=seuil_optimal, color=\"gray\", linestyle=\":\", linewidth=2, label=f\"Seuil optimal = {seuil_optimal:.2f}\")\n",
    "\n",
    "axes[1].set_xlabel(\"Seuil de decision\")\n",
    "axes[1].set_ylabel(\"Score\")\n",
    "axes[1].set_title(\"Precision / Recall / F1 en fonction du seuil\")\n",
    "axes[1].legend(loc=\"center left\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comparaison seuil 0.5 vs seuil optimal\n",
    "print(f\"\\n--- Comparaison des seuils ---\")\n",
    "print(f\"  Seuil par defaut : 0.50\")\n",
    "print(f\"  Seuil optimal (max F1) : {seuil_optimal:.2f}\")\n",
    "\n",
    "for seuil in [0.5, seuil_optimal]:\n",
    "    y_pred_seuil = (y_proba >= seuil).astype(int)\n",
    "    prec = precision_score(y_test, y_pred_seuil)\n",
    "    rec = recall_score(y_test, y_pred_seuil)\n",
    "    f1 = f1_score(y_test, y_pred_seuil)\n",
    "    print(f\"\\n  Seuil = {seuil:.2f} -> Precision={prec:.3f}, Recall={rec:.3f}, F1={f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline + GridSearchCV\n",
    "\n",
    "En production, il est recommande d'utiliser des **Pipelines sklearn** qui enchainent\n",
    "preprocessing et modele dans un seul objet. Cela evite les fuites de donnees (data leakage)\n",
    "et simplifie le deploiement.\n",
    "\n",
    "Nous allons aussi utiliser **GridSearchCV** pour optimiser les hyperparametres."
   ]
  },
  {
   "cell_type": "code",
   "source": "# ============================================================\n# Cellule 10 : Pipeline + GridSearchCV\n# ============================================================\n\n# Construction du pipeline : Scaling -> Random Forest\npipeline = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"classifier\", RandomForestClassifier(random_state=42, n_jobs=-1)),\n])\n\n# Grille d'hyperparametres a tester\nparam_grid = {\n    \"classifier__n_estimators\": [50, 100, 200],\n    \"classifier__max_depth\": [5, 10, None],\n    \"classifier__min_samples_split\": [2, 5],\n}\n\nprint(\"Lancement du GridSearchCV...\")\nprint(f\"Nombre de combinaisons : {3 * 3 * 2} x 5 folds = {3 * 3 * 2 * 5} evaluations\")\n\n# Recherche des meilleurs hyperparametres\ngrid_search = GridSearchCV(\n    pipeline,\n    param_grid,\n    cv=5,\n    scoring=\"f1\",\n    n_jobs=-1,\n    verbose=0,\n)\ngrid_search.fit(X_train, y_train)\n\nprint(f\"\\n--- Resultats du GridSearchCV ---\")\nprint(f\"  Meilleurs hyperparametres : {grid_search.best_params_}\")\nprint(f\"  Meilleur score F1 (CV)    : {grid_search.best_score_:.4f}\")\n\n# Evaluation du meilleur modele sur le jeu de test\nprint(\"\\n--- Evaluation sur le jeu de test ---\")\ny_pred_best = grid_search.predict(X_test)\ny_proba_best = grid_search.predict_proba(X_test)[:, 1]\n\nprint(f\"  Accuracy  : {accuracy_score(y_test, y_pred_best):.4f}\")\nprint(f\"  Precision : {precision_score(y_test, y_pred_best):.4f}\")\nprint(f\"  Recall    : {recall_score(y_test, y_pred_best):.4f}\")\nprint(f\"  F1-Score  : {f1_score(y_test, y_pred_best):.4f}\")\nprint(f\"  AUC-ROC   : {roc_auc_score(y_test, y_proba_best):.4f}\")\n\n# Affichage des resultats de la grille triee par score\nprint(\"\\n--- Top 5 des combinaisons ---\")\nresultats_grid = pd.DataFrame(grid_search.cv_results_)\ntop5 = resultats_grid.nsmallest(5, \"rank_test_score\")[[\"params\", \"mean_test_score\", \"std_test_score\"]]\nfor idx, row in top5.iterrows():\n    print(f\"  F1={row['mean_test_score']:.4f} (+/-{row['std_test_score']:.4f}) | {row['params']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Conclusion\n\n### Recapitulatif des resultats\n\nNous avons compare 3 modeles de classification pour predire le churn client :\n\n| Modele | Avantages | Inconvenients |\n|--------|-----------|---------------|\n| **Regression Logistique** | Simple, interpretable, rapide | Suppose linearite |\n| **Random Forest** | Non lineaire, robuste, importance features | Plus lent, moins interpretable |\n| **Gradient Boosting** | Tres performant, flexible | Risque de surapprentissage, lent |\n\n### Points cles\n\n1. Les **reclamations** et le **score de satisfaction** sont les meilleurs predicteurs du churn\n2. Les clients **Web** et **CDD/Freelance** ont un taux de churn plus eleve\n3. L'**anciennete** et le **montant total** d'achats sont negativement correles au churn\n4. L'ajustement du **seuil de decision** permet d'adapter le modele au contexte metier\n\n### Pour aller plus loin\n\n- Gerer le **desequilibre des classes** (SMOTE, class_weight)\n- Tester des modeles plus avances (XGBoost, LightGBM, CatBoost)\n- Implementer un **systeme d'alerte** pour les clients a risque\n- Calculer la **valeur metier** : combien un modele de churn fait-il economiser ?\n\n### Lexique debutant\n\n| Terme | Definition simple |\n|-------|------------------|\n| **Classification** | Predire une categorie (oui/non, spam/pas spam, churn/fidele) |\n| **Churn** | Un client qui quitte l'entreprise ou arrete d'acheter |\n| **Matrice de confusion** | Tableau qui resume les 4 types de resultats (TP, TN, FP, FN) |\n| **Precision** | \"Quand je dis oui, ai-je raison ?\" |\n| **Recall** | \"Est-ce que je detecte tous les oui ?\" |\n| **F1-Score** | Compromis entre precision et recall (utile quand les classes sont desequilibrees) |\n| **AUC-ROC** | Score global de 0.5 (hasard) a 1 (parfait) |\n| **Seuil** | Probabilite a partir de laquelle on decide \"positif\" (defaut : 0.5) |\n| **Stratification** | S'assurer que train et test ont les memes proportions de chaque classe |\n| **GridSearchCV** | Tester automatiquement plusieurs combinaisons d'hyperparametres |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cellule 11 : Resume final\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  TABLEAU COMPARATIF FINAL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df_resultats = pd.DataFrame(resultats)\n",
    "df_resultats = df_resultats.sort_values(\"F1-Score\", ascending=False)\n",
    "print(df_resultats.to_string(index=False, float_format=\"{:.4f}\".format))\n",
    "\n",
    "# Meilleur modele\n",
    "meilleur = df_resultats.iloc[0]\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"  MEILLEUR MODELE : {meilleur['Modele']}\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"  F1-Score : {meilleur['F1-Score']:.4f}\")\n",
    "print(f\"  AUC-ROC  : {meilleur['AUC-ROC']:.4f}\")\n",
    "print(f\"  Recall   : {meilleur['Recall']:.4f}\")\n",
    "print(f\"\\n  Interpretation :\")\n",
    "print(f\"  Le modele detecte {meilleur['Recall']*100:.0f}% des clients qui vont churner\")\n",
    "print(f\"  avec une precision de {meilleur['Precision']*100:.0f}%.\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}