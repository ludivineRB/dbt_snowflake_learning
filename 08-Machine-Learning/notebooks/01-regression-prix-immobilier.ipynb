{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression : Prediction des prix immobiliers\n",
    "\n",
    "> Ce notebook est un exemple pratique clef en main pour apprendre les techniques de regression en Machine Learning.\n",
    "> Nous allons predire le prix de biens immobiliers a partir de leurs caracteristiques (surface, nombre de pieces, ville, etc.).\n",
    ">\n",
    "> **Objectifs :**\n",
    "> - Comprendre le pipeline complet d'un projet de regression\n",
    "> - Comparer plusieurs algorithmes (Regression lineaire, Ridge, Lasso, Random Forest)\n",
    "> - Evaluer les performances avec les metriques adaptees (MSE, RMSE, MAE, R2, MAPE)\n",
    "> - Analyser les residus pour valider le modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cellule 1 : Imports et chargement des donnees\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    mean_absolute_percentage_error,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configuration graphique\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Chargement des donnees\n",
    "df = pd.read_csv(\"../data/house_prices.csv\")\n",
    "\n",
    "print(f\"Dataset charge avec succes : {df.shape[0]} lignes, {df.shape[1]} colonnes\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cellule 2 : Analyse exploratoire (EDA)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"INFORMATIONS GENERALES SUR LE DATASET\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDimensions : {df.shape}\")\n",
    "print(f\"\\nTypes des colonnes :\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VALEURS MANQUANTES\")\n",
    "print(\"=\" * 60)\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATISTIQUES DESCRIPTIVES (VARIABLES NUMERIQUES)\")\n",
    "print(\"=\" * 60)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisations exploratoires\n",
    "\n",
    "Nous allons examiner les relations entre les variables explicatives et la variable cible (prix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cellule 3 : Visualisations\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Scatter plot : prix vs surface\n",
    "axes[0, 0].scatter(df[\"surface_m2\"], df[\"prix\"], alpha=0.7, edgecolors=\"k\", linewidth=0.5)\n",
    "axes[0, 0].set_xlabel(\"Surface (m2)\")\n",
    "axes[0, 0].set_ylabel(\"Prix (euros)\")\n",
    "axes[0, 0].set_title(\"Prix en fonction de la surface\")\n",
    "\n",
    "# Scatter plot : prix vs nombre de pieces\n",
    "axes[0, 1].scatter(df[\"nb_pieces\"], df[\"prix\"], alpha=0.7, edgecolors=\"k\", linewidth=0.5, color=\"orange\")\n",
    "axes[0, 1].set_xlabel(\"Nombre de pieces\")\n",
    "axes[0, 1].set_ylabel(\"Prix (euros)\")\n",
    "axes[0, 1].set_title(\"Prix en fonction du nombre de pieces\")\n",
    "\n",
    "# Boxplot par ville\n",
    "ordre_villes = df.groupby(\"ville\")[\"prix\"].median().sort_values(ascending=False).index\n",
    "sns.boxplot(data=df, x=\"ville\", y=\"prix\", order=ordre_villes, ax=axes[1, 0], palette=\"Set2\")\n",
    "axes[1, 0].set_xlabel(\"Ville\")\n",
    "axes[1, 0].set_ylabel(\"Prix (euros)\")\n",
    "axes[1, 0].set_title(\"Distribution des prix par ville\")\n",
    "axes[1, 0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# Distribution des prix\n",
    "axes[1, 1].hist(df[\"prix\"], bins=15, edgecolor=\"black\", alpha=0.7, color=\"steelblue\")\n",
    "axes[1, 1].set_xlabel(\"Prix (euros)\")\n",
    "axes[1, 1].set_ylabel(\"Frequence\")\n",
    "axes[1, 1].set_title(\"Distribution des prix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Matrice de correlation (heatmap)\n",
    "print(\"\\n--- Matrice de correlation ---\")\n",
    "colonnes_num = [\"surface_m2\", \"nb_pieces\", \"etage\", \"parking\", \"annee_construction\", \"prix\"]\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "matrice_corr = df[colonnes_num].corr()\n",
    "sns.heatmap(matrice_corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0, ax=ax)\n",
    "ax.set_title(\"Matrice de correlation\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing des donnees\n",
    "\n",
    "Avant d'entrainer nos modeles, nous devons :\n",
    "1. **Encoder** la variable categorielle `ville` (Label Encoding ou One-Hot Encoding)\n",
    "2. **Separer** les donnees en jeu d'entrainement et jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cellule 4 : Preprocessing (encodage + split train/test)\n",
    "# ============================================================\n",
    "\n",
    "# Copie du dataframe pour ne pas modifier l'original\n",
    "df_model = df.copy()\n",
    "\n",
    "# One-Hot Encoding de la variable 'ville'\n",
    "df_model = pd.get_dummies(df_model, columns=[\"ville\"], drop_first=True)\n",
    "\n",
    "print(\"Colonnes apres encodage :\")\n",
    "print(df_model.columns.tolist())\n",
    "\n",
    "# Separation features / target\n",
    "X = df_model.drop(\"prix\", axis=1)\n",
    "y = df_model[\"prix\"]\n",
    "\n",
    "# Split train/test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTaille du jeu d'entrainement : {X_train.shape[0]} echantillons\")\n",
    "print(f\"Taille du jeu de test : {X_test.shape[0]} echantillons\")\n",
    "print(f\"Nombre de features : {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele 1 : Regression lineaire\n",
    "\n",
    "Nous commencons par le modele le plus simple : la regression lineaire ordinaire (OLS)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Comprendre les metriques de regression\n\nAvant de lancer notre premier modele, prenons le temps de comprendre **comment on mesure la qualite** d'une prediction. Imaginez que vous etes agent immobilier et que vous estimez des prix de maisons :\n\n### L'analogie du GPS\n\nPensez a un GPS qui vous dit : \"Vous arriverez dans 30 minutes\".\n\n- Si vous arrivez en **28 minutes** : l'erreur est de 2 minutes (pas grave)\n- Si vous arrivez en **55 minutes** : l'erreur est de 25 minutes (probleme !)\n\nLes metriques de regression mesurent exactement ca : **a quel point nos predictions sont loin de la realite**.\n\n### Les metriques expliquees simplement\n\n| Metrique | En langage courant | Exemple concret |\n|----------|-------------------|-----------------|\n| **MAE** (Mean Absolute Error) | \"En moyenne, je me trompe de X euros\" | MAE = 15 000 → le modele se trompe de 15 000€ en moyenne |\n| **RMSE** (Root Mean Squared Error) | \"Comme la MAE, mais penalise plus les grosses erreurs\" | Si une maison est predite a 100 000€ au lieu de 300 000€, le RMSE sera tres eleve |\n| **R²** (R-squared) | \"Quelle proportion du prix le modele arrive-t-il a expliquer ?\" | R² = 0.85 → le modele explique 85% des variations de prix |\n| **MAPE** | \"En pourcentage, je me trompe de X%\" | MAPE = 8% → les predictions sont a +/- 8% du vrai prix |\n\n### Comment lire les resultats ?\n\n```\nBon modele          Mauvais modele\n─────────────       ─────────────\nMAE  : 10 000€      MAE  : 80 000€\nRMSE : 15 000€      RMSE : 120 000€\nR²   : 0.92         R²   : 0.35\nMAPE : 5%           MAPE : 40%\n```\n\n> **A retenir** : Le R² est le plus intuitif pour debuter. Un R² de 0 = le modele ne predit rien. Un R² de 1 = prediction parfaite. En pratique, un R² > 0.80 est souvent considere comme bon.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cellule 5 : Regression lineaire + metriques\n",
    "# ============================================================\n",
    "\n",
    "def evaluer_modele(modele, X_train, X_test, y_train, y_test, nom_modele):\n",
    "    \"\"\"Fonction utilitaire pour evaluer un modele de regression.\"\"\"\n",
    "    # Predictions\n",
    "    y_pred_train = modele.predict(X_train)\n",
    "    y_pred_test = modele.predict(X_test)\n",
    "\n",
    "    # Calcul des metriques sur le jeu de test\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred_test) * 100\n",
    "\n",
    "    # R2 sur le train pour detecter le surapprentissage\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"  RESULTATS : {nom_modele}\")\n",
    "    print(f\"{'=' * 50}\")\n",
    "    print(f\"  R2 (train) : {r2_train:.4f}\")\n",
    "    print(f\"  R2 (test)  : {r2:.4f}\")\n",
    "    print(f\"  MSE        : {mse:,.0f}\")\n",
    "    print(f\"  RMSE       : {rmse:,.0f} euros\")\n",
    "    print(f\"  MAE        : {mae:,.0f} euros\")\n",
    "    print(f\"  MAPE       : {mape:.2f}%\")\n",
    "\n",
    "    return {\n",
    "        \"Modele\": nom_modele,\n",
    "        \"R2_train\": r2_train,\n",
    "        \"R2_test\": r2,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"MAPE\": mape,\n",
    "    }\n",
    "\n",
    "\n",
    "# Entrainement du modele de regression lineaire\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "resultats = []\n",
    "resultats.append(evaluer_modele(lr, X_train, X_test, y_train, y_test, \"Regression Lineaire\"))\n",
    "\n",
    "# Affichage des coefficients\n",
    "print(\"\\n--- Coefficients du modele lineaire ---\")\n",
    "coefs = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Coefficient\": lr.coef_\n",
    "}).sort_values(\"Coefficient\", ascending=False)\n",
    "print(coefs.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeles 2 et 3 : Ridge et Lasso\n",
    "\n",
    "Les regressions Ridge (L2) et Lasso (L1) ajoutent une penalite de regularisation pour eviter le surapprentissage.\n",
    "\n",
    "- **Ridge** : penalise la somme des carres des coefficients (les reduit mais ne les annule pas)\n",
    "- **Lasso** : penalise la somme des valeurs absolues des coefficients (peut les annuler, utile pour la selection de features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cellule 6 : Ridge et Lasso\n",
    "# ============================================================\n",
    "\n",
    "# Regression Ridge\n",
    "ridge = Ridge(alpha=1.0, random_state=42)\n",
    "ridge.fit(X_train, y_train)\n",
    "resultats.append(evaluer_modele(ridge, X_train, X_test, y_train, y_test, \"Ridge (alpha=1.0)\"))\n",
    "\n",
    "# Regression Lasso\n",
    "lasso = Lasso(alpha=100.0, random_state=42)\n",
    "lasso.fit(X_train, y_train)\n",
    "resultats.append(evaluer_modele(lasso, X_train, X_test, y_train, y_test, \"Lasso (alpha=100.0)\"))\n",
    "\n",
    "# Comparaison des coefficients Ridge vs Lasso\n",
    "print(\"\\n--- Comparaison des coefficients ---\")\n",
    "comp_coefs = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Lineaire\": lr.coef_,\n",
    "    \"Ridge\": ridge.coef_,\n",
    "    \"Lasso\": lasso.coef_,\n",
    "})\n",
    "print(comp_coefs.round(2).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele 4 : Random Forest Regression\n",
    "\n",
    "Le Random Forest est un modele d'ensemble base sur des arbres de decision.\n",
    "Il est capable de capturer des relations non lineaires entre les variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cellule 7 : Random Forest Regression\n",
    "# ============================================================\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "resultats.append(evaluer_modele(rf, X_train, X_test, y_train, y_test, \"Random Forest\"))\n",
    "\n",
    "# Importance des features\n",
    "print(\"\\n--- Importance des features (Random Forest) ---\")\n",
    "importances = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Importance\": rf.feature_importances_\n",
    "}).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.barplot(data=importances, x=\"Importance\", y=\"Feature\", palette=\"viridis\", ax=ax)\n",
    "ax.set_title(\"Importance des features - Random Forest\")\n",
    "ax.set_xlabel(\"Importance\")\n",
    "ax.set_ylabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des modeles\n",
    "\n",
    "Nous allons maintenant comparer les performances de tous les modeles dans un tableau recapitulatif,\n",
    "puis tracer les courbes d'apprentissage du meilleur modele."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Analyse des residus : verifier que le modele est fiable\n\nUn **residu**, c'est simplement la difference entre le prix reel et le prix predit par le modele.\n\n> **Exemple** : Si une maison vaut 250 000€ et que le modele predit 240 000€, le residu est de +10 000€ (le modele a sous-estime de 10 000€).\n\n### Pourquoi analyser les residus ?\n\nC'est comme verifier qu'un thermometre est fiable : on ne regarde pas juste s'il donne la bonne temperature en moyenne, on verifie aussi qu'il ne se trompe pas systematiquement dans un sens.\n\n**4 choses a verifier :**\n\n1. **Predictions vs Realite** (graphique en haut a gauche) : les points doivent etre proches de la ligne rouge (= prediction parfaite)\n2. **Distribution des residus** (en haut a droite) : doit ressembler a une cloche centree sur 0 (le modele se trompe autant vers le haut que vers le bas)\n3. **Residus vs Predictions** (en bas a gauche) : les points doivent etre repartis uniformement autour de 0 (pas de pattern en forme de V ou d'entonnoir)\n4. **QQ-Plot** (en bas a droite) : les points doivent suivre la ligne diagonale (confirme la distribution normale des erreurs)"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Conclusion\n\n### Recapitulatif des resultats\n\nNous avons compare 4 modeles de regression sur notre jeu de donnees immobilier :\n\n| Modele | Avantages | Inconvenients |\n|--------|-----------|---------------|\n| **Regression lineaire** | Simple, interpretable | Hypothese de linearite |\n| **Ridge** | Regularisation L2, robuste | Moins interpretable |\n| **Lasso** | Selection de features, parcimonie | Peut eliminer des features utiles |\n| **Random Forest** | Non lineaire, robuste | Boite noire, plus lent |\n\n### Points cles\n\n1. La **surface** est le facteur le plus important pour predire le prix\n2. La **ville** a un impact significatif (Paris plus cher que les autres villes)\n3. Le **Random Forest** capture mieux les relations non lineaires\n4. L'analyse des residus confirme la qualite du modele retenu\n\n### Pour aller plus loin\n\n- Tester un **Gradient Boosting** (XGBoost, LightGBM)\n- Ajouter des features supplementaires (proximite transports, quartier, etc.)\n- Realiser une **validation croisee** plus poussee\n- Optimiser les hyperparametres avec **GridSearchCV** ou **RandomizedSearchCV**\n\n### Lexique debutant\n\n| Terme | Definition simple |\n|-------|------------------|\n| **Regression** | Predire un nombre (prix, temperature, age...) |\n| **Feature** | Une information utilisee pour la prediction (surface, ville...) |\n| **Train set** | Les donnees sur lesquelles le modele apprend |\n| **Test set** | Les donnees reservees pour verifier que le modele generalise |\n| **Overfitting** | Le modele a \"appris par coeur\" le train set et echoue sur de nouvelles donnees |\n| **R²** | Score de 0 a 1, mesure la qualite globale du modele (1 = parfait) |\n| **Residu** | Difference entre la valeur reelle et la prediction |\n| **Regularisation** | Technique pour empecher l'overfitting (Ridge, Lasso) |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cellule 10 : Resume final\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  RESUME FINAL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Identification du meilleur modele\n",
    "meilleur = df_resultats.iloc[0]\n",
    "print(f\"\\n  Meilleur modele     : {meilleur['Modele']}\")\n",
    "print(f\"  R2 (test)           : {meilleur['R2_test']:.4f}\")\n",
    "print(f\"  RMSE                : {meilleur['RMSE']:,.0f} euros\")\n",
    "print(f\"  MAE                 : {meilleur['MAE']:,.0f} euros\")\n",
    "print(f\"  MAPE                : {meilleur['MAPE']:.2f}%\")\n",
    "\n",
    "print(f\"\\n  Interpretation : Le modele predit le prix a +/- {meilleur['MAE']:,.0f} euros en moyenne.\")\n",
    "print(f\"  Cela represente une erreur relative moyenne de {meilleur['MAPE']:.1f}%.\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}