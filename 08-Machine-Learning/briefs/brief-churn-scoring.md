# Brief Projet Fil Rouge : API de Scoring Churn Client

## ğŸ“‹ Contexte du projet

**Entreprise** : TelcoPlus, opÃ©rateur tÃ©lÃ©com avec 7 000 clients
**ProblÃ¨me mÃ©tier** : Le taux de churn (dÃ©sabonnement) est de ~26%. Chaque client perdu coÃ»te en moyenne 500â‚¬ en acquisition d'un nouveau client. L'entreprise souhaite **prÃ©dire le churn** pour cibler les actions de rÃ©tention.

**Votre mission** : Construire un systÃ¨me ML complet, de l'exploration des donnÃ©es au dÃ©ploiement d'une API de scoring, en passant par la modÃ©lisation et l'interprÃ©tation des rÃ©sultats.

---

## ğŸ¯ Objectifs pÃ©dagogiques

Ce projet couvre **toutes les phases** du parcours ML :

| Phase | CompÃ©tence Ã©valuÃ©e | Livrable |
|-------|--------------------|----------|
| 0 | Exploration et comprÃ©hension des donnÃ©es | Rapport d'audit |
| 1 | Bases mathÃ©matiques appliquÃ©es | Notebook explicatif |
| 2 | Preprocessing et feature engineering | Pipeline robuste |
| 3 | ModÃ©lisation et comparaison | Tableau comparatif |
| 4 | Ã‰valuation rigoureuse | Rapport d'Ã©valuation |
| 5 | InterprÃ©tabilitÃ© | Explications SHAP |
| 6 | Mise en production | API DockerisÃ©e |

---

## ğŸ“Š Dataset

**Fichier** : `data/clients_churn.csv`

Le dataset contient des informations sur les clients d'un opÃ©rateur tÃ©lÃ©com :
- Informations dÃ©mographiques (genre, senior, partenaire, personnes Ã  charge)
- Informations sur le compte (anciennetÃ©, contrat, facturation, paiement)
- Services souscrits (tÃ©lÃ©phone, internet, sÃ©curitÃ©, streaming...)
- Variable cible : `Churn` (Yes/No)

---

## ğŸ“ Livrables attendus

### Partie 0 : Exploration (Semaines 1-2)

**Livrable** : `notebooks/00-exploration.ipynb`

- [ ] Chargement et description du dataset (shape, dtypes, describe)
- [ ] Analyse des valeurs manquantes (quantification + stratÃ©gie)
- [ ] Distribution de la variable cible (dÃ©sÃ©quilibre ?)
- [ ] Visualisations : histogrammes, countplots, heatmap corrÃ©lation
- [ ] Identification des variables les plus corrÃ©lÃ©es au churn
- [ ] Rapport d'audit en markdown (10-15 lignes)

### Partie 1 : PrÃ©paration des donnÃ©es (Semaines 6-8)

**Livrable** : `src/preprocessing.py` + `notebooks/01-preprocessing.ipynb`

- [ ] Traitement des valeurs manquantes (imputation justifiÃ©e)
- [ ] Encodage des variables catÃ©gorielles (One-Hot / Ordinal selon le cas)
- [ ] Scaling des variables numÃ©riques (StandardScaler)
- [ ] CrÃ©ation d'au moins 3 nouvelles features pertinentes
- [ ] Pipeline scikit-learn avec ColumnTransformer
- [ ] **Aucun data leakage** (vÃ©rifiable : fit uniquement sur train)
- [ ] Train/test split stratifiÃ© (80/20)

### Partie 2 : ModÃ©lisation (Semaines 9-11)

**Livrable** : `notebooks/02-modelisation.ipynb`

- [ ] Baseline : RÃ©gression Logistique
- [ ] Au moins 4 autres modÃ¨les testÃ©s (RF, XGBoost, LightGBM, etc.)
- [ ] Tableau comparatif avec au moins 4 mÃ©triques
- [ ] Tuning des hyperparamÃ¨tres sur les 2 meilleurs modÃ¨les (GridSearchCV)
- [ ] Justification de la mÃ©trique principale choisie
- [ ] SÃ©lection du modÃ¨le final argumentÃ©e

### Partie 3 : Ã‰valuation (Semaines 12-13)

**Livrable** : `notebooks/03-evaluation.ipynb`

- [ ] Cross-validation (5-fold stratifiÃ©) avec scores et Ã©carts-types
- [ ] Matrice de confusion du modÃ¨le final
- [ ] Courbe ROC + AUC
- [ ] Courbe Precision-Recall
- [ ] Courbes d'apprentissage (diagnostic overfitting)
- [ ] Analyse du seuil de dÃ©cision optimal
- [ ] Rapport d'Ã©valuation formatÃ©

### Partie 4 : InterprÃ©tabilitÃ© (Semaine 14)

**Livrable** : `notebooks/04-interpretabilite.ipynb`

- [ ] Feature importance globale (permutation ou MDI)
- [ ] Analyse SHAP :
  - Summary plot (global)
  - Waterfall plot (3 exemples individuels)
  - Dependence plot (2 features clÃ©s)
- [ ] Explication "business-friendly" : pourquoi ce client va-t-il churner ?
- [ ] Identification de 3 leviers d'action pour la rÃ©tention

### Partie 5 : Mise en production (Semaines 15-16)

**Livrable** : `src/` + `Dockerfile` + `docker-compose.yml`

- [ ] SÃ©rialisation du modÃ¨le (joblib)
- [ ] API FastAPI avec endpoint `POST /predict`
- [ ] Validation des entrÃ©es avec Pydantic
- [ ] Endpoint `GET /health`
- [ ] Dockerfile fonctionnel
- [ ] docker-compose.yml
- [ ] Tests de l'API (au moins 3 tests)
- [ ] README avec instructions de lancement

---

## ğŸ“ Structure attendue du projet

```
projet-churn/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ clients_churn.csv
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ (gÃ©nÃ©rÃ© par le pipeline)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 00-exploration.ipynb
â”‚   â”œâ”€â”€ 01-preprocessing.ipynb
â”‚   â”œâ”€â”€ 02-modelisation.ipynb
â”‚   â”œâ”€â”€ 03-evaluation.ipynb
â”‚   â””â”€â”€ 04-interpretabilite.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ predict.py
â”‚   â””â”€â”€ api.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ pipeline.joblib
â”‚   â””â”€â”€ model_metadata.json
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”œâ”€â”€ test_model.py
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

---

## ğŸ† CritÃ¨res d'Ã©valuation

| CritÃ¨re | Points | DÃ©tails |
|---------|--------|---------|
| Exploration des donnÃ©es | /10 | QualitÃ© de l'audit, visualisations pertinentes |
| Preprocessing | /15 | Pipeline robuste, pas de leakage, features crÃ©Ã©es |
| ModÃ©lisation | /15 | Comparaison rigoureuse, tuning, choix argumentÃ© |
| Ã‰valuation | /15 | MÃ©triques complÃ¨tes, cross-validation, diagnostic |
| InterprÃ©tabilitÃ© | /15 | SHAP, feature importance, explications mÃ©tier |
| Production | /15 | API fonctionnelle, Docker, tests |
| QualitÃ© du code | /10 | LisibilitÃ©, structure, documentation |
| PrÃ©sentation orale | /5 | Pitch de 15 min clair et structurÃ© |
| **Total** | **/100** | |

---

## ğŸ“… Planning suggÃ©rÃ©

| Semaine | Livrable | Points |
|---------|----------|--------|
| 1-2 | Exploration | 10 |
| 6-8 | Preprocessing | 15 |
| 9-11 | ModÃ©lisation | 15 |
| 12-13 | Ã‰valuation | 15 |
| 14 | InterprÃ©tabilitÃ© | 15 |
| 15-16 | Production + Tests + PrÃ©sentation | 30 |

---

## ğŸ’¡ Conseils

- **Commencez simple** : une rÃ©gression logistique avec 3 features vaut mieux qu'un XGBoost sur un pipeline buggÃ©
- **Versionnez votre travail** : un commit par Ã©tape majeure
- **Documentez vos choix** : "J'ai choisi X parce que Y" vaut plus que "J'ai utilisÃ© X"
- **Testez votre API** : un `curl` qui fonctionne vaut mieux qu'un Swagger qui plante
- **PrÃ©parez votre pitch** : 15 min, orientÃ© mÃ©tier, pas technique
