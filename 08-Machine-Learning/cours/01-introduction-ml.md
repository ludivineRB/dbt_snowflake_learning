# Chapitre 1 : Introduction au Machine Learning

## üéØ Objectifs

- Comprendre ce qu'est le Machine Learning et pourquoi il existe
- Distinguer les types d'apprentissage (supervis√©, non-supervis√©, par renforcement)
- Conna√Ætre le workflow ML complet de bout en bout
- Savoir quand utiliser (et ne **PAS** utiliser) le ML
- Ma√Ætriser le vocabulaire essentiel du domaine
- D√©couvrir l'√©cosyst√®me Python pour le Machine Learning

---

## 1. üß† Qu'est-ce que le Machine Learning ?

### 1.1 D√©finition

Le **Machine Learning** (apprentissage automatique) est une branche de l'intelligence artificielle qui permet aux machines d'**apprendre √† partir de donn√©es** sans √™tre explicitement programm√©es pour chaque cas.

> üí° **Conseil** : Retenez cette d√©finition simple ‚Äî le ML, c'est **donner des exemples** √† un programme pour qu'il **apprenne les r√®gles tout seul**, plut√¥t que de coder les r√®gles √† la main.

### 1.2 ML vs Programmation traditionnelle

La diff√©rence fondamentale r√©side dans l'approche :

| Aspect | Programmation traditionnelle | Machine Learning |
|--------|------------------------------|------------------|
| **Entr√©e** | Donn√©es + R√®gles | Donn√©es + R√©sultats attendus |
| **Sortie** | R√©sultats | R√®gles (mod√®le) |
| **Approche** | D√©ductive (r√®gles ‚Üí r√©sultats) | Inductive (exemples ‚Üí r√®gles) |
| **Maintenance** | Modifier les r√®gles manuellement | R√©entra√Æner avec de nouvelles donn√©es |
| **Complexit√©** | Difficile si beaucoup de cas | G√®re bien la complexit√© |

**Programmation traditionnelle :**

```
Donn√©es + R√®gles ‚Üí Programme ‚Üí R√©sultats
```

**Machine Learning :**

```
Donn√©es + R√©sultats ‚Üí Algorithme ML ‚Üí Mod√®le (les r√®gles)
```

### 1.3 Analogie : reconna√Ætre un chat

**Approche traditionnelle** : √©crire des r√®gles comme "si l'image contient deux triangles (oreilles) + deux cercles (yeux) + des moustaches ‚Üí chat". C'est extr√™mement difficile et fragile.

**Approche ML** : montrer 10 000 photos de chats et 10 000 photos de non-chats √† un algorithme. Il apprend **tout seul** les caract√©ristiques qui distinguent un chat.

> üß† **Pour aller plus loin** : Cette analogie illustre pourquoi le ML excelle dans les t√¢ches o√π les r√®gles sont trop complexes ou trop nombreuses pour √™tre cod√©es manuellement ‚Äî reconnaissance d'images, traduction automatique, recommandation de contenu, etc.

### 1.4 Bref historique

| Ann√©e | √âv√©nement | Impact |
|-------|-----------|--------|
| 1950 | Alan Turing propose le "Test de Turing" | Fondation conceptuelle de l'IA |
| 1957 | Perceptron (Frank Rosenblatt) | Premier r√©seau de neurones |
| 1997 | Deep Blue bat Kasparov aux √©checs | R√®gles + force brute, pas du ML |
| 2012 | AlexNet gagne ImageNet | Explosion du Deep Learning |
| 2016 | AlphaGo bat Lee Sedol au Go | Apprentissage par renforcement |
| 2022+ | ChatGPT, LLMs | Mod√®les de langage √† grande √©chelle |

---

## 2. üìä Les types d'apprentissage

### 2.1 Apprentissage supervis√©

**Principe** : on fournit au mod√®le des donn√©es **√©tiquet√©es** (avec la r√©ponse attendue). Le mod√®le apprend la relation entre les entr√©es (features) et la sortie (target/label).

```
Donn√©es d'entra√Ænement = Features (X) + Labels (y)
         ‚Üì
    Algorithme ML
         ‚Üì
    Mod√®le entra√Æn√©
         ‚Üì
Nouvelles donn√©es (X) ‚Üí Mod√®le ‚Üí Pr√©dictions (≈∑)
```

L'apprentissage supervis√© se divise en deux grandes cat√©gories :

#### R√©gression vs Classification

| Aspect | R√©gression | Classification |
|--------|-----------|----------------|
| **Type de sortie** | Valeur continue (nombre) | Cat√©gorie (classe) |
| **Exemple** | Pr√©dire un prix (‚Ç¨) | Pr√©dire spam / non-spam |
| **M√©triques** | MSE, RMSE, MAE, R¬≤ | Accuracy, Precision, Recall, F1, AUC |
| **Algorithmes** | R√©gression lin√©aire, Ridge, Lasso | Logistique, SVM, KNN, Arbres |

#### Exemples concrets

| Probl√®me | Type | Entr√©e (Features) | Sortie (Target) |
|----------|------|-------------------|-----------------|
| Pr√©dire le prix d'un appartement | R√©gression | Surface, quartier, √©tage | Prix (‚Ç¨) |
| Diagnostiquer une maladie | Classification binaire | Sympt√¥mes, analyses | Malade / Sain |
| Estimer le temps de livraison | R√©gression | Distance, trafic, m√©t√©o | Dur√©e (min) |
| Reconna√Ætre un chiffre manuscrit | Classification multi-classes | Pixels de l'image | Chiffre (0-9) |
| Pr√©dire le taux de d√©sabonnement | Classification binaire | Historique client | Churn / No churn |
| Estimer la consommation √©lectrique | R√©gression | Temp√©rature, heure, jour | kWh |

> üí° **Conseil de pro** : Pour savoir si c'est de la r√©gression ou de la classification, posez-vous la question : "Est-ce que la sortie est un **nombre** ou une **cat√©gorie** ?" Si c'est un nombre ‚Üí r√©gression. Si c'est une cat√©gorie ‚Üí classification.

### 2.2 Apprentissage non-supervis√©

**Principe** : on fournit au mod√®le des donn√©es **sans √©tiquettes**. Le mod√®le doit trouver des **structures cach√©es** dans les donn√©es.

```
Donn√©es (X uniquement, pas de y)
         ‚Üì
    Algorithme ML
         ‚Üì
    Structures / Groupes / Patterns
```

#### Principales techniques

| Technique | Objectif | Algorithmes | Exemple |
|-----------|----------|------------|---------|
| **Clustering** | Regrouper des donn√©es similaires | K-Means, DBSCAN, Hierarchique | Segmentation clients |
| **R√©duction de dimension** | Simplifier les donn√©es | PCA, t-SNE, UMAP | Visualisation de donn√©es complexes |
| **D√©tection d'anomalies** | Trouver les points inhabituels | Isolation Forest, LOF | D√©tection de fraude |
| **R√®gles d'association** | Trouver des relations | Apriori, FP-Growth | Panier d'achat (qui ach√®te X ach√®te aussi Y) |

> üí° **Conseil** : Le non-supervis√© est souvent utilis√© en **exploration** ‚Äî pour comprendre ses donn√©es avant de construire un mod√®le supervis√©.

#### Exemples concrets

- **Segmentation clients** : regrouper les clients par comportement d'achat (sans savoir a priori combien de segments il y a)
- **D√©tection d'anomalies** : identifier des transactions bancaires frauduleuses (les fraudes sont rares et diff√©rentes de la norme)
- **Compression d'images** : r√©duire la dimensionalit√© tout en gardant l'essentiel de l'information

### 2.3 Apprentissage par renforcement

**Principe** : un **agent** interagit avec un **environnement**, prend des **actions**, re√ßoit des **r√©compenses** (ou p√©nalit√©s) et apprend √† maximiser la r√©compense totale.

```
Agent ‚Üí Action ‚Üí Environnement
                      ‚Üì
              √âtat + R√©compense
                      ‚Üì
                    Agent (apprend et s'am√©liore)
```

| Composant | R√¥le | Exemple (jeu vid√©o) |
|-----------|------|---------------------|
| **Agent** | Celui qui prend les d√©cisions | Le joueur IA |
| **Environnement** | Le monde dans lequel l'agent √©volue | Le jeu |
| **Action** | Ce que l'agent peut faire | Aller √† gauche, sauter, tirer |
| **√âtat** | La situation actuelle | Position, score, ennemis |
| **R√©compense** | Le feedback | +1 point, -1 vie, game over |

#### Exemples concrets

- **Jeux** : AlphaGo, AlphaZero (√©checs, Go, Shogi)
- **Robotique** : un robot qui apprend √† marcher
- **Recommandation** : optimiser le fil d'actualit√©s pour maximiser l'engagement
- **Trading** : optimiser une strat√©gie d'investissement

> üß† **Pour aller plus loin** : L'apprentissage par renforcement est le plus proche de la fa√ßon dont les humains apprennent ‚Äî par essai-erreur. Cependant, il n√©cessite beaucoup d'interactions avec l'environnement, ce qui le rend souvent impraticable dans le monde r√©el.

### 2.4 Tableau r√©capitulatif des types d'apprentissage

| Crit√®re | Supervis√© | Non-supervis√© | Par renforcement |
|---------|-----------|---------------|------------------|
| **Donn√©es** | √âtiquet√©es (X, y) | Non √©tiquet√©es (X) | Pas de dataset fixe |
| **Objectif** | Pr√©dire y | Trouver des structures | Maximiser r√©compense |
| **Feedback** | Direct (labels) | Aucun | R√©compense diff√©r√©e |
| **Exemples** | Classification, R√©gression | Clustering, PCA | Jeux, Robotique |
| **Difficult√©** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Donn√©es n√©cessaires** | Labels co√ªteux | Donn√©es brutes | Simulateur souvent n√©cessaire |

---

## 3. ‚öôÔ∏è Le workflow ML complet

Tout projet de Machine Learning suit un pipeline structur√©. Voici les √©tapes cl√©s :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. D√©finir  ‚îÇ    ‚îÇ  2. Collecter‚îÇ    ‚îÇ  3. Explorer ‚îÇ    ‚îÇ  4. Pr√©parer ‚îÇ
‚îÇ  le probl√®me ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  les donn√©es ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  (EDA)       ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  (Preprocess)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                    ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  5. Entra√Æner‚îÇ    ‚îÇ  6. √âvaluer  ‚îÇ    ‚îÇ  7. Optimiser‚îÇ    ‚îÇ  8. D√©ployer ‚îÇ
‚îÇ  le mod√®le   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  (M√©triques) ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  (Tuning)    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  (Production)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### √âtape 1 : D√©finir le probl√®me

- Quel est l'objectif m√©tier ?
- Est-ce un probl√®me de r√©gression ou classification ?
- Quelle m√©trique d'√©valuation ?
- Quel est le crit√®re de succ√®s ?

> üí° **Conseil de pro** : "Passez du temps √† bien d√©finir le probl√®me. Un mod√®le parfait qui r√©sout le **mauvais probl√®me** est inutile."

### √âtape 2 : Collecter les donn√©es

- Sources : bases de donn√©es, APIs, fichiers CSV, web scraping
- Qualit√© > Quantit√© (dans un premier temps)
- V√©rifier les aspects l√©gaux (RGPD)

### √âtape 3 : Explorer les donn√©es (EDA)

- Statistiques descriptives
- Visualisations (distributions, corr√©lations)
- Identifier les valeurs manquantes, aberrantes
- Comprendre les relations entre variables

### √âtape 4 : Pr√©parer les donn√©es (Preprocessing)

- Nettoyer les donn√©es (manquantes, aberrantes)
- Encoder les variables cat√©gorielles
- Normaliser/Standardiser les variables num√©riques
- S√©parer en train/test sets

### √âtape 5 : Entra√Æner le mod√®le

- Choisir un ou plusieurs algorithmes
- Entra√Æner sur les donn√©es d'entra√Ænement
- Commencer simple (baseline), puis complexifier

### √âtape 6 : √âvaluer le mod√®le

- Calculer les m√©triques sur le **test set** (jamais sur le train set !)
- Comparer avec la baseline
- Analyser les erreurs

### √âtape 7 : Optimiser

- Tuning des hyperparam√®tres (GridSearch, RandomSearch)
- Feature engineering
- Essayer d'autres algorithmes

### √âtape 8 : D√©ployer

- Mettre le mod√®le en production (API, batch)
- Monitorer les performances
- R√©entra√Æner si n√©cessaire

> üí° **Conseil** : "80% du temps d'un data scientist est pass√© sur les √©tapes 2, 3 et 4 ‚Äî les donn√©es ‚Äî pas sur le mod√®le lui-m√™me."

> ‚ö†Ô∏è **Attention** : "L'√©valuation (√©tape 6) est **critique**. Un mod√®le qui semble bon sur les donn√©es d'entra√Ænement peut √™tre catastrophique en production. Toujours √©valuer sur des donn√©es que le mod√®le n'a **jamais vues**."

---

## 4. üîç Quand utiliser le ML ?

Le Machine Learning n'est pas une solution universelle. Savoir quand l'utiliser (et quand ne **pas** l'utiliser) est une comp√©tence essentielle.

### ‚úÖ Bons cas d'usage

| Situation | Pourquoi le ML est adapt√© | Exemple |
|-----------|--------------------------|---------|
| Patterns complexes | Trop de r√®gles √† coder manuellement | Reconnaissance d'images |
| Beaucoup de donn√©es | Le ML a besoin de donn√©es pour apprendre | Recommandation Netflix |
| Le probl√®me √©volue | Les r√®gles changent avec le temps | D√©tection de spam |
| Pr√©diction | Anticiper un r√©sultat futur | Pr√©vision de ventes |
| Personnalisation | Adapter √† chaque utilisateur | Fil d'actualit√©s |

### ‚ùå Mauvais cas d'usage

| Situation | Pourquoi √©viter le ML | Alternative |
|-----------|----------------------|-------------|
| R√®gles simples et claires | Un `if/else` suffit | Programmation classique |
| Tr√®s peu de donn√©es | Le ML ne peut pas apprendre | R√®gles m√©tier, heuristiques |
| Besoin d'explicabilit√© totale | Les mod√®les ML sont souvent des "bo√Ætes noires" | Syst√®mes experts |
| Le co√ªt d'erreur est inacceptable | Le ML fait toujours des erreurs | Syst√®mes d√©terministes |
| Pas de donn√©es historiques | Rien √† apprendre | Collecte de donn√©es d'abord |

### Tableau de d√©cision

| Probl√®me | ML ou pas ? | Pourquoi |
|----------|-------------|----------|
| Calculer une TVA | ‚ùå Non | R√®gle simple : prix * 0.20 |
| D√©tecter des e-mails de phishing | ‚úÖ Oui | Patterns complexes, √©volutifs |
| Trier des fichiers par date | ‚ùå Non | Algorithme de tri classique |
| Pr√©dire le cours d'une action | ‚ö†Ô∏è Peut-√™tre | Donn√©es disponibles, mais tr√®s difficile |
| Segmenter une base clients | ‚úÖ Oui | Patterns cach√©s dans les donn√©es |
| Convertir des degr√©s C en F | ‚ùå Non | Formule : F = C * 9/5 + 32 |
| D√©tecter des tumeurs sur des radios | ‚úÖ Oui | Pattern visuel complexe |

> üí° **Conseil de pro** : "Commencez **toujours** par une baseline simple (moyenne, r√®gle m√©tier, `if/else`) avant de construire un mod√®le ML. Si la baseline suffit, pas besoin de ML. Si elle ne suffit pas, vous avez un point de comparaison pour √©valuer votre mod√®le."

> üí° **Conseil** : "Posez-vous la question : est-ce qu'un humain expert pourrait r√©soudre ce probl√®me avec les m√™mes donn√©es ? Si oui, le ML a de bonnes chances d'y arriver aussi."

---

## 5. üõ†Ô∏è Les biblioth√®ques Python pour le ML

Python est le langage de r√©f√©rence pour le Machine Learning. Voici les biblioth√®ques essentielles :

### √âcosyst√®me ML Python

| Biblioth√®que | R√¥le | Utilisation principale |
|--------------|------|----------------------|
| **NumPy** | Calcul num√©rique | Tableaux, op√©rations math√©matiques |
| **Pandas** | Manipulation de donn√©es | DataFrames, nettoyage, exploration |
| **Matplotlib** | Visualisation | Graphiques de base |
| **Seaborn** | Visualisation statistique | Graphiques avanc√©s, heatmaps |
| **scikit-learn** | Machine Learning classique | Mod√®les, m√©triques, preprocessing |
| **XGBoost** | Gradient Boosting | Mod√®les performants (comp√©titions) |
| **TensorFlow / PyTorch** | Deep Learning | R√©seaux de neurones |

### Quand utiliser quoi ?

```python
# NumPy : calcul num√©rique de base
import numpy as np
vecteur = np.array([1, 2, 3, 4, 5])
moyenne = np.mean(vecteur)

# Pandas : manipulation de donn√©es tabulaires
import pandas as pd
df = pd.read_csv("donnees.csv")
df.describe()  # Statistiques descriptives

# Matplotlib : visualisation
import matplotlib.pyplot as plt
plt.scatter(df["surface"], df["prix"])
plt.xlabel("Surface (m¬≤)")
plt.ylabel("Prix (‚Ç¨)")
plt.title("Prix en fonction de la surface")
plt.show()

# Seaborn : visualisations statistiques avanc√©es
import seaborn as sns
sns.heatmap(df.corr(), annot=True, cmap="coolwarm")
plt.title("Matrice de corr√©lation")
plt.show()

# scikit-learn : Machine Learning
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
modele = LinearRegression()
modele.fit(X_train, y_train)
predictions = modele.predict(X_test)
mse = mean_squared_error(y_test, predictions)
```

> üí° **Conseil de pro** : "scikit-learn est votre meilleur ami pour d√©buter. Son API est **coh√©rente** : tous les mod√®les utilisent `.fit()`, `.predict()`, `.score()`. Apprenez cette API et vous pourrez utiliser n'importe quel algorithme."

### Installation rapide

```bash
uv add numpy pandas matplotlib seaborn scikit-learn jupyter
```

---

## 6. üìñ Vocabulaire essentiel

Ma√Ætriser le vocabulaire est indispensable pour comprendre la documentation, les articles et communiquer avec d'autres data scientists.

### Termes fondamentaux

| Terme | D√©finition | Exemple |
|-------|-----------|---------|
| **Feature** (variable) | Une caract√©ristique d'entr√©e | Surface, nombre de pi√®ces |
| **Target** (cible) | La variable √† pr√©dire | Prix de l'appartement |
| **Label** (√©tiquette) | La valeur connue de la target (supervis√©) | "spam" ou "non-spam" |
| **Sample** (√©chantillon) | Une observation / une ligne | Un appartement sp√©cifique |
| **Training set** | Donn√©es pour entra√Æner le mod√®le | 80% des donn√©es |
| **Test set** | Donn√©es pour √©valuer le mod√®le | 20% des donn√©es |
| **Pr√©diction** | La sortie du mod√®le | Prix pr√©dit = 250 000‚Ç¨ |
| **Mod√®le** | La fonction apprise par l'algorithme | La "formule" qui pr√©dit |

### Concepts cl√©s

| Terme | D√©finition | Analogie |
|-------|-----------|----------|
| **Overfitting** (sur-apprentissage) | Le mod√®le apprend le bruit des donn√©es d'entra√Ænement | Un √©tudiant qui apprend les r√©ponses par c≈ìur sans comprendre |
| **Underfitting** (sous-apprentissage) | Le mod√®le est trop simple pour capturer les patterns | Un √©tudiant qui n'a pas assez r√©vis√© |
| **Biais** (bias) | Erreur due √† des hypoth√®ses trop simplistes | Supposer que toute relation est lin√©aire |
| **Variance** | Sensibilit√© du mod√®le aux fluctuations des donn√©es | Un mod√®le qui change beaucoup d'un dataset √† l'autre |
| **G√©n√©ralisation** | Capacit√© √† bien performer sur des donn√©es in√©dites | R√©ussir un examen avec des questions nouvelles |

### Le compromis Biais-Variance

```
Erreur totale = Biais¬≤ + Variance + Bruit irr√©ductible

     Erreur
       ‚îÇ
  High ‚îÇ  Underfitting                    Overfitting
       ‚îÇ     ‚ï≤                              ‚ï±
       ‚îÇ      ‚ï≤    Biais¬≤                  ‚ï± Variance
       ‚îÇ       ‚ï≤       ‚ï≤                ‚ï±
       ‚îÇ        ‚ï≤        ‚ï≤           ‚ï±
       ‚îÇ         ‚ï≤         ‚ï≤       ‚ï±
       ‚îÇ          ‚ï≤          Zone optimale
       ‚îÇ           ‚ï≤            ‚ï±
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Complexit√© du mod√®le
           Simple                   Complexe
```

> üí° **Conseil** : "L'objectif n'est pas de minimiser l'erreur sur les donn√©es d'entra√Ænement, mais de **minimiser l'erreur sur des donn√©es jamais vues** (g√©n√©ralisation). C'est le c≈ìur du ML."

### Hyperparam√®tres vs Param√®tres

| | Param√®tres | Hyperparam√®tres |
|--|-----------|-----------------|
| **D√©finition** | Appris par le mod√®le pendant l'entra√Ænement | Fix√©s par le data scientist avant l'entra√Ænement |
| **Exemple** | Coefficients d'une r√©gression lin√©aire | Nombre de voisins (K) dans KNN |
| **Comment les trouver** | Algorithme d'apprentissage | GridSearch, RandomSearch, exp√©rience |
| **Modifiables pendant l'entra√Ænement** | Oui (c'est le but) | Non (fix√©s avant) |

> üß† **Pour aller plus loin** : Le r√©glage des hyperparam√®tres (hyperparameter tuning) est une √©tape cruciale qui peut significativement am√©liorer les performances d'un mod√®le. Nous verrons les techniques de GridSearch et RandomSearch dans les chapitres suivants.

---

## 7. üìà Les m√©triques : pourquoi c'est fondamental

Les m√©triques sont la **boussole** d'un projet ML. Sans m√©triques appropri√©es, impossible de savoir si votre mod√®le est bon ou non.

### Principe fondamental

> ‚ö†Ô∏è **Attention** : "Un mod√®le sans m√©trique d'√©valuation, c'est comme conduire sans tableau de bord. Vous ne savez pas si vous allez dans la bonne direction."

### Aper√ßu des m√©triques

| Type de probl√®me | M√©triques principales | D√©tails |
|-----------------|----------------------|---------|
| **R√©gression** | MSE, RMSE, MAE, R¬≤, MAPE | Voir Chapitre 4 |
| **Classification** | Accuracy, Precision, Recall, F1, AUC-ROC | Voir Chapitre 5 |
| **Clustering** | Silhouette Score, Inertie | Voir chapitres avanc√©s |

### La m√©trique d√©pend du contexte m√©tier

| Contexte | M√©trique privil√©gi√©e | Raison |
|----------|---------------------|--------|
| Diagnostic m√©dical | **Recall** (sensibilit√©) | Ne pas rater un malade (FN co√ªteux) |
| Filtre anti-spam | **Precision** | Ne pas classer un vrai mail en spam (FP co√ªteux) |
| Pr√©diction de prix | **RMSE** ou **MAE** | Erreur en unit√© de la cible (‚Ç¨) |
| Classes d√©s√©quilibr√©es | **F1-Score** ou **AUC-ROC** | Accuracy est trompeuse |

> üí° **Conseil de pro** : "Choisissez **toujours** votre m√©trique d'√©valuation **AVANT** de commencer √† mod√©liser. Cette m√©trique doit refl√©ter le **co√ªt m√©tier** des erreurs."

---

## üéØ Points cl√©s √† retenir

1. **Le ML apprend √† partir de donn√©es** plut√¥t que de r√®gles cod√©es en dur
2. **Trois types d'apprentissage** : supervis√© (avec labels), non-supervis√© (sans labels), par renforcement (r√©compenses)
3. **Supervis√©** se divise en r√©gression (valeur continue) et classification (cat√©gorie)
4. **Le workflow ML** : Probl√®me ‚Üí Donn√©es ‚Üí Exploration ‚Üí Preprocessing ‚Üí Mod√®le ‚Üí √âvaluation ‚Üí Optimisation ‚Üí D√©ploiement
5. **80% du travail** porte sur les donn√©es, pas sur le mod√®le
6. **Ne pas tout r√©soudre avec le ML** : si un `if/else` suffit, inutile de complexifier
7. **Toujours commencer par une baseline simple** avant un mod√®le complexe
8. **Les m√©triques sont fondamentales** : choisir la bonne m√©trique selon le contexte m√©tier
9. **Overfitting** est l'ennemi principal : √©valuer toujours sur des donn√©es in√©dites
10. **scikit-learn** est la biblioth√®que de r√©f√©rence pour le ML classique en Python

---

## ‚úÖ Checklist de validation

- [ ] Je sais expliquer la diff√©rence entre ML et programmation traditionnelle
- [ ] Je sais distinguer apprentissage supervis√©, non-supervis√© et par renforcement
- [ ] Je sais si un probl√®me est de la r√©gression ou de la classification
- [ ] Je connais les 8 √©tapes du workflow ML
- [ ] Je sais quand utiliser le ML et quand ne pas l'utiliser
- [ ] Je comprends les concepts d'overfitting et underfitting
- [ ] Je connais la diff√©rence entre param√®tres et hyperparam√®tres
- [ ] Je sais ce que sont les features, la target, le training set et le test set
- [ ] J'ai install√© scikit-learn, pandas, numpy et matplotlib
- [ ] Je comprends pourquoi le choix de la m√©trique est crucial

---

**Suivant** : [Chapitre 2 : Environnement et Outils](02-environnement-setup.md)
