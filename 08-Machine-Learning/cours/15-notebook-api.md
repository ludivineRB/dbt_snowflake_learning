# Chapitre 15 : Du Notebook √† l'API ‚Äî Mettre en Production

## üéØ Objectifs

- Comprendre le **gap** entre un notebook Jupyter et un code de production
- Ma√Ætriser la **s√©rialisation** des mod√®les (pickle, joblib, ONNX)
- Savoir structurer un **projet ML** professionnel
- Construire une **API de pr√©diction** avec FastAPI
- √âcrire des **tests unitaires** pour le preprocessing et l'API
- R√©aliser un TP complet : API de scoring churn en local

> **Phase 6 - Semaine 15**

---

## 1. üß† Le gap Notebook vers Production

### 1.1 Pourquoi un notebook ne suffit pas

Un notebook Jupyter est parfait pour l'**exploration** et le **prototypage**. Mais il est **inadapt√©** √† la production.

```
NOTEBOOK (Exploration)              PRODUCTION (D√©ploiement)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Code spaghetti      ‚îÇ            ‚îÇ Code modulaire      ‚îÇ
‚îÇ Variables globales  ‚îÇ            ‚îÇ Fonctions/Classes   ‚îÇ
‚îÇ Pas de tests        ‚îÇ     ‚Üí      ‚îÇ Tests unitaires     ‚îÇ
‚îÇ Pas de versioning   ‚îÇ            ‚îÇ Git + CI/CD         ‚îÇ
‚îÇ D√©pendances floues  ‚îÇ            ‚îÇ requirements.txt    ‚îÇ
‚îÇ Ex√©cution manuelle  ‚îÇ            ‚îÇ API automatis√©e     ‚îÇ
‚îÇ "√áa marche chez moi"‚îÇ            ‚îÇ Docker = partout    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1.2 Les probl√®mes classiques du notebook

| Probl√®me | Exemple | Solution |
|----------|---------|----------|
| **Ordre d'ex√©cution** | Cellule 15 d√©pend de cellule 3 qu'on a modifi√©e | Modules Python |
| **Variables globales** | `df` modifi√© √† 10 endroits diff√©rents | Fonctions pures |
| **Pas de tests** | On ne sait pas si le code marche encore | pytest |
| **Pas de gestion d'erreurs** | Le notebook crash sur une donn√©e inattendue | try/except, validation |
| **Non reproductible** | "Kernel > Restart and Run All" √©choue | Pipeline reproductible |
| **Non d√©ployable** | On ne peut pas exposer un notebook en API | FastAPI, Flask |

> üí° **Conseil** : "Le notebook est votre **brouillon**. Le code de production est votre **copie propre**. Ne d√©ployez jamais un brouillon."

---

## 2. üíæ S√©rialisation du mod√®le

### 2.1 Pickle : simple mais dangereux

```python
import pickle
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# --- Entra√Æner ---
cancer = load_breast_cancer()
X_train, X_test, y_train, y_test = train_test_split(
    cancer.data, cancer.target, test_size=0.2, random_state=42
)

pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('model', RandomForestClassifier(n_estimators=100, random_state=42))
])
pipeline.fit(X_train, y_train)

# --- Sauvegarder avec pickle ---
with open('model_v1.pkl', 'wb') as f:
    pickle.dump(pipeline, f)

# --- Charger ---
with open('model_v1.pkl', 'rb') as f:
    pipeline_loaded = pickle.load(f)

y_pred = pipeline_loaded.predict(X_test)
print(f"Score apr√®s chargement : {pipeline_loaded.score(X_test, y_test):.4f}")
```

> ‚ö†Ô∏è **Attention** : "Pickle est **dangereux** d'un point de vue s√©curit√©. Ne chargez **JAMAIS** un fichier pickle provenant d'une source non fiable : il peut ex√©cuter du code arbitraire √† l'ouverture. Utilisez-le uniquement pour vos propres mod√®les."

### 2.2 Joblib : optimis√© pour numpy/sklearn

Joblib est plus **efficace** que pickle pour les objets contenant de grands tableaux numpy (comme les mod√®les sklearn).

```python
import joblib

# --- Sauvegarder avec joblib ---
joblib.dump(pipeline, 'model_v1.joblib')

# --- Charger ---
pipeline_loaded = joblib.load('model_v1.joblib')

y_pred = pipeline_loaded.predict(X_test)
print(f"Score apr√®s chargement : {pipeline_loaded.score(X_test, y_test):.4f}")
```

| Crit√®re | pickle | joblib |
|---------|--------|--------|
| **Vitesse (gros mod√®les)** | Lent | Rapide |
| **Taille fichier** | Plus gros | Plus compact |
| **Compression** | Non | Oui (optionnel) |
| **S√©curit√©** | Dangereux | Dangereux aussi |
| **Recommand√© pour sklearn** | Non | **Oui** |

```python
# Joblib avec compression
joblib.dump(pipeline, 'model_v1_compressed.joblib', compress=3)
```

### 2.3 ONNX : interop√©rabilit√©

ONNX (Open Neural Network Exchange) est un format **universel** qui permet de charger un mod√®le dans n'importe quel langage (Python, Java, C++, JavaScript...).

```python
# Installation
# pip install skl2onnx onnxruntime

from skl2onnx import convert_sklearn
from skl2onnx.common.data_types import FloatTensorType
import onnxruntime as rt
import numpy as np

# --- Convertir en ONNX ---
initial_type = [('float_input', FloatTensorType([None, X_train.shape[1]]))]
onnx_model = convert_sklearn(pipeline, initial_types=initial_type)

# --- Sauvegarder ---
with open('model_v1.onnx', 'wb') as f:
    f.write(onnx_model.SerializeToString())

# --- Charger et pr√©dire avec ONNX Runtime ---
session = rt.InferenceSession('model_v1.onnx')
input_name = session.get_inputs()[0].name

# Pr√©dire
y_pred_onnx = session.run(
    None,
    {input_name: X_test.astype(np.float32)}
)[0]
print(f"Pr√©dictions identiques : {(y_pred_onnx == pipeline.predict(X_test)).all()}")
```

### 2.4 Versioning du mod√®le + pipeline

```python
import joblib
from datetime import datetime

# --- Bonne pratique : sauvegarder le pipeline COMPLET ---
# (preprocessing + mod√®le ensemble)
metadata = {
    'model': pipeline,
    'version': '1.0.0',
    'date': datetime.now().isoformat(),
    'features': list(cancer.feature_names),
    'metrics': {
        'f1_test': 0.97,
        'accuracy_test': 0.96
    },
    'training_params': {
        'n_samples': X_train.shape[0],
        'random_state': 42
    }
}

joblib.dump(metadata, f"model_v{metadata['version']}_{datetime.now():%Y%m%d}.joblib")
```

> üí° **Conseil** : "Sauvegardez **toujours** le pipeline complet (scaler + mod√®le) et non le mod√®le seul. Sinon, vous devrez recr√©er le scaler √† chaque chargement, et les r√©sultats seront diff√©rents si le scaler n'est pas exactement le m√™me."

---

## 3. üìÅ Structure d'un projet ML

### 3.1 Structure recommand√©e

```
projet-ml-churn/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Donn√©es brutes (jamais modifi√©es)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ clients.csv
‚îÇ   ‚îî‚îÄ‚îÄ processed/              # Donn√©es transform√©es
‚îÇ       ‚îî‚îÄ‚îÄ clients_clean.csv
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_exploration.ipynb    # EDA
‚îÇ   ‚îú‚îÄ‚îÄ 02_modelisation.ipynb   # Exp√©rimentations
‚îÇ   ‚îî‚îÄ‚îÄ 03_evaluation.ipynb     # √âvaluation finale
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py        # Fonctions de nettoyage/transformation
‚îÇ   ‚îú‚îÄ‚îÄ model.py                # Entra√Ænement et √©valuation
‚îÇ   ‚îú‚îÄ‚îÄ predict.py              # Pr√©diction sur nouvelles donn√©es
‚îÇ   ‚îî‚îÄ‚îÄ api.py                  # API FastAPI
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_preprocessing.py   # Tests du preprocessing
‚îÇ   ‚îî‚îÄ‚îÄ test_model.py           # Tests du mod√®le
‚îú‚îÄ‚îÄ models/                     # Mod√®les s√©rialis√©s
‚îÇ   ‚îî‚îÄ‚îÄ model_v1.0.0.joblib
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ pyproject.toml              # D√©pendances et config
‚îî‚îÄ‚îÄ README.md
```

### 3.2 Pourquoi cette structure ?

| Dossier | R√¥le | R√®gle |
|---------|------|-------|
| `data/raw/` | Donn√©es originales | **Jamais** modifi√©es |
| `data/processed/` | Donn√©es transform√©es | Reproductibles via le code |
| `notebooks/` | Exploration | Ne pas d√©ployer |
| `src/` | Code de production | Modulaire, test√© |
| `tests/` | Tests unitaires | Ex√©cut√©s √† chaque commit |
| `models/` | Mod√®les s√©rialis√©s | Versionn√©s |

---

## 4. üîß Refactoring du notebook en modules Python

### 4.1 Extraire le preprocessing

```python
# src/preprocessing.py

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from typing import Tuple


def charger_donnees(chemin: str) -> pd.DataFrame:
    """Charge les donn√©es brutes depuis un fichier CSV."""
    df = pd.read_csv(chemin)
    print(f"Donn√©es charg√©es : {df.shape[0]} lignes, {df.shape[1]} colonnes")
    return df


def nettoyer_donnees(df: pd.DataFrame) -> pd.DataFrame:
    """Nettoie les donn√©es : valeurs manquantes, doublons, types."""
    df = df.copy()

    # Supprimer les doublons
    n_doublons = df.duplicated().sum()
    if n_doublons > 0:
        df = df.drop_duplicates()
        print(f"  {n_doublons} doublons supprim√©s")

    # Remplir les valeurs manquantes
    for col in df.select_dtypes(include=[np.number]).columns:
        if df[col].isnull().sum() > 0:
            mediane = df[col].median()
            df[col] = df[col].fillna(mediane)
            print(f"  {col} : NaN remplis par la m√©diane ({mediane:.2f})")

    return df


def preparer_features(
    df: pd.DataFrame,
    target_col: str,
    scaler: StandardScaler = None
) -> Tuple[np.ndarray, np.ndarray, StandardScaler, list]:
    """Pr√©pare les features et la target pour l'entra√Ænement."""
    # S√©parer features et target
    feature_cols = [c for c in df.select_dtypes(include=[np.number]).columns if c != target_col]
    X = df[feature_cols].values
    y = df[target_col].values

    # Scaler
    if scaler is None:
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
    else:
        X_scaled = scaler.transform(X)

    return X_scaled, y, scaler, feature_cols
```

### 4.2 Extraire le mod√®le

```python
# src/model.py

import joblib
import numpy as np
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import f1_score, classification_report
from datetime import datetime


def entrainer_modele(
    X_train: np.ndarray,
    y_train: np.ndarray,
    **params
) -> GradientBoostingClassifier:
    """Entra√Æne un Gradient Boosting Classifier."""
    default_params = {
        'n_estimators': 100,
        'max_depth': 3,
        'learning_rate': 0.1,
        'random_state': 42
    }
    default_params.update(params)

    model = GradientBoostingClassifier(**default_params)
    model.fit(X_train, y_train)
    return model


def evaluer_modele(model, X_test, y_test) -> dict:
    """√âvalue le mod√®le et retourne un dictionnaire de m√©triques."""
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]

    metrics = {
        'f1': f1_score(y_test, y_pred),
        'accuracy': (y_pred == y_test).mean(),
    }

    print("=== √âvaluation ===")
    print(classification_report(y_test, y_pred))
    return metrics


def sauvegarder_modele(model, scaler, feature_cols, metrics, version, path):
    """Sauvegarde le mod√®le avec ses m√©tadonn√©es."""
    artefact = {
        'model': model,
        'scaler': scaler,
        'feature_cols': feature_cols,
        'version': version,
        'date': datetime.now().isoformat(),
        'metrics': metrics
    }
    joblib.dump(artefact, path)
    print(f"Mod√®le sauvegard√© : {path}")


def charger_modele(path):
    """Charge un mod√®le et ses m√©tadonn√©es."""
    artefact = joblib.load(path)
    print(f"Mod√®le v{artefact['version']} charg√© (date : {artefact['date']})")
    return artefact
```

### 4.3 √âcrire des tests unitaires simples

```python
# tests/test_preprocessing.py

import pytest
import pandas as pd
import numpy as np
from src.preprocessing import nettoyer_donnees, preparer_features


def test_nettoyer_donnees_supprime_doublons():
    """V√©rifie que les doublons sont supprim√©s."""
    df = pd.DataFrame({
        'a': [1, 2, 2, 3],
        'b': [4, 5, 5, 6]
    })
    result = nettoyer_donnees(df)
    assert result.shape[0] == 3  # 1 doublon supprim√©


def test_nettoyer_donnees_remplit_nan():
    """V√©rifie que les NaN sont remplis par la m√©diane."""
    df = pd.DataFrame({
        'a': [1.0, 2.0, np.nan, 4.0],
        'b': [10, 20, 30, 40]
    })
    result = nettoyer_donnees(df)
    assert result['a'].isnull().sum() == 0
    assert result['a'].iloc[2] == 2.0  # M√©diane de [1, 2, 4]


def test_preparer_features_shape():
    """V√©rifie les dimensions de sortie."""
    df = pd.DataFrame({
        'feat1': [1.0, 2.0, 3.0],
        'feat2': [4.0, 5.0, 6.0],
        'target': [0, 1, 0]
    })
    X, y, scaler, cols = preparer_features(df, target_col='target')
    assert X.shape == (3, 2)
    assert y.shape == (3,)
    assert len(cols) == 2


def test_preparer_features_standardise():
    """V√©rifie que les features sont standardis√©es."""
    df = pd.DataFrame({
        'feat1': [10.0, 20.0, 30.0, 40.0, 50.0],
        'target': [0, 1, 0, 1, 0]
    })
    X, y, scaler, cols = preparer_features(df, target_col='target')
    assert abs(X.mean()) < 1e-10  # Moyenne ~ 0
    assert abs(X.std(ddof=0) - 1.0) < 1e-10  # √âcart-type ~ 1
```

```python
# tests/test_model.py

import pytest
import numpy as np
from src.model import entrainer_modele, evaluer_modele


def test_entrainer_modele():
    """V√©rifie que le mod√®le s'entra√Æne sans erreur."""
    X = np.random.rand(100, 5)
    y = (X[:, 0] > 0.5).astype(int)
    model = entrainer_modele(X, y, n_estimators=10)
    assert hasattr(model, 'predict')


def test_prediction_shape():
    """V√©rifie que les pr√©dictions ont la bonne forme."""
    X_train = np.random.rand(100, 5)
    y_train = (X_train[:, 0] > 0.5).astype(int)
    X_test = np.random.rand(20, 5)

    model = entrainer_modele(X_train, y_train, n_estimators=10)
    y_pred = model.predict(X_test)
    assert y_pred.shape == (20,)
    assert set(y_pred).issubset({0, 1})
```

Ex√©cuter les tests :

```bash
# Depuis la racine du projet
pytest tests/ -v
```

---

## 5. üöÄ API avec FastAPI

### 5.1 Pourquoi FastAPI

| Crit√®re | FastAPI | Flask | Django |
|---------|---------|-------|--------|
| **Performance** | Tr√®s rapide (async) | Correcte | Lourde |
| **Validation** | Automatique (Pydantic) | Manuelle | Manuelle |
| **Documentation** | Auto (Swagger + ReDoc) | Manuelle | Manuelle |
| **Type hints** | Natif | Non | Partiel |
| **Id√©al pour** | API ML | API simple | App web compl√®te |

### 5.2 Code complet de l'API

```python
# src/api.py

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from typing import List, Optional
import joblib
import numpy as np

# --- Initialiser l'application ---
app = FastAPI(
    title="API de Pr√©diction Churn",
    description="Pr√©dit si un client va quitter le service (churn)",
    version="1.0.0"
)

# --- Charger le mod√®le au d√©marrage ---
MODEL_PATH = "models/model_v1.0.0.joblib"

try:
    artefact = joblib.load(MODEL_PATH)
    model = artefact['model']
    scaler = artefact['scaler']
    feature_cols = artefact['feature_cols']
    print(f"Mod√®le v{artefact['version']} charg√© avec succ√®s")
except FileNotFoundError:
    print(f"ERREUR : Mod√®le non trouv√© √† {MODEL_PATH}")
    model = None


# --- Sch√©mas de donn√©es (Pydantic) ---
class ClientInput(BaseModel):
    """Donn√©es d'un client pour pr√©dire le churn."""
    anciennete_mois: float = Field(..., ge=0, description="Anciennet√© en mois")
    montant_mensuel: float = Field(..., ge=0, description="Montant mensuel en euros")
    nb_reclamations: int = Field(..., ge=0, description="Nombre de r√©clamations")
    nb_produits: int = Field(..., ge=1, le=10, description="Nombre de produits souscrits")
    satisfaction: float = Field(..., ge=1, le=5, description="Score de satisfaction (1-5)")

    class Config:
        json_schema_extra = {
            "example": {
                "anciennete_mois": 24.0,
                "montant_mensuel": 59.99,
                "nb_reclamations": 2,
                "nb_produits": 3,
                "satisfaction": 3.5
            }
        }


class PredictionOutput(BaseModel):
    """R√©sultat de la pr√©diction."""
    churn: bool
    probabilite_churn: float
    confidence: str


class BatchInput(BaseModel):
    """Lot de clients pour pr√©diction en masse."""
    clients: List[ClientInput]


class BatchOutput(BaseModel):
    """R√©sultats pour un lot de clients."""
    predictions: List[PredictionOutput]
    nb_clients: int


# --- Endpoints ---
@app.get("/")
def root():
    """Page d'accueil de l'API."""
    return {
        "message": "API de pr√©diction Churn",
        "version": "1.0.0",
        "docs": "/docs"
    }


@app.get("/health")
def health_check():
    """V√©rifie que l'API et le mod√®le fonctionnent."""
    if model is None:
        raise HTTPException(status_code=503, detail="Mod√®le non charg√©")
    return {"status": "healthy", "model_version": artefact.get('version', 'unknown')}


@app.post("/predict", response_model=PredictionOutput)
def predict(client: ClientInput):
    """Pr√©dit le churn pour un client."""
    if model is None:
        raise HTTPException(status_code=503, detail="Mod√®le non disponible")

    # Transformer en array numpy
    features = np.array([[
        client.anciennete_mois,
        client.montant_mensuel,
        client.nb_reclamations,
        client.nb_produits,
        client.satisfaction
    ]])

    # Scaler + pr√©dire
    features_scaled = scaler.transform(features)
    proba = model.predict_proba(features_scaled)[0]
    churn = bool(proba[1] > 0.5)

    # Niveau de confiance
    confidence_score = max(proba)
    if confidence_score > 0.8:
        confidence = "haute"
    elif confidence_score > 0.6:
        confidence = "moyenne"
    else:
        confidence = "faible"

    return PredictionOutput(
        churn=churn,
        probabilite_churn=round(float(proba[1]), 4),
        confidence=confidence
    )


@app.post("/predict/batch", response_model=BatchOutput)
def predict_batch(batch: BatchInput):
    """Pr√©dit le churn pour un lot de clients."""
    if model is None:
        raise HTTPException(status_code=503, detail="Mod√®le non disponible")

    predictions = []
    for client in batch.clients:
        prediction = predict(client)
        predictions.append(prediction)

    return BatchOutput(
        predictions=predictions,
        nb_clients=len(predictions)
    )
```

### 5.3 Lancer l'API

```bash
# Installation
pip install fastapi uvicorn

# Lancer le serveur
uvicorn src.api:app --reload --host 0.0.0.0 --port 8000
```

### 5.4 Tester avec curl et Swagger

```bash
# --- Test du health check ---
curl http://localhost:8000/health

# --- Test de pr√©diction ---
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "anciennete_mois": 6.0,
    "montant_mensuel": 89.99,
    "nb_reclamations": 5,
    "nb_produits": 1,
    "satisfaction": 1.5
  }'

# R√©ponse :
# {
#   "churn": true,
#   "probabilite_churn": 0.8234,
#   "confidence": "haute"
# }
```

La documentation **Swagger** est automatiquement disponible √† `http://localhost:8000/docs`. Elle permet de tester l'API directement depuis le navigateur.

```
Documentation automatique :

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  API de Pr√©diction Churn                    ‚îÇ
‚îÇ  Version 1.0.0                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                             ‚îÇ
‚îÇ  GET  /          Page d'accueil             ‚îÇ
‚îÇ  GET  /health    Health check               ‚îÇ
‚îÇ  POST /predict   Pr√©diction unitaire        ‚îÇ
‚îÇ  POST /predict/batch  Pr√©diction en masse   ‚îÇ
‚îÇ                                             ‚îÇ
‚îÇ  Chaque endpoint est document√© avec :       ‚îÇ
‚îÇ  - Sch√©ma d'entr√©e (avec exemples)          ‚îÇ
‚îÇ  - Sch√©ma de sortie                         ‚îÇ
‚îÇ  - Bouton "Try it out" pour tester          ‚îÇ
‚îÇ                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

> üí° **Conseil** : "Ajoutez toujours un endpoint `/health` √† votre API. C'est indispensable pour que les orchestrateurs (Kubernetes, Docker) v√©rifient que votre service est op√©rationnel."

---

## 6. üß™ Tests de l'API

### 6.1 Tests avec pytest + httpx

```python
# tests/test_api.py

import pytest
from fastapi.testclient import TestClient
from src.api import app

client = TestClient(app)


def test_root():
    """Teste la page d'accueil."""
    response = client.get("/")
    assert response.status_code == 200
    assert "message" in response.json()


def test_health():
    """Teste le health check."""
    response = client.get("/health")
    # 200 si le mod√®le est charg√©, 503 sinon
    assert response.status_code in [200, 503]


def test_predict_valid():
    """Teste une pr√©diction avec des donn√©es valides."""
    payload = {
        "anciennete_mois": 24.0,
        "montant_mensuel": 59.99,
        "nb_reclamations": 2,
        "nb_produits": 3,
        "satisfaction": 3.5
    }
    response = client.post("/predict", json=payload)

    # Si le mod√®le est charg√©
    if response.status_code == 200:
        data = response.json()
        assert "churn" in data
        assert "probabilite_churn" in data
        assert "confidence" in data
        assert isinstance(data["churn"], bool)
        assert 0 <= data["probabilite_churn"] <= 1


def test_predict_invalid_data():
    """Teste une pr√©diction avec des donn√©es invalides."""
    payload = {
        "anciennete_mois": -5,  # N√©gatif ‚Üí invalide
        "montant_mensuel": 59.99,
        "nb_reclamations": 2,
        "nb_produits": 3,
        "satisfaction": 3.5
    }
    response = client.post("/predict", json=payload)
    assert response.status_code == 422  # Validation error


def test_predict_missing_field():
    """Teste une pr√©diction avec un champ manquant."""
    payload = {
        "anciennete_mois": 24.0,
        # montant_mensuel manquant !
        "nb_reclamations": 2,
        "nb_produits": 3,
        "satisfaction": 3.5
    }
    response = client.post("/predict", json=payload)
    assert response.status_code == 422


def test_predict_batch():
    """Teste la pr√©diction en lot."""
    payload = {
        "clients": [
            {
                "anciennete_mois": 24.0,
                "montant_mensuel": 59.99,
                "nb_reclamations": 2,
                "nb_produits": 3,
                "satisfaction": 3.5
            },
            {
                "anciennete_mois": 3.0,
                "montant_mensuel": 99.99,
                "nb_reclamations": 8,
                "nb_produits": 1,
                "satisfaction": 1.0
            }
        ]
    }
    response = client.post("/predict/batch", json=payload)
    if response.status_code == 200:
        data = response.json()
        assert data["nb_clients"] == 2
        assert len(data["predictions"]) == 2
```

```bash
# Ex√©cuter les tests
pytest tests/test_api.py -v
```

---

## 7. üß™ TP : API de scoring churn en local

### 7.1 Le livrable

Cr√©ez un projet complet avec la structure vue en section 3. Le projet doit :

1. Charger et pr√©parer un dataset de churn (vous pouvez le simuler)
2. Entra√Æner un mod√®le dans un notebook
3. Refactorer le code en modules (`src/`)
4. S√©rialiser le mod√®le avec joblib
5. Exposer une API FastAPI avec les endpoints `/health`, `/predict` et `/predict/batch`
6. √âcrire au moins 5 tests unitaires

### 7.2 Script d'entra√Ænement complet

```python
# scripts/train.py

"""Script d'entra√Ænement du mod√®le de churn."""

import sys
sys.path.insert(0, '.')

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from src.preprocessing import nettoyer_donnees, preparer_features
from src.model import entrainer_modele, evaluer_modele, sauvegarder_modele


def generer_donnees_churn(n=2000):
    """G√©n√®re un dataset synth√©tique de churn."""
    np.random.seed(42)

    df = pd.DataFrame({
        'anciennete_mois': np.random.exponential(24, n).clip(1, 120).astype(int),
        'montant_mensuel': np.random.normal(60, 25, n).clip(10, 200),
        'nb_reclamations': np.random.poisson(2, n),
        'nb_produits': np.random.choice([1, 2, 3, 4, 5], n, p=[0.3, 0.3, 0.2, 0.15, 0.05]),
        'satisfaction': np.random.uniform(1, 5, n).round(1),
    })

    # Simuler le churn
    score = (
        -0.02 * df['anciennete_mois'] +
        0.01 * df['montant_mensuel'] +
        0.15 * df['nb_reclamations'] +
        -0.1 * df['nb_produits'] +
        -0.3 * df['satisfaction'] +
        np.random.normal(0, 0.5, n)
    )
    df['churn'] = (score > np.percentile(score, 70)).astype(int)

    return df


def main():
    # 1. G√©n√©rer les donn√©es
    print("=== G√©n√©ration des donn√©es ===")
    df = generer_donnees_churn()
    print(f"Shape : {df.shape}")
    print(f"Taux de churn : {df['churn'].mean():.2%}")

    # 2. Nettoyer
    print("\n=== Nettoyage ===")
    df = nettoyer_donnees(df)

    # 3. Pr√©parer
    print("\n=== Pr√©paration ===")
    X, y, scaler, feature_cols = preparer_features(df, target_col='churn')
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # 4. Entra√Æner
    print("\n=== Entra√Ænement ===")
    model = entrainer_modele(X_train, y_train, n_estimators=200, max_depth=4)

    # 5. √âvaluer
    print("\n=== √âvaluation ===")
    metrics = evaluer_modele(model, X_test, y_test)

    # 6. Sauvegarder
    print("\n=== Sauvegarde ===")
    sauvegarder_modele(
        model=model,
        scaler=scaler,
        feature_cols=feature_cols,
        metrics=metrics,
        version='1.0.0',
        path='models/model_v1.0.0.joblib'
    )

    print("\nTermin√© !")


if __name__ == '__main__':
    main()
```

```bash
# Entra√Æner
python scripts/train.py

# Lancer l'API
uvicorn src.api:app --reload --port 8000

# Tester
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"anciennete_mois": 6, "montant_mensuel": 89.99, "nb_reclamations": 5, "nb_produits": 1, "satisfaction": 1.5}'
```

---

## üéØ Points cl√©s √† retenir

1. Un **notebook** est pour l'exploration ; le code de production doit √™tre **modulaire et test√©**
2. **Joblib** est la m√©thode recommand√©e pour s√©rialiser les mod√®les sklearn
3. S√©rialisez toujours le **pipeline complet** (preprocessing + mod√®le)
4. Structurez votre projet avec `src/`, `tests/`, `models/`, `data/`
5. **FastAPI** est id√©al pour les API ML : rapide, validation auto, documentation auto
6. Utilisez **Pydantic** pour valider les donn√©es d'entr√©e (typage, bornes, exemples)
7. L'endpoint `/health` est indispensable pour le monitoring
8. Les **tests unitaires** (pytest) garantissent que le code ne casse pas lors des modifications
9. **ONNX** permet l'interop√©rabilit√© entre langages et frameworks
10. Ne chargez **jamais** un fichier pickle d'une source non fiable (risque de s√©curit√©)

---

## ‚úÖ Checklist de validation

- [ ] Je comprends pourquoi un notebook ne suffit pas en production
- [ ] Je sais s√©rialiser un mod√®le avec joblib (et je connais les risques de pickle)
- [ ] Je sais structurer un projet ML avec `src/`, `tests/`, `models/`
- [ ] Je sais refactorer un notebook en modules Python r√©utilisables
- [ ] Je sais construire une API avec FastAPI (endpoint POST /predict)
- [ ] Je sais utiliser Pydantic pour valider les donn√©es d'entr√©e
- [ ] Je sais √©crire des tests unitaires avec pytest pour le preprocessing et l'API
- [ ] Je sais lancer l'API avec uvicorn et la tester avec curl
- [ ] Je sais acc√©der √† la documentation Swagger auto-g√©n√©r√©e (/docs)
- [ ] J'ai r√©alis√© le TP complet : API de scoring churn en local

---

**Pr√©c√©dent** : [Chapitre 14 : Interpr√©ter ses Mod√®les et √âthique du ML](14-interpretabilite-ethique.md)

**Suivant** : [Chapitre 16 : Docker, Monitoring et la Vie en Production](16-docker-monitoring.md)
