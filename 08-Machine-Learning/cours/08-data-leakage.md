# Chapitre 8 : Data Leakage â€” Le Crime Parfait du ML

## ğŸ¯ Objectifs

- Comprendre ce qu'est le data leakage et pourquoi c'est le problÃ¨me le plus dangereux en ML
- Identifier les diffÃ©rents types de leakage (target, train-test contamination, temporel)
- DÃ©tecter le leakage dans un projet ML existant
- Appliquer les bonnes pratiques pour l'Ã©viter systÃ©matiquement
- Construire un pipeline scikit-learn robuste qui Ã©limine les risques de leakage

> ğŸ’¡ **Conseil** : "Le data leakage est responsable de la majoritÃ© des modÃ¨les qui brillent en dÃ©veloppement mais s'effondrent en production. C'est LE piÃ¨ge numÃ©ro 1 en Machine Learning."

---

## 1. ğŸ§  ScÃ©nario : "Votre ModÃ¨le a 99% de PrÃ©cision... Mais Ne Marche Pas"

### 1.1 L'histoire (vraie) d'un modÃ¨le trop beau pour Ãªtre vrai

```
Lundi matin, rÃ©union d'Ã©quipe :

  Data Scientist : "J'ai un modÃ¨le qui prÃ©dit le churn avec 99.2% de prÃ©cision !"
  Manager :        "Incroyable ! DÃ©ployons-le en production !"

  Deux semaines plus tard :

  Manager :        "Les prÃ©dictions sont catastrophiques... On fait Ã  peine 55%."
  Data Scientist : "Je ne comprends pas, sur mes donnÃ©es de test c'Ã©tait 99.2%..."

  Que s'est-il passÃ© ?
  â†’ DATA LEAKAGE ğŸ”“
```

### 1.2 Le rÃ©sultat du leakage

```
Performance en dÃ©veloppement vs production :

  PrÃ©cision (%)
  100 â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  99.2%  â† dÃ©veloppement (leakage)
      â”‚
   80 â”‚
      â”‚
   60 â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  55%  â† production (rÃ©alitÃ©)
      â”‚
   40 â”‚
      â”‚
   20 â”‚
      â”‚
    0 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
       DÃ©veloppement    Production

  â†’ Vous avez construit un modÃ¨le qui TRICHE pendant l'examen
    mais qui ne sait RIEN quand il est seul face au vrai problÃ¨me.
```

---

## 2. ğŸ” Qu'est-ce que le Data Leakage ?

### 2.1 DÃ©finition simple

Le **data leakage** (fuite de donnÃ©es) se produit quand le modÃ¨le a accÃ¨s, pendant l'entraÃ®nement, Ã  des **informations qu'il ne devrait pas connaÃ®tre**. Ces informations "fuient" depuis le futur, depuis le test set, ou depuis la variable cible elle-mÃªme.

### 2.2 L'analogie de l'examen

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                           â”‚
â”‚  SANS leakage (situation normale) :                       â”‚
â”‚                                                           â”‚
â”‚    ğŸ“š Ã‰tudier (train)  â†’  ğŸ“ Passer l'examen (test)      â”‚
â”‚    Avec le cours           Avec des questions nouvelles   â”‚
â”‚                                                           â”‚
â”‚  AVEC leakage (triche) :                                  â”‚
â”‚                                                           â”‚
â”‚    ğŸ“š Ã‰tudier (train)  â†’  ğŸ“ Passer l'examen (test)      â”‚
â”‚    Avec le cours           Mais en ayant VU les rÃ©ponses  â”‚
â”‚    + les rÃ©ponses          â†’ 100% Ã  l'examen              â”‚
â”‚    de l'examen !           â†’ 0% dans la vraie vie         â”‚
â”‚                                                           â”‚
â”‚  Le modÃ¨le "rÃ©ussit" l'examen parce qu'il a trichÃ©,      â”‚
â”‚  pas parce qu'il a compris.                               â”‚
â”‚                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> âš ï¸ **Attention** : "Le data leakage est particuliÃ¨rement insidieux parce qu'il donne l'impression que tout va bien. Les mÃ©triques sont excellentes, le modÃ¨le semble performant. Le problÃ¨me n'apparaÃ®t qu'en production, quand il est trop tard."

---

## 3. ğŸ“Š Les Types de Leakage

### 3.1 Target Leakage â€” La Variable qui Contient DÃ©jÃ  la RÃ©ponse

#### Le principe

Une feature contient **directement ou indirectement** l'information de la variable cible. Le modÃ¨le n'a pas besoin d'apprendre â€” il lui suffit de regarder cette feature.

#### Exemple concret : prÃ©dire le dÃ©faut de paiement

```
Dataset de crÃ©dit :

| client | revenu | montant_crÃ©dit | crÃ©dit_remboursÃ© | dÃ©faut |
|--------|--------|---------------|-----------------|--------|
| A      | 3000   | 10000         | Oui             | Non    |
| B      | 2500   | 15000         | Non             | Oui    |
| C      | 4000   | 8000          | Oui             | Non    |

âš ï¸  La colonne "crÃ©dit_remboursÃ©" EST la rÃ©ponse !
    Si le crÃ©dit est remboursÃ© â†’ pas de dÃ©faut
    Si le crÃ©dit n'est pas remboursÃ© â†’ dÃ©faut

    â†’ Le modÃ¨le n'a qu'Ã  regarder "crÃ©dit_remboursÃ©" pour prÃ©dire "dÃ©faut"
    â†’ Accuracy = 100% sur le train ET le test
    â†’ Mais en production, on N'A PAS cette info au moment de la prÃ©diction !
```

#### Autres exemples de target leakage

| Feature piÃ©gÃ©e | Target | Pourquoi c'est du leakage |
|---------------|--------|--------------------------|
| `crÃ©dit_remboursÃ©` | DÃ©faut de paiement | C'est la consÃ©quence directe de la target |
| `date_rÃ©siliation` | Churn (dÃ©sabonnement) | Si la date existe, le client a dÃ©jÃ  rÃ©siliÃ© |
| `montant_remboursement` | Fraude | Un remboursement implique une fraude dÃ©tectÃ©e |
| `score_satisfaction_post` | Churn | MesurÃ© APRÃˆS le churn, pas avant |
| `traitement_mÃ©dical` | Diagnostic maladie | On traite APRÃˆS le diagnostic |

```python
# Comment dÃ©tecter le target leakage ?
import pandas as pd

# 1. VÃ©rifier les corrÃ©lations anormalement Ã©levÃ©es avec la target
correlations = df.corrwith(df['target']).abs().sort_values(ascending=False)
print("=== CorrÃ©lations avec la target ===")
print(correlations.head(10))

# âš ï¸ Si une feature a une corrÃ©lation > 0.95 â†’ SUSPECT
suspects = correlations[correlations > 0.95].index.tolist()
if suspects:
    print(f"\nğŸ”´ ALERTE : Features suspectes de leakage : {suspects}")
    print("   â†’ VÃ©rifiez si ces features sont disponibles AU MOMENT de la prÃ©diction")
```

> ğŸ’¡ **Conseil** : "Pour chaque feature, posez-vous LA question : 'Cette information est-elle disponible au moment oÃ¹ je dois faire la prÃ©diction en production ?' Si la rÃ©ponse est non â†’ c'est du leakage. Supprimez cette feature."

### 3.2 Train-Test Contamination â€” Le Preprocessing qui Fuite

#### Le problÃ¨me

Le preprocessing (scaling, imputation, encodage) est appliquÃ© sur **tout le dataset** avant le split train/test. Le test set "contamine" le train set.

#### Scaler avant de split = ERREUR

```
âŒ MAUVAIS (leakage) :

  Dataset complet (100%)
       â†“
  StandardScaler.fit_transform()     â† La moyenne et l'Ã©cart-type
       â†“                                sont calculÃ©s sur TOUT le dataset
  train_test_split()                    y compris le test set
       â†“
  ModÃ¨le.fit(X_train)
       â†“
  ModÃ¨le.predict(X_test)    â† Le test a Ã©tÃ© normalisÃ© avec ses propres stats !
                                Le modÃ¨le a "vu" indirectement le test set.
```

```
âœ… BON (pas de leakage) :

  Dataset complet (100%)
       â†“
  train_test_split()                 â† Split D'ABORD
       â†“                    â†“
  X_train                X_test
       â†“
  StandardScaler.fit_transform()     â† Moyenne et Ã©cart-type
       â†“                                calculÃ©s sur le TRAIN seulement
  X_train_scaled
                         â†“
  StandardScaler.transform()         â† Transform avec les stats du TRAIN
       â†“
  X_test_scaled
```

#### DÃ©monstration en code

```python
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

np.random.seed(42)
X = np.random.randn(1000, 10)
y = (X[:, 0] + X[:, 1] > 0).astype(int)

# âŒ MAUVAIS : scaler AVANT split
scaler_mauvais = StandardScaler()
X_scaled_mauvais = scaler_mauvais.fit_transform(X)  # Leakage !
X_train_m, X_test_m, y_train, y_test = train_test_split(
    X_scaled_mauvais, y, test_size=0.2, random_state=42
)
model_m = LogisticRegression()
model_m.fit(X_train_m, y_train)
score_mauvais = accuracy_score(y_test, model_m.predict(X_test_m))

# âœ… BON : split AVANT scaler
X_train_b, X_test_b, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
scaler_bon = StandardScaler()
X_train_b_scaled = scaler_bon.fit_transform(X_train_b)
X_test_b_scaled = scaler_bon.transform(X_test_b)
model_b = LogisticRegression()
model_b.fit(X_train_b_scaled, y_train)
score_bon = accuracy_score(y_test, model_b.predict(X_test_b_scaled))

print(f"Score AVEC leakage    : {score_mauvais:.4f}")
print(f"Score SANS leakage    : {score_bon:.4f}")
print(f"DiffÃ©rence : {abs(score_mauvais - score_bon):.4f}")
print("\nâš ï¸ La diffÃ©rence semble faible ici, mais sur des donnÃ©es rÃ©elles")
print("   avec imputation + scaling + encoding, l'Ã©cart peut Ãªtre Ã‰NORME.")
```

#### fit_transform sur tout le dataset = ERREUR

```python
# âŒ MAUVAIS : imputation sur tout le dataset
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)  # â† La moyenne inclut le test set !
X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2)

# âœ… BON : imputation aprÃ¨s le split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
imputer = SimpleImputer(strategy='mean')
X_train_imputed = imputer.fit_transform(X_train)  # Moyenne du TRAIN
X_test_imputed = imputer.transform(X_test)          # Appliquer la moyenne du TRAIN
```

> âš ï¸ **Attention** : "Cette erreur est la plus frÃ©quente chez les dÃ©butants (et mÃªme chez certains expÃ©rimentÃ©s). Chaque Ã©tape de preprocessing qui utilise des statistiques (moyenne, Ã©cart-type, min, max, frÃ©quences) doit Ãªtre fit sur le train set UNIQUEMENT."

### 3.3 Temporal Leakage â€” Utiliser des DonnÃ©es du Futur

#### Le principe

Quand les donnÃ©es ont une dimension temporelle, utiliser des informations du **futur** pour prÃ©dire le **passÃ©** est du leakage.

```
Timeline :

  PassÃ© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Futur
  â”‚                                    â”‚
  Jan  FÃ©v  Mar  Avr  Mai  Jun  Jul  AoÃ»
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â”‚         Train         â”‚    Test     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
                                        â”‚
  âš ï¸ Si une feature utilise des donnÃ©es de Juil-AoÃ»
     pour prÃ©dire Mar-Avr â†’ LEAKAGE TEMPOREL !
```

#### Exemples

```python
# âŒ MAUVAIS : split alÃ©atoire sur des donnÃ©es temporelles
X_train, X_test = train_test_split(df, test_size=0.2, random_state=42)
# â†’ Des donnÃ©es de Janvier peuvent Ãªtre dans le test set
#   et des donnÃ©es de DÃ©cembre dans le train set
#   â†’ Le modÃ¨le utilise le futur pour prÃ©dire le passÃ©

# âœ… BON : split temporel (respecter la chronologie)
df = df.sort_values('date')
split_date = '2024-06-01'
X_train = df[df['date'] < split_date]
X_test = df[df['date'] >= split_date]

# Ou avec un pourcentage
split_index = int(len(df) * 0.8)
X_train = df.iloc[:split_index]
X_test = df.iloc[split_index:]
```

```python
# âŒ MAUVAIS : moyenne glissante qui inclut le futur
df['moyenne_7j'] = df['ventes'].rolling(window=7, center=True).mean()
# center=True â†’ utilise 3 jours avant ET 3 jours APRÃˆS

# âœ… BON : moyenne glissante qui n'utilise que le passÃ©
df['moyenne_7j'] = df['ventes'].rolling(window=7, min_periods=1).mean()
# Par dÃ©faut, rolling utilise les 7 jours PRÃ‰CÃ‰DENTS
```

> ğŸ’¡ **Conseil** : "Pour les donnÃ©es temporelles, utilisez TOUJOURS un split temporel (pas alÃ©atoire). Et pour les lag features / rolling averages, vÃ©rifiez bien que vous n'utilisez que des donnÃ©es du passÃ©."

---

## 4. ğŸ•µï¸ Cas Concrets de Leakage â€” 5 ScÃ©narios PiÃ©gÃ©s

### ScÃ©nario 1 : La Feature qui "Triche"

```python
# === SCÃ‰NARIO 1 : Feature qui contient la rÃ©ponse ===

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Dataset de prÃ©diction de churn
np.random.seed(42)
n = 1000
df = pd.DataFrame({
    'age': np.random.randint(18, 70, n),
    'anciennete_mois': np.random.randint(1, 120, n),
    'nb_appels_support': np.random.randint(0, 20, n),
    'montant_mensuel': np.random.normal(50, 20, n),
    'date_resiliation': [None] * 700 + [f'2024-{np.random.randint(1,13):02d}-01' for _ in range(300)],
    'churn': [0] * 700 + [1] * 300
})

# La feature "date_resiliation" EST la rÃ©ponse dÃ©guisÃ©e
# Si date_resiliation est remplie â†’ le client a rÃ©siliÃ© â†’ churn = 1

# CrÃ©er une feature Ã  partir de date_resiliation
df['a_date_resiliation'] = df['date_resiliation'].notna().astype(int)

# EntraÃ®ner avec la feature piÃ©gÃ©e
X = df[['age', 'anciennete_mois', 'nb_appels_support', 'montant_mensuel', 'a_date_resiliation']]
y = df['churn']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)
score_piege = accuracy_score(y_test, model.predict(X_test))
print(f"ğŸ”´ Score AVEC feature piÃ©gÃ©e : {score_piege:.4f}")  # ~1.0

# Importance des features
importances = pd.Series(model.feature_importances_, index=X.columns)
print(f"\nImportance des features :")
print(importances.sort_values(ascending=False))
# a_date_resiliation sera largement en tÃªte â†’ SUSPECT !

# EntraÃ®ner SANS la feature piÃ©gÃ©e
X_propre = df[['age', 'anciennete_mois', 'nb_appels_support', 'montant_mensuel']]
X_train, X_test, y_train, y_test = train_test_split(X_propre, y, test_size=0.2, random_state=42)
model.fit(X_train, y_train)
score_propre = accuracy_score(y_test, model.predict(X_test))
print(f"\nâœ… Score SANS feature piÃ©gÃ©e : {score_propre:.4f}")
```

### ScÃ©nario 2 : Preprocessing Avant Split

```python
# === SCÃ‰NARIO 2 : Preprocessing avant split ===

from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression

# Dataset avec des valeurs manquantes
np.random.seed(42)
X = np.random.randn(500, 5)
y = (X[:, 0] + X[:, 1] > 0).astype(int)

# Introduire des manquantes
mask = np.random.random(X.shape) < 0.1
X[mask] = np.nan

# âŒ MAUVAIS : imputer + scaler avant split
imputer = SimpleImputer(strategy='mean')
scaler = StandardScaler()

X_bad = imputer.fit_transform(X)    # Moyenne calculÃ©e sur TOUT (leakage)
X_bad = scaler.fit_transform(X_bad)  # Stats calculÃ©es sur TOUT (leakage)

X_train_bad, X_test_bad, y_train, y_test = train_test_split(
    X_bad, y, test_size=0.2, random_state=42
)

model = LogisticRegression()
model.fit(X_train_bad, y_train)
score_bad = model.score(X_test_bad, y_test)
print(f"âŒ Score AVEC leakage (preprocessing avant split) : {score_bad:.4f}")

# âœ… BON : split d'abord, puis preprocessing
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

imputer = SimpleImputer(strategy='mean')
scaler = StandardScaler()

X_train_good = imputer.fit_transform(X_train)
X_test_good = imputer.transform(X_test)

X_train_good = scaler.fit_transform(X_train_good)
X_test_good = scaler.transform(X_test_good)

model = LogisticRegression()
model.fit(X_train_good, y_train)
score_good = model.score(X_test_good, y_test)
print(f"âœ… Score SANS leakage (split avant preprocessing) : {score_good:.4f}")
```

### ScÃ©nario 3 : Information du Futur

```python
# === SCÃ‰NARIO 3 : Utiliser des donnÃ©es du futur ===

# Dataset de ventes quotidiennes
dates = pd.date_range('2023-01-01', '2024-12-31', freq='D')
np.random.seed(42)
df_ventes = pd.DataFrame({
    'date': dates,
    'ventes': np.random.poisson(100, len(dates)) + np.arange(len(dates)) * 0.1,
    'temperature': np.random.normal(15, 10, len(dates))
})

# âŒ MAUVAIS : utiliser la moyenne du mois (inclut le futur)
df_ventes['ventes_moy_mois'] = df_ventes.groupby(
    df_ventes['date'].dt.month
)['ventes'].transform('mean')
# â†’ La moyenne de janvier inclut TOUS les janviers, mÃªme ceux du futur

# âŒ MAUVAIS : rolling centrÃ© (inclut le futur)
df_ventes['rolling_centre'] = df_ventes['ventes'].rolling(
    window=7, center=True
).mean()

# âœ… BON : rolling qui ne regarde que le passÃ©
df_ventes['rolling_passe'] = df_ventes['ventes'].rolling(
    window=7, min_periods=1
).mean()

# âœ… BON : lag features (valeurs passÃ©es uniquement)
df_ventes['ventes_j-1'] = df_ventes['ventes'].shift(1)
df_ventes['ventes_j-7'] = df_ventes['ventes'].shift(7)

# âœ… BON : expanding mean (moyenne cumulative jusqu'Ã  ce point)
df_ventes['ventes_moy_cumul'] = df_ventes['ventes'].expanding().mean()

print(df_ventes.head(10))
```

### ScÃ©nario 4 : Duplication de DonnÃ©es

```python
# === SCÃ‰NARIO 4 : DonnÃ©es dupliquÃ©es entre train et test ===

# Si un mÃªme client apparaÃ®t dans le train ET le test
df_clients = pd.DataFrame({
    'client_id': [1, 1, 1, 2, 2, 3, 3, 3, 3, 4],
    'mois': [1, 2, 3, 1, 2, 1, 2, 3, 4, 1],
    'montant': [100, 120, 130, 200, 220, 50, 55, 60, 65, 300],
    'churn': [0, 0, 1, 0, 1, 0, 0, 0, 1, 0]
})

# âŒ MAUVAIS : split alÃ©atoire par ligne
# Le client 1 peut avoir des lignes dans le train ET le test
# â†’ Le modÃ¨le reconnaÃ®t le client, pas le pattern

# âœ… BON : split par client (GroupShuffleSplit)
from sklearn.model_selection import GroupShuffleSplit

gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
train_idx, test_idx = next(gss.split(df_clients, groups=df_clients['client_id']))

train = df_clients.iloc[train_idx]
test = df_clients.iloc[test_idx]

print("Clients dans le train :", train['client_id'].unique())
print("Clients dans le test :", test['client_id'].unique())
# VÃ©rifier qu'aucun client n'est dans les deux
assert len(set(train['client_id']) & set(test['client_id'])) == 0
print("âœ… Aucun client en commun entre train et test")
```

### ScÃ©nario 5 : AgrÃ©gation sur Tout le Dataset

```python
# === SCÃ‰NARIO 5 : AgrÃ©gation globale avant split ===

# âŒ MAUVAIS : calculer des features agrÃ©gÃ©es sur TOUT le dataset
df['revenu_moyen_ville'] = df.groupby('ville')['revenu'].transform('mean')
# â†’ La moyenne de Paris inclut des clients du test set !

# âœ… BON : calculer les agrÃ©gations APRÃˆS le split, sur le train uniquement
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Calculer les moyennes sur le TRAIN
moyennes_ville = X_train.groupby('ville')['revenu'].mean().to_dict()
global_mean = X_train['revenu'].mean()

# Appliquer sur train ET test
X_train['revenu_moyen_ville'] = X_train['ville'].map(moyennes_ville)
X_test['revenu_moyen_ville'] = X_test['ville'].map(moyennes_ville)

# GÃ©rer les villes inconnues dans le test
X_test['revenu_moyen_ville'].fillna(global_mean, inplace=True)
```

---

## 5. ğŸ” Comment DÃ©tecter le Leakage

### 5.1 Les signaux d'alerte

```
ğŸš¨ SIGNAUX D'ALERTE DE DATA LEAKAGE :

  1. Accuracy anormalement Ã©levÃ©e (> 98%)
     â†’ Trop beau pour Ãªtre vrai = probablement du leakage

  2. Ã‰cart Ã©norme entre train et test
     â†’ Train: 99.5%, Test: 99.2% â†’ suspect (pas d'overfitting normal)

  3. Une feature domine toutes les autres
     â†’ Feature importance : 1 feature > 80% â†’ vÃ©rifier cette feature

  4. Le modÃ¨le simple bat le modÃ¨le complexe de loin
     â†’ Logistic Regression: 99% vs Random Forest: 98.5% â†’ suspect

  5. Les performances s'effondrent en production
     â†’ Le signe le plus clair (mais le plus tardif)
```

### 5.2 Checklist de dÃ©tection

```python
# === CHECKLIST DE DÃ‰TECTION DU LEAKAGE ===

def verifier_leakage(df, target_col, date_col=None):
    """
    VÃ©rifie les signes courants de data leakage.
    """
    print("=" * 60)
    print("ğŸ” VÃ‰RIFICATION DE DATA LEAKAGE")
    print("=" * 60)

    # 1. CorrÃ©lations suspectes avec la target
    print("\n1. CorrÃ©lations avec la target :")
    colonnes_num = df.select_dtypes(include=['number']).columns.drop(target_col, errors='ignore')
    if len(colonnes_num) > 0:
        corr = df[colonnes_num].corrwith(df[target_col]).abs().sort_values(ascending=False)
        for feat, val in corr.items():
            if val > 0.95:
                print(f"   ğŸ”´ ALERTE : {feat} â€” corrÃ©lation = {val:.4f} (> 0.95)")
            elif val > 0.85:
                print(f"   ğŸŸ  SUSPECT : {feat} â€” corrÃ©lation = {val:.4f} (> 0.85)")
        print(f"   Top 5 corrÃ©lations :")
        print(f"   {corr.head().to_dict()}")

    # 2. Colonnes qui ressemblent Ã  la target
    print("\n2. Colonnes similaires Ã  la target :")
    for col in df.columns:
        if col == target_col:
            continue
        if df[col].nunique() == df[target_col].nunique():
            overlap = (df[col] == df[target_col]).mean()
            if overlap > 0.9:
                print(f"   ğŸ”´ ALERTE : {col} â€” identique Ã  {target_col} Ã  {overlap:.1%}")

    # 3. Features disponibles uniquement aprÃ¨s la target
    if date_col:
        print(f"\n3. VÃ©rification temporelle (colonne date : {date_col}) :")
        print("   â†’ VÃ©rifiez manuellement que les features sont disponibles AVANT la target")

    # 4. Doublons potentiels
    print(f"\n4. Lignes dupliquÃ©es : {df.duplicated().sum()}")
    if 'client_id' in df.columns:
        n_total = len(df)
        n_unique = df['client_id'].nunique()
        if n_unique < n_total:
            print(f"   âš ï¸ {n_total - n_unique} lignes avec client_id en double "
                  f"â†’ risque de leakage si split par ligne")

    print("\n" + "=" * 60)

# Utilisation
verifier_leakage(df, target_col='churn', date_col='date_inscription')
```

### 5.3 VÃ©rifier l'importance des features

```python
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt

# EntraÃ®ner un modÃ¨le rapide
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Importance des features
importances = pd.Series(rf.feature_importances_, index=X_train.columns)
importances = importances.sort_values(ascending=True)

plt.figure(figsize=(10, 8))
importances.plot(kind='barh')
plt.title("Importance des features â€” VÃ©rification de leakage")
plt.xlabel("Importance")

# Seuil d'alerte
seuil_alerte = 0.5
for feat, imp in importances.items():
    if imp > seuil_alerte:
        plt.annotate(f'ğŸ”´ SUSPECT', xy=(imp, feat), fontsize=10, color='red')

plt.tight_layout()
plt.show()

# Rapport
print("\n=== Analyse des importances ===")
for feat, imp in importances.sort_values(ascending=False).items():
    if imp > 0.5:
        print(f"  ğŸ”´ {feat}: {imp:.4f} â€” TRÃˆS SUSPECT (> 50%)")
    elif imp > 0.3:
        print(f"  ğŸŸ  {feat}: {imp:.4f} â€” Ã€ vÃ©rifier (> 30%)")
    else:
        print(f"  âœ… {feat}: {imp:.4f}")
```

### 5.4 VÃ©rifier la timeline des donnÃ©es

```python
# Pour les donnÃ©es temporelles : vÃ©rifier que le test est APRÃˆS le train
if 'date' in df.columns:
    df['date'] = pd.to_datetime(df['date'])

    print(f"Date min (train) : {X_train['date'].min()}")
    print(f"Date max (train) : {X_train['date'].max()}")
    print(f"Date min (test)  : {X_test['date'].min()}")
    print(f"Date max (test)  : {X_test['date'].max()}")

    # VÃ©rifier le chevauchement
    overlap = X_test[X_test['date'] <= X_train['date'].max()]
    if len(overlap) > 0:
        print(f"\nğŸ”´ ALERTE : {len(overlap)} lignes du test set sont AVANT "
              f"la fin du train set â†’ leakage temporel possible")
    else:
        print(f"\nâœ… Pas de chevauchement temporel")
```

---

## 6. ğŸ›¡ï¸ Comment Ã‰viter le Leakage

### 6.1 RÃ¨gle n.1 : Toujours Split AVANT le Preprocessing

```python
from sklearn.model_selection import train_test_split

# Ã‰TAPE 1 : SÃ©parer X et y
X = df.drop('target', axis=1)
y = df['target']

# Ã‰TAPE 2 : Split AVANT tout preprocessing
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Ã‰TAPE 3 : Preprocessing sur le train UNIQUEMENT
# (voir Pipeline ci-dessous)
```

### 6.2 RÃ¨gle n.2 : Utiliser les Pipelines scikit-learn

Les pipelines **garantissent** qu'il n'y a pas de leakage. Le `fit` est automatiquement appelÃ© uniquement sur les donnÃ©es d'entraÃ®nement.

```python
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier

# Colonnes par type
colonnes_num = ['age', 'revenu', 'anciennete_mois', 'nb_achats']
colonnes_cat = ['ville', 'canal', 'type_contrat']

# Pipeline numÃ©riques
pipe_num = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

# Pipeline catÃ©gorielles
pipe_cat = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False))
])

# ColumnTransformer
preprocessor = ColumnTransformer([
    ('num', pipe_num, colonnes_num),
    ('cat', pipe_cat, colonnes_cat)
])

# Pipeline complet
pipeline = Pipeline([
    ('preprocessing', preprocessor),
    ('model', RandomForestClassifier(n_estimators=200, random_state=42))
])

# Utilisation : UNE ligne pour tout
pipeline.fit(X_train, y_train)
score = pipeline.score(X_test, y_test)
print(f"Score (sans leakage, garanti par le pipeline) : {score:.4f}")
```

### 6.3 RÃ¨gle n.3 : Validation Temporelle pour les Time Series

```python
from sklearn.model_selection import TimeSeriesSplit

# TimeSeriesSplit respecte la chronologie
tscv = TimeSeriesSplit(n_splits=5)

scores = []
for i, (train_idx, test_idx) in enumerate(tscv.split(X)):
    X_train_fold = X.iloc[train_idx]
    X_test_fold = X.iloc[test_idx]
    y_train_fold = y.iloc[train_idx]
    y_test_fold = y.iloc[test_idx]

    pipeline.fit(X_train_fold, y_train_fold)
    score = pipeline.score(X_test_fold, y_test_fold)
    scores.append(score)

    print(f"Fold {i+1}: train [{train_idx[0]}-{train_idx[-1]}] "
          f"â†’ test [{test_idx[0]}-{test_idx[-1]}] "
          f"â†’ score = {score:.4f}")

print(f"\nScore moyen : {np.mean(scores):.4f} (+/- {np.std(scores):.4f})")
```

```
Visualisation du TimeSeriesSplit :

Fold 1:  [TRAIN]           [TEST]
Fold 2:  [TRAINâ”€â”€â”€â”€â”€â”€]     [TEST]
Fold 3:  [TRAINâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€][TEST]
Fold 4:  [TRAINâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€][TEST]
Fold 5:  [TRAINâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€][TEST]

â†’ Le train grandit Ã  chaque fold
â†’ Le test est TOUJOURS aprÃ¨s le train
â†’ Pas de leakage temporel !
```

### 6.4 RÃ©capitulatif des bonnes pratiques

| RÃ¨gle | Mauvaise pratique | Bonne pratique |
|-------|------------------|----------------|
| **Split** | Preprocessing puis split | **Split puis preprocessing** |
| **Scaling** | `fit_transform` sur tout | `fit` sur train, `transform` sur test |
| **Imputation** | Moyenne de tout le dataset | Moyenne du **train set** |
| **Encoding** | Target encoding global | Target encoding avec **CV** |
| **Time series** | Split alÃ©atoire | Split **temporel** |
| **Doublons** | Split par ligne | Split par **groupe** (client) |
| **Features** | Toutes les colonnes | VÃ©rifier la **disponibilitÃ© en production** |
| **AgrÃ©gations** | Sur tout le dataset | Sur le **train set** uniquement |

---

## 7. ğŸ‹ï¸ TP : Chasse au Leakage â€” Dataset PiÃ©gÃ© avec 5 Erreurs

### 7.1 Contexte

Vous recevez un notebook d'un collÃ¨gue qui a construit un modÃ¨le de prÃ©diction de churn. Son modÃ¨le affiche 98.7% de prÃ©cision. Votre mission : **trouver les 5 erreurs de leakage**.

### 7.2 Le code piÃ©gÃ© (trouvez les 5 erreurs)

```python
# === CODE PIÃ‰GÃ‰ â€” TROUVEZ LES 5 ERREURS ===

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Charger les donnÃ©es
df = pd.read_csv("clients_churn.csv")

# --- Erreur 1 : ??? ---
# CrÃ©er une feature Ã  partir de la date de rÃ©siliation
df['a_resilie'] = df['date_resiliation'].notna().astype(int)

# --- Erreur 2 : ??? ---
# Calculer le revenu moyen par ville (sur tout le dataset)
df['revenu_moyen_ville'] = df.groupby('ville')['revenu'].transform('mean')

# --- Erreur 3 : ??? ---
# Imputer les valeurs manquantes (avant le split)
imputer = SimpleImputer(strategy='mean')
df[['age', 'revenu', 'anciennete']] = imputer.fit_transform(
    df[['age', 'revenu', 'anciennete']]
)

# --- Erreur 4 : ??? ---
# Standardiser (avant le split)
scaler = StandardScaler()
df[['age', 'revenu', 'anciennete']] = scaler.fit_transform(
    df[['age', 'revenu', 'anciennete']]
)

# SÃ©parer features et target
X = df.drop('churn', axis=1)
y = df['churn']

# Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# --- Erreur 5 : ??? ---
# Le dataset contient plusieurs lignes par client
# et le split est fait par ligne, pas par client

# EntraÃ®ner
model = RandomForestClassifier(n_estimators=200, random_state=42)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print(f"Accuracy : {accuracy_score(y_test, y_pred):.4f}")  # 98.7% !
```

### 7.3 Les 5 erreurs expliquÃ©es

```python
# === CORRECTIONS ===

# Erreur 1 : TARGET LEAKAGE
# 'a_resilie' est directement liÃ©e Ã  'churn' (si rÃ©siliation â†’ churn)
# â†’ SOLUTION : supprimer cette feature et 'date_resiliation'
df = df.drop(columns=['date_resiliation'])

# Erreur 2 : AGRÃ‰GATION SUR TOUT LE DATASET
# La moyenne par ville inclut les donnÃ©es du test set
# â†’ SOLUTION : calculer APRÃˆS le split, sur le train uniquement

# Erreur 3 : IMPUTATION AVANT LE SPLIT
# La moyenne d'imputation utilise le test set
# â†’ SOLUTION : split d'abord, imputer ensuite (fit sur train)

# Erreur 4 : STANDARDISATION AVANT LE SPLIT
# La moyenne et l'Ã©cart-type incluent le test set
# â†’ SOLUTION : split d'abord, scaler ensuite (fit sur train)

# Erreur 5 : SPLIT PAR LIGNE (PAS PAR CLIENT)
# Le mÃªme client peut Ãªtre dans le train ET le test
# â†’ SOLUTION : GroupShuffleSplit ou split par client_id
```

### 7.4 Le code corrigÃ©

```python
# === CODE CORRIGÃ‰ â€” SANS LEAKAGE ===

import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GroupShuffleSplit
from sklearn.metrics import accuracy_score

# Charger les donnÃ©es
df = pd.read_csv("clients_churn.csv")

# âœ… Correction 1 : supprimer les features qui "trichent"
df = df.drop(columns=['date_resiliation'], errors='ignore')

# âœ… Corrections 2-4 : utiliser un Pipeline (pas de preprocessing avant split)
X = df.drop(columns=['churn', 'client_id'])
y = df['churn']
groups = df['client_id']

# âœ… Correction 5 : split par client
gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
train_idx, test_idx = next(gss.split(X, y, groups=groups))

X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

# Identifier les types de colonnes
colonnes_num = X.select_dtypes(include=['number']).columns.tolist()
colonnes_cat = X.select_dtypes(include=['object', 'category']).columns.tolist()

# âœ… Pipeline robuste (tout le preprocessing est DANS le pipeline)
preprocessor = ColumnTransformer([
    ('num', Pipeline([
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ]), colonnes_num),
    ('cat', Pipeline([
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False))
    ]), colonnes_cat)
])

pipeline = Pipeline([
    ('preprocessing', preprocessor),
    ('model', RandomForestClassifier(n_estimators=200, random_state=42))
])

# EntraÃ®ner et Ã©valuer
pipeline.fit(X_train, y_train)
y_pred = pipeline.predict(X_test)

score = accuracy_score(y_test, y_pred)
print(f"âœ… Accuracy (sans leakage) : {score:.4f}")
# Score rÃ©aliste : probablement autour de 70-80%, pas 98.7%
```

---

## 8. ğŸ“¦ Livrable : Pipeline Scikit-Learn Robuste

### 8.1 Template de Pipeline Anti-Leakage

```python
"""
Template de Pipeline ML Robuste â€” Anti-Leakage
================================================
Ce template garantit l'absence de data leakage grÃ¢ce Ã  :
- Split AVANT tout preprocessing
- Tout le preprocessing dans le Pipeline
- ColumnTransformer pour traitement diffÃ©renciÃ©
- Sauvegarde du pipeline complet
"""

import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import classification_report
import joblib

# ============================================
# 1. CHARGEMENT ET NETTOYAGE INITIAL
# ============================================
df = pd.read_csv("votre_dataset.csv")

# Supprimer les colonnes identifiant et les features suspectes de leakage
colonnes_a_supprimer = ['id', 'client_id', 'date_resiliation']  # Ã€ adapter
df = df.drop(columns=colonnes_a_supprimer, errors='ignore')

# ============================================
# 2. SPLIT AVANT TOUT PREPROCESSING
# ============================================
X = df.drop('target', axis=1)
y = df['target']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Train : {len(X_train)} Ã©chantillons")
print(f"Test  : {len(X_test)} Ã©chantillons")

# ============================================
# 3. IDENTIFIER LES TYPES DE COLONNES
# ============================================
colonnes_num = X.select_dtypes(include=['number']).columns.tolist()
colonnes_cat = X.select_dtypes(include=['object', 'category']).columns.tolist()

print(f"NumÃ©riques    : {colonnes_num}")
print(f"CatÃ©gorielles : {colonnes_cat}")

# ============================================
# 4. CONSTRUIRE LE PIPELINE
# ============================================
pipe_num = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

pipe_cat = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False))
])

preprocessor = ColumnTransformer([
    ('num', pipe_num, colonnes_num),
    ('cat', pipe_cat, colonnes_cat)
], remainder='drop')

pipeline = Pipeline([
    ('preprocessing', preprocessor),
    ('model', RandomForestClassifier(n_estimators=200, random_state=42))
])

# ============================================
# 5. ENTRAÃNER ET Ã‰VALUER
# ============================================

# Cross-validation
scores_cv = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='roc_auc', n_jobs=-1)
print(f"\nAUC-ROC (5-Fold CV) : {scores_cv.mean():.4f} (+/- {scores_cv.std():.4f})")

# EntraÃ®ner le modÃ¨le final
pipeline.fit(X_train, y_train)

# Ã‰valuer sur le test set (UNE SEULE FOIS)
y_pred = pipeline.predict(X_test)
print(f"\n=== Rapport sur le test set ===")
print(classification_report(y_test, y_pred))

# ============================================
# 6. SAUVEGARDER LE PIPELINE COMPLET
# ============================================
joblib.dump(pipeline, 'pipeline_robuste_v1.joblib')
print("\nâœ… Pipeline sauvegardÃ© : pipeline_robuste_v1.joblib")

# ============================================
# 7. UTILISER EN PRODUCTION
# ============================================
pipeline_prod = joblib.load('pipeline_robuste_v1.joblib')

# PrÃ©diction sur des donnÃ©es brutes
nouvelles_donnees = pd.DataFrame({...})  # donnÃ©es brutes
predictions = pipeline_prod.predict(nouvelles_donnees)
probas = pipeline_prod.predict_proba(nouvelles_donnees)[:, 1]
```

> ğŸ’¡ **Conseil** : "Ce template est votre point de dÃ©part pour TOUT projet ML. Copiez-le, adaptez les colonnes et le modÃ¨le, mais ne changez JAMAIS la structure : split â†’ pipeline â†’ Ã©valuation. C'est votre assurance anti-leakage."

---

## ğŸ¯ Points clÃ©s Ã  retenir

1. **Le data leakage est le piÃ¨ge n.1 du ML** â€” il donne des rÃ©sultats artificiellement bons en dÃ©veloppement qui s'effondrent en production
2. **Target leakage** : une feature contient directement ou indirectement la rÃ©ponse â€” posez-vous toujours la question "cette info est-elle disponible au moment de la prÃ©diction ?"
3. **Train-test contamination** : le preprocessing (scaling, imputation) est appliquÃ© avant le split â€” le test set "contamine" le train set via les statistiques calculÃ©es
4. **Temporal leakage** : utiliser des donnÃ©es du futur pour prÃ©dire le passÃ© â€” toujours faire un split temporel pour les donnÃ©es time series
5. **Signaux d'alerte** : accuracy > 98%, une feature qui domine Ã  > 50% d'importance, performances qui s'effondrent en production
6. **RÃ¨gle d'or : split AVANT tout preprocessing** â€” c'est la rÃ¨gle la plus importante de tout le ML
7. **Les Pipelines sklearn sont la solution** â€” ils garantissent que le fit se fait uniquement sur le train set
8. **TimeSeriesSplit pour les donnÃ©es temporelles** â€” le train est toujours avant le test, pas de mÃ©lange chronologique
9. **GroupShuffleSplit si donnÃ©es multi-lignes par entitÃ©** â€” un mÃªme client ne doit pas Ãªtre dans le train ET le test
10. **Sauvegarder le pipeline complet** â€” en production, les donnÃ©es brutes entrent, les prÃ©dictions sortent, pas de preprocessing manuel

---

## âœ… Checklist de validation

- [ ] Je sais expliquer ce qu'est le data leakage avec l'analogie de l'examen
- [ ] Je sais identifier un target leakage (feature qui contient la rÃ©ponse)
- [ ] Je comprends pourquoi scaler/imputer avant le split est du leakage
- [ ] Je connais le problÃ¨me du leakage temporel et sais utiliser TimeSeriesSplit
- [ ] Je sais dÃ©tecter le leakage (corrÃ©lations suspectes, feature importance, accuracy trop Ã©levÃ©e)
- [ ] J'applique la rÃ¨gle : split AVANT tout preprocessing
- [ ] Je sais construire un Pipeline avec ColumnTransformer anti-leakage
- [ ] Je sais utiliser GroupShuffleSplit pour les donnÃ©es multi-lignes par entitÃ©
- [ ] J'ai corrigÃ© les 5 erreurs du TP "Chasse au leakage"
- [ ] Je sais sauvegarder et utiliser un pipeline complet en production

---

**PrÃ©cÃ©dent** : [Chapitre 7 : Feature Engineering](07-feature-engineering.md)

**Suivant** : [Chapitre 9 : Feature Engineering AvancÃ©](09-feature-engineering.md)
