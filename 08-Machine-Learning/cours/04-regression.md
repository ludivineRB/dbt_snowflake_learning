# Chapitre 4 : RÃ©gression â€“ PrÃ©dire des Valeurs Continues

## ğŸ¯ Objectifs

- Comprendre et implÃ©menter la rÃ©gression linÃ©aire simple et multiple
- MaÃ®triser en profondeur les mÃ©triques de rÃ©gression (MSE, RMSE, MAE, RÂ², MAPE)
- Appliquer la rÃ©gularisation (Ridge, Lasso, ElasticNet) pour Ã©viter l'overfitting
- Comprendre le Gradient Descent et la rÃ©gression polynomiale
- Savoir diagnostiquer et amÃ©liorer un modÃ¨le de rÃ©gression

---

## 1. ğŸ“ˆ La rÃ©gression linÃ©aire simple

### 1.1 Concept

La rÃ©gression linÃ©aire simple modÃ©lise la relation entre **une feature** (x) et **une target** (y) par une droite :

```
y = a * x + b

OÃ¹ :
- a = pente (coefficient directeur) â†’ l'effet de x sur y
- b = ordonnÃ©e Ã  l'origine (intercept) â†’ la valeur de y quand x = 0
```

L'algorithme cherche les valeurs de `a` et `b` qui **minimisent** la somme des erreurs au carrÃ© entre les prÃ©dictions et les valeurs rÃ©elles. C'est la mÃ©thode des **moindres carrÃ©s ordinaires** (OLS â€“ Ordinary Least Squares).

### 1.2 ImplÃ©mentation avec scikit-learn

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# --- GÃ©nÃ©rer des donnÃ©es ---
np.random.seed(42)
surface = np.random.uniform(20, 150, 200)  # Surface en mÂ²
prix = 3000 * surface + 50000 + np.random.normal(0, 30000, 200)  # Prix en â‚¬

# CrÃ©er un DataFrame
df = pd.DataFrame({'surface': surface, 'prix': prix})

# --- PrÃ©parer les donnÃ©es ---
X = df[['surface']]  # Features (2D obligatoire pour sklearn)
y = df['prix']       # Target

# Split train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- EntraÃ®ner le modÃ¨le ---
modele = LinearRegression()
modele.fit(X_train, y_train)

# Coefficients appris
print(f"Coefficient (pente) : {modele.coef_[0]:.2f} â‚¬/mÂ²")
print(f"Intercept : {modele.intercept_:.2f} â‚¬")
# â†’ "Pour chaque mÂ² supplÃ©mentaire, le prix augmente de ~3000â‚¬"

# --- PrÃ©dire ---
y_pred = modele.predict(X_test)

# --- Visualiser ---
plt.figure(figsize=(10, 6))
plt.scatter(X_test, y_test, alpha=0.6, label='DonnÃ©es rÃ©elles')
plt.plot(X_test.sort_values('surface'),
         modele.predict(X_test.sort_values('surface')),
         color='red', linewidth=2, label='RÃ©gression linÃ©aire')
plt.xlabel('Surface (mÂ²)')
plt.ylabel('Prix (â‚¬)')
plt.title('RÃ©gression linÃ©aire : Prix vs Surface')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()
```

> ğŸ’¡ **Conseil** : "La rÃ©gression linÃ©aire est le modÃ¨le le plus simple et le plus interprÃ©table. Commencez **toujours** par une rÃ©gression linÃ©aire comme baseline avant d'essayer des modÃ¨les plus complexes."

---

## 2. ğŸ“Š La rÃ©gression linÃ©aire multiple

### 2.1 Concept

La rÃ©gression multiple utilise **plusieurs features** pour prÃ©dire la target :

```
y = bâ‚€ + bâ‚*xâ‚ + bâ‚‚*xâ‚‚ + bâ‚ƒ*xâ‚ƒ + ... + bâ‚™*xâ‚™

OÃ¹ :
- bâ‚€ = intercept
- bâ‚, bâ‚‚, ..., bâ‚™ = coefficients (un par feature)
- xâ‚, xâ‚‚, ..., xâ‚™ = features
```

### 2.2 ImplÃ©mentation

```python
from sklearn.datasets import fetch_california_housing
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd
import numpy as np

# --- Charger les donnÃ©es ---
housing = fetch_california_housing()
df = pd.DataFrame(housing.data, columns=housing.feature_names)
df['prix'] = housing.target  # Prix mÃ©dian en centaines de milliers de $

print("=== Features disponibles ===")
print(df.columns.tolist())
print(f"\nShape : {df.shape}")
print(f"\nDescription :\n{df.describe()}")

# --- PrÃ©parer ---
X = df.drop('prix', axis=1)
y = df['prix']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardiser (recommandÃ© pour interprÃ©ter les coefficients)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# --- EntraÃ®ner ---
modele = LinearRegression()
modele.fit(X_train_scaled, y_train)

# --- InterprÃ©ter les coefficients ---
coefs = pd.DataFrame({
    'Feature': housing.feature_names,
    'Coefficient': modele.coef_
}).sort_values('Coefficient', key=abs, ascending=False)

print("\n=== Coefficients (donnÃ©es standardisÃ©es) ===")
print(coefs)
print(f"\nIntercept : {modele.intercept_:.4f}")

# Visualiser l'importance des features
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.barh(coefs['Feature'], coefs['Coefficient'])
plt.xlabel('Coefficient (impact sur le prix)')
plt.title('Importance des features (rÃ©gression linÃ©aire)')
plt.axvline(x=0, color='black', linestyle='--')
plt.tight_layout()
plt.show()
```

> ğŸ’¡ **Conseil de pro** : "Standardisez vos features avant de comparer les coefficients. Sans standardisation, un coefficient de 1000 pour une feature en mÃ¨tres n'est pas comparable Ã  un coefficient de 0.01 pour une feature en kilomÃ¨tres."

### 2.3 HypothÃ¨ses de la rÃ©gression linÃ©aire

| HypothÃ¨se | Description | Comment vÃ©rifier |
|-----------|-------------|-----------------|
| **LinÃ©aritÃ©** | Relation linÃ©aire entre X et y | Scatter plots, rÃ©sidus vs prÃ©dictions |
| **IndÃ©pendance** | Les erreurs sont indÃ©pendantes | Durbin-Watson test |
| **HomoscÃ©dasticitÃ©** | Variance constante des erreurs | RÃ©sidus vs prÃ©dictions (pas de cÃ´ne) |
| **NormalitÃ© des rÃ©sidus** | Erreurs â‰ˆ distribution normale | QQ-Plot, test de Shapiro-Wilk |
| **Pas de multicolinÃ©aritÃ©** | Features pas trop corrÃ©lÃ©es entre elles | VIF (Variance Inflation Factor) |

> âš ï¸ **Attention** : "En pratique, ces hypothÃ¨ses sont rarement parfaitement respectÃ©es. Mais les vÃ©rifier vous aide Ã  comprendre les limites de votre modÃ¨le et Ã  choisir la bonne technique."

---

## 3. ğŸ“Š MÃ‰TRIQUES DE RÃ‰GRESSION

Les mÃ©triques sont **essentielles** pour Ã©valuer la qualitÃ© d'un modÃ¨le de rÃ©gression. Chacune a ses forces et faiblesses.

### 3.1 MSE â€“ Mean Squared Error (Erreur Quadratique Moyenne)

**Formule** : `MSE = (1/n) * Î£(yáµ¢ - Å·áµ¢)Â²`

```python
from sklearn.metrics import mean_squared_error

mse = mean_squared_error(y_test, y_pred)
print(f"MSE : {mse:.4f}")
```

| PropriÃ©tÃ© | DÃ©tail |
|-----------|--------|
| **InterprÃ©tation** | Moyenne des erreurs au carrÃ© |
| **UnitÃ©** | UnitÃ©Â² (ex: â‚¬Â² â†’ pas intuitif) |
| **Sensible aux outliers** | âš ï¸ Oui, trÃ¨s (les erreurs sont au carrÃ©) |
| **Quand l'utiliser** | Quand on veut pÃ©naliser fortement les grosses erreurs |
| **Valeur idÃ©ale** | 0 |

### 3.2 RMSE â€“ Root Mean Squared Error (Racine de l'Erreur Quadratique Moyenne)

**Formule** : `RMSE = âˆšMSE = âˆš[(1/n) * Î£(yáµ¢ - Å·áµ¢)Â²]`

```python
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
# Ou directement :
rmse = mean_squared_error(y_test, y_pred, squared=False)
print(f"RMSE : {rmse:.4f}")
```

| PropriÃ©tÃ© | DÃ©tail |
|-----------|--------|
| **InterprÃ©tation** | Erreur moyenne dans la mÃªme unitÃ© que la cible |
| **UnitÃ©** | MÃªme unitÃ© que y (ex: â‚¬ â†’ interprÃ©table !) |
| **Sensible aux outliers** | âš ï¸ Oui (hÃ©ritÃ© du MSE) |
| **Quand l'utiliser** | Quand on veut une erreur interprÃ©table dans l'unitÃ© cible |
| **Valeur idÃ©ale** | 0 |

> ğŸ’¡ **Conseil** : "Le RMSE est souvent prÃ©fÃ©rÃ© au MSE car il est dans la **mÃªme unitÃ©** que la cible. Un RMSE de 15 000â‚¬ sur des prix d'appartements est plus parlant qu'un MSE de 225 000 000â‚¬Â²."

### 3.3 MAE â€“ Mean Absolute Error (Erreur Absolue Moyenne)

**Formule** : `MAE = (1/n) * Î£|yáµ¢ - Å·áµ¢|`

```python
from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(y_test, y_pred)
print(f"MAE : {mae:.4f}")
```

| PropriÃ©tÃ© | DÃ©tail |
|-----------|--------|
| **InterprÃ©tation** | Erreur moyenne absolue |
| **UnitÃ©** | MÃªme unitÃ© que y |
| **Sensible aux outliers** | âœ… Plus robuste que RMSE (pas de carrÃ©) |
| **Quand l'utiliser** | Quand on veut une mesure robuste aux outliers |
| **Valeur idÃ©ale** | 0 |

### 3.4 RÂ² â€“ Coefficient de dÃ©termination

**Formule** : `RÂ² = 1 - (SS_res / SS_tot)` oÃ¹ `SS_res = Î£(yáµ¢ - Å·áµ¢)Â²` et `SS_tot = Î£(yáµ¢ - È³)Â²`

```python
from sklearn.metrics import r2_score

r2 = r2_score(y_test, y_pred)
print(f"RÂ² : {r2:.4f}")
# Ou directement avec le modÃ¨le :
print(f"RÂ² (score) : {modele.score(X_test, y_test):.4f}")
```

| PropriÃ©tÃ© | DÃ©tail |
|-----------|--------|
| **InterprÃ©tation** | % de variance de y expliquÃ© par le modÃ¨le |
| **Plage** | ]-âˆ, 1] (1 = parfait, 0 = prÃ©dit la moyenne, <0 = pire que la moyenne) |
| **Sans unitÃ©** | âœ… Comparable entre datasets |
| **Quand l'utiliser** | Pour une vue d'ensemble de la qualitÃ© du modÃ¨le |
| **Limite** | Peut Ãªtre trompeur si peu de variance dans y |

> âš ï¸ **Attention** : "Un RÂ² de 0.99 ne veut pas dire que le modÃ¨le est parfait. VÃ©rifiez toujours avec RMSE/MAE. Et un RÂ² qui augmente toujours quand on ajoute des features â†’ utilisez le **RÂ² ajustÃ©**."

**RÂ² ajustÃ©** : pÃ©nalise l'ajout de features non-informatives.

```python
def r2_ajuste(r2, n, p):
    """
    Calcule le RÂ² ajustÃ©
    r2 : RÂ² classique
    n  : nombre d'observations
    p  : nombre de features
    """
    return 1 - (1 - r2) * (n - 1) / (n - p - 1)

n = len(y_test)
p = X_test.shape[1]
r2_adj = r2_ajuste(r2, n, p)
print(f"RÂ² ajustÃ© : {r2_adj:.4f}")
```

### 3.5 MAPE â€“ Mean Absolute Percentage Error

**Formule** : `MAPE = (1/n) * Î£|( yáµ¢ - Å·áµ¢) / yáµ¢| * 100`

```python
from sklearn.metrics import mean_absolute_percentage_error

mape = mean_absolute_percentage_error(y_test, y_pred) * 100
print(f"MAPE : {mape:.2f}%")
```

| PropriÃ©tÃ© | DÃ©tail |
|-----------|--------|
| **InterprÃ©tation** | Erreur moyenne en pourcentage |
| **UnitÃ©** | % (trÃ¨s interprÃ©table par les mÃ©tiers) |
| **Quand l'utiliser** | Quand on veut communiquer l'erreur aux non-techniques |
| **Limite** | âš ï¸ ProblÃ¨me si y contient des valeurs proches de 0 (division par ~0) |

> ğŸ’¡ **Conseil de pro** : "Le MAPE est **idÃ©al** pour communiquer avec les Ã©quipes mÃ©tier. 'Notre modÃ¨le se trompe en moyenne de 8%' est beaucoup plus parlant que 'Le RMSE est de 12 345'."

### 3.6 Tableau comparatif complet des mÃ©triques

| MÃ©trique | Formule simplifiÃ©e | UnitÃ© | Sensible outliers | InterprÃ©table | Quand l'utiliser |
|----------|-------------------|-------|-------------------|---------------|-----------------|
| **MSE** | Moyenne(erreurÂ²) | UnitÃ©Â² | âš ï¸ TrÃ¨s | âŒ Non | Optimisation, pÃ©naliser grosses erreurs |
| **RMSE** | âˆšMSE | UnitÃ© | âš ï¸ Oui | âœ… Oui | MÃ©trique par dÃ©faut, erreur interprÃ©table |
| **MAE** | Moyenne(\|erreur\|) | UnitÃ© | âœ… Robuste | âœ… Oui | DonnÃ©es avec outliers |
| **RÂ²** | 1 - SS_res/SS_tot | Sans | ModÃ©rÃ© | âœ… Oui | Vue d'ensemble, comparaison |
| **MAPE** | Moyenne(\|erreur/y\|) | % | ModÃ©rÃ© | âœ…âœ… TrÃ¨s | Communication mÃ©tier |

> ğŸ’¡ **Conseil de pro** : "Toujours reporter **PLUSIEURS** mÃ©triques. RÂ² seul peut Ãªtre trompeur si les donnÃ©es ont peu de variance. RMSE seul ne dit rien sur la proportion d'erreur. Utilisez au minimum **RÂ² + RMSE + MAE**."

### 3.7 Exemple complet d'Ã©valuation

```python
import numpy as np
from sklearn.metrics import (mean_squared_error, mean_absolute_error,
                             r2_score, mean_absolute_percentage_error)

def evaluer_regression(y_true, y_pred, nom_modele="ModÃ¨le"):
    """Ã‰value un modÃ¨le de rÃ©gression avec toutes les mÃ©triques"""
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    mape = mean_absolute_percentage_error(y_true, y_pred) * 100

    print(f"=== Ã‰valuation : {nom_modele} ===")
    print(f"MSE  : {mse:.4f}")
    print(f"RMSE : {rmse:.4f}")
    print(f"MAE  : {mae:.4f}")
    print(f"RÂ²   : {r2:.4f}")
    print(f"MAPE : {mape:.2f}%")
    print()

    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R2': r2, 'MAPE': mape}

# Utilisation
resultats = evaluer_regression(y_test, y_pred, "RÃ©gression LinÃ©aire")
```

---

## 4. âš™ï¸ Le Gradient Descent (Descente de Gradient)

### 4.1 Intuition

Imaginez que vous Ãªtes au sommet d'une montagne, **les yeux bandÃ©s**, et vous voulez descendre au point le plus bas. Vous tÃ¢tez le sol autour de vous et faites un pas dans la direction de la plus forte descente. C'est le **Gradient Descent**.

```
  Fonction de coÃ»t (erreur)
       â”‚
  High â”‚  â—  DÃ©but (paramÃ¨tres alÃ©atoires)
       â”‚   â•²
       â”‚    â•²
       â”‚     â—  Pas 1
       â”‚      â•²
       â”‚       â—  Pas 2
       â”‚        â•²
       â”‚         â— Minimum (paramÃ¨tres optimaux)
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ParamÃ¨tre
```

### 4.2 Le Learning Rate

Le **learning rate** (taux d'apprentissage) contrÃ´le la taille des pas :

| Learning Rate | Comportement | RÃ©sultat |
|--------------|-------------|---------|
| **Trop grand** | Grands pas â†’ saute par-dessus le minimum | âŒ Diverge, ne converge jamais |
| **Trop petit** | Petits pas â†’ avance trÃ¨s lentement | âš ï¸ Converge, mais trop lent |
| **Optimal** | Pas adaptÃ©s | âœ… Converge rapidement |

> ğŸ’¡ **Conseil** : "Un bon learning rate est gÃ©nÃ©ralement entre 0.001 et 0.1. Commencez par 0.01 et ajustez."

### 4.3 Variantes du Gradient Descent

| Variante | DonnÃ©es utilisÃ©es par pas | Vitesse | StabilitÃ© |
|----------|--------------------------|---------|-----------|
| **Batch GD** | Toutes les donnÃ©es | Lent | Stable |
| **Stochastic GD (SGD)** | Un Ã©chantillon | Rapide | Bruyant |
| **Mini-batch GD** | Un sous-ensemble (32-256) | Bon compromis | Bon compromis |

```python
from sklearn.linear_model import SGDRegressor

# RÃ©gression avec Stochastic Gradient Descent
sgd_reg = SGDRegressor(
    max_iter=1000,
    learning_rate='adaptive',  # Adapte le learning rate
    eta0=0.01,                 # Learning rate initial
    random_state=42
)
sgd_reg.fit(X_train_scaled, y_train)
y_pred_sgd = sgd_reg.predict(X_test_scaled)

evaluer_regression(y_test, y_pred_sgd, "SGD Regressor")
```

---

## 5. ğŸ”„ RÃ©gression polynomiale

### 5.1 Quand la relation n'est pas linÃ©aire

Si la relation entre X et y n'est pas une droite, on peut utiliser des **features polynomiales** :

```
LinÃ©aire      : y = bâ‚€ + bâ‚*x
Polynomiale 2 : y = bâ‚€ + bâ‚*x + bâ‚‚*xÂ²
Polynomiale 3 : y = bâ‚€ + bâ‚*x + bâ‚‚*xÂ² + bâ‚ƒ*xÂ³
```

### 5.2 ImplÃ©mentation

```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
import numpy as np
import matplotlib.pyplot as plt

# GÃ©nÃ©rer des donnÃ©es non-linÃ©aires
np.random.seed(42)
X = np.sort(np.random.uniform(0, 10, 100)).reshape(-1, 1)
y = 2 * X.ravel()**2 - 5 * X.ravel() + 10 + np.random.normal(0, 10, 100)

# Comparer diffÃ©rents degrÃ©s
fig, axes = plt.subplots(1, 3, figsize=(18, 5))
degres = [1, 2, 5]

for ax, degree in zip(axes, degres):
    # Pipeline : features polynomiales + rÃ©gression linÃ©aire
    pipeline = Pipeline([
        ('poly', PolynomialFeatures(degree=degree)),
        ('regression', LinearRegression())
    ])
    pipeline.fit(X, y)

    # PrÃ©dictions
    X_plot = np.linspace(0, 10, 300).reshape(-1, 1)
    y_plot = pipeline.predict(X_plot)

    # Visualiser
    ax.scatter(X, y, alpha=0.5, label='DonnÃ©es')
    ax.plot(X_plot, y_plot, color='red', linewidth=2, label=f'DegrÃ© {degree}')
    ax.set_title(f'PolynÃ´me de degrÃ© {degree}\nRÂ² = {pipeline.score(X, y):.4f}')
    ax.legend()
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
```

> âš ï¸ **Attention** : "Un degrÃ© polynomial trop Ã©levÃ© = **overfitting garanti**. Le modÃ¨le colle parfaitement aux donnÃ©es d'entraÃ®nement mais gÃ©nÃ©ralise trÃ¨s mal. Un degrÃ© 2 ou 3 est souvent suffisant."

> ğŸ’¡ **Conseil de pro** : "Si vous avez besoin d'un degrÃ© supÃ©rieur Ã  3, c'est probablement un signe qu'il faut utiliser un modÃ¨le non-linÃ©aire (Random Forest, XGBoost) plutÃ´t que de la rÃ©gression polynomiale."

---

## 6. ğŸ›¡ï¸ RÃ©gularisation

La rÃ©gularisation ajoute une **pÃ©nalitÃ©** aux coefficients pour empÃªcher l'overfitting. Elle force le modÃ¨le Ã  rester simple.

### 6.1 Ridge (RÃ©gularisation L2)

**Principe** : pÃ©nalise la **somme des carrÃ©s** des coefficients.

**Fonction de coÃ»t** : `MSE + Î± * Î£(báµ¢Â²)`

```python
from sklearn.linear_model import Ridge

# Le paramÃ¨tre alpha contrÃ´le la force de la rÃ©gularisation
# alpha = 0 â†’ rÃ©gression linÃ©aire classique
# alpha â†‘  â†’ coefficients plus petits (plus de rÃ©gularisation)

ridge = Ridge(alpha=1.0)
ridge.fit(X_train_scaled, y_train)
y_pred_ridge = ridge.predict(X_test_scaled)

evaluer_regression(y_test, y_pred_ridge, "Ridge (alpha=1.0)")

# --- Comparer diffÃ©rentes valeurs d'alpha ---
alphas = [0.01, 0.1, 1, 10, 100]
for alpha in alphas:
    ridge = Ridge(alpha=alpha)
    ridge.fit(X_train_scaled, y_train)
    y_pred = ridge.predict(X_test_scaled)
    r2 = r2_score(y_test, y_pred)
    print(f"Alpha = {alpha:>6} â†’ RÂ² = {r2:.4f}")
```

| PropriÃ©tÃ© | DÃ©tail |
|-----------|--------|
| **Effet** | RÃ©duit les coefficients (les pousse vers 0) mais ne les met jamais exactement Ã  0 |
| **Quand l'utiliser** | Quand toutes les features sont potentiellement utiles |
| **HyperparamÃ¨tre** | `alpha` : plus il est grand, plus la rÃ©gularisation est forte |

### 6.2 Lasso (RÃ©gularisation L1)

**Principe** : pÃ©nalise la **somme des valeurs absolues** des coefficients.

**Fonction de coÃ»t** : `MSE + Î± * Î£|báµ¢|`

```python
from sklearn.linear_model import Lasso

lasso = Lasso(alpha=0.1)
lasso.fit(X_train_scaled, y_train)
y_pred_lasso = lasso.predict(X_test_scaled)

evaluer_regression(y_test, y_pred_lasso, "Lasso (alpha=0.1)")

# Lasso peut mettre des coefficients Ã  ZÃ‰RO â†’ sÃ©lection de features
print("\n=== Coefficients Lasso ===")
for name, coef in zip(housing.feature_names, lasso.coef_):
    marqueur = " â† Ã‰LIMINÃ‰" if coef == 0 else ""
    print(f"  {name:>15} : {coef:>10.4f}{marqueur}")

n_zero = sum(lasso.coef_ == 0)
print(f"\nFeatures Ã©liminÃ©es : {n_zero}/{len(lasso.coef_)}")
```

| PropriÃ©tÃ© | DÃ©tail |
|-----------|--------|
| **Effet** | Peut mettre des coefficients **exactement Ã  0** â†’ sÃ©lection automatique de features |
| **Quand l'utiliser** | Quand on suspecte que certaines features sont inutiles |
| **HyperparamÃ¨tre** | `alpha` : plus il est grand, plus de features sont Ã©liminÃ©es |

### 6.3 ElasticNet (L1 + L2)

**Principe** : combine Ridge et Lasso.

**Fonction de coÃ»t** : `MSE + Î± * (l1_ratio * Î£|báµ¢| + (1-l1_ratio) * Î£báµ¢Â²)`

```python
from sklearn.linear_model import ElasticNet

elastic = ElasticNet(alpha=0.1, l1_ratio=0.5)  # 50% L1 + 50% L2
elastic.fit(X_train_scaled, y_train)
y_pred_elastic = elastic.predict(X_test_scaled)

evaluer_regression(y_test, y_pred_elastic, "ElasticNet")
```

### 6.4 Tableau comparatif de la rÃ©gularisation

| ModÃ¨le | PÃ©nalitÃ© | SÃ©lection de features | Quand l'utiliser |
|--------|---------|----------------------|-----------------|
| **LinÃ©aire** | Aucune | Non | Baseline, peu de features |
| **Ridge (L2)** | Î£(báµ¢Â²) | Non (rÃ©duit, ne supprime pas) | Cas gÃ©nÃ©ral, toutes features utiles |
| **Lasso (L1)** | Î£\|báµ¢\| | Oui (met des coefs Ã  0) | Features inutiles suspectÃ©es |
| **ElasticNet** | L1 + L2 | Partiellement | Beaucoup de features corrÃ©lÃ©es |

> ğŸ’¡ **Conseil de pro** : "Commencez **toujours** par Ridge. Si vous suspectez que certaines features sont inutiles, passez Ã  Lasso. Si vos features sont trÃ¨s corrÃ©lÃ©es entre elles, ElasticNet est un bon compromis."

### 6.5 Trouver le meilleur alpha avec Cross-Validation

```python
from sklearn.linear_model import RidgeCV, LassoCV

# Ridge avec cross-validation automatique
ridge_cv = RidgeCV(alphas=[0.01, 0.1, 1, 10, 100], cv=5)
ridge_cv.fit(X_train_scaled, y_train)
print(f"Meilleur alpha (Ridge) : {ridge_cv.alpha_}")
print(f"RÂ² test : {ridge_cv.score(X_test_scaled, y_test):.4f}")

# Lasso avec cross-validation automatique
lasso_cv = LassoCV(alphas=[0.001, 0.01, 0.1, 1], cv=5)
lasso_cv.fit(X_train_scaled, y_train)
print(f"Meilleur alpha (Lasso) : {lasso_cv.alpha_}")
print(f"RÂ² test : {lasso_cv.score(X_test_scaled, y_test):.4f}")
```

---

## 7. ğŸ“ˆ Comment amÃ©liorer son modÃ¨le de rÃ©gression

### 7.1 Checklist d'amÃ©lioration

| Ã‰tape | Action | Comment |
|-------|--------|---------|
| 1ï¸âƒ£ | **Plus de donnÃ©es ?** | Courbes d'apprentissage |
| 2ï¸âƒ£ | **Meilleures features ?** | Feature engineering, interactions |
| 3ï¸âƒ£ | **Outliers ?** | VÃ©rifier et traiter les valeurs aberrantes |
| 4ï¸âƒ£ | **RÃ©gularisation ?** | Ridge, Lasso, ElasticNet |
| 5ï¸âƒ£ | **Non-linÃ©aritÃ© ?** | Polynomiale, ou modÃ¨le non-linÃ©aire |
| 6ï¸âƒ£ | **ModÃ¨le plus complexe ?** | Random Forest, XGBoost |

### 7.2 Courbes d'apprentissage (Learning Curves)

Les courbes d'apprentissage permettent de diagnostiquer l'**overfitting** et l'**underfitting** :

```python
from sklearn.model_selection import learning_curve
import matplotlib.pyplot as plt
import numpy as np

def tracer_courbes_apprentissage(modele, X, y, titre="Courbes d'apprentissage"):
    """Trace les courbes d'apprentissage pour diagnostiquer over/underfitting"""
    train_sizes, train_scores, val_scores = learning_curve(
        modele, X, y,
        train_sizes=np.linspace(0.1, 1.0, 10),
        cv=5,
        scoring='r2',
        n_jobs=-1
    )

    train_mean = train_scores.mean(axis=1)
    train_std = train_scores.std(axis=1)
    val_mean = val_scores.mean(axis=1)
    val_std = val_scores.std(axis=1)

    plt.figure(figsize=(10, 6))
    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')
    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color='orange')
    plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Score entraÃ®nement')
    plt.plot(train_sizes, val_mean, 'o-', color='orange', label='Score validation')
    plt.xlabel("Nombre d'Ã©chantillons d'entraÃ®nement")
    plt.ylabel('RÂ² Score')
    plt.title(titre)
    plt.legend(loc='best')
    plt.grid(True, alpha=0.3)
    plt.show()

# Utilisation
tracer_courbes_apprentissage(LinearRegression(), X_train_scaled, y_train)
```

**InterprÃ©tation** :

| Diagnostic | Train score | Val score | Ã‰cart | Action |
|-----------|------------|----------|-------|--------|
| **Underfitting** | Bas | Bas | Faible | ModÃ¨le plus complexe, plus de features |
| **Overfitting** | Haut | Bas | **Grand** | RÃ©gularisation, plus de donnÃ©es, simplifier |
| **Bon modÃ¨le** | Haut | Haut | Faible | Continuer ! |

### 7.3 Analyse des rÃ©sidus

Les **rÃ©sidus** (erreurs) = y_vrai - y_prÃ©dit. Analyser les rÃ©sidus permet de vÃ©rifier que le modÃ¨le a bien capturÃ© tous les patterns.

```python
def analyser_residus(y_true, y_pred, titre="Analyse des rÃ©sidus"):
    """Analyse complÃ¨te des rÃ©sidus d'un modÃ¨le de rÃ©gression"""
    residus = y_true - y_pred

    fig, axes = plt.subplots(1, 3, figsize=(18, 5))

    # 1. RÃ©sidus vs PrÃ©dictions
    axes[0].scatter(y_pred, residus, alpha=0.3)
    axes[0].axhline(y=0, color='red', linestyle='--')
    axes[0].set_xlabel('PrÃ©dictions')
    axes[0].set_ylabel('RÃ©sidus')
    axes[0].set_title('RÃ©sidus vs PrÃ©dictions')

    # 2. Distribution des rÃ©sidus
    axes[1].hist(residus, bins=30, edgecolor='black')
    axes[1].axvline(x=0, color='red', linestyle='--')
    axes[1].set_xlabel('RÃ©sidus')
    axes[1].set_ylabel('FrÃ©quence')
    axes[1].set_title('Distribution des rÃ©sidus')

    # 3. QQ-Plot (normalitÃ© des rÃ©sidus)
    from scipy import stats
    stats.probplot(residus, dist="norm", plot=axes[2])
    axes[2].set_title('QQ-Plot des rÃ©sidus')

    plt.suptitle(titre)
    plt.tight_layout()
    plt.show()

    # Statistiques des rÃ©sidus
    print(f"RÃ©sidus - Moyenne : {residus.mean():.4f} (devrait Ãªtre â‰ˆ 0)")
    print(f"RÃ©sidus - Ã‰cart-type : {residus.std():.4f}")
    print(f"RÃ©sidus - MÃ©diane : {np.median(residus):.4f}")

# Utilisation
analyser_residus(y_test, y_pred)
```

> ğŸ’¡ **Conseil** : "Tracez **TOUJOURS** les rÃ©sidus. Des patterns dans les rÃ©sidus (courbe, cÃ´ne, clusters) indiquent que le modÃ¨le n'a pas capturÃ© toute l'information. Un bon modÃ¨le a des rÃ©sidus **alÃ©atoires et centrÃ©s sur 0**."

### 7.4 Comparaison de plusieurs modÃ¨les

```python
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import Pipeline
import pandas as pd

# DÃ©finir les modÃ¨les Ã  comparer
modeles = {
    'LinÃ©aire': LinearRegression(),
    'Ridge (Î±=1)': Ridge(alpha=1.0),
    'Ridge (Î±=10)': Ridge(alpha=10.0),
    'Lasso (Î±=0.1)': Lasso(alpha=0.1),
    'Polynomiale (deg=2)': Pipeline([
        ('poly', PolynomialFeatures(degree=2)),
        ('reg', LinearRegression())
    ])
}

# EntraÃ®ner et Ã©valuer chaque modÃ¨le
resultats = []
for nom, modele in modeles.items():
    modele.fit(X_train_scaled, y_train)
    y_pred = modele.predict(X_test_scaled)

    resultats.append({
        'ModÃ¨le': nom,
        'RÂ²': r2_score(y_test, y_pred),
        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),
        'MAE': mean_absolute_error(y_test, y_pred)
    })

# Afficher le tableau comparatif
df_resultats = pd.DataFrame(resultats).sort_values('RÂ²', ascending=False)
print("=== Comparaison des modÃ¨les de rÃ©gression ===")
print(df_resultats.to_string(index=False))
```

> ğŸ’¡ **Conseil de pro** : "Comparez **toujours** plusieurs modÃ¨les avec les **mÃªmes mÃ©triques** et le **mÃªme split** de donnÃ©es. C'est la seule faÃ§on de faire une comparaison juste."

---

## ğŸ¯ Points clÃ©s Ã  retenir

1. **Commencez simple** : rÃ©gression linÃ©aire comme baseline
2. **MÃ©triques multiples** : toujours reporter RÂ², RMSE, MAE (au minimum)
3. **RMSE** est souvent la mÃ©trique par dÃ©faut â€” mÃªme unitÃ© que la cible
4. **MAPE** est idÃ©ale pour communiquer avec les mÃ©tiers (erreur en %)
5. **RÂ² seul peut Ãªtre trompeur** â€” toujours vÃ©rifier avec d'autres mÃ©triques
6. **RÃ©gularisation** : Ridge par dÃ©faut, Lasso pour la sÃ©lection de features
7. **Learning curves** : diagnostic overfitting/underfitting
8. **RÃ©sidus** : toujours les analyser â€” des patterns = modÃ¨le incomplet
9. **Standardiser** les features pour comparer les coefficients
10. **Ne pas oublier** : le preprocessing (chapitre 3) est souvent plus impactant que le choix du modÃ¨le

---

## âœ… Checklist de validation

- [ ] Je sais implÃ©menter une rÃ©gression linÃ©aire simple et multiple avec sklearn
- [ ] Je sais interprÃ©ter les coefficients d'une rÃ©gression
- [ ] Je connais et sais calculer MSE, RMSE, MAE, RÂ² et MAPE
- [ ] Je sais quand utiliser chaque mÃ©trique selon le contexte
- [ ] Je comprends le Gradient Descent et le rÃ´le du learning rate
- [ ] Je sais implÃ©menter une rÃ©gression polynomiale avec PolynomialFeatures
- [ ] Je comprends la rÃ©gularisation et sais choisir entre Ridge, Lasso et ElasticNet
- [ ] Je sais tracer et interprÃ©ter les courbes d'apprentissage
- [ ] Je sais analyser les rÃ©sidus d'un modÃ¨le de rÃ©gression
- [ ] Je sais comparer plusieurs modÃ¨les avec les mÃªmes mÃ©triques

---

**PrÃ©cÃ©dent** : [Chapitre 3 : Preprocessing â€“ PrÃ©parer ses DonnÃ©es](03-preprocessing.md)

**Suivant** : [Chapitre 5 : Classification â€“ PrÃ©dire des CatÃ©gories](05-classification.md)
